,normalized_name,name,display_name,version,created_at,modified_at,author,package_metadata_author_email,license,home_github,home_pypi,home_other,package_metadata_home_page,summary,package_metadata_requires_python,package_metadata_requires_dist,package_metadata_description,package_metadata_classifier,package_metadata_project_url,contributions_readers_0_command,contributions_writers_0_command,contributions_widgets_0_command,contributions_sample_data_0_command,contributions_readers_0_filename_patterns,contributions_writers_0_filename_extensions,contributions_writers_1_filename_extensions
0,annotrack,annotrack,annotrack,0.0.3,2023-12-01,2024-03-19,Abigail S McGovern,abigail_mcgovern@hotmail.com,BSD-3-Clause,https://github.com/abigailmcgovern/annotrack/issues,https://pypi.org/project/annotrack/,,https://github.com/abigailmcgovern/annotrack,napari plugin for annotating tracks to estimate error rates,>=3.7,"['dask', 'napari', 'numpy', 'zarr', 'pandas', ""sphinx ; extra == 'docs'"", ""nd2 ; extra == 'io'"", ""pytest ; extra == 'testing'""]","# annotrack
Annotrack is a napari plugin for annotating errors in object trajectories. The plugin will help you take a sample of track segments along with a small section of corresponding image and segmentation. Annotrack allows you to annotate three types of errors: (1) ID swap errors (track jumps between objects), (2) false starts (track starts on a pre-existing object) and false terminations (track ends but object still exists). By looking at the combined rates of false starts and false terminations you can assess track discontinutation errors. 

**Please note:** Images and segmentations must be in zarr format. Tracks should be in parquet format.  

## Installation 

There are three main ways to install annotrack:

### Install Using pip
*Please note that this is planned/under development*

Type the following into your terminal (MacOS or Ubuntu) or annaconda prompt (windows):

```bash
pip install annotrack
```

### Install
*Please note that this is planned/under development*

Type the following into your terminal (MacOS or Ubuntu) or annaconda prompt (windows):

```bash
install napari
napari
```

Once napari has opened (this may take a second the first time you open it), go to the pannel at the top of the screen and select the 'plugins' dropdown. Then select install/uninstall plugins. A new window will open showing available plugins. Either scroll down to or search 'annotrack' and click 'install'. 

### Install from Source Code
*please use this for now*

Type the following into your terminal (MacOS or Ubuntu) or annaconda prompt (windows):

```bash
git clone https://github.com/AbigailMcGovern/annotrack.git
cd annotrack
pip install .
```

## Opening Annotrack
Once annotrack is properly installed you will be able to open annotrack by opening napari. You can open napari through the command line (terminal (MacOS or Ubuntu) or annaconda prompt (windows)) as follows:

```bash
napari
```

You can find the annotrack widgets by selecting the dropdown 'plugins' at the pannel at the top of the screen and hovering over 'annotrack'.  

## Sample from CSV

To sample your tracks you will need to supply the file paths for the images, segmentations, and tracks. You supply this in a csv that is structured as shown below:

 ![csv_structure widget](https://github.com/AbigailMcGovern/annotrack/blob/main/media/csv_structure.png)

In this csv, you may also specify how many samples are to be taken from each file. If this is not provided, annotrack will use the value you supply to the `sample_from_csv` widget. The csv must contain a column that specifies a category to which each sample belongs (e.g., species, experimental condition, drug, etc.).  If this isnt important for your samples, just add a dummy category (e.g., sample_type : [A, A, A, A]). 

To access the widget and sample track segments, go to the top of the screen, go to **plugins > annotrack > sample_from_csv**. When the widget is displayed, select the csv file, select a directory into which to save results, and proivide a name for the summary data file (i.e., where your annotations will be written). 

 ![sample_from_csv widget](https://github.com/AbigailMcGovern/annotrack/blob/main/media/sample_from_csv.png)

### Widget parameters
- **path to csv**: 
        The path storing the info from which to generate the samples. 
        The CSV should have the columns: image_path, labels_path, tracks_path, <category_col>, 
        You can also add an optional n_samples column if you would like to 
        specify how many samples to take from each individual file. Otherwise, 
        the default ""n_samples"" you've supplied will be used.
- **output dir**: 
        Where will the output be saved?
- **output name**: 
        What will output summary files/directories be called?
- **n samples**: 
        How many samples to be obtained from each file. Will be overwritten
        if there is a valid integer number in the n_samples colum of the csv.
- **tzyx cols**: 
        What are the names of the columns denoting time (in frames) and coordinate
        positions (in pixels) in the file containing tracks? The order should be:
        t, z, y, x. 
- **id col**: 
        What is the name of the column denoting the specific ID for each tracked
        object?
- **scale**: 
        size of pixels (e.g., in um) for the z, y, and x coordinates (in that
        order)
- **frames**: 
        Approximate maximum number of frames of track segment. 
        Max frames = frames (if even) or frames - 1 (if odd)
- **box size**: 
        Approximate size of bounding box (in pixels). 
- **min track len**: 
        You can set a minimum track len to include in the search. 
        This can help to eliminate less useful data. This should be at least 1 to only include tracked objects. Set higher only if you are specifically interested in longer lived tracks. 
- **image channel**: 
        This denotes the index of the channel from which to get 
        image data (0: channel 1, 1: channel 2, 2: channel 3, 3: channel 4)

### Annotate Now?

In the case that we are annotating multiple conditions to compare, we want to show them in the one session in randomised order with the annotator blinded to where the sample has originated from. We want to be able to annotated unannotated data from the sample without having the burden of having to do this all at once. The annotations are therefore saved into the saved sample. A selected number of samples saved from the various tracking experiments can be annotated using the following code. If you re-execute this code, you will only be shown not yet annotated data, unless you request otherwise.

Keys to navagate and annotate samples
- '2' - move to next sample
- '1' - move to previous sample
- 'y' - annotate as correct (will move to the next sample automatically)
- 'n' - annotate as containing an error (will move to the next sample automatically)
- 'i' - annotate the frame following a ID swap error
- 't' - annotate the fame following an incorrect termination
- 'Shift-t' - annotate the frame containing a false start error
- 's' - annotate an error ('i', 't', or 'Shift-t') as being associated with a segmentation error (merge or split of objects)

When an error is associated the specific frame ('i', 't', 'Shift-t', or 's'), the frame number (within the original image) will be added to a list of errors for the sample within the sample's (.smpl) info data frame. E.g., you may have a list of ID swaps for your sampled track segment (`[108, 111, 112]`) and a corresponding list of segmentation error associations (`[108, 112]`). 

## Annotate Existing Sample
If you have already saved a sample and want to annotate it, you can load the sample data using the `annotate_existing_sample` widget. This might be useful if you want to have several annotators annotate the same sample. To access this widget, open napari

 ![annotate_existing_sample widget](https://github.com/AbigailMcGovern/annotrack/blob/main/media/annotate_existing_sample.png)

## Contributing and User Support

**User support:** If you have an issue with annotrack please add an issue (go to the Issues tab at the top of the GitHub page). If your issue is a bug, please include as much information as possible to help debug the problem. Examples of information include: details about the image and segmentation data (dimensions), number of images, number of samples you are trying to take. If you are requesting an improvement, try to be as clear as possible about what you need. 

**Contributing:** If you want to contribute to annotrack, please fork the repo and if you want to make changes make a pull request with as much detail about the change as possible. Please ensure any changes you want to make don't break the existing functions.
","['Programming Language :: Python :: 3', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Intended Audience :: Science/Research', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Image Processing', 'Framework :: napari']","['Bug Tracker, https://github.com/abigailmcgovern/annotrack/issues', 'Documentation, https://github.com/abigailmcgovern/annotrack#README.md', 'Source Code, https://github.com/abigailmcgovern/annotrack', 'User Support, https://github.com/abigailmcgovern/annotrack/issues']",,,annotrack.sample_from_csv,,,,
1,arcospx-napari,arcosPx-napari,arcosPx,0.1.3,2025-03-27,2025-06-14,Benjamin GrÃ¤del,benjamin.graedel@unibe.ch,BSD-3-Clause,https://github.com/pertzlab/arcosPx-napari/issues,https://pypi.org/project/arcosPx-napari/,,https://github.com/pertzlab/arcosPx-napari,A plugin to track spatio-temporal correlations in images,>=3.10,"['numpy', 'magicgui', 'qtpy', 'arcos4py>=0.3.0', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# arcosPx-napari

[![License BSD-3](https://img.shields.io/pypi/l/arcosPx-napari.svg?color=green)](https://github.com/pertzlab/arcosPx-napari/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/arcosPx-napari.svg?color=green)](https://pypi.org/project/arcosPx-napari)
[![Python Version](https://img.shields.io/pypi/pyversions/arcosPx-napari.svg?color=green)](https://python.org)
[![tests](https://github.com/pertzlab/arcosPx-napari/workflows/tests/badge.svg)](https://github.com/pertzlab/arcosPx-napari/actions)
[![codecov](https://codecov.io/gh/pertzlab/arcosPx-napari/branch/main/graph/badge.svg)](https://codecov.io/gh/pertzlab/arcosPx-napari)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/arcosPx-napari)](https://napari-hub.org/plugins/arcosPx-napari)


## Introduction

This repository contains a dedicated ARCOS.px plugin for the [napari](https://napari.org/stable/) image viewer. It tracks spatio-temporal correlations in images as described in a publication of GrÃ¤del et al. _Tracking Coordinated Cellular Dynamics in Time-Lapse Microscopy with ARCOS.px_ ([link](https://doi.org/10.1101/2025.03.14.643386)).

<p align=""center"">
  <img alt=""ARCOS.px logo"" src=""misc/ARCOS-px-logo.png"" width=""45%"">
&nbsp; &nbsp; &nbsp; &nbsp;
  <img alt=""CDL logo"" src=""misc/cellular-dynamics-lab-logo2.png"" width=""45%""> 
</p>

ARCOS.px is a computational method to identify and track clusters of correlated cell signaling in time-lapse microscopy images. 
It is the latest addition to the [ARCOS ecosystem](https://arcos.gitbook.io/home) developed in the [Cellular Dynamics Lab](https://www.pertzlab.net) at the University of Bern.

![ARCOS.px napari plugin screenshot](misc/napari-plugin.png)


<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Example tracking

Actin polymerization waves in REF52 fibroblasts treated with 50 ng/mL PDGF, 24h before imaging.

![Polymerisation wave in REF52 cells](misc/tracked_waves_rgb_wLabels_F1-181.gif)


## Installation

You can install `arcosPx-napari` via [pip]:

    pip install arcosPx-napari



To install latest development version :

    pip install git+https://github.com/pertzlab/arcosPx-napari.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""arcosPx-napari"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/pertzlab/arcosPx-napari/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/pertzlab/arcosPx-napari/issues', 'Documentation, https://github.com/pertzlab/arcosPx-napari#README.md', 'Source Code, https://github.com/pertzlab/arcosPx-napari', 'User Support, https://github.com/pertzlab/arcosPx-napari/issues']",,,arcosPx-napari.remove_background,,,,
2,applet3,AppleT3,Appletree,0.1.dev1,2025-04-19,2025-04-19,Herearii Metuarea,herearii.metuarea@univ-angers.fr,"Copyright (c) 2025, Herearii M...",https://github.com/hereariim/appletree/issues,https://pypi.org/project/AppleT3/,,,Apple tree segmentation for young apple tree,==3.10.16,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'torch>=2.5.1', 'torchvision>=0.20.1', 'numpy>=1.24.4', 'tqdm>=4.66.1', 'hydra-core>=1.3.2', 'iopath>=0.1.10', 'pillow>=9.4.0', 'supervision==0.25.1', 'transformers==4.51.3', 'einops==0.8.1', 'tensorflow==2.19.0', 'accelerate==1.6.0', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# appletree

[![License BSD-3](https://img.shields.io/pypi/l/appletree.svg?color=green)](https://github.com/hereariim/appletree/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/appletree.svg?color=green)](https://pypi.org/project/appletree)
[![Python Version](https://img.shields.io/pypi/pyversions/appletree.svg?color=green)](https://python.org)
[![tests](https://github.com/hereariim/appletree/workflows/tests/badge.svg)](https://github.com/hereariim/appletree/actions)
[![codecov](https://codecov.io/gh/hereariim/appletree/branch/main/graph/badge.svg)](https://codecov.io/gh/hereariim/appletree)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/appletree)](https://napari-hub.org/plugins/appletree)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

Apple tree segmentation for young apple tree

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `appletree` via [pip]:

    pip install appletree

To install latest development version :

    pip install git+https://github.com/hereariim/appletree.git

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""appletree"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/hereariim/appletree/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hereariim/appletree/issues', 'Documentation, https://github.com/hereariim/appletree#README.md', 'Source Code, https://github.com/hereariim/appletree', 'User Support, https://github.com/hereariim/appletree/issues']",,,appletree.make_container_widget,,,,
3,anchor-droplet-chip,anchor-droplet-chip,anchor_droplet_chip,0.4.6,2023-03-13,2024-07-19,Andrey Aristov,aaristov@pasteur.fr,BSD-3-Clause,https://github.com/BaroudLab/anchor-droplet-chip,https://pypi.org/project/anchor-droplet-chip/,,https://github.com/BaroudLab/anchor-driplet-chip,Segment organoids and measure intensities,>=3.8,"['dask', 'fire', 'h5py', 'jupyterlab', 'matplotlib', 'napari', 'nd2', 'numpy', 'pandas', 'pyqt6', 'pytest-qt', 'pyyaml', 'scikit-image', 'scipy', 'seaborn', 'tifffile', 'zarr-tools', 'zenodo-get']","# â anchor-droplet-chip
## Measuring single-cell susceptibility to antibiotics within monoclonal fluorescent bacteria.

We are imaging the entire chip using 20x 0.7NA objective lens using automatic stitching in NIS.
Bright-field image 2D and TRITC-3D acquired. The 3D stack is converted to 2D using maximum projection in NIS or Fiji. Both channels are then merged together and saved as a tif stack. After that this package can be applied to detect the individual droplets and count the fluorescent cells.

As the chips are bonded to the coverslip manually, they contain a randon tilt and shift, so detecting individual droplets proved to be unreliable. The current approach consisnts of preparing a well-lebelled template bright-field image and a labelled mask and matching the experimental brightfield image to the template.
![Paper outline(1)](https://user-images.githubusercontent.com/11408456/178001287-513e6398-c4e0-4946-b38f-6cb98dc0ee6c.svg)

## Installation
```bash
pip install anchor-droplet-chip
```
## Usage

1. Notebook: `jupyter lab example.ipynb`
2. Napari plugin: see the menu `Plugins / andhor-droplet-chips / ...
3. Command line:

    `python -m adc.align --help`

    `python -m adc.count --help`

### Dowloading the raw data
Head to release page https://github.com/BaroudLab/anchor-droplet-chip/releases/tag/v0.0.1 and download files one by one.

Or

Execute the notebook example.ipynb - the data will be fetched automatically.

### Aligning the chips with the template and the mask

Day 1:
```bash
python -m adc.align day1/00ng_BF_TRITC_bin2.tif template_bin16_bf.tif labels_bin2.tif
```
This command will create the stack day1/00ng_BF_TRITC_bin2-aligned.tif, which can be viewed in Fiji.
![Screenshot of 00ng_BF_TRITC_bin2-aligned.tif](https://user-images.githubusercontent.com/11408456/176169270-3d494fc3-a771-4bf0-859e-c9cc853ce2d9.png)

Day 2:
```bash
python -m adc.align day2/00ng_BF_TRITC_bin2_24h.tif template_bin16_bf.tif labels_bin2.tif
```

### Counting the cells day 1 and day2
```
python -m adc.count day1/00ng_BF_TRITC_bin2-aligned.tif day1/counts.csv
python -m adc.count day2/00ng_BF_TRITC_bin2_24h-aligned.tif day2/counts.csv
```

### Combining the tables from 2 days
```
python adc.merge day1/counts.csv day2/counts.csv table.csv
```

### Plotting and fitting the probabilities


## Sample data

### Batch processing:

First you'll need to clone the repo locally and install it to have the scripts at hand.

```bash
git clone https://github.com/BaroudLab/anchor-droplet-chip.git

cd anchor-droplet-chip

pip install .
```
Make a data folder
```bash
mkdir data

```
Download the dataset from Zenodo https://zenodo.org/record/6940212
```bash
zenodo_get 6940212 -o data
```
Proceed with Snakemake pipeline to get tha table and plots. Be careful with the number of threads `-c` as a single thread can consume over 8 GBs of RAM.
```bash
snakemake -c4 -d data table.csv
```

# Napari plugin functionaluties

## nd2 reader

Open large nd2 file by drag-n-drop and select anchor-droplet-chip as a reader.
The reader plugin will aotimatically detect the subchannels and split them in different layers.
The reader will also extract the pixel size from metadata and save it as Layer.metadata[""pixel_size_um""]
The data itself is opened ad dask array using nd2 python library.

## Substack

Some datasets are so big, it's hard to even to open them, let alone doing processing in them.
`anchor-droplet-chip / Make a sub stack ` addresses this problem.
Upon opening the plugin you'll see all  dimensions of you dataset, and the axes will become named accordingly.
Simply choose the subset of data you need, and click ""Crop it!"". This will create a new layer with the subset of data.
Note that no new files are created in the process and in the background nd2 library lazy loading chunks of data from the original nd2 file.

## Populate ROIs along the line
Draw a line in the new shapes layer and call the widget. It will populate square ROIs along the line. Adjust the number of columns and rows. This way you can manually map the 2D wells on your chip.

## Crop ROIs
Use this widget to crop the mapped previously ROIs. The extracted crops can be saved as tifs.

## Split along axis

Allows to split any dataset along a selected axis and save the pieces as separate tifs (imagej format, so only TZCYX axes supported)
* Select the axis name
* Click Split it! and check the table with the names, shapes and paths.
* To change the prefix, set the folder by clicking at ""Choose folder""
* Once the table looks right, click ""Save tifs"" and wait. The colunm ""saved"" will be updated along the way.
![image](https://user-images.githubusercontent.com/11408456/214313498-5b1f8408-1fa3-4e24-810a-b9394e936c8e.png)
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: Implementation :: CPython', 'Topic :: Software Development :: Testing']","['Source Code, https://github.com/BaroudLab/anchor-droplet-chip']",anchor_droplet_chip.get_reader,,anchor_droplet_chip.segment,anchor_droplet_chip.make_template,"['*.npy', '*.nd2', '*.zarr', '*.tif', '*.tiff', '*.csv']",,
4,allencell-segmenter-ml,allencell-segmenter-ml,allencell-segmenter-ml,1.0.0,2024-09-20,2025-05-29,,,Allen Institute Software Licen...,https://github.com/AllenCell/allencell-ml-segmenter/issues,https://pypi.org/project/allencell-segmenter-ml/,,,A plugin to leverage ML segmentation in napari,"<3.11,>=3.9","['npe2>=0.6.2', 'numpy', 'hydra-core==1.3.2', 'bioio==1.1.0', 'bioio-base==1.0.4', 'tifffile<2025.2.18,>=2023.4.12', 'watchdog', 'cyto-dl>=0.4.5', 'scikit-image!=0.23.0', 'napari>=0.4.18; extra == ""napari""', 'pyqt5; extra == ""napari""', 'pytest<8.0.0; extra == ""test-lint""', 'pytest-cov; extra == ""test-lint""', 'pytest-qt; extra == ""test-lint""', 'qtpy; extra == ""test-lint""', 'pyqt5; extra == ""test-lint""', 'black>=24.2.0; extra == ""test-lint""', 'pytest-xvfb; sys_platform == ""linux"" and extra == ""test-lint""', 'responses; extra == ""test-lint""', 'mypy; extra == ""test-lint""', 'toml; extra == ""test-lint""', 'bumpver; extra == ""test-lint""', 'napari>=0.4.18; extra == ""test-lint""', 'magicgui; extra == ""test-lint""', 'black>=24.2.0; extra == ""dev""', 'coverage>=7.2.2; extra == ""dev""', 'flake8>=6.0.0; extra == ""dev""', 'pytest<8.0.0,>=7.2.2; extra == ""dev""', 'pytest-qt>=3.3.0; extra == ""dev""', 'pytest-cov>=2.6.1; extra == ""dev""', 'pyqt5>=5.15.9; extra == ""dev""', 'bumpver>=2023.1129; extra == ""dev""', 'build>=1.0.3; extra == ""dev""', 'twine>=5.0.0; extra == ""dev""', 'responses; extra == ""dev""', 'mypy; extra == ""dev""', 'linkify-it-py; extra == ""sphinx-docs""', 'sphinx; extra == ""sphinx-docs""', 'furo; extra == ""sphinx-docs""', 'sphinxext-opengraph; extra == ""sphinx-docs""', 'sphinx_inline_tabs; extra == ""sphinx-docs""', 'sphinx_copybutton; extra == ""sphinx-docs""', 'myst_parser; extra == ""sphinx-docs""', 'sphinx_togglebutton; extra == ""sphinx-docs""', 'sphinx_design; extra == ""sphinx-docs""']","# Allencell-segmenter-ml

[![Test and lint](https://github.com/AllenCell/allencell-segmenter-ml/actions/workflows/test_lint.yaml/badge.svg?branch=main&event=push)](https://github.com/AllenCell/allencell-segmenter-ml/actions/workflows/test_lint_pr.yaml)


## What is Allen Cell Segmenter ML
A napari plugin for deep-learning based segmentation of cellular structures.

![SegmenterML-plugin_fig1_output.png](docs%2Fuser_docs%2Fimages%2FSegmenterML-plugin_fig1_output.png)

- **Available at no cost** â available on PyPI
- **User-friendly** â leverage napari as a fast 3D viewer with interactive plugin interface
- **Beginner-friendly** â new to machine learning? This plugin simplifies the application of machine learning in the segmentation process through the 3 main modules:
  - **Curation**: curate training datasets
  - **Training**: iteratively train custom segmentation model(s) (UNET) to target cellular structure with wide morphological variability
  - **Prediction & Thresholding**: generate segmentation prediction on 2D and 3D cell image data


##  ð° News

 - **[2024.09.24]** :tada: Initial release of the plugin and Megaseg models!
 - **[2024.05.29]** :tada: v1.0.0 Released on PyPi


## User Documentation
[See our full user documentation on our github pages site.](https://allencell.github.io/allencell-segmenter-ml/index.html)


## ð ï¸ Installation

### System and Data Requirements

[Please click here to check out our latest System and Data requirements.](https://allencell.github.io/allencell-segmenter-ml/1_Get-started/1_prerequisites.html)


### Installation Steps
[Please click here for our latest installation steps.](https://allencell.github.io/allencell-segmenter-ml/1_Get-started/2_installation.html)


## Models
[More information about the pre-trained models we provide with our plugin, and citation information, can be found here.](https://allencell.github.io/allencell-segmenter-ml/1_Get-started/4_pretrained-models.html)

## License

Distributed under the terms of the [Allen Institute Software License].

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[@napari]: https://github.com/napari
[Allen Institute Software License]: https://github.com/AllenCell/allencell-segmenter-ml/blob/main/LICENSE
[file an issue]: https://github.com/AllenCell/allencell-ml-segmenter/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[PyTorch]: https://pytorch.org/get-started/locally/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Science/Research', 'License :: Other/Proprietary License', 'License :: Free for non-commercial use', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Homepage, https://github.com/AllenCell/allencell-ml-segmenter', 'Bug Tracker, https://github.com/AllenCell/allencell-ml-segmenter/issues', 'Documentation, https://github.com/AllenCell/allencell-ml-segmenter#README.md', 'User Support, https://github.com/AllenCell/allencell-ml-segmenter/issues']",,,allencell-segmenter-ml.make_qwidget,,,,
5,alveoleye,AlveolEye,AlveolEye,0.1.7,2024-05-22,2025-07-18,Joseph Hirsh,josephhirsh9@gmail.com,BSD,,https://pypi.org/project/AlveolEye/,None,,Reads lung slides with AI-driven and classical methods,>=3.8,"['numpy', 'magicgui', 'qtpy', 'typeguard', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'qtpy; extra == ""testing""']","# AlveolEye: Automated Lung Morphometry Made Easy

[![Napari Plugin](https://img.shields.io/badge/Napari-Plugin-1157c4?logo=napari)](https://www.napari-hub.org/plugins/AlveolEye)
![Python Version](https://img.shields.io/badge/Python-3.9%20|%203.10%20|%203.11-blue)
![OS Support](https://img.shields.io/badge/Platform-Windows%20%7C%20macOS%20%7C%20Linux-blue)
![GitHub Release](https://img.shields.io/github/v/release/SucreLab/AlveolEye?display_name=tag)
![License](https://img.shields.io/github/license/SucreLab/AlveolEye)
[![PyPI Downloads](https://img.shields.io/pypi/dm/AlveolEye)](https://pypi.org/project/AlveolEye/)
![Maintenance](https://img.shields.io/maintenance/yes/2025)
![Last Commit](https://img.shields.io/github/last-commit/SucreLab/AlveolEye)
![Issues](https://img.shields.io/github/issues/SucreLab/AlveolEye)

This repository contains the beta version of AlveolEye, created by the [Sucre lab](https://www.sucrelab.org/).  
The code is authored by Samuel Hirsh, Joseph Hirsh, Nick Negretti, and Shawyon Shirazi.

AlveolEye is a Napari plugin that uses computer vision and classical image processing  
to calculate mean linear intercept (MLI) and airspace volume density (ASVD) of histologic images.

The goal of this tool is to aid researchers, not provide a complete automated annotation solution.

We welcome GitHub issues and feedback!

## Installation

The goal of this process is to create a conda environment containing Napari and all AlveolEye requirements.

*If you already have conda set up, you can skip step 1.*

1. **Install Miniconda** by downloading the appropriate version from [here](https://www.anaconda.com/docs/getting-started/miniconda/install):  
   - Choose the version that matches your processor.  
   - Download the `.pkg` version for easy installation.

2. **Clone the repository** (by opening a terminal or Miniconda prompt and running the following)
   ```
   git clone https://github.com/SucreLab/AlveolEye
   ```

3. **Navigate to the directory**:
   ```
   cd AlveolEye
   ```

4. **Create the conda environment**:
   ```
   conda env create -f ./environment.yml
   ```

5. **Activate the environment**:
   ```
   conda activate AlveolEye
   ```

6. **Install the plugin**:
   ```
   pip install .
   ```

7. **Launch Napari** and locate the plugin in the plugin menu:
   ```
   napari
   ```

## Running Post-Installation

1. **Activate the environment** in the terminal or Miniconda prompt:
   ```
   conda activate AlveolEye
   ```

2. **Run Napari** in the terminal:
   ```
   napari
   ```

<div align=""right"">
  <a href=""#alveoleye-automated-lung-morphometry-made-easy"">Back to Top</a>
</div>

## Usage

### Processing: Identify and Segment Vessel Endothelium and Airway Epithelium with Computer Vision

![processing diagram](https://raw.githubusercontent.com/SucreLab/AlveolEye/main/docs/PROCESSING_FINAL.svg)

1. **Import image**  
   - Click the ""Import Image"" button.  
   - Use the file dialog to select an image (`.jpg`, `.png`, or `.tiff`).  
   - Verify that the image correctly loaded. The file name should appear to the right of the button.

2. **Toggle processing with computer vision**  
   - Keep the checkbox selected to process the image with computer vision (continue to step 3).  
   - Deselect to skip computer vision processing (skip to step 5).

3. **Import weights**  
   - To use the default model, proceed to step 4.  
   - To use a custom model:  
     - Click the ""Import Weights"" button.  
     - Select a model file (`.pth`).  
     - Verify that the weights correctly loaded. The file name should appear to the right of the button.

4. **Set minimum confidence**  
   - Adjust the minimum confidence using the input box or the ""-/+"" buttons.  
   - Predictions from the computer vision model with lower confidence than this threshold will not appear.

5. **Run processing**  
   - Click the ""Run Processing"" button.  
   - Once completed, manually edit the prediction as needed using Napari's built-in tools.

<div align=""right"">
  <a href=""#alveoleye-automated-lung-morphometry-made-easy"">Back to Top</a>
</div>

### Postprocessing: Segment Alveolar Tissue and Find Vessel and Aireway Lumens

![postprocessing diagram](https://raw.githubusercontent.com/SucreLab/AlveolEye/main/docs/POSTPROCESSING_FINAL.svg)

1. **Configure thresholding**  
   - For manual thresholding: Select the ""Manual threshold"" checkbox and use the spinbox to set the threshold level.  
   - For automatic thresholding ([Otsu's method](https://learnopencv.com/otsu-thresholding-with-opencv/)): Leave the box unchecked.

2. **Remove small particles**  
   - Set the minimum size cutoff.
   - Particles with fewer pixels than this value will be removed.

3. **Remove small holes**  
   - Set the minimum size cutoff.  
   - Holes with fewer pixels than this value will be removed.

4. **Run postprocessing**  
   - Click the ""Run Postprocessing"" button.  
   - Once completed, manually edit the results as needed using Napari's built-in tools.

<div align=""right"">
  <a href=""#alveoleye-automated-lung-morphometry-made-easy"">Back to Top</a>
</div>

### Assessments: Calculate Morphometry Measurements

![assessments diagram](https://raw.githubusercontent.com/SucreLab/AlveolEye/main/docs/ASSESSMENTS_FINAL.svg)

1. **Airspace Volume Density (ASVD)**
   - Select the checkbox to run ASVD calculation.
   - Deselect the checkbox to exclude data from export and increase processing speed.

2. **Mean Linear Intercept (MLI)**
   - Select the checkbox to run MLI calculation.
   - Deselect the checkbox to exclude data from export and increase processing speed.

3. **Number of lines**
   - Set the number of lines used for MLI calculation.

5. **Minimum length**
   - Set the minimum chord length for inclusion in MLI calculations.
   - Note: Chords are the line segments that span across an airspace between two alveolar tissue boundaries during MLI calculation.

7. **Scale**
   - Set the pixel-to-physical space multiplier.

9. **Run assessments**
   - Click the ""Run Assessments"" button.
   - View results displayed beside assessment checkboxes and in the export box.

<div align=""right"">
  <a href=""#alveoleye-automated-lung-morphometry-made-easy"">Back to Top</a>
</div>

### Export Results: Save Assessment Results as a CSV or JSON File

![export diagram](https://raw.githubusercontent.com/SucreLab/AlveolEye/main/docs/EXPORT_FINAL.svg)

1. **Add results**
   - Click ""Add"" to include current assessment data in the export file.

3. **Remove last result**
   - Click ""Remove"" to delete the last added results from the export file.

5. **Clear export data**
   - Click ""Clear"" to empty the export file.

7. **Export results**
   - Click ""Export Results"" to save the data (`.csv` or `.json` format).

**Results Key**

- **MLI**: Mean Linear Intercept for the tissue image
 
- **Standard deviation**: Standard deviation of chord lengths used in MLI calculation
  
- **Number of chords**: Number of chords used in MLI calculation

- **ASVD**: Airspace Volume Density for the image
 
- **Airspace pixels**: Total number of airspace pixels
   
- **Non-airspace pixels**: Total number of non-airspace pixels

<div align=""right"">
  <a href=""#alveoleye-automated-lung-morphometry-made-easy"">Back to Top</a>
</div>

## Manual Annotation Guide

### Label Reference

| Structure          | Label Number |
|--------------------|--------------|
| Blocker            | 1            |
| Airway Epithelium  | 2            |
| Vessel Endothelium | 3            |
| Airway Lumen       | 4            |
| Vessel Lumen       | 5            |
| Parenchyma         | 6            |
| Alveoli            | 7            |

### Annotation Tips

- **Eyedropper tool**: Click the eyedropper tool, then click a pixel in the image to set your active label (for drawing and editing) to that pixel's label.  
- **Layer selection**: Ensure you're working on the correct layer before annotating.  
- **Visibility control**: Hide unnecessary layers using the eye icon on the layer boxes (to the left of the image viewer) for clearer viewing.
- **Blocking**: Encircle airways and vessels in the blocking label, and everything within that closed shape will be discounted from assessments calculation. 

<div align=""right"">
  <a href=""#alveoleye-automated-lung-morphometry-made-easy"">Back to Top</a>
</div>

## Additional Information

### Theme Settings

Toggle between dark and light mode using:

- **Windows/Linux**: `Ctrl + Shift + T`  
- **macOS**: `Cmd + Shift + T`

Or through Napari preferences:

1. Select ""napari"" in the menu bar.
   
2. Choose ""Preferences.""
   
3. Click ""Appearance"" in the left menu.
     
4. Select ""dark,"" ""light,"" or ""system"" in the theme dropdown.

<div align=""right"">
  <a href=""#alveoleye-automated-lung-morphometry-made-easy"">Back to Top</a>
</div>
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,AlveolEye.get_reader,AlveolEye.write_multiple,AlveolEye.make_qwidget,AlveolEye.make_sample_data,"['.jpeg', '.jpg', '.png', '.tif', '.tiff']",,['.npy']
6,affinder,affinder,affinder,0.5.0,2021-02-04,2025-07-20,Juan Nunez-Iglesias,juan.nunez-iglesias@monash.edu,BSD-3,https://github.com/jni/affinder,https://pypi.org/project/affinder/,,https://github.com/jni/affinder,Quickly find the affine matrix mapping one image to another using manual correspondence points annotation,>=3.9,"['napari>=0.4.17', 'npe2>=0.1.2', 'numpy', 'scikit-image>=0.19.2', 'magicgui>=0.3.7', 'toolz', 'coverage; extra == ""testing""', 'pydantic<2; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'scikit-image[data]; extra == ""testing""', 'napari[pyqt5]!=0.4.18; extra == ""testing""', 'pygments!=2.16; extra == ""testing""', 'zarr; extra == ""testing""', 'furo; extra == ""docs""', 'myst-parser; extra == ""docs""']","# Description

This GUI plugin allows you to quickly find the affine matrix mapping
one image to another using manual correspondence points annotation.

More simply, this plugin allows you to select corresponding points
on an image, and a second image you wish to transform. It computes 
the requisite transformation matrix using Affine Transform, Euclidean Transform, 
or Similarity Transform, and performs this transformation on the
moving image, aligning it to the reference image.

https://user-images.githubusercontent.com/17995243/120086403-f1d0b300-c121-11eb-8000-a44a2ac54339.mp4


# Who is This For?

This is a simple plugin which can be used on any 2D images, provided
they can be loaded as layers into napari. The images need not be the same
file format and this plugin also works with labels layers.

No prior understanding of the transformation methods is required, as
they perform in the background based on the reference points selected.

# How to Guide

You will need a combination of two or more 2D image and/or labels layers 
loaded into napari. Once you have installed affinder, you can find it in
the dock widgets menu.

![Affinder widget in the Plugins->Add Dock Widget menu](https://i.imgur.com/w7MCXQy.png)

The first two dropdown boxes will be populated with the layers currently
loaded into napari. Select a layer to use as reference, and another to
transform.

![Dropdowns allow you to select the reference and moving layers](https://i.imgur.com/Tdbm1sX.png)

Next, you can select the transformation model to use (affine is selected by default
and is the least rigid transformation of those available). See [below](#transformation-models) for a
description of the different models.

Finally, you can optionally select a path to a text file for saving out the
resulting transformation matrix.

When you click Start, affinder will add two points layers to napari. 
The plugin will also bring your reference image in focus, and its associated points
layer. You can then start adding reference points by clicking on your image.

![Adding reference points to layer](https://i.imgur.com/WPzNtyy.png)

Once three points are added, affinder will switch focus to the moving image,
and you should then proceed to select the corresponding three points.

![Adding corresponding points to newly focused layer](https://i.imgur.com/JVZCvmp.png)

affinder will immediately transform the moving image to align the points you've
selected when you add your third corresponding point to your moving image.

![The moving image is transformed once three points are added](https://i.imgur.com/NTne9fj.png)

From there, you can continue iteratively adding points until you 
are happy with the alignment. Affinder will switch focus between
reference and moving image with each point.

Click Finish to exit affinder.

## Transformation Models

There are three transformation models available for use with affinder.
They are listed here in order of increasing rigidity in the types of
transforms they will allow. The eponymous Affine Transform is the 
least rigid and is the default choice.

- [**Affine Transform**](https://en.wikipedia.org/wiki/Affine_transformation): 
the least rigid transformation, it preserves
lines and parallelism, but not necessarily distance and angles. Translation,
scaling, similarity, reflection, rotation and shearing are all valid
affine transformations.

- [**Similarity Transform**](https://en.wikipedia.org/wiki/Similarity_(geometry)): 
this is a ""shape preserving"" transformation, producing objects which are 
geometrically similar. Translation, rotation, reflection and uniform scaling are 
valid similarity transforms. Shearing is not.

- [**Euclidean Transform**](https://en.wikipedia.org/wiki/Rigid_transformation):
Also known as a rigid transformation, this transform preserves the Euclidean
distance between each pair of points on the image. This includes rotation,
translation and reflection but not scaling or shearing.

# Getting Help

If you find a bug with affinder, or would like support with using it, please raise an
issue on the [GitHub repository](https://github.com/jni/affinder).

# How to Cite

Many plugins may be used in the course of published (or publishable) research, as well as
during conference talks and other public facing events. If you'd like to be cited in
a particular format, or have a DOI you'd like used, you should provide that information here.
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,affinder.start_affinder,,,,
7,acquifer-napari,acquifer-napari,acquifer-napari,0.0.2,2023-07-07,2024-02-27,Laurent Thomas,,GPL-3.0-only,https://github.com/Luxendo/acquifer-napari,https://pypi.org/project/acquifer-napari/,,,"Loader plugin for napari, to load Acquifer Imaging Machine datasets in napari, using dask for efficient lazy data-loading.",>=3.7,"['acquifer', 'napari', 'numpy', 'sortedcontainers', 'dask-image', 'xarray']","# acquifer-napari

The acquifer-napari plugin allows loading IM04 dataset directory, as multi-dimensional images in napari.  
Sliders for well, channel, time and Z are automatically rendered when there are more than 1 coordinates along the dimension.  
The plugin uses Dask-Image for efficient data-loading ""on request"" similar to the VirtualStack in ImageJ.  

## Installation
Via the napari plugin manager : acquifer-napari.
Or with pip : `pip install acquifer-napari`.

Use `pip install -e .` to install in developement mode, so any change in the source code is directly reflected.  
Use `npe2 list` to check that the plugin is correctly installed and visible by napari.  
For instance here, the package defines 1 command, which is a reader.  
One could have more commands, which would be implement other types.   
This should output something like following 
ââââââââââââââââââââââââââââââââ¬ââââââââââ¬âââââââ¬ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ
â Name                         â Version â Npe2 â Contributions                                             â
ââââââââââââââââââââââââââââââââ¼ââââââââââ¼âââââââ¼ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ¤
â acquifer-napari              â 0.0.1   â â   â commands (1), readers (1)

The plugin should be installed in an environment with napari installed.  
Napari can be started with the `napari`command in a command prompt with a system wide python installation.  
Once installed, napari can be opened in a IPython interactive session with

```python
>> import napari
>> napari.Viewer()
```

## Configurations
The file `napari.yaml` in `acquifer_napari_plugin` defines what functions of the python package are visible to napari.  
The top level `name` field must be the same than the python package name defined in `setup.cfg`.
It first define a set of commands, which have a custom `id`, and a `python_name`, which is the actual location of the function in the python package (or module).  
Then the napari.yaml has optional subsections `readers`, `writers`, `widget`, to reference some of the commands previously defined, to notify napari that they implemente those standard functions.  
For instance I first define a command myReader pointing to myPackage.myReader, and I reference that command using the id it in the section readers  
See https://napari.org/stable/plugins/first_plugin.html#add-a-napari-yaml-manifest  


## Issues
If you encounter any problems, please [file an issue](https://github.com/Luxendo/acquifer-napari/issues) along with a detailed description.
","['Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']","['HomePage, https://acquifer.de', 'Twitter, https://twitter.com/myacquifer', 'Bug Tracker, https://github.com/Luxendo/acquifer-napari/issues', 'Documentation, https://github.com/Luxendo/acquifer-napari#README.md', 'Source Code, https://github.com/Luxendo/acquifer-napari']",acquifer-napari.get_reader,,,,['*'],,
8,arcos-gui,arcos-gui,napari ARCOS,0.1.5,2022-02-24,2025-04-01,Benjamin GrÃ¤del,benjamin.graedel@unibe.ch,BSD-3-Clause,https://github.com/bgraedel/arcos-gui/issues,https://pypi.org/project/arcos-gui/,,https://github.com/bgraedel/arcos-gui,A napari plugin to detect and visualize collective signaling events,>=3.9,"['arcos4py>=0.3.1', 'matplotlib>=3.3.4', 'napari>=0.4.14', 'numpy>=1.22.2; python_version >= ""3.10""', 'numpy<2,>=1.22.2; python_version < ""3.10""', 'pandas>=1.3.5', 'pyarrow>=11.0.0', 'scikit-image>=0.20.0; python_version < ""3.12""', 'scikit-image>=0.22.0; python_version >= ""3.12""', 'scipy>=1.7.3', 'napari-timestamper', 'mkdocs; extra == ""doc""', 'mkdocs-include-markdown-plugin; extra == ""doc""', 'mkdocs-material; extra == ""doc""', 'mkdocs-material-extensions; extra == ""doc""', 'pyqt5; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-mock; extra == ""testing""', 'pytest-qt; extra == ""testing""']","# arcos-gui

[![License](https://img.shields.io/pypi/l/arcos-gui.svg?color=green)](https://github.com/pertzlab/pertzlab/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/arcos-gui.svg)](https://pypi.org/project/arcos-gui)
[![conda-forge](https://img.shields.io/conda/vn/conda-forge/arcos-gui)](https://anaconda.org/conda-forge/arcos-gui)
[![Python Version](https://img.shields.io/pypi/pyversions/arcos-gui.svg?color=green?)](https://python.org)
[![tests](https://github.com/pertzlab/arcos-gui/workflows/tests/badge.svg)](https://github.com/pertzlab/arcos-gui/actions)
[![codecov](https://codecov.io/gh/pertzlab/arcos-gui/branch/main/graph/badge.svg)](https://codecov.io/gh/pertzlab/arcos-gui)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/arcos-gui)](https://napari-hub.org/plugins/arcos-gui)

A napari plugin to detect and visualize collective signaling events

----------------------------------
- Package specific Documentation: <https://pertzlab.github.io/arcos-gui>
- ARCOS documentation: <https://arcos.gitbook.io>

**A**utomated **R**ecognition of **C**ollective **S**ignalling (ARCOS) is an algorithm to identify collective spatial events in time series data.
It is available as an [R (ARCOS)](https://github.com/pertzlab/ARCOS) and [python (arcos4py)](https://github.com/pertzlab/arcos4py) package.
ARCOS can identify and visualize collective protein activation in 2- and 3D cell cultures over time.

This plugin integrates ARCOS into napari. Users can import tracked time-series data in CSV format or load data from napari-layer properties (such as the ones generated with [napari-skimage-regionprops](https://www.napari-hub.org/plugins/napari-skimage-regionprops). The plugin
provides GUI elements to process this data with ARCOS. Layers containing the detected collective events are subsequently added to the viewer.

Following analysis, the user can export the output as a CSV file with the detected collective events or as a sequence of images to generate a movie.


![](https://github.com/bgraedel/arcos-gui/assets/100028238/66fa2afa-6f24-4cce-b29e-4279066c6c25)

[Watch full demo on youtube](https://www.youtube.com/watch?v=hG_z_BFcAiQ) (older plugin version)


# Installation

You can install `arcos-gui` via [pip]:

    pip install arcos-gui

Or via [conda-forge]:

    conda install -c conda-forge arcos-gui

## Usage

The plugin can be started from the napari menu `Plugins > ARCOS GUI`.
For detailed instructions on how to use the plugin, please refer to the [Usage section of the documentation](https://pertzlab.github.io/arcos-gui/Usage).

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.
See the [Contributing Guide](https://pertzlab.github.io/arcos-gui/Contributing) for more information.

## License

Distributed under the terms of the [BSD-3] license,
""arcos-gui"" is free and open-source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/pertzlab/arcos-gui/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/arcos-gui/
[conda-forge]: https://anaconda.org/conda-forge/arcos-gui
[PyPI]: https://pypi.org/

## Credits
We were able to develop this plugin in part due to funding from the [CZI napari Plugin Foundation Grant](https://chanzuckerberg.com/science/programs-resources/imaging/napari/detecting-and-quantifying-space-time-correlations-in-cell-signaling/).

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Citation

If you use this plugin in your research, please cite the following [paper](https://doi.org/10.1083/jcb.202207048):

    @article{10.1083/jcb.202207048,
        author = {Gagliardi, Paolo Armando and GrÃ¤del, Benjamin and Jacques, Marc-Antoine and Hinderling, Lucien and Ender, Pascal and Cohen, Andrew R. and Kastberger, Gerald and Pertz, Olivier and DobrzyÅski, Maciej},
        title = ""{Automatic detection of spatio-temporal signaling patterns in cell collectives}"",
        journal = {Journal of Cell Biology},
        volume = {222},
        number = {10},
        pages = {e202207048},
        year = {2023},
        month = {07},
        abstract = ""{Increasing experimental evidence points to the physiological importance of spaceâtime correlations in signaling of cell collectives. From wound healing to epithelial homeostasis to morphogenesis, coordinated activation of biomolecules between cells allows the collectives to perform more complex tasks and to better tackle environmental challenges. To capture this information exchange and to advance new theories of emergent phenomena, we created ARCOS, a computational method to detect and quantify collective signaling. We demonstrate ARCOS on cell and organism collectives with spaceâtime correlations on different scales in 2D and 3D. We made a new observation that oncogenic mutations in the MAPK/ERK and PIK3CA/Akt pathways of MCF10A epithelial cells hyperstimulate intercellular ERK activity waves that are largely dependent on matrix metalloproteinase intercellular signaling. ARCOS is open-source and available as R and Python packages. It also includes a plugin for the napari image viewer to interactively quantify collective phenomena without prior programming experience.}"",
        issn = {0021-9525},
        doi = {10.1083/jcb.202207048},
        url = {https://doi.org/10.1083/jcb.202207048},
        eprint = {https://rupress.org/jcb/article-pdf/222/10/e202207048/1915749/jcb/_202207048.pdf},
    }
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/bgraedel/arcos-gui/issues', 'Documentation, https://pertzlab.github.io/arcos-gui/', 'Source Code, https://github.com/bgraedel/arcos-gui', 'User Support, https://github.com/bgraedel/arcos-gui/issues']",,,arcos-gui.MainWindow,arcos-gui.data.arcos_sample_data_1,,,
9,avidaq,avidaq,napari avidaq,0.0.5,2022-07-21,2022-08-25,Riley M Shea,RileyMShea@gmail.com,BSD-3-Clause,,https://pypi.org/project/avidaq/,None,,controls for napari and micromanger,>=3.8,"['magicgui', 'numpy', 'pycromanager', 'qtpy', ""twine ; extra == 'build'"", ""black ; extra == 'testing'"", ""ipykernel ; extra == 'testing'"", ""matplotlib ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pyright ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'"", ""yappi ; extra == 'testing'""]","# avidaq

[![PyPI](https://img.shields.io/pypi/v/avidaq.svg?color=green)](https://pypi.org/project/avidaq)
[![Python Version](https://img.shields.io/pypi/pyversions/avidaq.svg?color=green)](https://python.org)
[![tests](https://github.com/optimax/avidaq/workflows/tests/badge.svg)](https://github.com/optimax/avidaq/actions)
[![codecov](https://codecov.io/gh/optimax/avidaq/branch/main/graph/badge.svg)](https://codecov.io/gh/optimax/avidaq)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/avidaq)](https://napari-hub.org/plugins/avidaq)

controls for napari and micromanger

---

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

### Standard installation

You can install `avidaq` via [pip]:

```shell
pip install napari[all] avidaq
```

### Install from plugin menu

Alternatively you can install `avidaq` via the [napari] plugin menu:

## ![napari-add-plugin](napari-add-plugin.png)

## Running

First start micromanager.  Make sure the server port checkbox is activated.

Then to start napari with the avidaq plugin active run:
`napari -w avidaq`

![](screenshot.png)

## Updating presets

MDA presets are stored in a json file in the user's home directory.

```shell

`C:\\Users\YourName\.avidaq\mda_presets.json`
```

This file should exist after plugin installation with some defaults. You do not need to create the file yourself.

Add or modify the values and reload napari to see the changes.

All parameter entries are optional, if not provided the default value will be used.

The parameter names and their descriptions can be found [here] (https://github.com/micro-manager/pycro-manager/blob/main/pycromanager/acq_util.py#L102-L115)

The format is as follows:

```json
{
    ""gui_display_name"": {
        ""parameter_name"": value,
        ""parameter_name"": value,
        ...
    },
    ""gui_display_name"": {
        ""parameter_name"": value,
        ""parameter_name"": value,
        ...
    },
    ...
}
```

defaults:

```json
{
  ""Basic"": {
    ""num_time_points"": 5,
    ""z_start"": 0,
    ""z_end"": 6,
    ""z_step"": 0.4
  },
  ""Simple"": {
    ""num_time_points"": 2,
    ""z_start"": 0,
    ""z_end"": 2,
    ""z_step"": 0.1
  },
  ""Detailed"": {
    ""num_time_points"": 10,
    ""z_start"": 0,
    ""z_end"": 12,
    ""z_step"": 0.2
  }
}
```

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

## Development

You should have python3.8 or higher installed.

1. clone this repo
2. create a virtual environment `python -m venv .venv && source .venv/bin/activate`
3. run `pip install -e '.[testing,build]'`
4. run `pre-commit install`

### To run unit tests

`pytest`

### typical workflow

1. edit code in `/src`
2. run napari -w avidaq
3. repeat

### Releasing to pypi


Project is automically built and deployed to pypi upon


---

[napari]: https://github.com/napari/napari
[cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[mit]: http://opensource.org/licenses/MIT
[bsd-3]: http://opensource.org/licenses/BSD-3-Clause
[gnu gpl v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[gnu lgpl v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[apache software license 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[mozilla public license 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[pypi]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing', 'Typing :: Typed']",,avidaq.get_reader,avidaq.write_multiple,avidaq.make_qwidget,avidaq.make_sample_data,['*.npy'],,['.npy']
10,axondeepseg,AxonDeepSeg,AxonDeepSeg,5.1.1,2025-02-28,2025-06-30,"NeuroPoly Lab, Polytechnique Montreal","""NeuroPoly Lab, Polytechnique Montreal"" <axondeepseg@googlegroups.com>",MIT,https://github.com/axondeepseg/axondeepseg/issues,https://pypi.org/project/AxonDeepSeg/,,,Axon/Myelin segmentation using AI,"<3.13,>=3.11","['numpy<2', 'scipy', 'scikit-image!=0.25.0,!=0.25.1', 'tabulate', 'pandas', 'matplotlib', 'mpld3', 'tqdm', 'requests', 'pillow!=9.0.0', 'imageio>=2.28.0', 'pytest', 'pytest-cov', 'prettytable', 'jupyter', 'openpyxl', 'qtconsole<5.4.2', 'napari[all]<0.6.2', 'acvl_utils!=0.2.1', 'nnunetv2==2.2.1', 'loguru', 'torch<2.4.0', 'pydicom<3', 'pytest-qt', 'magicgui', 'qtpy']","
<picture>
  <source media=""(prefers-color-scheme: dark)"" srcset=""https://github.com/axondeepseg/doc-figures/blob/main/logo/logo_ads-dark-alpha.png?raw=true"" width=""385"">
  <img alt=""ADS logo (simplified image of segmented axons/myelin in blue and red beside the text 'AxonDeepSeg')"" src=https://github.com/axondeepseg/doc-figures/blob/main/logo/logo_ads-alpha.png?raw=true"" width=""385"">
</picture>


[![Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/neuropoly/axondeepseg/master?filepath=notebooks%2Fgetting_started.ipynb)
[![Build Status](https://github.com/axondeepseg/axondeepseg/actions/workflows/run_tests.yaml/badge.svg)](https://github.com/axondeepseg/axondeepseg/actions/workflows/run_tests.yaml)
[![Documentation Status](https://readthedocs.org/projects/axondeepseg/badge/?version=stable)](http://axondeepseg.readthedocs.io/en/latest/?badge=latest)
[![Coverage Status](https://coveralls.io/repos/github/axondeepseg/axondeepseg/badge.svg?branch=master)](https://coveralls.io/github/axondeepseg/axondeepseg?branch=master)
[![Twitter Follow](https://img.shields.io/twitter/follow/axondeepseg.svg?style=social&label=Follow)](https://twitter.com/axondeepseg)

Segment axon and myelin from microscopy data using deep learning. Written in Python. Using the TensorFlow framework.
Based on a convolutional neural network architecture. Pixels are classified as either axon, myelin or background.

For more information, see the [documentation website](http://axondeepseg.readthedocs.io/).

![alt tag](https://github.com/axondeepseg/doc-figures/blob/main/animations/napari.gif?raw=true)



## Help

Whether you are a newcomer or an experienced user, we will do our best to help and reply to you as soon as possible. Of course, please be considerate and respectful of all people participating in our community interactions.

* If you encounter difficulties during installation and/or while using AxonDeepSeg, or have general questions about the project, you can start a new discussion on the [AxonDeepSeg GitHub Discussions forum](https://github.com/neuropoly/axondeepseg/discussions). We also encourage you, once you've familiarized yourself with the software, to continue participating in the forum by helping answer future questions from fellow users!
* If you encounter bugs during installation and/or use of AxonDeepSeg, you can open a new issue ticket on the [AxonDeepSeg GitHub issues webpage](https://github.com/neuropoly/axondeepseg/issues).




### Napari plugin

A tutorial demonstrating the basic features of our plugin for Napari is hosted on YouTube, and can be viewed by clicking [this link](https://www.youtube.com/watch?v=zibDbpko6ko).

## References

**AxonDeepSeg**

* [Lubrano et al. *Deep Active Leaning for Myelin Segmentation on Histology Data.* Montreal Artificial Intelligence and Neuroscience 2019](https://arxiv.org/abs/1907.05143) - \[[**source code**](https://github.com/neuropoly/deep-active-learning)\]
* [Zaimi et al. *AxonDeepSeg: automatic axon and myelin segmentation from microscopy data using convolutional neural networks.* Scientific Reports 2018](https://www.nature.com/articles/s41598-018-22181-4)
* [Collin et al. *Multi-Domain Data Aggregation for Axon and Myelin Segmentation in Histology Images*. preprint](https://arxiv.org/abs/2409.11552v1) - \[[**source code**](https://github.com/axondeepseg/model_seg_generalist)]

**Applications**

* [Tabarin et al. *Deep learning segmentation (AxonDeepSeg) to generate axonal-property map from ex vivo human optic chiasm using light microscopy.* ISMRM 2019](https://www.ismrm.org/19/program_files/DP23.htm) - \[[**source code**](https://github.com/thibaulttabarin/UnAxSeg)\]
* [Lousada et al. *Characterization of cortico-striatal myelination in the context of pathological Repetitive Behaviors.*  International Basal Ganglia Society (IBAGS) 2019](http://www.ibags2019.com/key4register/images/client/863/files/Abstractbook1405.pdf)
* [Duval et al. *Axons morphometry in the human spinal cord.* NeuroImage 2019](https://www.sciencedirect.com/science/article/pii/S1053811918320044)
* [Yu et al. *Model-informed machine learning for multi-component T2 relaxometry.* Medical Image Analysis 2021](https://www.sciencedirect.com/science/article/pii/S1361841520303042) - \[[**source code**](https://github.com/thomas-yu-epfl/Model_Informed_Machine_Learning)\]

**Reviews**

* [Riordon et al. *Deep learning with microfluidics for biotechnology.* Trends in Biotechnology 2019](https://www.sciencedirect.com/science/article/pii/S0167779918302452)

## Citation

If you use this work in your research, please cite it as follows:

Zaimi, A., Wabartha, M., Herman, V., Antonsanti, P.-L., Perone, C. S., & Cohen-Adad, J. (2018). AxonDeepSeg: automatic axon and myelin segmentation from microscopy data using convolutional neural networks. Scientific Reports, 8(1), 3816. Link to paper: https://doi.org/10.1038/s41598-018-22181-4.

Copyright (c) 2018 NeuroPoly (Polytechnique Montreal)

## Licence

The MIT License (MIT)

Copyright (c) 2018 NeuroPoly, Ãcole Polytechnique, UniversitÃ© de MontrÃ©al

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the âSoftwareâ), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED âAS ISâ, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

## Contributors

Pierre-Louis Antonsanti, Stoyan Asenov, Mathieu Boudreau, Oumayma Bounou, Marie-HÃ©lÃ¨ne Bourget, Julien Cohen-Adad, Victor Herman, Melanie Lubrano, Antoine Moevus, Christian Perone, Vasudev Sharma, Thibault Tabarin, Maxime Wabartha, Aldo Zaimi.
","['Development Status :: 5 - Production/Stable', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: MIT License', 'Framework :: napari', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Homepage, https://github.com/neuropoly/axondeepseg', 'Bug Tracker, https://github.com/axondeepseg/axondeepseg/issues', 'Documentation, https://github.com/axondeepseg/axondeepseg#README.md', 'Source Code, https://github.com/axondeepseg/axondeepseg', 'User Support, https://github.com/axondeepseg/axondeepseg/issues']",,,AxonDeepSeg.ads_napari.make_qwidget,,,,
11,bbii-decon,bbii-decon,bbii-decon,0.0.1,2021-12-13,2021-12-13,"Graham Dellaire, Robert Haase",dellaire@Dal.Ca,BSD-3-Clause,https://github.com/gdellaire/bbii-decon/issues,https://pypi.org/project/bbii-decon/,,https://github.com/gdellaire/bbii-decon,Projected Barzilai-Borwein Image Deconvolution with Infeasible Iterates (BBii-Decon),>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'pypher']","# BBii-Decon

[![License](https://img.shields.io/pypi/l/bbii-decon.svg?color=green)](https://github.com/gdellaire/bbii-decon/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/bbii-decon.svg?color=green)](https://pypi.org/project/bbii-decon)
[![Python Version](https://img.shields.io/pypi/pyversions/bbii-decon.svg?color=green)](https://python.org)
[![tests](https://github.com/gdellaire/bbii-decon/workflows/tests/badge.svg)](https://github.com/gdellaire/bbii-decon/actions)
[![codecov](https://codecov.io/gh/gdellaire/bbii-decon/branch/main/graph/badge.svg)](https://codecov.io/gh/gdellaire/bbii-decon)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/bbii-decon)](https://napari-hub.org/plugins/bbii-decon)

Projected Barzilai-Borwein Image Deconvolution with Infeasible Iterates (BBii-Decon)


The projected Barzilai-Borwein method of image deconvolution utilizing infeasible iterates (BBii-Decon), utilizes Barzilai-Borwein (BB) or projected BB (PBB) method and enforces a nonnegativity constraint, but allows for infeasible iterates between projections. This algorithm (BBii) results in faster convergence than the basic PBB method, while achieving better quality images, with reduced background than the unconstrained BB method (1). 

The code represented is based on the original BBii algorithm written in MatLab by Kathleen Fraser and Dirk Arnold, which was ported to python 3.8 by Graham Dellaire, Dirk Arnold and Kathleen Fraser for non-commercial use.

The first implementation shown here is for 2D deconvolution using a known 2D PSF of 256 X 256 pixels, and images of at least 256 pixels in one dimension. One file implements just the deconvolution of a blurred image, while the second file contains a modification of the BBii-Decon algorithm that has a built in heuristic for measuring image reconstruction error relative to a ground truth image. For general 2D deconvolution, either a theoretical 2D PSF (if you know the optical properties of your system) or the central in focus image of a fluorescent bead taken with the same imaging setup (lens, magnification, camera) can produce a suitable PSF.

### GPU-acceleration

For most 2D deconvolution, optimal results are obtained with 10 iterations of the algorithm. However, if processing takes too long, acceleration using graphics processing units (GPUs) may make sense, especially for processing larger images with >10 iterations or 3D images. (Note: At this time BBii-Decon is optimized for 2D deconvolution, with a 3D implementation planned in future). 

This plugin supports accelerated processing using the [cupy](https://cupy.dev) library. To make use of it, please follow 
[the instructions](https://docs.cupy.dev/en/stable/install.html#installing-cupy-from-conda-forge) to install cupy. 
Installation may look like this:
```
conda create --name cupy_p38 python=3.8
conda activate cupy_p38
conda install -c conda-forge cupy cudatoolkit=10.2
```

If cupy installation worked out, you will find another checkbox in the user interface. By activating it, processing 
should become faster by factor 5-10, depending on processed image data and use GPU hardware.

![img.png](https://github.com/gdellaire/BBii-Decon/raw/main/demo/use_GPU_checkbox.png)

## Usage - napari

You can use the BBii deconvolution from within napari by clicking the menu `Plugins > bbii-decon > bbii deconvolution`. 
In the dialog, select the PSF, the image to process (a) and click on `Run`. After a moment, the deconvolved image (b) 
will show up.

![img.png](https://github.com/gdellaire/BBii-Decon/raw/main/demo/screenshot_napari.png)

## Usage from python

You can also call the function from python. There is a full working example in [this notebook](demo/BBii_Decon_2D_2021.ipynb).

```
from bbii_decon import bbii

bbii(PSF, image, number_of_iterations = 15, tau = 1.0e-08, rho = 0.98)
```


## Citation
1) [Kathleen Fraser, Dirk V. Arnold, and Graham Dellaire (2014). Projected Barzilai-Borwein
method with infeasible iterates for nonnegative least-squares image deblurring. In Proceedings
of the Eleventh Conference on Computer and Robot Vision (CRV 2014), Montreal, Canada, pp.
189--194.](https://ieeexplore.ieee.org/abstract/document/6816842)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `bbii-decon` via [pip]:

    pip install bbii-decon


## Installation for developers

Clone the github repository:

```
conda install git

git clone https://github.com/gdellaire/BBii-Decon.git

cd BBii-Decon

pip install -e .
```

## Deployment to pypi

For deploying the plugin to the python package index (pypi), one needs a [pypi user account](https://pypi.org/account/register/) 
first. For deploying the plugin to pypi, one needs to install some tools:

```
python -m pip install --user --upgrade setuptools wheel
python -m pip install --user --upgrade twine
```

The following command allows us to package the souce code as a python wheel. Make sure that the 'dist' and 'build' folders are deleted before doing this:

```
python setup.py sdist bdist_wheel
```

This command ships the just generated to pypi:

```
python -m twine upload --repository pypi dist/*
```

[Read more about distributing your python package via pypi](https://realpython.com/pypi-publish-python-package/#publishing-to-pypi).


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""bbii-decon"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/gdellaire/bbii-decon/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/gdellaire/bbii-decon/issues', 'Documentation, https://github.com/gdellaire/bbii-decon#README.md', 'Source Code, https://github.com/gdellaire/bbii-decon', 'User Support, https://github.com/gdellaire/bbii-decon/issues']",,,bbii-decon.napari_experimental_provide_function,,,,
12,beetlesafari,beetlesafari,beetlesafari,0.4.0,2022-04-21,2022-06-21,Robert Haase,robert.haase@tu-dresden.de,Unavailable,https://github.com/haesleinhuepf/beetlesafari,https://pypi.org/project/beetlesafari/,,https://github.com/haesleinhuepf/beetlesafari,"A napari plugin for loading and working with light sheet imaging data of developing embryos acquired using ClearControl, e.g. _Tribolium castaneum_.",>=3.7,"['numpy', 'pyopencl', 'toolz', 'scikit-image', 'requests', 'pyclesperanto-prototype', 'napari', 'magicgui', 'dask', 'cachetools', 'napari-tools-menu']","A library for working with light sheet imaging data of developing embryos acquired using [ClearControl](https://github.com/ClearControl) at the [Center for Systems Biology Dresden](https://www.csbdresden.de/), e.g. _Tribolium castaneum_.

# Installation
```
conda install -c conda-forge pyopencl
pip install beetlesafari
```
","['Programming Language :: Python :: 3', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Framework :: napari', 'Intended Audience :: Science/Research', 'Development Status :: 3 - Alpha']",,,,,,,,
13,brainglobe-stitch,brainglobe-stitch,BrainGlobe Stitch,0.0.1,2024-10-16,2024-11-19,Brainglobe Developers,Brainglobe Developers <hello@brainglobe.info>,BSD-3-Clause,https://github.com/brainglobe/brainglobe-stitch,https://pypi.org/project/brainglobe-stitch/,,,A tool to stich large tiled datasets generated by the mesoSPIM.,>=3.10,"['napari>=0.4.18', 'brainglobe-utils>=0.3.4', 'h5py', 'napari-ome-zarr', 'ome-zarr', 'zarr', 'numpy', 'qtpy', 'tifffile', 'pytest; extra == ""dev""', 'pytest-cov; extra == ""dev""', 'pytest-mock; extra == ""dev""', 'pytest-qt; extra == ""dev""', 'pyqt5; extra == ""dev""', 'coverage; extra == ""dev""', 'tox; extra == ""dev""', 'pooch; extra == ""dev""', 'black; extra == ""dev""', 'mypy; extra == ""dev""', 'pre-commit; extra == ""dev""', 'ruff; extra == ""dev""', 'setuptools-scm; extra == ""dev""']","# brainglobe-stitch

Stitching tiled 3D light-sheet data in napari

<p align=""center"">
  <img height=""460"" src=""https://github.com/user-attachments/assets/91f61f24-6fcf-4aa1-8a8f-de8c5e3db4a2"" alt=""Stitching a mouse brain acquired at a resolution of 4.06 &micro;m/px, 4.06 &micro;m/px, 5 &micro;m/px using 4 tiles"">
</p>

----------------------------------

A [napari] plugin for stitching tiled 3D acquisitions from a [mesoSPIM] light-sheet microscope.
The plugin utilises [BigStitcher] to align the tiles and napari to visualise the stitched data.

## Installation

We strongly recommend to use a virtual environment manager (like `conda`). The installation instructions below
will not specify the Qt backend for napari, and you will therefore need to install that separately. Please see the
[`napari` installation instructions](https://napari.org/stable/tutorials/fundamentals/installation.html) for further advice on this.

To install latest development version:

    pip install git+https://github.com/brainglobe/brainglobe-stitch.git

This plugin requires Fiji to be installed on your system. You can download Fiji [here](https://imagej.net/Fiji/Downloads).

The BigStitcher plugin must be installed in Fiji. Please follow the instructions [here](https://imagej.net/plugins/bigstitcher/#download).

## Seeking help or contributing
We are always happy to help users of our tools, and welcome any contributions. If you would like to get in contact with us for any reason, please see the [contact page of our website](https://brainglobe.info/contact.html).

## Citation
If you find this package useful, please make sure to cite the original BigStitcher publication:
> HÃ¶rl, D., Rojas Rusak, F., Preusser, F. *et al.* BigStitcher: reconstructing high-resolution image datasets of cleared and expanded samples. Nat Methods 16, 870â874 (2019). https://doi.org/10.1038/s41592-019-0501-0


## License
Distributed under the terms of the [BSD-3] license,
""brainglobe-stitch"" is free and open source software

## Acknowledgements
This [napari] plugin was generated with [Cookiecutter] using napari's [cookiecutter-napari-plugin] template and the [Neuroinformatics Unit's template](https://github.com/neuroinformatics-unit/python-cookiecutter).

[napari]: https://napari.org
[mesoSPIM]: https://www.mesospim.org/
[BigStitcher]: https://imagej.net/BigStitcher
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License', 'Topic :: Scientific/Engineering :: Image Processing']","['Homepage, https://brainglobe.info', 'Bug Tracker, https://github.com/brainglobe/brainglobe-stitch/issues', 'Documentation, https://github.com/brainglobe/brainglobe-stitch#README.md', 'Source Code, https://github.com/brainglobe/brainglobe-stitch', 'User Support, https://forum.image.sc/tag/brainglobe']",,,brainglobe-stitch.make_stitching_widget,,,,
14,biaplotter,biaplotter,Canvas Widget from BiAPoL,0.4.2,2024-05-06,2025-07-29,Marcelo Leomil Zoccoler,Marcelo Leomil Zoccoler <marzoccoler@gmail.com>,"Copyright (c) 2024, DFG Cluste...",https://github.com/BiAPoL/biaplotter/issues,https://pypi.org/project/biaplotter/,,,A base napari plotter widget for interactive plotting,>=3.10,"['numpy>=1.22.0', 'magicgui', 'qtpy', 'napari-matplotlib', 'nap-plot-tools>=0.1.0', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# biaplotter

[![License BSD-3](https://img.shields.io/pypi/l/biaplotter.svg?color=green)](https://github.com/BiAPoL/biaplotter/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/biaplotter.svg?color=green)](https://pypi.org/project/biaplotter)
[![Python Version](https://img.shields.io/pypi/pyversions/biaplotter.svg?color=green)](https://python.org)
[![tests](https://github.com/BiAPoL/biaplotter/workflows/tests/badge.svg)](https://github.com/BiAPoL/biaplotter/actions)
[![codecov](https://codecov.io/gh/BiAPoL/biaplotter/branch/main/graph/badge.svg)](https://codecov.io/gh/BiAPoL/biaplotter)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/biaplotter)](https://napari-hub.org/plugins/biaplotter)

A base napari plotter widget for interactive plotting

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Documentation

The full documentation with API and examples can be found [here](https://biapol-biaplotter.readthedocs.io/en/stable).

## Installation

* Make sure you have Python in your computer, e.g. download [miniforge](https://github.com/conda-forge/miniforge?tab=readme-ov-file#download).

* Create a new environment, for example, like this:

```
mamba create --name biaplotter-env python=3.11
```

If you never used mamba/conda environments before, take a look at [this blog post](https://biapol.github.io/blog/mara_lampert/getting_started_with_mambaforge_and_python/readme.html).

* **Activate** the new environment with `mamba`:

```
mamba activate biaplotter-env
```

* Install [napari](https://napari.org/stable/), e.g. via `mamba`:

```
mamba install -c conda-forge napari pyqt
```

Afterwards, install `biaplotter` via `pip`:

```
pip install biaplotter
```

To install latest development version :

```
pip install git+https://github.com/BiAPoL/biaplotter.git
```


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""biaplotter"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/BiAPoL/biaplotter/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Visualization']","['Homepage, https://github.com/BiAPoL/biaplotter', 'Bug Tracker, https://github.com/BiAPoL/biaplotter/issues', 'Documentation, https://biapol-biaplotter.readthedocs.io/en/stable/', 'Source Code, https://github.com/BiAPoL/biaplotter', 'User Support, https://github.com/BiAPoL/biaplotter/issues']",,,biaplotter.make_qwidget,,,,
15,brainglobe-registration,brainglobe-registration,BrainGlobe Registration,0.0.4,2025-01-27,2025-05-30,Brainglobe Developers,Brainglobe Developers <hello@brainglobe.info>,BSD-3-Clause,https://github.com/brainglobe/brainglobe-registration,https://pypi.org/project/brainglobe-registration/,,,A napari plugin for registration to a  BrainGlobe atlas.,>=3.11,"['napari!=0.6.0,>=0.4.18', 'brainglobe-atlasapi', 'brainglobe-utils>=0.4.3', 'dask', 'dask-image', 'itk-elastix', 'lxml_html_clean', 'numpy', 'pandas', 'pytransform3d', 'qtpy', 'qt-niu', 'scikit-image', 'scipy', 'pytest; extra == ""dev""', 'pytest-cov; extra == ""dev""', 'pytest-mock; extra == ""dev""', 'pytest-qt; extra == ""dev""', 'coverage; extra == ""dev""', 'tox; extra == ""dev""', 'black; extra == ""dev""', 'mypy; extra == ""dev""', 'pre-commit; extra == ""dev""', 'ruff; extra == ""dev""', 'setuptools_scm; extra == ""dev""', 'pyqt5; extra == ""dev""']","# brainglobe-registration

[![License BSD-3](https://img.shields.io/pypi/l/brainglobe-registration.svg?color=green)](https://github.com/brainglobe/brainglobe-registration/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/brainglobe-registration.svg?color=green)](https://pypi.org/project/brainglobe-registration)
[![Python Version](https://img.shields.io/pypi/pyversions/brainglobe-registration.svg?color=green)](https://python.org)
[![tests](https://github.com/brainglobe/brainglobe-registration/workflows/tests/badge.svg)](https://github.com/brainglobe/brainglobe-registration/actions)
[![codecov](https://codecov.io/gh/brainglobe/brainglobe-registration/branch/main/graph/badge.svg)](https://codecov.io/gh/brainglobe/brainglobe-registration)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/brainglobe-registration)](https://napari-hub.org/plugins/brainglobe-registration)

Registration to a BrainGlobe atlas using Elastix

----------------------------------

> [!WARNING]
> This tool is in very early development. The interface may change and some features are not yet available.

A [napari] plugin for registering images to a BrainGlobe atlas.

![brainglobe-registration](./imgs/brainglobe_registration_main.png)

## Usage

1. Open `napari`.
2. [Install the plugin](#Installation).
3. Open the widget by selecting `Plugins > BrainGlobe Registration` in the napari menu bar near the
top left of the window.
![brainglobe-registration-plugin](./imgs/brainglobe_registration_plugin_window.png)
The `BrainGlobe Registration` plugin will appear on the right hand side of the napari window.
4. Open the image you want to register in napari (a sample 2D image can be found by selecting `File > Open Sample > Sample Brain Slice`).
5. Select the atlas you want to register to from the dropdown menu.
![brainglobe-registration-atlas-selection](./imgs/brainglobe_registration_atlas_selection.png)
The atlas will appear in the napari viewer. Select the approximate `Z` slice of the atlas that you want to register to,
using the slider at the bottom of the napari viewer.
![brainglobe-registration-atlas-selection](./imgs/brainglobe_registration_atlas_selection_2.png)
6. Adjust the sample image to roughly match the atlas image.
You can do this by adjusting X and Y translation as well as rotating around the centre of the image.
You can overlay the two images by toggling `Grid` mode in the napari viewer (Ctrl+G).
You can then adjust the color map and opacity of the atlas image to make manual alignment easier.
![brainglobe-registration-overlay](./imgs/brainglobe_registration_overlay.png)
The sample image can be reset to its original position and orientation by clicking `Reset Image` in the `BrainGlobe Registration` plugin window.
7. Select the transformations you want to use from the dropdown menu. Set the transformation type to empty to remove a step.
Select from one of the three provided default parameter sets (elastix, ARA, or IBL). Customise the parameters further in the
`Parameters` tab.
8. Click `Run` to register the image. The registered image will appear in the napari viewer.
![brainglobe-registration-registered](./imgs/brainglobe_registration_registered.png)
![brainglobe-registration-registered](./imgs/brainglobe_registration_registered_stacked.png)

## Installation

We strongly recommend to use a virtual environment manager (like `conda` or `venv`). The installation instructions below
will not specify the Qt backend for napari, and you will therefore need to install that separately. Please see the
[`napari` installation instructions](https://napari.org/stable/tutorials/fundamentals/installation.html) for further advice on this.

You can install `brainglobe-registration` via [pip]:

    pip install brainglobe-registration

or [via napari](https://napari.org/stable/plugins/start_using_plugins/finding_and_installing_plugins.html).

To install the latest development version :

    pip install git+https://github.com/brainglobe/brainglobe-registration.git

## License

Distributed under the terms of the [BSD-3] license,
""brainglobe-registration"" is free and open source software

## Seeking help or contributing
We are always happy to help users of our tools, and welcome any contributions. If you would like to get in contact with us for any reason, please see the [contact page of our website](https://brainglobe.info/contact.html).

## Citation
If you find this package useful, and use it in your research, please cite the following:
> Igor Tatarnikov, Alessandro Felder, Kimberly Meechan, & Adam Tyson. (2025). brainglobe/brainglobe-registration. Zenodo. https://doi.org/10.5281/zenodo.14750325

## Acknowledgements

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/brainglobe/brainglobe-registration/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Science/Research', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License', 'Topic :: Scientific/Engineering :: Image Processing']","['Homepage, https://brainglobe.info', 'Bug Tracker, https://github.com/brainglobe/brainglobe-registration/issues', 'Documentation, https://github.com/brainglobe/brainglobe-registration#README.md', 'Source Code, https://github.com/brainglobe/brainglobe-registration', 'User Support, https://forum.image.sc/tag/brainglobe']",,,brainglobe-registration.make_registration_widget,brainglobe-registration.load_sample_2d,,,
16,brainglobe-segmentation,brainglobe-segmentation,brainglobe-segmentation,1.3.3,2023-11-06,2025-05-30,"Adam Tyson, Horst Obenhaus","""Adam Tyson, Horst Obenhaus"" <code@adamltyson.com>",BSD-3-Clause,https://github.com/brainglobe/brainglobe-segmentation/issues,https://pypi.org/project/brainglobe-segmentation/,,,Segmentation of anatomical structures in a common coordinate space,>=3.11,"['brainglobe-atlasapi>=2.0.1', 'brainglobe-napari-io>=0.3.0', 'brainglobe-utils>=0.5.0', 'napari!=0.6.0,>=0.5', 'numpy', 'pandas[hdf5]', 'qtpy', 'scikit-image', 'scipy', 'tifffile', 'qt-niu', 'black; extra == ""dev""', 'gitpython; extra == ""dev""', 'pre-commit; extra == ""dev""', 'pytest; extra == ""dev""', 'coverage; extra == ""dev""', 'pytest-cov; extra == ""dev""', 'pytest-qt; extra == ""dev""', 'napari-time-slicer; extra == ""dev""']","[![Python Version](https://img.shields.io/pypi/pyversions/brainglobe-segmentation.svg)](https://pypi.org/project/brainglobe-segmentation)
[![PyPI](https://img.shields.io/pypi/v/brainglobe-segmentation.svg)](https://pypi.org/project/brainglobe-segmentation)
[![Wheel](https://img.shields.io/pypi/wheel/brainglobe-segmentation.svg)](https://pypi.org/project/brainglobe-segmentation)
[![Development Status](https://img.shields.io/pypi/status/brainglobe-segmentation.svg)](https://github.com/brainglobe/brainglobe-segmentation)
[![Tests](https://img.shields.io/github/actions/workflow/status/brainglobe/brainglobe-segmentation/test_and_deploy.yml?branch=main)](https://github.com/brainglobe/brainglobe-segmentation/actions)
[![codecov](https://codecov.io/gh/brainglobe/brainglobe-segmentation/graph/badge.svg?token=WP9KTPZE5R)](https://codecov.io/gh/brainglobe/brainglobe-segmentation)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/python/black)
[![Twitter](https://img.shields.io/twitter/follow/brain_globe?style=social)](https://twitter.com/brain_globe)

# brainglobe-segmentation

Segmentation of anatomical structures in a common coordinate space

## Installation
**PyPI**
```
pip install brainglobe-segmentation
```

**conda**
```
conda install -c conda-forge brainglobe-segmentation
```

N.B. Your data will need to be registered to an anatomical atlas first.

## Usage
See [user guide](https://brainglobe.info/documentation/brainglobe-segmentation/index.html).

## Seeking help or contributing
We are always happy to help users of our tools, and welcome any contributions. If you would like to get in contact with us for any reason, please see the [contact page of our website](https://brainglobe.info/contact.html).

## Citing brainglobe-segmentation

If you find brainglobe-segmentation useful, and use it in your research, please let us know and also cite the paper:

> Tyson, A. L., V&eacute;lez-Fort, M.,  Rousseau, C. V., Cossell, L., Tsitoura, C., Lenzi, S. C., Obenhaus, H. A., Claudi, F., Branco, T.,  Margrie, T. W. (2022). Accurate determination of marker location within whole-brain microscopy images. Scientific Reports, 12, 867 [doi.org/10.1038/s41598-021-04676-9](https://doi.org/10.1038/s41598-021-04676-9)
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13']","['Homepage, https://brainglobe.info/', 'Source Code, https://github.com/brainglobe/brainglobe-segmentation', 'Bug Tracker, https://github.com/brainglobe/brainglobe-segmentation/issues', 'Documentation, https://brainglobe.info/documentation/brainglobe-segmentation/index.html', 'User Support, https://forum.image.sc/tag/brainglobe']",,,brainglobe-segmentation.SegmentationWidget,,,,
17,brainglobe-napari-io,brainglobe-napari-io,brainglobe-napari-io,0.3.6,2021-03-12,2025-05-30,Adam Tyson,Adam Tyson <hello@brainglobe.info>,BSD-3-Clause,https://github.com/brainglobe/brainglobe-napari-io/issues,https://pypi.org/project/brainglobe-napari-io/,,,Read and write files from the BrainGlobe computational neuroanatomy suite into napari,>=3.11,"['brainglobe-atlasapi>=2.0.1', 'brainglobe-space>=1.0.0', 'brainglobe-utils>=0.4.2', 'napari!=0.6.0,>=0.5', 'tifffile>=2020.8.13', 'numpy', 'pandas', 'pytest; extra == ""dev""', 'pytest-cov; extra == ""dev""', 'coverage; extra == ""dev""', 'tox; extra == ""dev""', 'black; extra == ""dev""', 'mypy; extra == ""dev""', 'pre-commit; extra == ""dev""', 'ruff; extra == ""dev""', 'setuptools_scm; extra == ""dev""']","# napari-brainglobe-io

[![License](https://img.shields.io/pypi/l/brainglobe-napari-io.svg?color=green)](https://github.com/brainglobe/brainglobe-napari-io/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/brainglobe-napari-io.svg?color=green)](https://pypi.org/project/brainglobe-napari-io)
[![Python Version](https://img.shields.io/pypi/pyversions/brainglobe-napari-io.svg?color=green)](https://python.org)
[![tests](https://github.com/brainglobe/brainglobe-napari-io/workflows/tests/badge.svg)](https://github.com/brainglobe/brainglobe-napari-io/actions)
[![codecov](https://codecov.io/gh/brainglobe/brainglobe-napari-io/branch/main/graph/badge.svg)](https://codecov.io/gh/brainglobe/brainglobe-napari-io)

Visualise cellfinder and brainreg results with napari


----------------------------------


## Installation
This package is likely already installed
(e.g. with cellfinder, brainreg or another napari plugin), but if you want to
install it again, either use the napari plugin install GUI or you can
install `brainglobe-napari-io` via [pip]:

    pip install brainglobe-napari-io

## Usage
* Open napari (however you normally do it, but typically just type `napari` into your terminal, or click on your desktop icon)

### brainreg
#### Sample space
Drag your [brainreg](https://github.com/brainglobe/brainreg) output directory (the one with the log file) onto the napari window.

Various images should then open, including:
* `Registered image` - the image used for registration, downsampled to atlas resolution
* `atlas_name` - e.g. `allen_mouse_25um` the atlas labels, warped to your sample brain
* `Boundaries` - the boundaries of the atlas regions

If you downsampled additional channels, these will also be loaded.

Most of these images will not be visible by default. Click the little eye icon to toggle visibility.

_N.B. If you use a high resolution atlas (such as `allen_mouse_10um`), then the files can take a little while to load._

![sample_space](https://raw.githubusercontent.com/brainglobe/brainglobe-napari-io/master/resources/sample_space.gif)


#### Atlas space
`napari-brainreg` also comes with an additional plugin, for visualising your data
in atlas space.

This is typically only used in other software, but you can enable it yourself:
* Open napari
* Navigate to `Plugins` -> `Plugin Call Order`
* In the `Plugin Sorter` window, select `napari_get_reader` from the `select hook...` dropdown box
* Drag `brainreg_read_dir_atlas_space` (the atlas space viewer plugin) above `brainreg_read_dir` (the normal plugin) to ensure that the atlas space plugin is used preferentially.


### cellfinder
#### Load cellfinder XML file
* Load your raw data (drag and drop the data directories into napari, one at a time)
* Drag and drop your cellfinder XML file (e.g. `cell_classification.xml`) into napari.

#### Load cellfinder directory
* Load your raw data (drag and drop the data directories into napari, one at a time)
* Drag and drop your cellfinder output directory into napari.

The plugin will then load your detected cells (in yellow) and the rejected cell
candidates (in blue). If you carried out registration, then these results will be
overlaid (similarly to the loading brainreg data, but transformed to the
coordinate space of your raw data).

![load_data](https://raw.githubusercontent.com/brainglobe/brainglobe-napari-io/master/resources/load_data.gif)
**Loading raw data**

![load_data](https://raw.githubusercontent.com/brainglobe/brainglobe-napari-io/master/resources/load_results.gif)
**Loading cellfinder results**

## Seeking help or contributing
We are always happy to help users of our tools, and welcome any contributions. If you would like to get in contact with us for any reason, please see the [contact page of our website](https://brainglobe.info/contact.html).
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Science/Research', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Recognition']","['Homepage, https://brainglobe.info', 'Source Code, https://github.com/brainglobe/brainglobe-napari-io', 'Bug Tracker, https://github.com/brainglobe/brainglobe-napari-io/issues', 'Documentation, https://docs.brainglobe.info', 'User Support, https://forum.image.sc/tag/brainglobe', 'Twitter, https://twitter.com/brain_globe']",brainglobe-napari-io.brainreg_read_dir,brainglobe-napari-io.cellfinder_write_multiple_xml,,,['*.tiff'],['.xml'],
18,brendan-beads,brendan-beads,Brendan Beads,0.2,2025-05-20,2025-06-13,Anders Folkesson,anders.folkesson@gu.se,MIT,https://github.com/xfolka/brendan-beads/issues,https://pypi.org/project/brendan-beads/,,,Calculating and visualizing distances of beads to surface,>=3.10,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'pyometiff', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'numpy; extra == ""testing""', 'pandas; extra == ""testing""', 'matplotlib; extra == ""testing""', 'pyometiff; extra == ""testing""']","# brendan-beads

[![License MIT](https://img.shields.io/pypi/l/brendan-beads.svg?color=green)](https://github.com/xfolka/brendan-beads/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/brendan-beads.svg?color=green)](https://pypi.org/project/brendan-beads)
[![Python Version](https://img.shields.io/pypi/pyversions/brendan-beads.svg?color=green)](https://python.org)
[![tests](https://github.com/xfolka/brendan-beads/workflows/tests/badge.svg)](https://github.com/xfolka/brendan-beads/actions)
[![codecov](https://codecov.io/gh/xfolka/brendan-beads/branch/main/graph/badge.svg)](https://codecov.io/gh/xfolka/brendan-beads)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/brendan-beads)](https://napari-hub.org/plugins/brendan-beads)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

Calculating and visualizing distances of beads to surface

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `brendan-beads` via [pip]:

    pip install brendan-beads



To install latest development version :

    pip install git+https://github.com/xfolka/brendan-beads.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""brendan-beads"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/xfolka/brendan-beads/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/xfolka/brendan-beads/issues', 'Documentation, https://github.com/xfolka/brendan-beads#README.md', 'Source Code, https://github.com/xfolka/brendan-beads', 'User Support, https://github.com/xfolka/brendan-beads/issues']",,,brendan-beads.make_main_widget,,,,
19,blik,blik,blik,0.9.2,2022-04-21,2025-05-16,Lorenzo Gaifas,Lorenzo Gaifas <brisvag@gmail.com>,GPLv3,https://github.com/brisvag/blik,https://pypi.org/project/blik/,,,Python tool for visualising and interacting with cryo-ET and subtomogram averaging data.,>=3.10,"['cryohub>=0.6.4', 'cryotypes>=0.2.0', 'dask', 'einops', 'magicgui>=0.4.0', 'morphosamplers[segment]>=0.0.10', 'numpy', 'packaging', 'pandas', 'pydantic', 'scipy', ""napari-label-interpolator>=0.1.1; extra == 'all'"", ""napari-properties-plotter; extra == 'all'"", ""napari-properties-viewer; extra == 'all'"", ""napari[all]>=0.6.0; extra == 'all'"", ""black; extra == 'dev'"", ""ipython; extra == 'dev'"", ""mypy; extra == 'dev'"", ""napari[all]>=0.6.0; extra == 'dev'"", ""pdbpp; extra == 'dev'"", ""pre-commit; extra == 'dev'"", ""pytest-cov; extra == 'dev'"", ""pytest-qt; extra == 'dev'"", ""pytest>=6.0; extra == 'dev'"", ""rich; extra == 'dev'"", ""ruff; extra == 'dev'"", ""napari[all]>=0.6.0; extra == 'test'"", ""pytest-cov; extra == 'test'"", ""pytest-qt; extra == 'test'"", ""pytest>=6.0; extra == 'test'""]","![logo](https://github.com/brisvag/blik/raw/main/docs/images/logo.png)

# blik

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.10090438.svg)](https://zenodo.org/doi/10.5281/zenodo.10090438)
[![Paper DOI](https://zenodo.org/badge/DOI/10.1371/journal.pbio.3002447.svg)](https://doi.org/10.1371/journal.pbio.3002447)
[![License](https://img.shields.io/pypi/l/blik.svg?color=green)](https://github.com/brisvag/blik/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/blik.svg?color=green)](https://pypi.org/project/blik)
[![Python Version](https://img.shields.io/pypi/pyversions/blik.svg?color=green)](https://python.org)
[![CI](https://github.com/brisvag/blik/actions/workflows/ci.yml/badge.svg)](https://github.com/brisvag/blik/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/brisvag/blik/branch/main/graph/badge.svg)](https://codecov.io/gh/brisvag/blik)


![blik showcase](https://private-user-images.githubusercontent.com/23482191/361246457-b7447060-7ccd-4a8c-a41c-55c1678bf089.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjQ2MDQ0OTksIm5iZiI6MTcyNDYwNDE5OSwicGF0aCI6Ii8yMzQ4MjE5MS8zNjEyNDY0NTctYjc0NDcwNjAtN2NjZC00YThjLWE0MWMtNTVjMTY3OGJmMDg5LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA4MjUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwODI1VDE2NDMxOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTRkZTAxMmU0MjViNjA4NTRmMWRlYzRhYmJkYjNkNWRiNjcxZjRjYWI1MWJkYmMxZmFiZjZmNzFhZTE0ODkwY2MmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.ye5hVTZ-yociOCArw2_KSlvde1MZCQuVYH2LQgul4B0)

**`blik`** is a tool for visualising and interacting with cryo-ET and subtomogram averaging data. It leverages the fast, multi-dimensional [napari viewer](https://napari.org) and the scientific python stack.

**DISCLAIMER**: this package is in development phase. Expect bugs and crashes. Please, report them on the issue tracker and ask if anything is unclear!

## Installation

You can either install `blik` through the [napari plugin system](https://napari.org/plugins/index.html), through pip, or get both napari and blik directly with:

```bash
pip install ""blik[all]""
```

The `[all]` qualifier also installs `pyqt5` as the napari GUI backend, and a few additional napari plugins that you might find useful in your workflow:
- [napari-properties-plotter](https://github.com/brisvag/napari-properties-plotter)
- [napari-properties-viewer](https://github.com/kevinyamauchi/napari-properties-viewer)
- [napari-label-interpolator](https://github.com/brisvag/napari-label-interpolator)

### Nightly build

If you'd like the most up to date `blik` possible, you can install directly from the `main` branch on github. This also uses napari `main`, so expect some instability!

```
pip install ""git+https://github.com/brisvag/blik.git@main#egg=blik[all]""
pip install ""git+https://github.com/napari/napari.git@main#egg=napari[all]""
```

## Basic Usage

From the command line:
```bash
napari -w blik -- /path/to.star /path/to/mrc/files/*
```

The `-w blik` is important for proper initialization of all the layers. Always open the main widget open to ensure nothing goes wrong!

*`blik` is just `napari`*. Particles and images are exposed as simple napari layers, which can be analysed and manipulated with simple python, and most importantly other [napari plugins](https://napari-hub.org/).

## Widgets

The main widget has a few functions:

- `experiment`: quickly switch to a different experiment id (typically, everything related to an individual tomogram such as volume, particles and segmentations)
- `new`: generate a new `segmentation`, a new manually-picked set of `particles`, or a new `surface`, `sphere`, or `filament picking` for segmentation, particle generation or volume resampling.
- `add to exp`: add a layer to the currently selected `experiment` (just a shorthand for `layer.metadata['experiment_id'] = current_exp_id`)
- `slice_thickness`: changes the slicing thickness in all dimensions in napari. Images will be averaged over that thickness, and all particles in the slice will be displayed.

There are also widgets for picking surfaces, spheres and filaments:

- `surface`: process a previously picked `surface picking` layer to generate a surface mesh and distribute particles on it for subtomogram averaging, or resample a tomogram along the surface.
- `sphere`: process a previously picked `sphere picking` layer to generate a sphere mesh and distribute particles on it for subtomogram averaging.
- `filament`: process a previously picked `filament picking` layer to generate a filament and distribute particles on it for subtomogram averaging, or resample a tomogram along the filament.

# References

If you use `blik`, please cite the repo on zenodo and the paper on Plos Biology: [https://doi.org/10.1371/journal.pbio.3002447](https://doi.org/10.1371/journal.pbio.3002447).
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Natural Language :: English', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Visualization', 'Typing :: Typed']","['homepage, https://github.com/brisvag/blik', 'repository, https://github.com/brisvag/blik']",blik.read_files,blik.write_image,blik.main_widget,blik.sample_hiv_dataset,"['*.mrc', '*.mrcs', '*.st', '*.map', '*.hdf', '*.em', '*.star', '*.tbl', '*.box', '*.cbox', '*.picks', '*.surf', '*.rec']","['.mrc', '.mrcs', '.st', '.rec']","['.mrc', '.mrcs', '.st']"
20,brainways,brainways,Brainways,0.1.16.2,2024-11-14,2025-05-22,Ben Kantor,benkantor@mail.tau.ac.il,GPL-3.0,https://github.com/bkntr/brainways/issues,https://pypi.org/project/brainways/,,https://github.com/bkntr/brainways,Brainways,>=3.9,"['aicsimageio[base-imageio]==4.14.0', 'aicspylibczi', 'brainglobe-atlasapi', 'click', 'dacite', 'datasets', 'fsspec', 'huggingface-hub', 'importlib-resources', 'itk-elastix', 'kornia', 'napari[all]>=0.5.0', 'natsort', 'networkx', 'numpy<2.0.0', 'opencv-contrib-python-headless', 'opencv-python-headless', 'openpyxl', 'pandas', 'paquo', 'qtpy', 'scikit-image', 'scikit-learn', 'scikit-posthocs', 'stardist', 'statsmodels', 'tensorflow', 'toml', 'torch', 'torchvision', 'lightning', 'tqdm', 'scyjava', 'jpype1==1.5.0', 'albumentations==2.0.5', 'jsonargparse<5.0.0,>=4.0.0', 'timm<2.0.0,>=1.0.0', 'pre-commit; extra == ""dev""', 'scipy-stubs; extra == ""dev""', 'py; extra == ""testing""', 'pyqt5; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-mock; extra == ""testing""', 'pytest-qt<4.1.0; extra == ""testing""', 'tox; extra == ""testing""']","# Brainways

[![DOI](https://img.shields.io/badge/DOI-10.1101/2023.05.25.542252-green.svg)](https://doi.org/10.1101/2023.05.25.542252)
[![License GNU GPL v3.0](https://img.shields.io/pypi/l/brainways.svg?color=green)](https://github.com/bkntr/brainways/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/brainways.svg?color=green)](https://pypi.org/project/brainways)
[![Python Version](https://img.shields.io/pypi/pyversions/brainways.svg?color=green)](https://python.org)
[![tests](https://github.com/bkntr/brainways/workflows/tests/badge.svg)](https://github.com/bkntr/brainways/actions)
[![codecov](https://codecov.io/gh/bkntr/brainways/branch/main/graph/badge.svg)](https://codecov.io/gh/bkntr/brainways)
[![Documentation Status](https://readthedocs.org/projects/brainways/badge/?version=latest)](https://brainways.readthedocs.io/en/latest/?badge=latest)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/brainways)](https://napari-hub.org/plugins/brainways)

## Overview

Brainways is an AI-powered tool designed for the automated analysis of brain-wide activity networks from fluorescence imaging in coronal slices. It streamlines the process of registration, cell quantification, and statistical comparison between experimental groups, all accessible through a user-friendly interface without requiring programming expertise. For advanced users, Brainways also offers a flexible Python backend for customization.

![Brainways User Interface Demo](assets/brainways-ui.gif)

## Key Features

Brainways simplifies complex analysis workflows into manageable steps:

1.  **Rigid Registration:** Aligns coronal slices to a 3D reference atlas.
2.  **Non-rigid Registration:** Refines alignment to account for individual variations and tissue distortions.
3.  **Cell Detection:** Automatically identifies cells using the [StarDist](https://github.com/stardist/stardist) algorithm.
4.  **Quantification:** Counts cells within defined brain regions.
5.  **Statistical Analysis:**
    *   Performs ANOVA contrast analysis between experimental conditions.
    *   Conducts Partial Least Squares (PLS) analysis.
    *   Generates network graphs visualizing brain-wide activity patterns.

## Getting Started

!!! note ""Windows GPU Support Pre-installation""
    If you plan to use Brainways with GPU acceleration on Windows, you must install GPU-compatible versions of PyTorch and TensorBoard *before* installing Brainways. Follow the instructions on the [PyTorch](https://pytorch.org/get-started/locally/) and [TensorBoard](https://www.tensorflow.org/install/pip) websites. Once these dependencies are met, proceed with the Brainways installation below.

Install and launch the Brainways user interface using pip:

```bash
pip install brainways
brainways ui
```

For a detailed walkthrough, please refer to our [Getting Started Guide](02_getting_started.md).

!!! tip ""Achieving Reliable Results""
    To ensure the best possible outcomes with Brainways, we highly recommend reviewing our [Best Practices Guide](04_best_practices.md).

## Architecture

Brainways is built as a monorepo containing two primary components:

*   `brainways`: The core library housing all backend functionalities, including registration algorithms, quantification logic, and statistical tools. It can be used programmatically via Python for custom workflows. The automatic registration model inference code resides within the `brainways.model` subpackage.
*   `brainways.ui`: A [napari](https://napari.org/stable/) plugin providing the graphical user interface for interactive analysis.

## Development Status

Brainways is under active development by Ben Kantor at the Bartal Lab, Tel Aviv University, Israel. Check out our [releases page](https://github.com/bkntr/brainways/releases) for the latest updates.

## Citation

If Brainways contributes to your research, please cite our publication: [Kantor and Bartal (2025)](https://doi.org/10.1038/s41386-025-02105-3).

```bibtex
@article{kantor2025mapping,
    title={Mapping brain-wide activity networks: brainways as a tool for neurobiological discovery},
    author={Kantor, Ben and Ruzal, Keren and Ben-Ami Bartal, Inbal},
    journal={Neuropsychopharmacology},
    pages={1--11},
    year={2025},
    publisher={Springer International Publishing Cham}
}
```

## License

Brainways is distributed under the terms of the [GNU GPL v3.0] license. It is free and open-source software.

## Issues and Support

Encountering problems? Please [file an issue] on our GitHub repository with a detailed description of the problem.

[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[file an issue]: https://github.com/bkntr/brainways/issues
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: Implementation :: CPython', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/bkntr/brainways/issues', 'Documentation, https://github.com/bkntr/brainways#README.md', 'Source Code, https://github.com/bkntr/brainways', 'User Support, https://github.com/bkntr/brainways/issues']",brainways.read_bwp,,brainways.make_qwidget,brainways.load_sample_project,['*.bwp'],,
21,cellpose-counter,cellpose-counter,CellPose Counter,0.1.8,2024-11-21,2024-12-10,Nicolas Buitrago,nsb5@rice.edu,"Copyright (c) 2024, Szablowski...",,https://pypi.org/project/cellpose-counter/,None,,Cell/nuclei counter using cellpose models,>=3.10,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'napari[all]>=0.5.4', 'cellpose>=3.1.0', 'accelerate>=1.1.1', 'napari-czifile2>=0.2.7', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# cellpose-counter

[![License BSD-3](https://img.shields.io/pypi/l/cellpose-counter.svg?color=green)](https://github.com/szablowskilab/cellpose-counter/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/cellpose-counter.svg?color=green)](https://pypi.org/project/cellpose-counter)
[![Python Version](https://img.shields.io/pypi/pyversions/cellpose-counter.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/cellpose-counter)](https://napari-hub.org/plugins/cellpose-counter)

A Napari plugin for cell/nuclei counting from a region or interest using
cellpose models.

----------------------------------

## Installation

Option 1: via [pip](https://pip.pypa.io/en/stable/) (or pip alternatives like
[uv](https://docs.astral.sh/uv/)):

Below is a minimally working example of setting up a new virtual environment and
installing the counter module with uv on Unix based systems.

```bash
uv venv # create virtual environment in .venv
source .venv/bin/activate

uv pip install ""napari[all]"" cellpose-counter
```

Option 2: via Docker/Podman. The provide [Dockerfile](./Dockerfile) can be used
to install Napari and the counter plugin along with a preconfigured Xpra server
using the napari-xpra image. Below is an example of building the image and
running the application with GPU support.

```bash
podman build -t cellpose-counter .
podman run -it -d \
    -p 9876:9876 \
    -e XPRA_START=""python3 -m napari -w cellpose-counter"" \
    --device nvidia.com/gpu=all
```

Then, navigate to `http://localhost:9876` to view the application in a virtual
machine.

Note: There is a known issue installing the plugin directly from Napari. Please
see [this issue](https://github.com/szablowskilab/cellpose-counter/issues/12)
for more updates.

## GPU Acceleration

To enable GPU acceleration, you will need a CUDA capable GPU along with the
[CUDA toolkit](https://developer.nvidia.com/cuda-toolkit) and [cudNN library](https://developer.nvidia.com/cudnn).

For instructions on installing cuda toolkit and cudNN, see:

1. [cuda toolkit installation for Linux](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#fedora)
1. [cudNN installation for Linux](https://docs.nvidia.com/deeplearning/cudnn/latest/installation/linux.html)

Once these are installed, update the pytorch package by first uninstalling torch
(if already instsalled).

```bash
uv pip uninstall torch
```

Then install a torch version that is compatible with your CUDA version. For example,

```bash
uv pip install torch --index-url https://download.pytorch.org/whl/cu118
```

After installation, you can verify in an interactive python console with:

```python3
import torch
torch.cuda.is_available()
```

## Usage

To open Napari with the cellpose counter loaded, run `napari -w cellpose-counter`.

A dock widget will be open on the right side of the Napari interface. There
you can view options for restoring images (using the cellpose denoise module),
and counting cells/nuclei in a region of interest (ROI).

A few important notes:

1. Images in TIFF or CZI file formats may be used.
1. Images must be grayscale or single channel. RGB images may be loaded, but
should be split. You can do this by right clicking on the image and select
`split rgb` or `split stack`.
1. ROIs can be drawn using the shape layer tools. Only a single ROI can be drawn
per shape layer (otherwise only the first draw ROI will be used).
1. ROIs should be square or rectangular. You can draw ROIs as polygons or other
shapes, but a bounding box will be made from these shapes anyway.
1. For long running processes such as image restoration or counting, it may seem
like Napari is not doing anything. Notifications are shown in the viewer to
display import information and a small activity indicator can be seen in the
bottom right hand corner. If this indicator is spinning, then work is being done
even if it doesn't look like it.
1. In case of a large number of uncounted nuclei, consider modifying the
segmentation parameters, or use the `Continue Counting` option to re-run the
segmentation on uncounted nuclei.

## Updating

1. via Napari plugin manager. Select cellpose-counter plugin and update button.

1. via pip (or uv, ..., etc.)

```bash
uv pip install cellpose-counter --upgrade
```

## Contributing

All contributions are welcome. Please submit an issue for feedback or bugs.

## Citations

This plugin is built on top of the Cellpose segmentation and denoising models.
If you use this plugin, please cite the following paper:

```bitex
@article{stringer2021cellpose,
title={Cellpose: a generalist algorithm for cellular segmentation},
author={Stringer, Carsen and Wang, Tim and Michaelos, Michalis and Pachitariu, Marius},
journal={Nature Methods},
volume={18},
number={1},
pages={100--106},
year={2021},
publisher={Nature Publishing Group}
}
```

## License

[BSD-3](./LICENSE)
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']",,,,cellpose-counter.make_counter_widget,,,,
22,cellcanvas,cellcanvas,cellcanvas,0.0.1,2024-03-10,2024-03-10,Kyle Harrington,czii@kyleharrington.com,MIT,https://github.com/cellcanvas/cellcanvas/issues,https://pypi.org/project/cellcanvas/,,https://github.com/cellcanvas/cellcanvas,A tool for painting in cellular architecture,>=3.8,"['numpy <2.0.0', 'magicgui >=0.8.1', 'mrcfile', 'qtpy >=2.4.1', 'scikit-image >=0.22.0', 'toolz >=0.12.0', 'scikit-learn >=1.3.2', 'pyclesperanto-prototype', 'pymeshfix', 'psygnal >=0.9.5', 'superqt >=0.6.1', 'surforama', 'starfile', 'zarr >=2.16.1', 'xgboost >=2', 'matplotlib >=3.8.2', ""tox ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""pytest-cov ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""napari ; extra == 'dev'"", ""pyqt5 ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# cellcanvas
A tool to support painting in cellular architecture

![cellcanvas_screenshot](cover.png)
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/cellcanvas/cellcanvas/issues', 'Documentation, https://github.com/cellcanvas/cellcanvas#README.md', 'Source Code, https://github.com/cellcanvas/cellcanvas', 'User Support, https://github.com/cellcanvas/cellcanvas/issues']",,,cellcanvas.make_qwidget,,,,
23,cell-aap,cell-AAP,cell-AAP,0.0.9,2024-05-28,2025-02-20,Anish Virdi,,Unavailable,,https://pypi.org/project/cell-AAP/,None,,,"<3.13,>=3.11","['napari[all]>=0.4.19', 'numpy==1.26.4', 'opencv-python>=4.9.0', 'tifffile>=2024.2.12', 'torch>=2.3.1', 'torchvision>=0.18.1', 'scikit-image>=0.22.0', 'qtpy>=2.4.1', 'pillow>=10.3.0', 'scipy>=1.3.0', 'timm>=1.0.7', 'pandas>=2.2.2', 'superqt>=0.6.3', 'btrack>=0.6.5', 'seaborn>=0.13.2', 'openpyxl>=3.1.4', 'joblib>=1.0', 'scikit-learn>=0.22', 'cython<3,>=0.27']","# Cellular Annotation & Perception Pipeline

![](https://github.com/anishjv/cell-AAP/blob/main/images/figure2.png?raw=true)
![](https://github.com/anishjv/cell-AAP/blob/main/images/rpe1_u2os.png?raw=true)




Utilities for the semi-automated generation of instance segmentation annotations to be used for neural network training. Utilities are built ontop of [UMAP](https://github.com/lmcinnes/umap), [HDBSCAN](https://arxiv.org/abs/1911.02282) and a finetuned encoder version of FAIR's [Segment Anything Model](https://github.com/facebookresearch/segment-anything/tree/main?tab=readme-ov-file) developed by Computational Cell Analytics for the project [micro-sam](https://github.com/computational-cell-analytics/micro-sam/tree/master/micro_sam/sam_annotator). In addition to providing utilies for annotation building, we train networks using FAIR's [detectron2](https://github.com/facebookresearch/detectron2) to 
1. Demonstrate the efficacy of our utilities. 
2. Be used for microscopy annotation of supported cell lines 

Cell-line specific models currently include:
1. HeLa
2. U2OS

Models have demonstrated performance efficacy on:
1. HT1080 (HeLa model)
2. RPE1 (U2OS model)

We've also developed a napari application for the usage of these pre-trained networks.


# Installation 
We highly recommend installing cell-AAP in a clean conda environment. To do so you must have [miniconda](https://docs.anaconda.com/free/miniconda/#quick-command-line-install) or [anaconda](https://docs.anaconda.com/free/anaconda/) installed.

If a conda distribution has been installed:

1. Create and activate a clean environment 

        conda create -n cell-aap-env python=3.11.0
        conda activate cell-app-env

2. Within this environment install pip

        conda install pip

3. Then install cell-AAP from PyPi

        pip install cell-AAP --upgrade

4. Finally detectron2 must be built from source, atop cell-AAP
    
        #For MacOS
        CC=clang CXX=clang++ ARCHFLAGS=""-arch arm64"" python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'

        #For other operating systems 
        python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'



# Napari Plugin Usage

1. To open napari simply type ""napari"" into the command line, ensure that you are working the correct environment
2. To instantiate the plugin navigate to the ""Plugins"" menu and select ""cell-AAP""
3. You should now see the Plugin, where you can select an image, display it, and run inference on it. 


# Configs Best Practices

If running inference on large volumes of data, i.e. timeseries data >= 300 MB in size, we recommend to proceed in the following manner. 

1. Assemble a small, < 100 MB, substack of your data using python or a program like [ImageJ](https://imagej.net/ij/download.html)
2. Use this substack to find the optimal parameters for your data, (Number of Cells, Network confidence threshold)
3. Run Inference over the volume using the discovered optimal parameters


# Interpreting Results 

Once inference is complete the following colors indicate class prediction
- Red: Non-mitotic
- Blue: Mitotic

For analysis purposes, masks in the semantic and instance segmentations have the following value mapping:
Semantic
- 1: Non-mitotic
- 100: Mitotic

Instance
- $2x$: Non-mitotic
- $2x-1$: Mitotic








","['Framework :: napari', 'Programming Language :: Python :: 3']",,,,cell-AAP.run,,,,
24,brainreg,brainreg,brainreg,1.0.13,2023-12-14,2025-05-30,"Adam Tyson, Charly Rousseau, Stephen Lenzi","""Adam Tyson, Charly Rousseau, Stephen Lenzi"" <code@adamltyson.com>",BSD 3-Clause,https://github.com/brainglobe/brainreg,https://pypi.org/project/brainreg/,,,Automated multi-atlas whole-brain microscopy registration,>=3.11,"['brainglobe-atlasapi>=2.0.1', 'brainglobe-space>=1.0.0', 'brainglobe-utils>=0.5.0', 'fancylog', 'numpy', 'scikit-image>=0.24.0', 'brainglobe-napari-io>=0.3.2; extra == ""napari""', 'brainglobe-segmentation>=1.0.0; extra == ""napari""', 'magicgui; extra == ""napari""', 'napari-plugin-engine>=0.1.4; extra == ""napari""', 'napari[pyqt5]!=0.6.0,>=0.5; extra == ""napari""', 'pooch>1; extra == ""napari""', 'qtpy; extra == ""napari""', 'black; extra == ""dev""', 'check-manifest; extra == ""dev""', 'gitpython; extra == ""dev""', 'napari[pyqt5]!=0.6.0,>=0.5; extra == ""dev""', 'pre-commit; extra == ""dev""', 'pytest-cov; extra == ""dev""', 'pytest-qt; extra == ""dev""', 'pytest-mock; extra == ""dev""', 'pytest; extra == ""dev""', 'setuptools_scm; extra == ""dev""', 'tox; extra == ""dev""']","[![Python Version](https://img.shields.io/pypi/pyversions/brainreg.svg)](https://pypi.org/project/brainreg)
[![PyPI](https://img.shields.io/pypi/v/brainreg.svg)](https://pypi.org/project/brainreg)
[![Wheel](https://img.shields.io/pypi/wheel/brainreg.svg)](https://pypi.org/project/brainreg)
[![Development Status](https://img.shields.io/pypi/status/brainreg.svg)](https://github.com/brainglobe/brainreg)
[![Tests](https://img.shields.io/github/actions/workflow/status/brainglobe/brainreg/test_and_deploy.yml?branch=main)](https://github.com/brainglobe/brainreg/actions)
[![codecov](https://codecov.io/gh/brainglobe/brainreg/branch/main/graph/badge.svg?token=FbPgwBIGnd)](https://codecov.io/gh/brainglobe/brainreg)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/python/black)

# brainreg

brainreg is an update to [amap](https://github.com/SainsburyWellcomeCentre/amap_python) (which is itself a port
of the [original Java software](https://www.nature.com/articles/ncomms11879)) to include multiple registration backends, and to support the many atlases provided by [brainglobe-atlasapi](https://github.com/brainglobe/brainglobe-atlasapi).
It also comes with an optional [napari plugin](https://github.com/brainglobe/brainreg-napari) if you'd rather use brainreg with through graphical interface.

Documentation for both the command-line tool and graphical interface can be found [here](https://brainglobe.info/documentation/brainreg/index.html).

For segmentation of bulk structures in 3D space (e.g. injection sites, Neuropixels probes), please see [brainglobe-segmentation](https://github.com/brainglobe/brainglobe-segmentation).

## Details

The aim of brainreg is to register the template brain (e.g. from the [Allen Reference Atlas](https://mouse.brain-map.org/static/atlas)) to the sample image.
Once this is complete, any other image in the template space can be aligned with the sample (such as region annotations, for segmentation of the sample image).
The template to sample transformation can also be inverted, allowing sample images to be aligned in a common coordinate space.

To do this, the template and sample images are filtered, and then registered in a three step process (reorientation, affine registration, and freeform registration).
The resulting transform from template to standard space is then applied to the atlas.

Full details of the process are in the [original aMAP paper](https://www.nature.com/articles/ncomms11879).

![An illustrated overview of the registration process](https://user-images.githubusercontent.com/13147259/143553945-a046e918-7614-4211-814c-fc840bb0159d.png)

## Installation

To install both the command line tool and the napari plugin, run

```bash
pip install brainreg[napari]
```

in your desired Python environment.
To only install the command line tool with no GUI (e.g. to run brainreg on an HPC cluster), just run:

```bash
pip install brainreg
```

### Installing on macOS

If you are using macOS, please run

```bash
conda install -c conda-forge niftyreg
```

in your environment before installing, to ensure all dependencies are installed.

## Command line usage

### Basic usage

```bash
brainreg /path/to/raw/data /path/to/output/directory -v 5 2 2 --orientation psl
```

Full command-line arguments are available with `brainreg -h`, but please
[get in touch](mailto:code@adamltyson.com?subject=brainreg) if you have any questions.

### Mandatory arguments

- Path to the directory of the images. This can also be a text file pointing to the files.
- Output directory for all intermediate and final results.
- You must also specify the voxel sizes with the `-v` flag, see [specifying voxel size](https://brainglobe.info/documentation/general/image-definition.html#voxel-sizes) for details.

### Atlas

By default, brainreg will use the 25um version of the [Allen Mouse Brain Atlas](https://mouse.brain-map.org/).
To use another atlas (e.g. for another species, or another resolution), you must use the `--atlas` flag, followed by the string describing the atlas, e.g.:

```bash
--atlas allen_mouse_50um
```

To find out which atlases are available, once brainreg is installed, please run `brainglobe list`.
The name of the resulting atlases is the string to pass with the `--atlas` flag.

### Input data orientation

If your data does not match the BrainGlobe default orientation (the origin voxel is the most anterior, superior, left-most voxel), then you must specify the orientation by using the `--orientation` flag.
What follows must be a string in the [brainglobe-space](https://github.com/brainglobe/brainglobe-space) ""initials"" form, to describe the origin voxel.

If the origin of your data (first, top left voxel) is the most anterior, superior, left part of the brain, then the orientation string would be ""asl"" (anterior, superior, left), and you would use:

```bash
--orientation asl
```

### Registration options

To change how the actual registration performs, see [registration parameters](https://brainglobe.info/documentation/brainreg/user-guide/parameters.html)

### Additional options

- `-a` or `--additional` Paths to N additional channels to downsample to the same coordinate space.
- `--sort-input-file` If set to true, the input text file will be sorted using natural sorting. This means that the file paths will be sorted as would be expected by a human and not purely alphabetically.
- `--brain_geometry` Can be one of `full` (default) for full brain registration, `hemisphere_l` for left hemisphere data-set and `hemisphere_r` for right hemisphere data-set.

### Misc options

- `--n-free-cpus` The number of CPU cores on the machine to leave unused by the program to spare resources.
- `--debug` Debug mode. Will increase verbosity of logging and save all intermediate files for diagnosis of software issues.
- `--save-original-orientation` Option to save the registered atlas with the same orientation as the input data.

## Visualising results

If you have installed the optional [napari](https://github.com/napari/napari) plugin, you can use napari to view your data.
The plugin automatically fetches the [brainglobe-napari-io](https://github.com/brainglobe/brainglobe-napari-io) which provides this functionality.
If you have installed only the command-line tool you can still manually install [brainglobe-napari-io](https://github.com/brainglobe/brainglobe-napari-io) and follow the steps below.

### Sample space

Open napari and drag your brainreg output directory (the one with the log file) onto the napari window.

Various images should then open, including:

- `Registered image` - the image used for registration, downsampled to atlas resolution
- `atlas_name` - e.g. `allen_mouse_25um` the atlas labels, warped to your sample brain
- `Boundaries` - the boundaries of the atlas regions

If you downsampled additional channels, these will also be loaded.
Most of these images will not be visible by default - click the little eye icon to toggle visibility.

**Note:** If you use a high resolution atlas (such as `allen_mouse_10um`), then the files can take a little while to load.

![GIF illustration of loading brainreg output into napari for visualisation](https://raw.githubusercontent.com/brainglobe/napari-brainreg/master/resources/sample_space.gif)

## Seeking help or contributing
We are always happy to help users of our tools, and welcome any contributions. If you would like to get in contact with us for any reason, please see the [contact page of our website](https://brainglobe.info/contact.html).

## Citing brainreg

If you find brainreg useful, and use it in your research, please let us know and also cite the paper:

> Tyson, A. L., V&eacute;lez-Fort, M.,  Rousseau, C. V., Cossell, L., Tsitoura, C., Lenzi, S. C., Obenhaus, H. A., Claudi, F., Branco, T.,  Margrie, T. W. (2022). Accurate determination of marker location within whole-brain microscopy images. Scientific Reports, 12, 867 [doi.org/10.1038/s41598-021-04676-9](https://doi.org/10.1038/s41598-021-04676-9)

Please also cite aMAP (the original pipeline from which this software is based):

>Niedworok, C.J., Brown, A.P.Y., Jorge Cardoso, M., Osten, P., Ourselin, S., Modat, M. and Margrie, T.W., (2016). AMAP is a validated pipeline for registration and segmentation of high-resolution mouse brain data. Nature Communications. 7, 1â9. <https://doi.org/10.1038/ncomms11879>

Lastly, if you can, please cite the BrainGlobe Atlas API that provided the atlas:

>Claudi, F., Petrucco, L., Tyson, A. L., Branco, T., Margrie, T. W. and Portugues, R. (2020). BrainGlobe Atlas API: a common interface for neuroanatomical atlases. Journal of Open Source Software, 5(54), 2668, <https://doi.org/10.21105/joss.02668>

Finally, **don't forget to cite the developers of the atlas that you used (e.g. the Allen Brain Atlas)!**
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Framework :: napari']","['Homepage, https://brainglobe.info', 'Bug Tracker, https://github.com/brainglobe/brainreg/issues', 'Documentation, https://docs.brainglobe.info/brainreg', 'Source Code, https://github.com/brainglobe/brainreg', 'User support, https://forum.image.sc/tag/brainglobe', 'Twitter, https://twitter.com/brain_globe']",,,brainreg.Register,brainreg.SampleData,,,
25,brainrender-napari,brainrender-napari,brainrender,0.1.2,2023-10-13,2025-05-30,Alessandro Felder,Alessandro Felder <a.felder@ucl.ac.uk>,BSD-3-Clause,https://github.com/brainglobe/brainrender-napari/issues,https://pypi.org/project/brainrender-napari/,,,A napari plugin to render BrainGlobe atlases and associated data as layers.,>=3.11.0,"['brainglobe-atlasapi>=2.2.0', 'brainglobe-utils>=0.4.3', 'meshio', 'napari!=0.6.0,>=0.4.18', 'numpy', 'qtpy', 'pytest; extra == ""dev""', 'pytest-cov; extra == ""dev""', 'pytest-mock; extra == ""dev""', 'pytest-qt; extra == ""dev""', 'coverage; extra == ""dev""', 'tox; extra == ""dev""', 'black; extra == ""dev""', 'mypy; extra == ""dev""', 'pre-commit; extra == ""dev""', 'ruff; extra == ""dev""', 'setuptools_scm; extra == ""dev""', 'pyqt5; extra == ""dev""']","# brainrender-napari

[![License BSD-3](https://img.shields.io/pypi/l/brainrender-napari.svg?color=green)](https://github.com/brainglobe/brainrender-napari/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/brainrender-napari.svg?color=green)](https://pypi.org/project/brainrender-napari)
[![Python Version](https://img.shields.io/pypi/pyversions/brainrender-napari.svg?color=green)](https://python.org)
[![tests](https://github.com/brainglobe/brainrender-napari/workflows/tests/badge.svg)](https://github.com/brainglobe/brainrender-napari/actions)
[![codecov](https://codecov.io/gh/brainglobe/brainrender-napari/branch/main/graph/badge.svg)](https://codecov.io/gh/brainglobe/brainrender-napari)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/brainrender-napari)](https://napari-hub.org/plugins/brainrender-napari)

Visualisation and management of BrainGlobe atlases in napari.

----------------------------------

A napari plugin to visualise and manage BrainGlobe atlases. `brainrender-napari` aims to port the functionality of [`brainrender`](https://github.com/brainglobe/brainrender) to [`napari`](https://napari.org/stable/).
![add-region-brainrender-napari](https://github.com/brainglobe/brainrender-napari/assets/10500965/24fd3752-0ba7-4f47-aabf-5de22ff0f69b)

## Usage

Check out the [""Visualising an atlas in napari""](https://brainglobe.info/tutorials/visualise-atlas-napari.html) tutorial in the BrainGlobe documentation.

## Installation

We strongly recommend to use a virtual environment manager (like `conda` or `venv`). The installation instructions below will not specify the Qt backend for napari, and you will therefore need to install that separately. Please see [the `napari` installation instructions](https://napari.org/stable/tutorials/fundamentals/installation.html) for further advice on this.

You can install `brainrender-napari` via [pip]:

    pip install brainrender-napari



To install latest development version :

    pip install git+https://github.com/brainglobe/brainrender-napari.git

## Seeking help or contributing
We are always happy to help users of our tools, and welcome any contributions. If you would like to get in contact with us for any reason, please see the [contact page of our website](https://brainglobe.info/contact.html).

## License

Distributed under the terms of the [BSD-3] license,
""brainrender-napari"" is free and open source software


## Acknowledgements

This [@napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template and the [Neuroinformatics Unit's template](https://github.com/neuroinformatics-unit/python-cookiecutter).

[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[file an issue]: https://github.com/brainglobe/brainrender-napari/issues
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License', 'Topic :: Scientific/Engineering :: Image Processing']","['Homepage, https://github.com/brainglobe/brainrender-napari', 'Bug Tracker, https://github.com/brainglobe/brainrender-napari/issues', 'Documentation, https://brainglobe.github.io/brainrender-napari', 'Source Code, https://github.com/brainglobe/brainrender-napari', 'User Support, https://github.com/brainglobe/brainrender-napari/issues']",,,brainrender-napari.make_brainrender_viewer_widget,,,,
26,brainglobe-utils,brainglobe-utils,BrainGlobe,0.7.0,2024-07-31,2025-03-10,Adam Tyson,Adam Tyson <code@adamltyson.com>,MIT,https://github.com/brainglobe/brainglobe-utils/issues,https://pypi.org/project/brainglobe-utils/,https://brainglobe.info,,Shared general purpose tools for the BrainGlobe project,>=3.11,"['brainglobe-atlasapi>=2.0.1', 'brainglobe-space', 'configobj', 'natsort', 'nibabel>=2.1.0', 'numba', 'numpy', 'dask', 'pandas', 'psutil', 'pyarrow', 'PyYAML', 'scikit-image', 'scipy', 'slurmio', 'tifffile', 'tqdm', 'qt-niu', 'qtpy; extra == ""qt""', 'superqt; extra == ""qt""', 'brainglobe-utils[qt]; extra == ""napari""', 'napari[all]; extra == ""napari""', 'black; extra == ""dev""', 'coverage; extra == ""dev""', 'mypy; extra == ""dev""', 'pre-commit; extra == ""dev""', 'pyqt5; extra == ""dev""', 'pytest-cov; extra == ""dev""', 'pytest-qt; extra == ""dev""', 'pytest-mock; extra == ""dev""', 'pytest; extra == ""dev""', 'ruff; extra == ""dev""', 'scikit-image; extra == ""dev""', 'setuptools_scm; extra == ""dev""', 'tox; extra == ""dev""', 'pooch; extra == ""dev""', 'brainglobe-utils[napari]; extra == ""dev""']","# brainglobe-utils

Shared general purpose tools for the BrainGlobe project, including [citation generation](#citations-for-brainglobe-tools).

## Installation

```bash
pip install brainglobe-utils
```

To also include the dependencies required for Qt widgets, use:

```bash
pip install brainglobe-utils[qt]
```

For development, clone this repository and install the dependencies with:

```bash
pip install -e .[dev]
```

## Seeking help or contributing
We are always happy to help users of our tools, and welcome any contributions. If you would like to get in contact with us for any reason, please see the [contact page of our website](https://brainglobe.info/contact.html).

## Citations for BrainGlobe tools

`brainglobe-utils` comes with the `cite-brainglobe` command line tool, to write citations for BrainGlobe tools for you so you don't need to worry about fetching the data yourself.
You can read about [how to use the tool](https://brainglobe.info/documentation/brainglobe-utils/citation-module.html) on the documentation website.
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13']","['homepage, https://brainglobe.info', 'bug_tracker, https://github.com/brainglobe/brainglobe-utils/issues', 'source_code, https://github.com/brainglobe/brainglobe-utils', 'user_support, https://github.com/brainglobe/brainglobe-utils/issues']",,,brainglobe-utils.brainmapper,,,,
27,cryocanvas,cryocanvas,cryocanvas,0.0.1,2024-02-02,2024-02-02,Kyle Harrington,czii@kyleharrington.com,MIT,https://github.com/kephale/cryocanvas/issues,https://pypi.org/project/cryocanvas/,,https://github.com/kephale/cryocanvas,A plugin for interactive segmentation of CryoET data using ML embeddings,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'toolz', 'scikit-learn', 'psygnal', 'superqt', 'zarr', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# cryocanvas
A tool to support interactive machine learning for cryoET data

![cryocanvas screenshot](cover.png)
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kephale/cryocanvas/issues', 'Documentation, https://github.com/kephale/cryocanvas#README.md', 'Source Code, https://github.com/kephale/cryocanvas', 'User Support, https://github.com/kephale/cryocanvas/issues']",,,cryocanvas.make_qwidget,,,,
28,cochlea-synapseg,cochlea-synapseg,Cochlea SynapSeg,0.0.1,2024-11-07,2024-11-07,Cayla Miller,cayla@ucsd.edu,"Copyright (c) 2024, Cayla Mill...",,https://pypi.org/project/cochlea-synapseg/,None,,"A plugin to segment cochlear ribbon synapses automatically, as well as edit and adjust",>=3.9,"['numpy', 'qtpy', 'scikit-image', 'scipy', 'zarr', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# cochlea-synapseg

[![License BSD-3](https://img.shields.io/pypi/l/cochlea-synapseg.svg?color=green)](https://github.com/ucsdmanorlab/cochlea-synapseg/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/cochlea-synapseg.svg?color=green)](https://pypi.org/project/cochlea-synapseg)
[![Python Version](https://img.shields.io/pypi/pyversions/cochlea-synapseg.svg?color=green)](https://python.org)
[![tests](https://github.com/ucsdmanorlab/cochlea-synapseg/workflows/tests/badge.svg)](https://github.com/ucsdmanorlab/cochlea-synapseg/actions)
[![codecov](https://codecov.io/gh/ucsdmanorlab/cochlea-synapseg/branch/main/graph/badge.svg)](https://codecov.io/gh/ucsdmanorlab/cochlea-synapseg)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/cochlea-synapseg)](https://napari-hub.org/plugins/cochlea-synapseg)

A plugin to segment cochlear ribbon synapses. 

More is in the works, but for now it includes tools to more quickly generate ground truth ribbon segmentation (Plugins > SynapSeg - Ground Truth Widget).

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `cochlea-synapseg` (receommended: in a new conda environment with up-to-date napari) via [pip]:

    python -m pip install cochlea-synapseg

## Usage

After successfull installation, you can find the plugin next time you launch napari (Plugins > SynapSeg - Ground Truth Widget).

The ground truth widget is divided into multiple sections, for ""quick use"", be sure to check the settings denoted with asterisks:

### Image Tools

![image_tools](https://github.com/user-attachments/assets/323984ad-2cd3-4816-8ee5-e8b3f5063bc0)

\***1. Image Layer Selection** - use the dropdown to select the name of your image layer (here, the layer that contains the ribbon stain)

(First load a 3D image using one of napari's native readers, or using the Cochlea-Synapseg .zarr reader (reads a .zarr with '3d/raw' and '3d/labeled').)

\***2. Refresh Image Layer Selection** - update the list of available image layers in #1

**3. Pixel size information** - (in microns), used for some point readers to successfully convert real units to pixel coordinates. Can be left as 1 if this functionality is not needed.

**4. Split channels** - splits multiple channels into separate image layers (useful for FIJI-saved .tif images)

### Points Tools & Points to Labels

![points_tools](https://github.com/user-attachments/assets/6b271d5c-51c1-4ca4-b3c0-683dddd69dc8)

**5. Points Layer Selection and Refresh** - use the dropdown to select an existing points layer, use the refresh button to update the list (or skip to #8 if not loading in existing points)

**6. Real -> Pixel Units** - if you've loaded some points were saved in real units, make sure the pixel size information above in #3 is correct, then click ""real -> pixel units""

**7. Channel Adjustment** - some points (like ImageJ/FIJI rois or CellCounter points), show up in the wrong z plane because their ""slice"" coordinates are a combination of both slice and channel info. If this happens, set the number of channels (in the original image, where the ROIs were created!), and then click ""chan -> z convert"". Z coordinates of the points layer will be divided by the number of channels specified. 

\***8. New Points Layer** - if starting annotation from scratch, click to create a new points layer. #5 should automatically select this new layer. 

\***9. Rotate to XY and \*10. Auto-adjust Z** - these convenient functions allow you to quickly annotate points in Napari's 3D view. Simply click ""Rotate to XY before adding new points. These points will now have the correct XY position but will have missing Z information. (Rotate out of XY to confirm.) Click ""Auto-adjust z"" and the z will automatically adjust to the brightest point. 

**11. Manually Edit Z** - useful for overlapping points, can be used to manually edit the z position of ONLY selected points. Use the +/- arrow keys for single z steps type in a number to move a larger amount. 

**12. Snap too Max** - will automatically adjust all points to their local max (search radius defined in pixels in Advanced Settings -> snap to max rad). Useful for adjusting quickly dropped points, but proceed with caution if you have close-together points. 

\***13. Points to Labels** - the key functionality of the module, creates a label layer by performing a local segmentation on all points.

**14. Advanced Settings** - adjust settings for the points to labels function to optimize local segmentation and watershed separation of points. 

### Labels Tools

![labels_tools](https://github.com/user-attachments/assets/6ef20ff6-61e2-4337-a177-8f957a67fb39)

**15. Lables Layer Selection and Refresh** - use the dropdown to select an existing labels layer, use the refresh button to update the list

**16. Make Labels Editable** - zarrs and other file formats tend to load in as dask arrays, which don't allow editing. Checking this box will make the labels layer editable by converting to a numpy array (will load the layer into memory, so be careful if dealing with large images!). This will allow you to edit the labels layer with tools like the paintbrush and eraser. Automatically enables if merging or removing labels is requested (see #17 and #19)

\***17. Remove a Label** - use the labels layer eyedropper tool to identify the ID of an unwanted label, then type in the box and click ""Remove label""

**18. Max Label Display** - shows the current maximum label ID. If you're painting labels by hand and need a new label ID, increment above this number. Use the refresh button to the right to get an up-to-date number if you've made changes to your label layer.

\***19. Merge labels** - if you have an existing labels layer, and then create new labels (e.g. from the points to labels function), select the layer you'd like to merge into your existing labels layer (i.e. box 15 and 19a should be different from one another!), and then click ""merge labels"". This function will automatically ensure overlapping label IDs are not used. 

**20. Labels to Points** - if wanted, you can take all your existing labels and convert them to a points layer based on their centroids. This may be helpful for quickly generating better labels using the points tools above. 

### Save to Zarr

![save_zarr](https://github.com/user-attachments/assets/1d824f49-012f-4fac-8fa1-64d7d319cd34)

Functionality to save to .zarr format. Saves image as '3d/raw' and labels as '3d/labeled'. Used for later auto-segmentation of ribbons (not live in this plugin yet, but coming soon!). 

\***21. File Path** - the directory in which to save the zarr; use the folder icon to search for an existing directory

\***22. File Name** - the zarr name to save to; use the magnifying glass icon to select an existing .zarr

**23. From Source** - set the file path and name to where the image layer was loaded from. (Caution: if you loaded a zarr, this will result in the zarr being overwritten!)

\***24. Save 3D Only (recommended)** - saves the image and labels layers (selected in #1 and #15) in the specified .zarr, as 3d/raw and 3d/labeled, respectively. A reader is included with this plugin for this format as well. 

**25. Save 2D and 3D** - (not recommended) to be used in the future if 2D models are to be run on the data, saves both the 3D stacks as in 24, and then individual 2D slices for each z in 2d/raw/[z] and 2d/labeled/[z]



## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""cochlea-synapseg"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']",,cochlea-synapseg.get_reader,cochlea-synapseg.write_multiple,cochlea-synapseg.make_gtwidget,cochlea-synapseg.make_sample_data,"['*.zarr', '*.xml', '*.csv', '*.xls', '*.XLS']",,['.npy']
29,cut-detector,cut-detector,Cut Detector,1.6.5,2023-10-17,2025-05-12,Thomas Bonte,thomas.bonte@mines-paristech.fr,BSD-3-Clause,https://github.com/15bonte/cut-detector/issues,https://pypi.org/project/cut-detector/,,https://github.com/15bonte/cut-detector,Automatic Cut Detector,>=3.9,"['cellpose==3.0.9', 'pyimagej', 'cnn_framework==0.0.16', 'magicgui', 'pydantic==1.10.12', 'xmltodict', 'shapely', 'aicsimageio==4.14.0', 'fsspec==2023.6.0', 'charset-normalizer==3.3.0', 'napari[all]', 'laptrack==0.16.2', 'scikit-learn==1.5.0', 'numba>=0.59.1', 'scipy<=1.14.1', 'tensorflow<=2.18.0', 'munch', 'plotly', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# Cut Detector

[![License BSD-3](https://img.shields.io/pypi/l/cut-detector.svg?color=green)](https://github.com/15bonte/cut-detector/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/cut-detector.svg?color=green)](https://pypi.org/project/cut-detector)
[![Python Version](https://img.shields.io/pypi/pyversions/cut-detector.svg?color=green)](https://python.org)
[![tests](https://github.com/15bonte/cut-detector/workflows/tests/badge.svg)](https://github.com/15bonte/cut-detector/actions)
[![codecov](https://codecov.io/gh/15bonte/cut-detector/branch/main/graph/badge.svg)](https://codecov.io/gh/15bonte/cut-detector)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/cut-detector)](https://napari-hub.org/plugins/cut-detector)

Automatic micro-tubule cut detector.

https://github.com/user-attachments/assets/2af2e1a6-adf9-4d63-a353-e190c4814d83

---

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

<video width=""640"" height=""480"" controls>
  <source src=""https://github.com/15bonte/cut-detector-models/blob/main/demo.mp4"" type=""video/mp4"">
  Your browser does not support the video tag.
</video>

## Installation

### Conda environment

It is highly recommended to create a dedicated conda environment, by following these few steps:

1. Install an [Anaconda] distribution of Python. Note you might need to use an anaconda prompt if you did not add anaconda to the path.

2. Open an Anaconda prompt as admin to create a new environment using [conda]. We advice to use python 3.10 and conda 23.10.0, to get conda-libmamba-solver as default solver.

```bash
conda create --name cut_detector python=3.10 conda=23.10.0
conda activate cut_detector
```

### Package installation

Once in a dedicated environment, our package can be installed via [pip]:

```bash
pip install cut_detector
```

Alternatively, you can clone the github repo to access to playground scripts.

```bash
git clone https://github.com/15bonte/cut-detector.git
cd cut-detector
pip install -e .
```

### GPU

We highly recommend to use GPU to speed up segmentation. To use your NVIDIA GPU, the first step is to download the dedicated driver from [NVIDIA].

Next we need to remove the CPU version of torch:

```bash
pip uninstall torch
```

The GPU version of torch to be installed can be found [here](https://pytorch.org/get-started/locally/). You may choose the CUDA version supported by your GPU, and install it with conda. This package has been developed with the version 11.6, installed with this command:

```bash
conda install pytorch==1.12.1 torchvision pytorch-cuda=11.6 -c pytorch -c nvidia
```

## Update

To update cut-detector to the latest version, open an Anaconda prompt and use the following commands:

```bash
conda activate cut_detector
pip install cut-detector --upgrade
```

## Definitions

Each detected cell division is labeled with one of the following categories:

- NORMAL: Division happening as expected, where (at least) 1 micro-tubule cut is detected.
- NO_MID_BODY_DETECTED: Along the cell division, no mid-body was detected on the MKLP1 channel. This category encompasses different cases: the detection may have failed, the mid-body may not express the fluorescence, or this may not actually be a division.
- MORE_THAN_TWO_DAUGHTER_TRACKS: Tripolar division. This category encompasses both actual tripolar divisions and wrong identifications of daughter cells (mainly caused by segmentation issues).
- NEAR_BORDER: Division close to the border of the image, hence ignored as it is likely to be difficult to detect micro-tubule cuts. A division is classified as NEAR_BORDER as soon as the distance between 1 detected mid-body and the border of the image is less than 20px.
- NO_CUT_DETECTED: Division whose mid-body was detected, but with all micro-tubule bridges classified as ""No cut"". Likely to be at the end of the video, cells dying before the end of division, or cells going out of frame.
- TOO_SHORT_CUT: First micro-tubule cut detected before or at 50 minutes. Ignored as this is very unlikely, so it is probably caused by a wrong division detection.

Division movies start at the maximum between:

- Mother cell start frame
- 10 frames before the end of metaphase

Division movies end at the minimum between:

- Last frame of any of the daughter cells
- Metaphase of any of the daughter cells

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

Scripts required to improve any of Cut Detector tasks can be found in the folder [developers].

## License

Distributed under the terms of the [BSD-3] license,
""cut-detector"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/15bonte/cut-detector/issues
[developers]: https://github.com/15bonte/cut-detector/tree/main/developers
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[Anaconda]: https://www.anaconda.com/products/distribution
[Fiji]: https://imagej.net/software/fiji/
[NVIDIA]: https://www.nvidia.com/Download/index.aspx?lang=en-us
[conda]: https://docs.conda.io/en/latest/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/15bonte/cut-detector/issues', 'Documentation, https://github.com/15bonte/cut-detector#README.md', 'Source Code, https://github.com/15bonte/cut-detector', 'User Support, https://github.com/15bonte/cut-detector/issues']",,,cut-detector.whole_process,,,,
30,btrack,btrack,btrack,0.6.5,2023-04-17,2024-03-05,Alan R. Lowe,"""Alan R. Lowe"" <a.lowe@ucl.ac.uk>",MIT,https://github.com/quantumjot/btrack/discussions,https://pypi.org/project/btrack/,,,A framework for Bayesian multi-object tracking,>=3.9,"['cvxopt >=1.3.1', 'h5py >=2.10.0', 'numpy >=1.17.3', 'pandas >=2.0.3', 'pooch >=1.0.0', 'pydantic <2', 'scikit-image >=0.16.2', 'scipy >=1.3.1', 'tqdm >=4.65.0', ""black ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""ruff ; extra == 'dev'"", ""numpydoc ; extra == 'docs'"", ""pytz ; extra == 'docs'"", ""sphinx ; extra == 'docs'"", ""sphinx-automodapi ; extra == 'docs'"", ""sphinx-panels ; extra == 'docs'"", ""sphinx-rtd-theme ; extra == 'docs'"", ""magicgui >=0.5.0 ; extra == 'napari'"", ""napari-plugin-engine >=0.1.4 ; extra == 'napari'"", ""napari >=0.4.16 ; extra == 'napari'"", ""qtpy ; extra == 'napari'""]","[![PyPI](https://img.shields.io/pypi/v/btrack)](https://pypi.org/project/btrack)
[![Downloads](https://static.pepy.tech/badge/btrack/month)](https://pepy.tech/project/btrack)
[![Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Tests](https://github.com/quantumjot/btrack/actions/workflows/test.yml/badge.svg)](https://github.com/quantumjot/btrack/actions/workflows/test.yml)
[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)
[![Documentation](https://readthedocs.org/projects/btrack/badge/?version=latest)](https://btrack.readthedocs.io/en/latest/?badge=latest)
[![codecov](https://codecov.io/gh/quantumjot/btrack/branch/main/graph/badge.svg?token=QCFC9AWK0R)](https://codecov.io/gh/quantumjot/btrack)

![logo](https://btrack.readthedocs.io/en/latest/_images/btrack_logo.png)

# Bayesian Tracker (btrack) ð¬ð»

`btrack` is a Python library for multi object tracking, used to reconstruct trajectories in crowded fields.
Here, we use a probabilistic network of information to perform the trajectory linking.
This method uses spatial information as well as appearance information for track linking.

The tracking algorithm assembles reliable sections of track that do not contain splitting events (tracklets).
Each new tracklet initiates a probabilistic model, and utilises this to predict future states (and error in states) of each of the objects in the field of view.
We assign new observations to the growing tracklets (linking) by evaluating the posterior probability of each potential linkage from a Bayesian belief matrix for all possible linkages.

The tracklets are then assembled into tracks by using multiple hypothesis testing and integer programming to identify a globally optimal solution.
The likelihood of each hypothesis is calculated for some or all of the tracklets based on heuristics.
The global solution identifies a sequence of high-likelihood hypotheses that accounts for all observations.

We developed `btrack` for cell tracking in time-lapse microscopy data.

## Installation

`btrack` has been tested with ![Python](https://img.shields.io/pypi/pyversions/btrack)
on `x86_64` `macos>=11`, `ubuntu>=20.04` and `windows>=10.0.17763`.
Note that `btrack<=0.5.0` was built against earlier version of
[Eigen](https://eigen.tuxfamily.org) which used `C++=11`, as of `btrack==0.5.1`
it is now built against `C++=17`.

### Installing the latest stable version

```sh
pip install btrack
```

## Usage examples

Visit [btrack documentation](https://btrack.readthedocs.io) to learn how to use it and see other examples.

### Cell tracking in time-lapse imaging data

 We provide integration with Napari, including a plugin for graph visualization, [arboretum](https://btrack.readthedocs.io/en/latest/user_guide/napari.html).


[![CellTracking](http://lowe.cs.ucl.ac.uk/images/youtube.png)](https://youtu.be/EjqluvrJGCg)  
*Video of tracking, showing automatic lineage determination*


<img src=""https://user-images.githubusercontent.com/8217795/225356392-6eb4b68c-eda5-4b96-af50-76930fa45e9d.png"" width=""700"" />


---

## Development

The tracker and hypothesis engine are mostly written in C++ with a Python wrapper.
If you would like to contribute to btrack, you will need to install the latest version from GitHub. Follow the [instructions on our developer guide](https://btrack.readthedocs.io/en/latest/dev_guide).


---
### Citation

More details of how this type of tracking approach can be applied to tracking cells in time-lapse microscopy data can be found in the following publications:

**Automated deep lineage tree analysis using a Bayesian single cell tracking approach**  
Ulicna K, Vallardi G, Charras G and Lowe AR.  
*Front in Comp Sci* (2021)  
[![doi:10.3389/fcomp.2021.734559](https://img.shields.io/badge/doi-10.3389%2Ffcomp.2021.734559-blue)](https://doi.org/10.3389/fcomp.2021.734559)


**Local cellular neighbourhood controls proliferation in cell competition**  
Bove A, Gradeci D, Fujita Y, Banerjee S, Charras G and Lowe AR.  
*Mol. Biol. Cell* (2017)  
[![doi:10.1091/mbc.E17-06-0368](https://img.shields.io/badge/doi-10.1091%2Fmbc.E17--06--0368-blue)](https://doi.org/10.1091/mbc.E17-06-0368)

```
@ARTICLE {10.3389/fcomp.2021.734559,
   AUTHOR = {Ulicna, Kristina and Vallardi, Giulia and Charras, Guillaume and Lowe, Alan R.},
   TITLE = {Automated Deep Lineage Tree Analysis Using a Bayesian Single Cell Tracking Approach},
   JOURNAL = {Frontiers in Computer Science},
   VOLUME = {3},
   PAGES = {92},
   YEAR = {2021},
   URL = {https://www.frontiersin.org/article/10.3389/fcomp.2021.734559},
   DOI = {10.3389/fcomp.2021.734559},
   ISSN = {2624-9898}
}
```

```
@ARTICLE {Bove07112017,
  author = {Bove, Anna and Gradeci, Daniel and Fujita, Yasuyuki and Banerjee,
    Shiladitya and Charras, Guillaume and Lowe, Alan R.},
  title = {Local cellular neighborhood controls proliferation in cell competition},
  volume = {28},
  number = {23},
  pages = {3215-3228},
  year = {2017},
  doi = {10.1091/mbc.E17-06-0368},
  URL = {http://www.molbiolcell.org/content/28/23/3215.abstract},
  eprint = {http://www.molbiolcell.org/content/28/23/3215.full.pdf+html},
  journal = {Molecular Biology of the Cell}
}
```
","['Framework :: napari', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: C++', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Recognition', 'Topic :: Scientific/Engineering :: Visualization']","['bugtracker, https://github.com/quantumjot/btrack/issues', 'documentation, https://btrack.readthedocs.io', 'homepage, https://github.com/quantumjot/btrack', 'usersupport, https://github.com/quantumjot/btrack/discussions']",btrack.read_btrack,btrack.write_hdf,btrack.track,,"['*.h5', '*.hdf', '*.hdf5']","['.h5', '.hdf', '.hdf5']",
31,cellfinder,cellfinder,cellfinder,1.7.0,2024-01-03,2025-05-30,"Adam Tyson, Christian Niedworok, Charly Rousseau","""Adam Tyson, Christian Niedworok, Charly Rousseau"" <code@adamltyson.com>",BSD-3-Clause,https://github.com/brainglobe/cellfinder/issues,https://pypi.org/project/cellfinder/,,,Automated 3D cell detection in large microscopy images,>=3.11,"['brainglobe-utils>=0.5.0', 'brainglobe-napari-io>=0.3.4', 'dask[array]', 'fancylog>=0.0.7', 'natsort', 'numba', 'numpy', 'scikit-image', 'scikit-learn', 'keras>=3.7.0', 'torch>=2.4.1', 'tifffile', 'tqdm', 'qt-niu', 'black; extra == ""dev""', 'pre-commit; extra == ""dev""', 'pyinstrument; extra == ""dev""', 'pytest-cov; extra == ""dev""', 'pytest-mock; extra == ""dev""', 'pytest-qt; extra == ""dev""', 'pytest-timeout; extra == ""dev""', 'pytest; extra == ""dev""', 'tox; extra == ""dev""', 'pooch>=1; extra == ""dev""', 'brainglobe-napari-io; extra == ""napari""', 'magicgui; extra == ""napari""', 'napari-ndtiffs; extra == ""napari""', 'napari-plugin-engine>=0.1.4; extra == ""napari""', 'napari[pyqt5]; extra == ""napari""', 'pooch>=1; extra == ""napari""', 'qtpy; extra == ""napari""']","[![Python Version](https://img.shields.io/pypi/pyversions/cellfinder.svg)](https://pypi.org/project/cellfinder)
[![PyPI](https://img.shields.io/pypi/v/cellfinder.svg)](https://pypi.org/project/cellfinder)
[![Downloads](https://pepy.tech/badge/cellfinder)](https://pepy.tech/project/cellfinder)
[![Wheel](https://img.shields.io/pypi/wheel/cellfinder.svg)](https://pypi.org/project/cellfinder)
[![Development Status](https://img.shields.io/pypi/status/cellfinder.svg)](https://github.com/brainglobe/cellfinder)
[![Tests](https://img.shields.io/github/actions/workflow/status/brainglobe/cellfinder/test_and_deploy.yml?branch=main)](https://github.com/brainglobe/cellfinder/actions)
[![codecov](https://codecov.io/gh/brainglobe/cellfinder/branch/main/graph/badge.svg?token=nx1lhNI7ox)](https://codecov.io/gh/brainglobe/cellfinder)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/python/black)
[![Imports: isort](https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&labelColor=ef8336)](https://pycqa.github.io/isort/)
[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)
[![Contributions](https://img.shields.io/badge/Contributions-Welcome-brightgreen.svg)](https://brainglobe.info/community/developers/index.html)
[![Twitter](https://img.shields.io/twitter/follow/brain_globe?style=social)](https://twitter.com/brain_globe)

# cellfinder

cellfinder is software for automated 3D cell detection in very large 3D images (e.g., serial two-photon or lightsheet volumes of whole mouse brains).
There are three different ways to interact and use it, each with different user interfaces and objectives in mind.
For more details, head over to [the documentation website](https://brainglobe.info/documentation/cellfinder/index.html).

At a glance:

- There is a command-line interface called [brainmapper](https://brainglobe.info/documentation/brainglobe-workflows/brainmapper/index.html) that integrates [with `brainreg`](https://github.com/brainglobe/brainreg) for automated cell detection and classification. You can install it through [`brainglobe-workflows`](https://brainglobe.info/documentation/brainglobe-workflows/index.html).
- There is a [napari plugin](https://brainglobe.info/documentation/cellfinder/user-guide/napari-plugin/index.html) for interacting graphically with the cellfinder tool.
- There is a [Python API](https://brainglobe.info/documentation/cellfinder/user-guide/cellfinder-core.html) to allow users to integrate BrainGlobe tools into their custom workflows.

## Installation

You can find [the installation instructions](https://brainglobe.info/documentation/cellfinder/installation.html#installation) on the BrainGlobe website, which will go into more detail about the installation process if you want to minimise your installation to suit your needs.
However, we recommend that users install `cellfinder` either through installing BrainGlobe version 1, or (if you also want the command-line interface) installing `brainglobe-workflows`.

```bash
# If you want to install all BrainGlobe tools, including cellfinder, in a consistent manner with one command:
pip install brainglobe>=1.0.0
# If you want to install the brainmapper CLI tool as well:
pip install brainglobe-workflows>=1.0.0
```

If you only want the `cellfinder` package by itself, you can `pip install` it alone:

```bash
pip install cellfinder>=1.0.0
```

Be sure to specify a version greater than version `v1.0.0` - prior to this version the `cellfinder` package had a very different structure that is incompatible with BrainGlobe version 1 and the other tools in the BrainGlobe suite.
See [our blog posts](https://brainglobe.info/blog/) for more information on the release of BrainGlobe version 1.

## Seeking help or contributing
We are always happy to help users of our tools, and welcome any contributions. If you would like to get in contact with us for any reason, please see the [contact page of our website](https://brainglobe.info/contact.html).

## Citation
If you find this package useful, and use it in your research, please cite the following paper:
> Tyson, A. L., Rousseau, C. V., Niedworok, C. J., Keshavarzi, S., Tsitoura, C., Cossell, L., Strom, M. and Margrie, T. W. (2021) âA deep learning algorithm for 3D cell detection in whole mouse brain image datasetsâ PLOS Computational Biology, 17(5), e1009074
[https://doi.org/10.1371/journal.pcbi.1009074](https://doi.org/10.1371/journal.pcbi.1009074)

**If you use this, or any other tools in the brainglobe suite, please
 [let us know](https://brainglobe.info/contact.html), and
 we'd be happy to promote your paper/talk etc.**
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Recognition']","['Homepage, https://brainglobe.info/documentation/cellfinder/index.html', 'Source Code, https://github.com/brainglobe/cellfinder', 'Bug Tracker, https://github.com/brainglobe/cellfinder/issues', 'Documentation, https://brainglobe.info/documentation/cellfinder/index.html', 'User Support, https://forum.image.sc/tag/brainglobe']",,,cellfinder.napari.detect_widget,cellfinder.napari.SampleData,,,
32,cellpose-napari,cellpose-napari,cellpose-napari,0.2.0,2021-04-28,2024-08-26,Carsen Stringer,stringerc@janelia.hhmi.org,BSD-3,https://github.com/Mouseland/cellpose-napari,https://pypi.org/project/cellpose-napari/,,https://github.com/Mouseland/cellpose-napari,a generalist algorithm for anatomical segmentation,>=3.7,"['napari', 'napari-plugin-engine>=0.1.4', 'cellpose>0.6.3', 'imagecodecs', 'sphinx>=3.0; extra == ""docs""', 'sphinxcontrib-apidoc; extra == ""docs""', 'sphinx-rtd-theme; extra == ""docs""', 'sphinx-prompt; extra == ""docs""', 'sphinx-autodoc-typehints; extra == ""docs""', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# cellpose-napari <img src=""docs/_static/favicon.ico"" width=""50"" title=""cellpose"" alt=""cellpose"" align=""right"" vspace = ""50"">

[![Documentation Status](https://readthedocs.org/projects/cellpose-napari/badge/?version=latest)](https://cellpose-napari.readthedocs.io/en/latest/?badge=latest)
[![tests](https://github.com/mouseland/cellpose-napari/workflows/tests/badge.svg)](https://github.com/mouseland/cellpose-napari/actions)
[![codecov](https://codecov.io/gh/Mouseland/cellpose-napari/branch/main/graph/badge.svg)](https://codecov.io/gh/MouseLand/cellpose-napari)
[![PyPI version](https://badge.fury.io/py/cellpose-napari.svg)](https://badge.fury.io/py/cellpose-napari)
[![PyPI - Downloads](https://img.shields.io/pypi/dm/cellpose-napari)](https://pypistats.org/packages/cellpose-napari)
[![Python version](https://img.shields.io/pypi/pyversions/cellpose-napari)](https://pypistats.org/packages/cellpose-napari)
[![License](https://img.shields.io/pypi/l/cellpose-napari.svg?color=green)](https://github.com/mouseland/cellpose-napari/raw/master/LICENSE)
[![Contributors](https://img.shields.io/github/contributors-anon/MouseLand/cellpose-napari)](https://github.com/MouseLand/cellpose-napari/graphs/contributors)
[![website](https://img.shields.io/website?url=https%3A%2F%2Fwww.cellpose.org)](https://www.cellpose.org)
[![GitHub stars](https://img.shields.io/github/stars/MouseLand/cellpose-napari?style=social)](https://github.com/MouseLand/cellpose-napari/)
[![GitHub forks](https://img.shields.io/github/forks/MouseLand/cellpose-napari?style=social)](https://github.com/MouseLand/cellpose-napari/)

a napari plugin for anatomical segmentation of general cellular images

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

The plugin code was written by Carsen Stringer, and the cellpose code was written by Carsen Stringer and Marius Pachitariu. To learn about Cellpose, read the [**paper**](https://t.co/kBMXmPp3Yn?amp=1) or watch this [**talk**](https://t.co/JChCsTD0SK?amp=1). 

For support with the plugin, please open an [issue](https://github.com/MouseLand/cellpose-napari/issues). For support with cellpose, please open an [issue](https://github.com/MouseLand/cellpose/issues) on the cellpose repo. 


If you use this plugin please cite the [paper](https://www.nature.com/articles/s41592-020-01018-x):
::
    
      @article{stringer2021cellpose,
      title={Cellpose: a generalist algorithm for cellular segmentation},
      author={Stringer, Carsen and Wang, Tim and Michaelos, Michalis and Pachitariu, Marius},
      journal={Nature Methods},
      volume={18},
      number={1},
      pages={100--106},
      year={2021},
      publisher={Nature Publishing Group}
      }


![cellpose-napari_plugin](https://cellpose-napari.readthedocs.io/en/latest/_images/napari_main_demo_fast_small.gif?raw=true ""cellpose-napari"")

## Installation

Install an [Anaconda](https://www.anaconda.com/download/) distribution of Python -- Choose **Python 3** and your operating system. Note you might need to use an anaconda prompt if you did not add anaconda to the path.

Install `napari` with pip: `pip install napari[all]`. Then install `cellpose-napari` via [pip]:

    pip install cellpose-napari
    
 Or install the plugin inside napari in the plugin window.

If install fails in your base environment, create a new environment:
1. Download the [`environment.yml`](https://github.com/MouseLand/cellpose-napari/blob/master/environment.yml?raw=true) file from the repository. You can do this by cloning the repository, or copy-pasting the text from the file into a text document on your local computer.
2. Open an anaconda prompt / command prompt with `conda` for **python 3** in the path
3. Change directories to where the `environment.yml` is and run `conda env create -f environment.yml`
4. To activate this new environment, run `conda activate cellpose_napari`
5. You should see `(cellpose_napari)` on the left side of the terminal line. 

If you have **issues** with cellpose installation, see the [cellpose docs](https://cellpose.readthedocs.io/en/latest/installation.html) for more details, and then if the suggestions fail, open an issue.

### Upgrading software

You can upgrade the plugin with
~~~
pip install cellpose-napari --upgrade
~~~

and you can upgrade cellpose with
~~~
pip install cellpose --upgrade
~~~

### GPU version (CUDA) on Windows or Linux

If you plan on running many images, you may want to install a GPU version of *torch* (if it isn't already installed).

Before installing the GPU version, remove the CPU version:
~~~
pip uninstall torch
~~~

Follow the instructions [here](https://pytorch.org/get-started/locally/) to determine what version to install. The Anaconda install is recommended along with CUDA version 10.2. For instance this command will install the 10.2 version on Linux and Windows (note the `torchvision` and `torchaudio` commands are removed because cellpose doesn't require them):

~~~
conda install pytorch cudatoolkit=10.2 -c pytorch
~~~~

When upgrading GPU Cellpose in the future, you will want to ignore dependencies (to ensure that the pip version of torch does not install):
~~~
pip install --no-deps cellpose --upgrade
~~~

### Installation of github version

Follow steps from above to install the dependencies. In the github repository, run `pip install -e .` and the github version will be installed. If you want to go back to the pip version of cellpose-napari, then say `pip install cellpose-napari`.


## Running the software


Open napari with the cellpose-napari dock widget open
```
napari -w cellpose-napari
```

There is sample data in the File menu, or get started with your own images!

### Detailed usage [documentation](https://cellpose-napari.readthedocs.io/).

## Contributing

Contributions are very welcome. Tests are run with pytest.

## License

Distributed under the terms of the [BSD-3] license,
""cellpose-napari"" is free and open source software.

## Dependencies
cellpose-napari relies on the following excellent packages (which are automatically installed with conda/pip if missing):
- [napari](https://napari.org)
- [magicgui](https://napari.org/magicgui/)

cellpose relies on the following excellent packages (which are automatically installed with conda/pip if missing):
- [torch](https://pytorch.org/)
- [numpy](http://www.numpy.org/) (>=1.16.0)
- [numba](http://numba.pydata.org/numba-doc/latest/user/5minguide.html)
- [scipy](https://www.scipy.org/)
- [natsort](https://natsort.readthedocs.io/en/master/)
- [tifffile](https://pypi.org/project/tifffile/)
- [opencv](https://opencv.org/)


[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
","['Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License', 'Framework :: napari']",,,,cellpose-napari.widget_wrapper,cellpose-napari.data.rgb_3D,,,
33,disease-classifier,disease-classifier,Disease classifier,0.0.1,2022-06-07,2022-06-07,Chenqi Zhang,cqzhang@g.ecc.u-tokyo.ac.jp,BSD-3-Clause,https://github.com/zcqwh/disease-classifier/issues,https://pypi.org/project/disease-classifier/,,https://github.com/zcqwh/disease-classifier,A disease classifier based on iPAC images.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'matplotlib', 'h5py (>=3.6.0)', 'napari (>=0.4.15)', 'numpy (>=1.22.4)', 'opencv-contrib-python-headless (>=4.5.5.64)', 'pytranskit (>=0.2.3)', 'statsmodels (>=0.13.2)', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# disease-classifier

[![License](https://img.shields.io/pypi/l/disease-classifier.svg?color=green)](https://github.com/zcqwh/disease-classifier/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/disease-classifier.svg?color=green)](https://pypi.org/project/disease-classifier)
[![Python Version](https://img.shields.io/pypi/pyversions/disease-classifier.svg?color=green)](https://python.org)
[![tests](https://github.com/zcqwh/disease-classifier/workflows/tests/badge.svg)](https://github.com/zcqwh/disease-classifier/actions)
[![codecov](https://codecov.io/gh/zcqwh/disease-classifier/branch/main/graph/badge.svg)](https://codecov.io/gh/zcqwh/disease-classifier)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/disease-classifier)](https://napari-hub.org/plugins/disease-classifier)

A napari plugin for disease classification based on iPAC images.



## Installation

You can install `disease-classifier` via [pip]:

    pip install disease-classifier



To install latest development version :

    pip install git+https://github.com/zcqwh/disease-classifier.git

## Introduction
#### Load data (.rtdc or .bin)
* Drag and drop the data in .rtdc or .bin into the files table.
* Click eye button to preview images.
![](https://github.com/zcqwh/disease-classifier/blob/main/Tutorial/Gif/01_Load_preview.gif?raw=true)


#### Choose model and classify

* Choose the model folder including CNN and RF/PLDA.
* Check the data.
* Click classify.
![](https://github.com/zcqwh/disease-classifier/blob/main/Tutorial/Gif/02_model_classify.gif?raw=true)

#### Preview classification results
* Click the eye button to preview the result.
* Click the header to show all.
![](https://github.com/zcqwh/disease-classifier/blob/main/Tutorial/Gif/03_preview_result.gif?raw=true)


#### Save results
* Click âAdd classification to .rtdc fileâ button to save results.
![](https://github.com/zcqwh/disease-classifier/blob/main/Tutorial/Gif/04_save.gif?raw=true)


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""disease-classifier"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/zcqwh/disease-classifier/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/zcqwh/disease-classifier/issues', 'Documentation, https://github.com/zcqwh/disease-classifier#README.md', 'Source Code, https://github.com/zcqwh/disease-classifier', 'User Support, https://github.com/zcqwh/disease-classifier/issues']",,,disease-classifier.make_qwidget,,,,
34,darth-d,darth-d,darth-d,0.4.0,2023-10-26,2023-11-21,Robert Haase,robert.haase@uni-leipzig.de,BSD-3-Clause,https://github.com/haesleinhuepf/darth-d,https://pypi.org/project/darth-d/,,https://github.com/haesleinhuepf/darth-d/,A simple to use image generator based on OpenAIs DALL-E,>=3.8,"['openai >=1.2.0', 'Pillow', 'numpy', 'stackview >=0.7.1']","# Darth-D
[![License](https://img.shields.io/pypi/l/darth-d.svg?color=green)](https://github.com/haesleinhuepf/darth-d/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/darth-d.svg?color=green)](https://pypi.org/project/darth-d)
[![Python Version](https://img.shields.io/pypi/pyversions/darth-d.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/darth-d/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/darth-d/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/darth-d/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/darth-d)
[![Development Status](https://img.shields.io/pypi/status/darth-d.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/darth-d)](https://napari-hub.org/plugins/darth-d)

A simple to use image generator based on [OpenAIs DALL-E 2/3](https://openai.com/dall-e-2).
It comes as [napari](https://napari.org/) plugin and has a Python interface. 
You need an [OpenAI API KEY](https://openai.com/blog/openai-api/) to use it.

Using some of the functions on scientific images could be seen as scientific misconduct. Handle these functions with care.

![](https://github.com/haesleinhuepf/darth-d/raw/main/docs/images/replace_screencast.gif)

## Usage

### From Python

You can generate images from text prompts in Python like this ([see this notebool](https://github.com/haesleinhuepf/darth-d/blob/main/demo/demo_darth-d.ipynb)).

```
from darth_d import create
```

```
image = create(""an image of a cat"")

image
```

![](https://github.com/haesleinhuepf/darth-d/raw/main/docs/images/jupyter_screenshot.png)

You can also vary images ([see this notebook](https://github.com/haesleinhuepf/darth-d/blob/main/demo/demo_vary.ipynb)):
```
from darth_d import vary

output_image = vary(input_image)
```

![](https://github.com/haesleinhuepf/darth-d/raw/main/docs/images/vary_screenshot.png)

Replacing regions in images is also possible. Note: Using this function on scientific images could be seen as scientific misconduct. Handle this function with care.

### In Napari

To generate images in Napari, click the `Tools > Generate > Image` menu. You can for example enter the prompt
""a professional comic with white background showing a cat having an idea. the idea is visualized using a light bulb.

![](https://github.com/haesleinhuepf/darth-d/raw/main/docs/images/napari_screenshot.png)


## Installation

```
pip install darth-d
```

If you want to use it from napari, please also install napari and the [tools menu](https://github.com/haesleinhuepf/napari-tools-menu):

```
mamba install napari pyqt napari-tools-menu -c conda-forge
```

## Similar tools and plugins

* https://github.com/kephale/napari-stable-diffusion
* https://github.com/seankmartin/napari-stable-diffusion

## Feedback welcome!

The `darth-d` is developed in the open because we believe in the open source community. Feel free to drop feedback as [github issue](https://github.com/haesleinhuepf/darth-d) or via [image.sc](https://image.sc)

## Contributing

Contributions are very welcome. 

## License

Distributed under the terms of the [BSD-3] license,
""darth-d"" is free and open source software

[BSD-3]: http://opensource.org/licenses/BSD-3-Clause

","['Framework :: napari', 'License :: OSI Approved :: BSD License', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent']","['Bug Tracker, https://github.com/haesleinhuepf/darth-d/issues', 'Documentation, https://github.com/haesleinhuepf/darth-d/', 'Source Code, https://github.com/haesleinhuepf/darth-d', 'User Support, https://forum.image.sc/']",,,darth-d.napari_experimental_provide_function,,,,
35,elastix-napari,elastix-napari,elastix-napari,0.2.1,2021-03-24,2023-06-20,Viktor van der Valk,v.o.van_der_valk@lumc.nl,Apache Software License 2.0,https://github.com/SuperElastix/elastix-napari,https://pypi.org/project/elastix-napari/,,https://github.com/SuperElastix/elastix-napari,A toolbox for rigid and nonrigid registration of images.,>=3.8,"['itk-elastix (>=0.11.1)', 'numpy (>=1.19.0)', 'napari[all] (>=0.4.6)', 'napari-plugin-engine (>=0.1.4)', 'magicgui (>=0.4.0)', 'itk-napari-conversion (>=0.3.1)', 'napari-itk-io (>=0.1.0)']","# elastix-napari

[![License](https://img.shields.io/pypi/l/elastix-napari.svg?color=green)](https://github.com/SuperElastix/elastix-napari/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/elastix-napari.svg?color=green)](https://pypi.org/project/elastix-napari)
[![Python Version](https://img.shields.io/pypi/pyversions/elastix-napari.svg?color=green)](https://python.org)
[![tests](https://github.com/SuperElastix/elastix-napari/workflows/tests/badge.svg)](https://github.com/SuperElastix/elastix-napari/actions)
[![codecov](https://codecov.io/gh/SuperElastix/elastix-napari/branch/main/graph/badge.svg)](https://codecov.io/gh/SuperElastix/elastix-napari)
[![Youtube](https://img.shields.io/badge/YouTube-Demo-red)](https://www.youtube.com/watch?v=GzbP-qUR034)

The [napari] plugin for [elastix], a toolbox for rigid and nonrigid registration of images, based on [itk-elastix].

For a demo video see [youtube] channel.
For tutorials on how to use elastix, see our [Jupyter notebooks].

To find parameters that work well with specific datasets, see the [elastix Model Zoo].

<img width=""1438"" alt=""Screenshot 2021-05-12 at 15 07 24"" src=""https://user-images.githubusercontent.com/33719474/117980045-d6009b00-b333-11eb-9976-f64d34f4f7cc.png"">

## Installation

You can install `elastix-napari` via [pip]:

    pip install elastix-napari

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""elastix-napari"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/SuperElastix/elastix-napari/issues
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[elastix]: https://elastix.lumc.nl/
[itk-elastix]: https://github.com/InsightSoftwareConsortium/ITKElastix
[elastix Model Zoo]: https://elastix.lumc.nl/modelzoo/
[Jupyter notebooks]: https://mybinder.org/v2/gh/InsightSoftwareConsortium/ITKElastix/master?urlpath=lab/tree/examples%2FITK_Example01_SimpleRegistration.ipynb
[youtube]: https://www.youtube.com/watch?v=GzbP-qUR034
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: Apache Software License']","['Project Site, https://elastix.lumc.nl/', 'Bug Tracker, https://github.com/SuperElastix/elastix-napari/issues', 'Source Code, https://github.com/SuperElastix/elastix-napari', 'User Support, https://groups.google.com/g/elastix-imageregistration']",,,elastix-napari.elastix_registration,,,,
36,empanada-napari,empanada-napari,empanada-napari,1.2,2022-03-04,2025-04-28,"Madeline Barry, Abhishek Bhardwaj, Ryan Conrad",abhishek.bhardwaj@nih.gov,BSD-3-Clause,https://github.com/volume-em/empanada-napari/issues,https://pypi.org/project/empanada-napari/,,https://github.com/volume-em/empanada-napari,Napari plugin of algorithms for Panoptic Segmentation of organelles in EM,>=3.7,"['torch>=1.10', 'torchvision>=0.2', 'zarr>=2.12', 'albumentations>=1.2', 'pyyaml', 'cztile', 'mlflow', 'opencv-python==4.9.0.80', 'opencv-python-headless==4.9.0.80', 'napari==0.4.18', 'numpy==1.22', 'napari-plugin-engine>=0.1.4', 'scikit-image>=0.19', 'numba==0.58.1', 'imagecodecs', 'openpyxl', 'imagehash', 'simpleitk', 'tqdm']","# empanada-napari

> [!IMPORTANT]
> **New Version 1.2 Announcement!**
> * New Models:
>   * NucleoNet: A base model for EM instance nucleus segmentation
>   * DropNet: A base model for EM Lipid Droplet instance segmentation
> * New modules 
>   * Archive Model - archives the model into a hidden archive folder 
>   * Create Tiles - Split big images winto small tiles (with Mask/ optional)
>   * Merge Tiles - Opposite of split tiles, create full image from tiles created by create tiles
>   * Morph labels - applies morphological operations to labels
>   * Count labels - counts and lists the label IDs within the dataset
>   * Filter labels - removes small pixel/voxel area labels or labels touching the image boundaries
>   * Export and import a model - export or import locally saved model files to use within empanada-napari
> * Updated modules
>   * 2D Inference - now allows ROI inference and filling holes in segmentation label maps
>   * 3D Inference - allows erosion, dilation and fill holes in segmentation to help tackle big split merge errors
>   * Export segmentations - now allows 3D segmentations to be exported as a single .tiff image
>   * Pick and save finetune/training patches - now allows paired grayscale and label mask images to create training patches 
>   * Split label - now allows users to specify new label IDs 
> * Updated documentation
>   * Check out the updated documentation [here](https://empanada.readthedocs.io/en/latest/index.html)!

**The paper describing this work is now available [on Cell Systems](https://www.cell.com/cell-systems/fulltext/S2405-4712(22)00494-X).**

**Documentation for the plugin, including more detailed installation instructions, can be found [here](https://empanada.readthedocs.io/en/latest/empanada-napari.html).**

empanada is a tool for deep learning-based panoptic segmentation of 2D and 3D electron microscopy images of cells.
This plugin allows the running of panoptic segmentation models trained in empanada within [napari](https://napari.org).
For help with this plugin please open an [issue](https://github.com/volume-em/empanada-napari/issues), for issues with napari specifically
raise an [issue here instead](https://github.com/napari/napari/issues).

## Implemented Models

  - *MitoNet*: A generalist mitochondrial instance segmentation model.

## Example Datasets

Volume EM datasets for benchmarking mitochondrial instance segmentation are available from
[EMPIAR-10982](https://www.ebi.ac.uk/empiar/EMPIAR-10982/).

## Installation

### New Users

If you've previously installed and used conda, it's recommended (but optional) to create a new virtual 
environment in order to avoid dependency conflicts. 

empanada-napari works with python=3.9 or lower

It's recommended to have installed napari through [conda](https://docs.conda.io/en/latest/miniconda.html). Then to install this plugin:

```shell
pip install empanada-napari==1.2
```

Launch napari:

```shell
napari
```

Look for empanada-napari under the ""Plugins"" menu.


### Returning Users

If you installed napari into a virtual environment as suggested in the original release documentation, 
be sure to activate it and uninstall the old empanada-napari.

```shell
pip uninstall empanada-napari
```

Then install the newest version:

```shell
pip install empanada-napari==1.2
```


![empanada](images/demo.gif)

## GPU Support

**Note: Mac doesn't support NVIDIA GPUS. This section only applies to Windows and Linux systems.**

As for any deep learning models, having a GPU installed on your system will significantly
increase model throughput (although we ship CPU optimized versions of all models with the plugin).

This plugin relies on torch for running models. If a GPU was found on your system, then you will see that the
""Use GPU"" checkbox is checked by default in the ""2D Inference"" and ""3D Inference"" plugin widgets. Or if when running
inference you see a message that says ""Using CPU"" in the terminal that means a GPU is not being used.

Make sure that GPU drivers are correctly installed. In terminal or command prompt:

```shell
nvidia-smi
```

If this returns ""command not found"" then you need to [install the driver from NVIDIA](https://www.nvidia.com/download/index.aspx). Instead, if
if the driver is installed correctly, you may need to switch to the GPU enabled version of torch.

First, uninstall the current version of torch:

```shell
pip uninstall torch
```

Then [install torch >= 1.10 using conda for your system](https://pytorch.org/get-started/locally/).
This command should work:

```shell
conda install pytorch cudatoolkit=11.3 -c pytorch
```

## Citing this work

If you use results generated by this plugin in a publication, please cite:

```bibtex
@article { Conrad2023,
    author = {Conrad, Ryan and Narayan, Kedar},
    title = {Instance segmentation of mitochondria in electron microscopy images with a generalist deep learning model trained on a diverse dataset},
    journal = {Cell Systems},
    year = {2023},
    month = {Jan},
    day = {18},
    publisher = {Elsevier},
    volume = {14},
    number = {1},
    pages = {58-71.e5},
    issn = {2405-4712},
    doi = {10.1016/j.cels.2022.12.006},
    url = {https://doi.org/10.1016/j.cels.2022.12.006}
}
```
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/volume-em/empanada-napari/issues', 'Documentation, https://github.com/volume-em/empanada-napari#README.md', 'Source Code, https://github.com/volume-em/empanada-napari', 'User Support, https://github.com/volume-em/empanada-napari/issues']",,,empanada-napari.test_widget,,,,
37,domb-napari,domb-napari,domb-napari,0.4.1,2024-03-01,2025-06-03,Borys Olifirov,omnia.fatum@gmail.com,MIT,https://github.com/wisstock/domb-napari/issues,https://pypi.org/project/domb-napari/,,,napari plugin for analyzing the redistribution of fluorescence-labeled proteins,>=3.8,"['napari', 'domb', 'dipy', 'numba', 'pybaselines']","domb-napari
===========

[![Stand With Ukraine](https://raw.githubusercontent.com/vshymanskyy/StandWithUkraine/main/banner-direct-single.svg)](https://stand-with-ukraine.pp.ua)

[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/domb-napari)](https://napari-hub.org/plugins/domb-napari)
![PyPI - Version](https://img.shields.io/pypi/v/domb-napari)
![PyPI - License](https://img.shields.io/pypi/l/domb-napari)
[![DOI](https://zenodo.org/badge/722100876.svg)](https://doi.org/10.5281/zenodo.14843770)
<!-- ![Website](https://img.shields.io/website?up_message=domb.bio%2Fnapari&up_color=%2323038C93&url=https%3A%2F%2Fdomb.bio%2Fnapari%2F) -->

__napari Toolkit of Department of Molecular Biophysics <br /> Bogomoletz Institute of Physiology of NAS of Ukraine, Kyiv,  Ukraine__

This plugin offers widgets specifically designed to analyze the redistribution of fluorescence-labeled proteins in widefield epifluorescence time-lapse acquisitions. It is particularly useful for studying various phenomena, including:
- Calcium-dependent translocation of neuronal calcium sensors.
- Synaptic receptor traffic during long-term plasticity induction.
- Membrane protein tracking.

![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/translocation.gif)
__Hippocalcin (neuronal calcium sensor) redistributes in dendritic branches upon NMDA application__

---

## Preprocessing
### Dual-view Stack Registration
Registration of four-channel image stacks, including two excitation wavelengths and two emission pathbands, acquired with a dual-view beam splitter. This setup detects different spectral pathbands using distinct sides of the camera matrix.

- `offset img` - input for a four-channel time-lapse image stack.
- `reference img` - an optional four-channel reference image (e.g., fluorescence beads image), used for offset estimation if `use reference img` is selected.
- `input crop` - number of pixels that will be deleted from each side of input stack frames to discard misalignment artifacts from the dual-view system.
- `output crop` - number of pixels that will be deleted from each side of output stack frames to discard registration artifacts.


### Multichannel Stack Preprocessing
- `stack order` -  represents the order of axes in the input data array: T (time), C (color), X, and Y (image dimensions). If the input image stack has four dimensions (time, channel, x-axis, y-axis), channels will be split into individual three-dimensional images (time, x-axis, y-axis), each labeled with the `_ch%index%` suffix.
- `median filter` - provides frame-by-frame image smoothing with a kernel of size specified in `median kernel`.
- `background subtraction` -  compensates for background fluorescence intensity. Background intensity is estimated frame by frame as the 0.5 percentile of frame intensity.
- If the `photobleaching correction` option is selected, the image will undergo correction using either an exponential (method `exp`) or bi-exponential (method `bi_exp`) fitting.
- Image stacks can be cropped according to start and stop indexes specified in `frames range` if `drop frames` is selected.

![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/stack_preprocessing.png)

---

## Detection of Fluorescence Redistribution
A set of widgets designed for preprocessing multispectral image stacks and detecting redistributions in fluorescence intensity. These widgets specifically analyze differential ""red-green"" image series to identify changes in fluorescence intensity.

Inspired by [Dovgan et al., 2010](https://pubmed.ncbi.nlm.nih.gov/20704590/) and [Osypenko et al., 2019](https://www.sciencedirect.com/science/article/pii/S0969996119301974?via%3Dihub).

### Red-Green Series
Primary method for detecting fluorescence-labeled targets redistribution. This widget returns a series of differential images, each representing the intensity difference between the current frame and the previous one, output image labeled with the `_red-green` suffix.

Parameters:

- `left frames` - specifies the number of previous frames used for pixel-wise averaging.
- `space frames` - determines the number of frames between the last left frame and the first right frame.
- `right frames` - specifies the number of subsequent frames used for pixel-wise averaging.

`normalize by int`  function normalizes the differential images relative to the absolute intensity of the input image stack, which helps to reduce background noise amplitude.

If `save MIP` is selected, the maximal intensity projection (MIP) of the differential image stack will be saved with the `_red-green-MIP` suffix.

![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/rg_series.png)

### ÎF/F Series
_In progress._

---

## Masking
### Dots Pattern Masking
Creates labels for bright dot elements on an image, such as pre- and postsynaptic fluorescence markers (e.g., Bassoon/Synaptobrevin for presynapses, PSD-95/Homer for postsynapses, etc.). It returns a labels layer with the `_dots-labels` suffix.

The widget detects the location on the MIP (Maximum Intensity Projection) of the input time series image and applies simple round masks to each detected dot. Watershed segmentation is then used to prevent the merging of overlapping masks.

Parameters:

- `background level` - Background level for filtering out low-intensity elements. This is specified as a percentile of the MIP intensity.
- `detection level` - Minimum intensity of dots, specified as a percentile of the MIP's maximum intensity.
- `mask diameter` - Diameter in pixels for the round mask of each individual dot.
- `minimal distance` - Minimum distance in pixels between the centers of individual round masks.

![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/dots_masking.png)
__Hippocalcin (green) and PSD95 (magents) in dendritic branches__


### Up Masking
Generates labels for regions with high intensity based on raw or -red-green images. Returns a labels layer with the `_up-labels` suffix.

The widget provides two detection modes:

- Global masking with a fixed threshold for the entire image.
- In-ROIs masking with a loop over individual ROIs in the input `ROIs mask` with separate detections.

Parameters:

- `det frame index` - index of the frame from the input image used for label detection.
- `det th` - treshold value for detecting bright sites, where the intensity on the selected frame is normalized in the range of -1 to 0.
- `in ROIs det` - option for activating in-ROIs masking.
- `in ROIs det method` - method for in-ROIs masking; otsu provides simple Otsu thresholding, while the threshold method is identical to global detection on nomilized detection frame.
- `in_ROIs_det_th_corr` - caling factor for the det th threshold value for in-ROIs masking.
- `final opening fp` - footprint size in pixels for mask filtering using morphological opening (disabled if set to 0).
- `final dilation fp` - footprint size in pixels for mask morphological dilation (disabled if set to 0).
- `save total up mask` - if selected, a total up mask (containing all ROIs) will be created with the _up-mask suffix.

![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/up_labels.png)
__Gplobal up labels__

The In-ROIs masking option can be particularly useful for co-localization detection. By applying a broad reference mask to several target images, you can create more precise labels for ROIs in specified cell compartments. The following examples demonstrate the detection of mutual locations for static PSD-95 enriched sites (postsynaptic membranes) and HPCA translocation sites only in the vicinity of synapses, using `_dots-labels` for PSD95-mRFP images.

_Note: In the In-ROIs masking mode, labels of detected sites correspond to the matching labels from the input ROIs mask._

In-ROIs masking (reference)|![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/up_labels_1.png)
:------------------:|:-------------------------:
__In-ROIs maskin (translocation)__|![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/up_labels_2.png)
__Masks overlay__|![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/up_labels_overlay.png)


### Intensity Masking
Extension of __Up Masking__ widget. Detects regions with increasing (`masking mode` - `up`) or decreasing (`masking mode` - `down`) intensity in `-red-green` images. Returns a labels layer with either `_up-labels` or `_down-labels` suffix, depending on the mode.

![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/int_labels.png)

---

## 3-cube E-FRET Approach
Widgets for detection and analysis of FÃ¶rster resonance energy transfer on multispectral image stacks.

Based on notation and approaches from [Zal and Gascoigne, 2004](https://pubmed.ncbi.nlm.nih.gov/15189889/), [Chen et al., 2006](https://pubmed.ncbi.nlm.nih.gov/16815904/) and [Kamino et al., 2023](https://pubmed.ncbi.nlm.nih.gov/37014867/).


### E-FRET Crosstalk Estimation
_In progress._ 

Estimation of the crosstalk/bleedthrough of fluorescence between the donor and acceptorâs spectral channels.

```math
F_c = I_{DA} - a (I_{AA} - c I_{DD}) - d (I_{DD} - b I_{AA})
```

```math
F_c = I_{DA} - a I_{AA} - d I_{DD} \; \text{if} \; b \approx c \approx 0
```

```math
a = \frac{I_{DA(A)}}{I_{AA(A)}}
```

```math
b = \frac{I_{DD(A)}}{I_{AA(A)}}
```

```math
c = \frac{I_{AA(D)}} {I_{DD(D)}}
```

```math
d = \frac{I_{DA(D)}} {I_{DD(D)}}
```

```math
b \approx c \approx 0
```

Parameters:
- `DD img` - donor emission channel image acquired with the donor excitation wavelength.
- `DA img` - donor emission channel image acquired with the acceptor excitation wavelength.
- `AD img` - acceptor emission channel image acquired with the donor excitation wavelength.
- `AA img` - acceptor emission channel image acquired with the acceptor excitation wavelength.
- `mask` - .
- `presented_fluorophore` - .
- `saving_path` - .


### E-FRET G-factor Estimation
_In progress._ 

```math
G = \frac{(I_{DA} - a I_{AA} - d I_{DD}) - (I_{DA}^{post} - a I_{AA}^{post} - d I_{DD}^{post})}{I_{DD}^{post} - I_{DD}} = \frac{F_c - F_{c}^{post}}{I_{DD}^{post} - I_{DD}} = \frac{\Delta F_c}{\Delta I_{DD}}
```


```math
\Delta F_c = G \cdot \Delta I_{DD}
```

### E-FRET Estimation
Estimation of the E-FRET with 3-cube approach.

```math
E_{app} = \frac{R}{R+G}
```

```math
R = \frac{F_c}{I_{DD}}
```


__ECFP and EYFP Setup:__

- Microscope Olympus IX71
- Camera PCO Sensicam QE
- Cube Chroma 69008
- Dual-view system with Chroma 505DCXR beam splitter
- Donor excitation wavelength 435 nm
- Acceptor excitation wavelength 505 nm

__TagBFP and mBaoJin Setup:__

- Microscope Olympus IX71
- Camera PCO Sensicam QE
- Cube Chroma 69002
- Dual-view system with Chroma 505DCXR beam splitter
- Donor excitation wavelength 405 nm
- Acceptor excitation wavelength 495 nm

This method utilizes default values of `a` and `d` coefficients and the `G`-factor for TagBFP and mBaoJin pair. 

Parameters:

- `DD img` - donor emission channel image acquired with the donor excitation wavelength.
- `AD img` - acceptor emission channel image acquired with the donor excitation wavelength.
- `AA img` - acceptor emission channel image acquired with the acceptor excitation wavelength.
- `output type` - type of output image: sensitized emission (`Fc`), apparent FRET efficiency (`Eapp`), or FRET efficiency with photobleaching correction (`Ecorr`).

If the `save normalized` option is selected, an additional image will be saved. This image is normalized to the absolute intensity of the `AA img`, which results in reduced background noise amplitude.

_Note: normalized images are useful for visual control and mask building only; they are not representative for quantitative analysis._

Raw Eapp| ![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/fret_raw.png)
:-:|:-:
__Normalized Eapp__|![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/fret_norm.png)


---


## Exo/Endo-cytosis Monitoring with pH-Sensitive Tag
A set of widgets designed for the analysis of image series containing the pH-sensitive fluorescence protein Superecliptic pHluorin (SEP).

Insipred by [Fujii et al., 2017](https://pubmed.ncbi.nlm.nih.gov/28474392/) and [Sposini et al., 2020](https://www.nature.com/articles/s41596-020-0371-z).


### SEP image preprocessing
Processes image series obtained through repetitive pH exchange methods (such as U-tube or ppH approaches). `pH 1st frame` option indicates the 1st frame pH. By default frames with odd indexes, including index 0, are interpreted as images acquired at pH 7.0, representing total fluorescence intensity (saved with the suffix `_total`). Even frames are interpreted as images obtained at acidic pH (5.5-6.0), representing intracellular fluorescence only (saved with the suffix `_intra`).

If `calc surface img` is selected, an additional total fluorescence image with subtracted intracellular intensity will be saved as the cell surface fluorescence fraction (suffix `_surface`). The input image should be a 3-dimensional single-channel time-lapse.

The `calc projections` option allows obtaining individual pH series projections (pixel-wise series MIP - pixel-wise series average) for the detection of individual exo/endocytosis events.


---


## Plotting and Data Frame Saving
### ROIs Profiles
This widget builds a plot with mean intensity profiles for each Region of Interest (ROI) in labels. It uses either absolute intensity (if `absolute intensity` is selected) or relative intensities (ÎF/F0).

- `time scale` - sets the number of seconds between frames for x-axis scaling.
- `values mod` - the mode of output profile calculation. Options are `ÎF/F0` (relative intensity changes), `ÎF` (absolute intensity changes), or `abs` (absolute intensity value)
- `ÎF win` - if selected `use_simple_baseline`, the baseline intensity for ÎF/F0 profiles is estimated as the mean intensity of the specified number of initial profile points. Othervise, this paramater specify half-size of the moving median baseline estimator (`noisy_median` from `pybaselines` package).
- `profiles crop` - if selected, only a specified range of intensity profile indexes will be plotted, corresponding to the start and stop indexes from `profiles range`.

Additionally, you can save ROI intensity profiles as .csv files using the `save data frame` option and specifying the `saving path`. The output data frames named %img_name%_lab_prof.csv will include the following columns:

- `id` - unique image ID, the name of the input `napari.Image` object.
- `roi` - ROI number, consecutively numbered starting from 1.
- `int` - ROI mean intensity, either raw or ÎF/F0, according to the selected intensity option.
- `dist` - average distance in px to the ROI from the frame, (if `save ROIs distances in data frame` option is selected).
- `index` - frame index.
- `time` - frame time point, adjusted according to the `time scale`.

_Note: the data frame will contain information for all ROIs; amplitude filtering and crop options pertain to plotting only._

Absolute intensity         | ![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/rois_abs.png)
:-------------------------:|:-------------------------:
__ÎF/F0__|![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/rois_df.png)


### Multiple Images Stat Profiles
This widget builds a plot displaying the average intensity of all Regions of Interest (ROIs) specified in `lab`. It can handle up to three images (`img 0`, `img 1`, and `img 2`) as inputs, depending on the selected `profiles num`.

`time scale`, `values mod`, and `ÎF win` parameters are identical as described in the __ROIs profiles__ widget.

The `stat method` allows estimation of intensity and associated errors using the following methods:
- `se` - mean Â± standard error of the mean.
- `iqr` - median Â± interquartile range.
- `ci` - mean Â± 95% confidence interval (t-distribution).

Absolute intensity         | ![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/stat_abs.png)
:-------------------------:|:-------------------------:
__ÎF/F0__|![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/stat_df.png)


### Multiple Labels Stat Profiles
This widget builds a plot displaying the averaged intensity of all Regions of Interest (ROI) for one target `img`. It can handle up to three labels (`lab 0`, `lab 1`, and `lab 2`), depending on the selected `profiles num`.

`time scale`, `values mod`, and `ÎF win` parameters are identical as described in the __ROIs profiles__ widget.

The `stat method` allows estimation of intensity and associated errors using the following methods:
- `se` - mean +/- standard error of the mean.
- `iqr` - median +/- interquartile range.
- `ci` - mean +/- 95% confidence interval based on the t-distribution.

Absolute intensity         | ![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/stat_lab_abs.png)
:-------------------------:|:-------------------------:
__ÎF/F0__|![](https://raw.githubusercontent.com/wisstock/domb-napari/master/images/stat_lab_df.png)

### Save Data Frame
This widget allows saving the data frame with the following columns:

- `id` - unique image ID, the name of the input `napari.Image` object.
- `lab_id` - unique label ID, the name of the input `napari.Labels` object.
- `roi` - ROI number, consecutively numbered starting from 1.
- `dist` - average distance in px to the ROI from the frame, (if `save ROIs distances in data frame` option is selected).
- `index` - frame index.
- `time` - frame time point, adjusted according to the `time scale`.
- `abs_int` - absolute intensity value.
- `dF_int` - absolute intensity changes (ÎF).
- `dF/F0_int` - relative intensity changes (ÎF/F0).


---


## How to Cite
If you use this plugin in your work, please cite the following paper:

```
@article{Olifirov2025,
  title = {Local Iontophoretic Application for Pharmacological Induction of Long-Term Synaptic Depression},
  volume = {15},
  ISSN = {2331-8325},
  url = {http://dx.doi.org/10.21769/BioProtoc.5338},
  DOI = {10.21769/bioprotoc.5338},
  number = {1373},
  journal = {BIO-PROTOCOL},
  publisher = {Bio-Protocol,  LLC},
  author = {Olifirov,  Borys and Fedchenko,  Oleksandra and Dovgan,  Alexandr and Babets,  Daria and Krotov,  Volodymyr and Cherkas,  Volodymyr and Belan,  Pavel},
  year = {2025}
}
```

or zenodo:
```
@misc{https://doi.org/10.5281/zenodo.14843770,
  doi = {10.5281/ZENODO.14843770},
  url = {https://zenodo.org/doi/10.5281/zenodo.14843770},
  author = {wisstock,  },
  title = {wisstock/domb-napari: Zenodo release v0.3.0},
  publisher = {Zenodo},
  year = {2025},
  copyright = {MIT License}
}
```
","['Framework :: napari', 'Development Status :: 3 - Alpha', 'License :: OSI Approved :: MIT License', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Image Recognition', 'Topic :: Utilities']","['Documentation, https://domb.bio/', 'Source Code, https://github.com/wisstock/domb-napari', 'Bug Tracker, https://github.com/wisstock/domb-napari/issues', 'User Support, https://github.com/wisstock/domb-napari/issues']",,,domb-napari.dw_registration_widget,,,,
38,devbio-napari,devbio-napari,devbio-napari,0.11.0,2021-06-08,2024-10-18,Robert Haase,robert.haase@uni-leipzig.de,BSD-3,https://github.com/haesleinhuepf/devbio-napari/issues,https://pypi.org/project/devbio-napari/,,https://github.com/haesleinhuepf/devbio-napari,A bundle of napari plugins useful for 3D+t image processing and analysis for studying developmental biology.,>=3.9,"['napari-plugin-engine>=0.1.4', 'npe2', 'numpy>=1.21.4', 'napari-assistant>=0.4.9', 'napari-pyclesperanto-assistant>=0.23.0', 'napari-skimage-regionprops', 'napari-animation', 'PlatyMatch', 'napari-plot-profile', 'napari-accelerated-pixel-and-object-classification', 'napari-brightness-contrast', 'napari-plugin-search', 'napari-segment-blobs-and-things-with-membranes', 'napari-simpleitk-image-processing', 'napari-stl-exporter', 'napari-folder-browser', 'napari-crop', 'napari-clusters-plotter>=0.7.1', 'napari-tabu', 'napari-workflow-optimizer', 'napari-workflow-inspector', 'napari-curtain', 'napari-layer-details-display', 'napari', 'vispy', 'napari-mouse-controls', 'the-segmentation-game', 'napari-blob-detection', 'jupyterlab', 'napari-czifile2', 'napari-roi', 'pydantic!=1.10.0', 'napari-pystackreg', 'imageio!=2.22.1', 'redlionfish', 'jupyter-server', 'seaborn']","# devbio-napari

[![License](https://img.shields.io/pypi/l/devbio-napari.svg?color=green)](https://github.com/haesleinhuepf/devbio-napari/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/devbio-napari.svg?color=green)](https://pypi.org/project/devbio-napari)
[![Python Version](https://img.shields.io/pypi/pyversions/devbio-napari.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/devbio-napari/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-plot-profile/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/devbio-napari/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/devbio-napari)
[![Development Status](https://img.shields.io/pypi/status/devbio-napari.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/devbio-napari)](https://napari-hub.org/plugins/devbio-napari)

 
A bundle of napari plugins useful for 3D+t image processing and analysis for studying developmental biology.

* [accelerated-pixel-and-object-classification](https://www.napari-hub.org/plugins/napari-accelerated-pixel-and-object-classification)
  * Instance segmentation
  * Semantic segmentation
  * Object classification
  * Random Forest Classifier training
* [animation](https://www.napari-hub.org/plugins/napari-animation) 
  * Visualization
* [blob-detection](https://www.napari-hub.org/plugins/napari-blob-detection)
  * Detection
* [brightness-contrast](https://www.napari-hub.org/plugins/napari-brightness-contrast)
  * Visualization
* [clusters-plotter](https://www.napari-hub.org/plugins/napari-clusters-plotter)
  * Visualization
  * Plotting
  * Semantic object segmentation
  * Dimensionality reduction
  * Unsupervised machine learning
* [crop](https://www.napari-hub.org/plugins/napari-crop)
  * Transformation
* [curtain](https://www.napari-hub.org/plugins/napari-curtain)
  * Visualization 
* [czifile2](https://www.napari-hub.org/plugins/napari-czifile2)
  * File input/output
* [folder-browser](https://www.napari-hub.org/plugins/napari-folder-browser)
  * File input/output
* [layer-details-display](https://www.napari-hub.org/plugins/napari-layer-details-display)
  * Visualization
* [mouse-controls](https://www.napari-hub.org/plugins/napari-mouse-controls)
  * Interaction
* [PlatyMatch](https://www.napari-hub.org/plugins/PlatyMatch)
  * Image registration
* [plot-profile](https://www.napari-hub.org/plugins/napari-plot-profile)
  * Visualization
  * Quantification
* [plugin-search](https://www.napari-hub.org/plugins/napari-plugin-search)
  * Interaction
* [pyclesperanto-assistant](https://www.napari-hub.org/plugins/napari-pyclesperanto-assistant)
  * Filtering
  * Instance segmentation
  * Semantic segmentation
  * Quantification
* [pystackreg](https://www.napari-hub.org/plugins/napari-pystackreg)
  * Image registration
  * Motion correction
* [RedLionfish](https://www.napari-hub.org/plugins/RedLionfish)
  * Deconvolution
  * Processing
* [roi](https://www.napari-hub.org/plugins/napari-roi)
  * Manual segmentation
* [segment-blobs-and-things-with-membranes](https://www.napari-hub.org/plugins/napari-segment-blobs-and-things-with-membranes)
  * Filtering
  * Instance segmentation
  * Semantic segmentation
* [simpleitk-image-processing](https://www.napari-hub.org/plugins/napari-simpleitk-image-processing)
  * Filtering
  * Instance segmentation
  * Semantic segmentation
  * Quantification
* [skimage-regionprops](https://www.napari-hub.org/plugins/napari-skimage-regionprops)
  * Quantification
* [stl-exporter](https://www.napari-hub.org/plugins/napari-stl-exporter)
  * File input/output
* [tabu](https://www.napari-hub.org/plugins/napari-tabu)
  * Interaction
* [the-segmentation-game](https://www.napari-hub.org/plugins/the-segmentation-game)
  * Quantification
  * Segmentation quality assurance
* [workflow-inspector](https://www.napari-hub.org/plugins/napari-workflow-inspector)
  * Visualization
* [workflow-optimizer](https://www.napari-hub.org/plugins/napari-workflow-optimizer)
  * Interaction
  * Optimization

----------------------------------

## Installation

You can install `devbio-napari` via conda/mamba. If you have never used conda before, please [read this guide first](https://biapol.github.io/blog/mara_lampert/getting_started_with_mambaforge_and_python/readme.html).  
Start by creating an environment using mamba.

```
mamba create --name devbio-napari-env napari=0.4.19 python=3.9 devbio-napari pyqt -c conda-forge -c pytorch
```

Afterwards, activate the environment like this:

```
mamba activate devbio-napari-env
```

Afterwards, run this command from the command line

```
naparia
```

This window should open. It shows the [Assistant](https://www.napari-hub.org/plugins/napari-assistant) graphical user interface. 
Read more about how to use it in its [documentation](https://www.napari-hub.org/plugins/napari-assistant).

![img.png](https://github.com/haesleinhuepf/devbio-napari/raw/master/docs/screenshot.png)

## Troubleshooting: Graphics cards drivers

In case error messages contains ""ImportError: DLL load failed while importing cl: The specified procedure could not be found"" [see also](https://github.com/clEsperanto/pyclesperanto_prototype/issues/55) or """"clGetPlatformIDs failed: PLATFORM_NOT_FOUND_KHR"", please install recent drivers for your graphics card and/or OpenCL device. Select the right driver source depending on your hardware from this list:

* [AMD drivers](https://www.amd.com/en/support)
* [NVidia drivers](https://www.nvidia.com/download/index.aspx)
* [Intel GPU drivers](https://www.intel.com/content/www/us/en/download/726609/intel-arc-graphics-windows-dch-driver.html)
* [Intel CPU OpenCL drivers](https://www.intel.com/content/www/us/en/developer/articles/tool/opencl-drivers.html#latest_CPU_runtime)
* [Microsoft Windows OpenCL support](https://www.microsoft.com/en-us/p/opencl-and-opengl-compatibility-pack/9nqpsl29bfff)

Sometimes, mac-users need to install this:

    conda install -c conda-forge ocl_icd_wrapper_apple

Sometimes, linux users need to install this:

    conda install -c conda-forge ocl-icd-system


In case installation didn't work in the first attempt, you may have to call this command line to reset the napari configuration:

```
napari --reset
```

## Troubleshooting: pytorch

In case pytorch-related plugins fail, install pytorch as explained on [its website](https://pytorch.org/get-started/locally/). Consider replacing `conda` with `mamba` in given instructions.

For example if you have an NVidia GPU at hand, install pytorch like this:
```
mamba install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia
```
Or if not:
```
mamba install pytorch torchvision torchaudio cpuonly -c pytorch
```

## Contributing

Contributions are very welcome. 
If you want to [suggest a new napari plugin](https://github.com/haesleinhuepf/devbio-napari/pulls) to become part of this distribution, please make sure it interoperates nicely with the other plugins. 
For example, if the plugin you suggest provided cell segmentation algorithms, please check if the resulting segmented cells can be analysed using napari-skimage-regionprops.
Furthermore, please make sure the README of the plugin you are proposing comes with user documentation, e.g. a step-by-step guide with screenshots explaining what users can do with the plugin and how to use it. 
It is recommended to provide example data as well so that end-users can try out the plugin under conditions it was developed for.

## License

Distributed under the terms of the [BSD-3] license,
""devbio-napari"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/haesleinhuepf/devbio/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/devbio-napari/issues', 'Documentation, https://github.com/haesleinhuepf/devbio-napari#README.md', 'Source Code, https://github.com/haesleinhuepf/devbio-napari', 'User Support, https://github.com/haesleinhuepf/devbio-napari/issues']",,,,,,,
39,cylindra,cylindra,cylindra,1.0.0b7,2024-05-07,2025-05-14,Hanjin Liu,liuha@med.kobe-u.ac.jp,Unavailable,,https://pypi.org/project/cylindra/,None,,"Spectral analysis, simulation and subtomogram averaging of heterogenic cylindrical structures",>=3.10,"['impy-array>=2.4.5', 'acryo>=0.4.17', 'macro-kit>=0.4.6', 'magicgui>=0.8.1', 'magic-class>=0.7.16', 'psygnal>=0.9.1', 'superqt[iconify]>=0.6.1', 'pydantic>=1.10.0', 'pydantic-compat', 'pyqtgraph>=0.12.4', 'pyarrow>=11.0.0', 'numpy>=1.23.0', 'scipy>=1.11.3', 'pandas>=1.5.0', 'polars>=1.19.0', 'scikit-image>=0.21.0', 'napari>=0.5.1', 'qtpy>=2.3.1', 'qt-command-palette>=0.0.7', 'matplotlib>=3.8.1', 'rich>=13.6.0', 'dask>=2023.12.1,<2025.0.0', 'platformdirs>=4.3.6', ""pytest ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""scikit-learn>=1.2.2 ; extra == 'testing'"", ""mrcfile>=1.3.0 ; extra == 'testing'"", ""tifffile>=2023.2.28 ; extra == 'testing'"", ""starfile!=0.5.10 ; extra == 'testing'"", ""imodmodel ; extra == 'testing'"", ""cookiecutter ; extra == 'testing'"", ""maturin>=1.5.0,<2.0.0 ; extra == 'testing'"", ""pyqt5 ; extra == 'all'"", ""scikit-learn>=1.2.2 ; extra == 'all'"", ""mrcfile>=1.3.0 ; extra == 'all'"", ""tifffile>=2023.2.28 ; extra == 'all'"", ""starfile ; extra == 'all'"", ""imodmodel ; extra == 'all'"", ""cookiecutter ; extra == 'all'"", ""pyqt5 ; extra == 'docs'"", ""mrcfile>=1.3.0 ; extra == 'docs'"", ""mkdocs>=1.5.3 ; extra == 'docs'"", ""mkdocs-autorefs>=0.5.0 ; extra == 'docs'"", ""mkdocs-gen-files>=0.5.0 ; extra == 'docs'"", ""mkdocs-material>=9.5.2 ; extra == 'docs'"", ""mkdocs-material-extensions>=1.3.1 ; extra == 'docs'"", ""mkdocstrings>=0.24.0 ; extra == 'docs'"", ""mkdocstrings-python>=1.7.5 ; extra == 'docs'"", ""maturin>=1.5.0,<2.0.0 ; extra == 'docs'""]","[![BSD 3-Clause License](https://img.shields.io/pypi/l/cylindra.svg?color=green)](https://github.com/hanjinliu/cylindra/blob/main/LICENSE)
[![Python package index download statistics](https://img.shields.io/pypi/dm/cylindra.svg)](https://pypistats.org/packages/cylindra)
[![PyPI version](https://badge.fury.io/py/cylindra.svg)](https://badge.fury.io/py/cylindra)
[![codecov](https://codecov.io/gh/hanjinliu/cylindra/graph/badge.svg?token=X1F259JYT5)](https://codecov.io/gh/hanjinliu/cylindra)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/cylindra)](https://napari-hub.org/plugins/cylindra)

![](https://github.com/hanjinliu/cylindra/blob/main/resources/fig.png)

# cylindra

`cylindra` is a GUI-integrated cryo-ET image analysis tool for cylindric periodic
structures such as microtubules.

### [&rarr; Documentation](https://hanjinliu.github.io/cylindra/)

## Installation

- Use `pip`

```shell
pip install cylindra -U
```

- From source

If you install from the source, you'll need Rust to compile a part of the code.

```shell
git clone git+https://github.com/hanjinliu/cylindra
cd cylindra
pip install -e .
```

## Usage

#### Launch GUI

- From shell

  ```shell
  cylindra
  ```

- From a Python interpreter

  ```python
  from cylindra import start

  # launch a napari viewer with a cylindra dock widget.
  ui = start()
  ```

#### Command line interface

`cylindra` is implemented with some basic command line interface (CLI).

```shell
cylindra --help
```

## Implemented Functions

- Automatic/manual fitting of splines to cylindrical structures in 3D.
- Analyze lattice structures (such as lattice spacing and skew angle) using Cylindric
  Fourier transformation.
- Automatic determination of polarity, protofilament number etc.
- Monomer mapping along splines for subtomogram averaging and alignment.
- Microtubule seam search with or without binding proteins.
- Subtomogram alignment with 2D constraint.
- Tomogram simulation of cylindric structures.
- Efficient manual picking along cylindrical structures.

## Prerequisite and Recommendations

- **Python &ge; 3.10**. This project follows [spec-0000](https://scientific-python.org/specs/spec-0000/).
- **Sufficient memory size**. Most of the intense calculations are done out-of-core
  using `dask`, so that you can even run on 8-GB memory PC in many cases. However,
  larger memory size will make parallel processing more efficient. &ge;32 GB is
  recommended.
- **Images should be loaded from SSD**. Raw image stacks are loaded lazily in most of
  the processes. Loading from HDD will slow down many analyses as well. In the latest version, you can use ""Cache image on SSD"" option to directly analyze tomograms stored in HDD.

## Issues

If you encountered any bugs or have any requests, feel free to
[report an issue](https://github.com/hanjinliu/cylindra/issues/new).
(We'll appreciate if you find some methods are over-fitted to microtubules and do not
work well on other cylindric structures)

For better reproducibility, please copy your environments from `Others > cylindra info`
and the recorded macro from `Others > Macro > Show macro`.

## Citation

If you find `cylindra` useful in your work, please consider citing [our paper](https://www.biorxiv.org/content/10.1101/2024.04.30.591984v1).

```
Heterogeneous local structures of the microtubule lattice revealed by cryo-ET and non-averaging analysis
Hanjin Liu, Hiroshi Yamaguchi, Masahide Kikkawa, Tomohiro Shima
bioRxiv 2024.04.30.591984; doi: https://doi.org/10.1101/2024.04.30.591984
```

","['Programming Language :: Rust', 'Programming Language :: Python :: Implementation :: CPython', 'Programming Language :: Python :: Implementation :: PyPy', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Framework :: napari']",,,,cylindra.main_widget,,,,
40,epitools,epitools,EpiTools,0.0.13,2023-05-04,2025-01-27,Yanlan Mao,"""Daniel R. Matthews"" <d.matthews@ucl.ac.uk>, Giulia Paci <g.paci@ucl.ac.uk>, Pablo Vicente Munuera <p.munuera@ucl.ac.uk>, ""Patrick J. Roddy"" <patrick.roddy@ucl.ac.uk>, ""Paul J. Smith"" <paul.j.smith@ucl.ac.uk>, Yanlan Mao <y.mao@ucl.ac.uk>",BSD 3-Clause,https://github.com/epitools/epitools/issues,https://pypi.org/project/epitools/,,https://www.ucl.ac.uk/lmcb/users/yanlan-mao,Quantifying 2D cell shape and epithelial tissue dynamics,>=3.9,"['PartSeg', 'magicgui', 'matplotlib', 'napari', 'networkx', 'numpy', 'pandas', 'scikit-image>=0.20', 'scipy', 'black; extra == ""dev""', 'mypy; extra == ""dev""', 'pre-commit; extra == ""dev""', 'pyqt5; extra == ""dev""', 'ruff; extra == ""dev""', 'tox; extra == ""dev""', 'myst-parser; extra == ""docs""', 'pydata-sphinx-theme; extra == ""docs""', 'pytz; extra == ""docs""', 'sphinx-autobuild; extra == ""docs""', 'sphinx<5; extra == ""docs""', 'sphinx_autodoc_typehints; extra == ""docs""', 'sphinxcontrib-video; extra == ""docs""', 'types-pytz; extra == ""docs""', 'btrack[napari]>=0.6.1; extra == ""wf""', 'napari-segment-blobs-and-things-with-membranes; extra == ""wf""']","[![Licence](https://img.shields.io/pypi/l/epitools.svg?color=green)](https://raw.githubusercontent.com/epitools/epitools/main/LICENCE.md)
[![PyPI](https://img.shields.io/pypi/v/epitools.svg?color=green)](https://pypi.org/project/epitools)
[![Python Version](https://img.shields.io/pypi/pyversions/epitools.svg?color=green)](https://python.org)
[![tests](https://github.com/epitools/epitools/actions/workflows/test.yml/badge.svg)](https://github.com/epitools/epitools/actions/workflows/test.yml)
[![Documentation](https://readthedocs.org/projects/epitools/badge/?version=latest)](https://epitools.readthedocs.io/en/latest/?badge=latest)
[![coverage](https://coveralls.io/repos/github/epitools/epitools/badge.svg?branch=main)](https://coveralls.io/github/epitools/epitools?branch=main)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/epitools)](https://napari-hub.org/plugins/epitools)

# Welcome to EpiTools!

EpiTools is a Python package and associated [napari](https://napari.org/stable/) plugin to extract the membrane signal from epithelial tissues and analyze it with the aid of computer vision.

The development of EpiTools was inspired by the challenges in analyzing time-lapses of growing Drosophila imaginal discs.

The folded morphology, the very small apical cell surfaces and the long time series required a new automated cell recognition to accurately study growth dynamics.

## Installation

First, install [napari](https://napari.org/index.html#installation).

The recommended way to install `EpiTools` is via
[pip](https://pypi.org/project/pip)

```sh
python -m pip install epitools
```

To install the latest development version of `EpiTools` clone this repository
and run

```sh
python -m pip install -e .
```

If working on Apple Silicon make sure to also install the following package from
[conda-forge](https://conda-forge.org).

```sh
conda install -c conda-forge pyqt
```

### Recommended Companion Napari Plugins

To also install the recommended plugins for the `EpiTools` workflow run

```sh
python -m pip install epitools[wf]
```

and

```sh
python -m pip install -e .[wf]
```

When installing with Apple Mac OS X terminal, you might need to add '""' to [wf] as in:

```sh
python -m pip install -e .""[wf]""
```

If working on Apple Silicon make sure to also install the following package from
[conda-forge](https://conda-forge.org)

```sh
conda install -c conda-forge cvxopt
```

which is required for [btrack](https://github.com/quantumjot/btrack).

## Issues

If you encounter any problems, please
[file an issue](https://github.com/epitools/epitools/issues) along with a
detailed description.

## Contributing

Contributions are very welcome. Tests can be run with [tox](https://tox.wiki),
please ensure the coverage at least stays the same before you submit a pull request.
","['Framework :: napari', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Medical Science Apps.', 'Topic :: Scientific/Engineering :: Bio-Informatics']","['Code, https://github.com/epitools/epitools', 'Download, https://pypi.org/project/epitools', 'Homepage, https://github.com/epitools/epitools', 'Issues, https://github.com/epitools/epitools/issues']",epitools.get_reader,epitools.write_single_image,epitools.projection_widget,epitools.load_sample_data,"['*.tif', '*.tiff']","['.tif', '.tiff']","['.tif', '.tiff']"
41,faser,faser,faser,0.3.6,2022-05-23,2024-12-25,"Johannes Roos, Stephane Bancelin","Johannes Roos <jhnnsrs@gmail.com>, Stephane Bancelin <stephane.bancelin@cnrs.fr>",MIT,https://github.com/jhnnsrs/faser,https://pypi.org/project/faser/,,,Faser is a tool for vectorial psf simulation,"<3.13,>=3.9","['matplotlib>=3.9.2', 'numpy<2', 'psygnal>=0.11.1', 'pydantic>2', 'python-slugify>=8.0.4', 'qtpy>=2.4.2', 'superqt>=0.6.7', 'tifffile>=2024.8.30', ""rich-click>=1.8.3; extra == 'cli'"", ""pyqt5>=5.15.11; extra == 'full'"", ""rich-click>=1.8.3; extra == 'full'"", ""numba>=0.60.0; extra == 'numba'""]","# faser

faser is a Python-based software package designed to simulate the excitation
point spread function (PSF) of optical microscopes. Faser  calculates PSFs for high NA
focusing by using a vectorial model of the electromagnetic field, enabling exploration of the impact
of geometrical and optical parameters on imaging performance in advanced applications. The
software supports various beam profiles, including those used in STED microscopy, and allows for
the simulation of common experimental conditions such as a cranial window and a coverslip tilt.

We provide to prefered ways to use faser:

## Faser as a Napari Plugin

The recommended way to install faser is as a Napari plugin, which provides a user-friendly GUI for interactively exploring the PSF simulation. This can be done via:

```bash
pip install faser napari[pyqt5]
```

#### Usage

You can run the GUI application via (or just as a Napari plugin)

```bash
qtfaser
```

For more information on how to use the GUI, please refer to the [preprint](https://faser.readthedocs.io/en/latest/).

## Faser as a standalone application

Alternatively, you can install the package as a standalone application only, that you can run in enironments without Napari or GUI support:

```bash
pip install faser[cli]
```
This will install the package as a standalone application that can be run from the command line via:

```bash
faser
```
We generally recommend the GUI application for most users, as it provides a more user-friendly interface.
However faser can also be used as a library, and the CLI application is useful for scripting and batch processing.

#### Usage

To simulate the PSF, with a specific numerical aperture (NA) and a beam profile, you can run the following command:

```bash
faser --na 1.4 --window=NO
```

For more information and options you can run:

```bash
faser --help
```

To display the GUI interface and the available options:

```
  __                     
 / _| __ _ ___  ___ _ __ 
| |_ / _` / __|/ _ \ '__|
|  _| (_| \__ \  __/ |   
|_|  \__,_|___/\___|_|   

Generating PSF with config
faserâ  faser git:(master) â uv run faser --help
                                                                                                                                                                                                                                                   
 Usage: faser [OPTIONS]                                                                                                                                                                                                                            
                                                                                                                                                                                                                                                   
â­â Options ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ®
â --config                     FILENAME         Path to a JSON file                                                                                                                                                                               â
â --detector_gaussian_noise    FLOAT            Detector Gaussian noise                                                                                                                                                                           â
â --gaussian_beam_noise        FLOAT            Gaussian_beam noise                                                                                                                                                                               â
â --add_noise                  NOISE                                                                                                                                                                                                              â
â --loaded_phase_mask          OPTIONAL         Loaded Phasemak                                                                                                                                                                                   â
â --p                          FLOAT            Ratio between Donut (p) and Bottle (1-p) intensity                                                                                                                                                â
â --mask_offset_y              FLOAT            Y offset of the phase mask in regard to pupil center                                                                                                                                              â
â --mask_offset_x              FLOAT            X offset of the phase mask in regard to pupil center                                                                                                                                              â
â --ring_radius                FLOAT            Radius of the ring phase mask (on unit pupil)                                                                                                                                                     â
â --rc                         FLOAT            Ring charge (should be odd to produce bottle)                                                                                                                                                     â
â --vc                         FLOAT            Vortex charge (should be integer to produce donut)                                                                                                                                                â
â --epsilon                    FLOAT            Ellipticity of the polarization (in Â°)                                                                                                                                                            â
â --psi                        FLOAT            Direction of the polarization (in Â°)                                                                                                                                                              â
â --ampl_offset_y              FLOAT            Y offset of the amplitude profile in regard to pupil center                                                                                                                                       â
â --ampl_offset_x              FLOAT            X offset of the amplitude profile in regard to pupil center                                                                                                                                       â
â --waist                      FLOAT            Diameter of the input beam on the objective pupil (in Âµm)                                                                                                                                         â
â --wavelength                 FLOAT            Wavelength of light (in Âµm)                                                                                                                                                                       â
â --polarization               POLARIZATION                                                                                                                                                                                                       â
â --mode                       MODE                                                                                                                                                                                                               â
â --aberration_offset_y        FLOAT            Y offset of the aberration function in regard to pupil center                                                                                                                                     â
â --aberration_offset_x        FLOAT            X offset of the aberration function in regard to pupil center                                                                                                                                     â
â --a24                        ABERRATIONFLOAT  Secondary spherical                                                                                                                                                                               â
â --a12                        ABERRATIONFLOAT  Primary spherical                                                                                                                                                                                 â
â --a9                         ABERRATIONFLOAT  Oblique Trefoil                                                                                                                                                                                   â
â --a8                         ABERRATIONFLOAT  Horizontal Coma                                                                                                                                                                                   â
â --a7                         ABERRATIONFLOAT  Vertical Coma                                                                                                                                                                                     â
â --a6                         ABERRATIONFLOAT  Vertical Trefoil                                                                                                                                                                                  â
â --a5                         ABERRATIONFLOAT  Vertical Astigmatism                                                                                                                                                                              â
â --a4                         ABERRATIONFLOAT  Defocus                                                                                                                                                                                           â
â --a3                         ABERRATIONFLOAT  Oblique Astigmatism                                                                                                                                                                               â
â --a2                         ABERRATIONFLOAT  Horizontal Tilt                                                                                                                                                                                   â
â --a1                         ABERRATIONFLOAT  Vertical Tilt                                                                                                                                                                                     â
â --a0                         ABERRATIONFLOAT  Piston                                                                                                                                                                                            â
â --wind_offset_y              FLOAT            Y offset of the cranial window in regard to pupil center                                                                                                                                          â
â --wind_offset_x              FLOAT            X offset of the cranial window in regard to pupil center                                                                                                                                          â
â --wind_depth                 FLOAT            Depth of the cranial window (in mm)                                                                                                                                                               â
â --wind_radius                FLOAT            Diameter of the cranial window (in mm)                                                                                                                                                            â
â --window                     WINDOW                                                                                                                                                                                                             â
â --tilt                       FLOAT            Tilt angle of the coverslip (in Â°)                                                                                                                                                                â
â --depth                      FLOAT            Imaging depth in the sample (in Âµm)                                                                                                                                                               â
â --collar                     FLOAT            Correction collar setting to compensate coverslip thickness                                                                                                                                       â
â --thickness                  FLOAT            Thickness of the coverslip (in Âµm)                                                                                                                                                                â
â --n3                         FLOAT            Refractive index of the sample                                                                                                                                                                    â
â --n2                         FLOAT            Refractive index of the coverslip                                                                                                                                                                 â
â --n1                         FLOAT            Refractive index of the immersion medium                                                                                                                                                          â
â --wd                         FLOAT            Working Distance of the objective lens (in Âµm)                                                                                                                                                    â
â --na                         FLOAT            Numerical Aperture of Objective Lens                                                                                                                                                              â
â --normalize                  NORMALIZE                                                                                                                                                                                                          â
â --nphi                       INTEGER          Integration sted of the aximutal angle on the pupil                                                                                                                                               â
â --ntheta                     INTEGER          Integration sted of the focalization angle                                                                                                                                                        â
â --nz                         INTEGER          Discretization of Z axis - better be odd number for perfect 0                                                                                                                                     â
â --nxy                        INTEGER          Discretization of image plane - better be odd number for perfect 0                                                                                                                                â
â --l_obs_z                    FLOAT            Observation scale in Z (in Âµm)                                                                                                                                                                    â
â --l_obs_xy                   FLOAT            Observation scale in XY (in Âµm)                                                                                                                                                                   â
â --help                                        Show this message and exit.                                                                                                                                                                       â
â°ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ¯
```


","['Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12']","['Bug Tracker, https://jhnnsrs.github.io/faser/issues', 'Documentation, https://jhnnsrs.github.io/faser', 'Source Code, https://github.com/jhnnsrs/faser']",,,faser.napari.helper_widget,,,,
42,epicure,epicure,EpiCure,0.2.12,2024-10-18,2025-04-09,GaÃ«lle Letort,,BSD-3-Clause,,https://pypi.org/project/epicure/,,https://gitlab.pasteur.fr/gletort/epicure,Napari plugin to manually correct epithelia segmentation in movies,>=3.8,"['napari<=0.4.19', 'numpy', 'magicgui', 'qtpy', 'pyqtwebengine', 'scikit-image', 'scipy', 'opencv_python_headless', 'roifile', 'xlsxwriter', 'plotly', 'kaleido', 'imagecodecs', 'edt', 'packaging', 'laptrack', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# EpiCure

[![License BSD-3](https://img.shields.io/pypi/l/epicure.svg?color=green)](https://gitlab.pasteur.fr/gletort/epicure/-/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/epicure.svg?color=green)](https://pypi.org/project/epicure)
[![Python Version](https://img.shields.io/pypi/pyversions/epicure.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/epicure)](https://napari-hub.org/plugins/epicure)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.13952184.svg)](https://doi.org/10.5281/zenodo.13952184)

![EpiCure logo](https://gitlab.pasteur.fr/gletort/epicure/-/raw/main/imgs/epicure_logo.png?raw=True ""EpiCure logo"")

**Napari plugin to ease manual correction of epithelia segmentation in movies.**

To analyse individual cell trajectory from epithelia movies marked for cell-cell junctions, a very precise segmentation and tracking is required.
Several tools such as TissuAnalyzer, Epyseg, CellPose or Dist2Net perform very good segmentation (~5% of errors). 
However, this still implies a high amount of cells to correct manually. 
EpiCure allows to decrease the burden of this task. 
Several features are proposed to ease the manual correction of the segmented movies, such as error detection, numerous shortcuts for editing the segmentation, option for tracking, display and measure/export options.
EpiCure detect segmentation errors by taking advantage of temporal information. 
When a correction is done at a given frame, EpiCure relink the track to adjust for the changes.


 > **Documentation in the [wiki](https://gitlab.pasteur.fr/gletort/epicure/-/wikis/Home)**

<p align=""center"">
![EpiCure interface](https://gitlab.pasteur.fr/gletort/epicure/-/raw/main/imgs/EpiGen.png?raw=True ""EpiCure interface"")
</p>

## Installation

### Install plugin
To install EpiCure on a fresh python virtual environment, type inside the environement:
```
pip install epicure
``` 

Then launch `Napari`, and the plugin should be visible in the `Plugins` list.

If you already have an environment with `Napari` installed, you can also install it directly in `Napari>Plugins>Install/Uninstall plugins`

### Install code
To have the code to be able to modify it, clone this repository. You can use `pip install -e .` so that everytime you update the code, the plugin will be updated. 

## Dependencies

The input files of EpiCure can be already tracked or not.
Tracking options are proposed in EpiCure:
* Laptrack centroids
* Laptrack overlaps

## Usage
Refer to the [wiki](https://gitlab.pasteur.fr/gletort/epicure/-/wikis/Home) for documentation of the different steps possible in the pipeline.

## References

If you use EpiCure, thank you for citing our work: 

EpiCure is not published yet, you can cite it using Zenodo for now: https://doi.org/10.5281/zenodo.13952184


## Issues
Issues have been disactivated to avoid spammed issues. To report an issue or ask for development, please contact us directly by email.


This [napari] plugin was initialized with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[file an issue]: https://github.com/gletort/epicure/issues
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://gitlab.pasteur.fr/gletort/epicure/issues', 'Documentation, https://gitlab.pasteur.fr/gletort/epicure#README.md', 'Source Code, https://gitlab.pasteur.fr/gletort/epicure', 'User Support, https://gitlab.pasteur.fr/gletort/epicure/issues']",,,epicure.start,,,,
43,frontveg,frontveg,Frontveg,0.3.5,2025-04-20,2025-06-04,Herearii Metuarea,herearii.metuarea@univ-angers.fr,"Copyright (c) 2025, Herearii M...",https://github.com/hereariim/frontveg/issues,https://pypi.org/project/frontveg/,,,Segmentation of vegetation located to close to camera,==3.11.12,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'transformers==4.51.3', 'torch>=2.3.1', 'torchvision>=0.18.1', 'hydra-core==1.3.2', 'iopath>=0.1.10', 'pillow>=9.4.0', 'sam2==1.1.0', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# frontveg

[![License BSD-3](https://img.shields.io/pypi/l/frontveg.svg?color=green)](https://github.com/hereariim/frontveg/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/frontveg.svg?color=green)](https://pypi.org/project/frontveg)
[![Python Version](https://img.shields.io/pypi/pyversions/frontveg.svg?color=green)](https://python.org)
[![tests](https://github.com/hereariim/frontveg/workflows/tests/badge.svg)](https://github.com/hereariim/frontveg/actions)
[![codecov](https://codecov.io/gh/hereariim/frontveg/branch/main/graph/badge.svg)](https://codecov.io/gh/hereariim/frontveg)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/frontveg)](https://napari-hub.org/plugins/frontveg)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

A plugin for foreground vegetation segmentation, tailored for trellised vegetation row images. It uses RGB images to perform inference and allows users to manually refine the generated mask.

----------------------------------

The method was developped by Herearii Metuarea, PHENET PhD at LARIS (French laboratory located in Angers, France) and Abdoul Djalil Ousseini Hamza, AgroEcoPhen Engineer at IRHS (French Institute located in INRAe Angers, France) in Imhorphen team (bioimaging research group lead) under the supervision of Eric DuchÃªne (Research Engineer), Morgane Roth (Research Engineer) and David Rousseau (Full professor). This plugin was written by Herearii Metuarea and was designed in the context of the european project PHENET.

![Data Warehouse](https://github.com/user-attachments/assets/4a110408-5854-4e8c-b655-4cb588434b79)


----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `frontveg` via [pip]:

    pip install frontveg

To install latest development version :

    pip install git+https://github.com/hereariim/frontveg.git

GPU is mandatory for time processing and models running (especially Grounding-DINO). Please visit the official PyTorch website to get the appropriate installation command: ð https://pytorch.org/get-started/locally

**Exemple : GPU (CUDA 12.1)**

    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

## Description

This plugin is a tool to perform image inference. This plugin contained two steps of image processing. First, from RGB image, a depth map is estimated and then thresholded based on the estimated depth histogram modes to detect foreground and background regions in image. Second, a Grounding DINO model detects foliage in the foreground. The output is a binary mask where white colour are associated to foliage in the foreground.

The plugin is applicable to images of trellised plants; in this configuration, it has been applied to images of pome fruit trees (apple), stone fruit trees (apricot) and climbing plants (grapevine).

![sample_example](https://github.com/user-attachments/assets/ae845e01-9f48-4bcf-98ad-bf5f6e037f01)

## Contact

Imhorphen team, bioimaging research group

42 rue George Morel, Angers, France

- Pr David Rousseau, david.rousseau@univ-angers.fr
- Abdoul Djalil Ousseini Hamza, abdoul-djalil.ousseini-hamza@inrae.fr
- Herearii Metuarea, herearii.metuarea@univ-angers.fr

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""frontveg"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/hereariim/frontveg/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hereariim/frontveg/issues', 'Documentation, https://github.com/hereariim/frontveg#README.md', 'Source Code, https://github.com/hereariim/frontveg', 'User Support, https://github.com/hereariim/frontveg/issues']",,,frontveg.vegetation,,,,
44,fspi-analysis,fspi-analysis,Controls,0.1.2,2025-05-18,2025-07-17,Olivier Cahn,oc124@ic.ac.uk,"GNU GENERAL PUBLIC LICENSE
   ...",https://github.com/engpol/fspi_analysis/issues,https://pypi.org/project/fspi-analysis/,,,A simple plugin to perform fspi analysis within napari,>=3.10,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'pandas', 'napari', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""']","# fspi_analysis

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/fspi_analysis.svg?color=green)](https://github.com/engpol/fspi_analysis/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/fspi_analysis.svg?color=green)](https://pypi.org/project/fspi_analysis)
[![Python Version](https://img.shields.io/pypi/pyversions/fspi_analysis.svg?color=green)](https://python.org)
[![tests](https://github.com/engpol/fspi_analysis/workflows/tests/badge.svg)](https://github.com/engpol/fspi_analysis/actions)
[![codecov](https://codecov.io/gh/engpol/fspi_analysis/branch/main/graph/badge.svg)](https://codecov.io/gh/engpol/fspi_analysis)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/fspi_analysis)](https://napari-hub.org/plugins/fspi_analysis)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

A simple plugin to analyse fluorescent sediment profile images (FSPI) within napari.

[Here](https://vimeo.com/1090902747) is a tutorial on installing, and using, the plugin from within the napari standalone application.

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `fspi_analysis` via [pip]:

    pip install fspi_analysis

To install latest development version :

    pip install git+https://github.com/engpol/fspi_analysis.git

Alternatively, install directly from within napari by searching for `fspi_analysis` in the 'Plugins' Tab.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""fspi_analysis"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/engpol/fspi_analysis/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/engpol/fspi_analysis/issues', 'Documentation, https://github.com/engpol/fspi_analysis#README.md', 'Source Code, https://github.com/engpol/fspi_analysis', 'User Support, https://github.com/engpol/fspi_analysis/issues']",,,fspi_analysis.make_F_Analysis_widget,,,,
45,fitellipsoid,fitellipsoid,Fit Ellipsoid,0.0.6,2025-04-08,2025-04-11,Pierre Weiss,pierre.weiss@cnrs.fr,"GNU GENERAL PUBLIC LICENSE
   ...",,https://pypi.org/project/fitellipsoid/,None,,A plugin to that fits an ellipsoid to a set of user clicked points in 3D,>=3.10,"['napari>=0.5.6', 'npe2', 'numpy', 'magicgui', 'qtpy', 'scikit-image', 'tifffile', 'scipy', 'pandas', 'pathlib', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# fitellipsoid

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/fitellipsoid.svg?color=green)](https://github.com/pierre-weiss/fitellipsoid/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/fitellipsoid.svg?color=green)](https://pypi.org/project/fitellipsoid)
[![Python Version](https://img.shields.io/pypi/pyversions/fitellipsoid.svg?color=green)](https://python.org)
<!-- [![tests](https://github.com/pierre-weiss/fitellipsoid/workflows/tests/badge.svg)](https://github.com/pierre-weiss/fitellipsoid/actions)-->
[![codecov](https://codecov.io/gh/pierre-weiss/fitellipsoid/branch/main/graph/badge.svg)](https://codecov.io/gh/pierre-weiss/fitellipsoid)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/fitellipsoid)](https://napari-hub.org/plugins/fitellipsoid)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)

A plugin to find the best ellipsoid to fit a set of points clicked by the user.
With just a few clicks (10 is the absolute minimum) around the cells/nuclei boundaries, the plugin fits an ellipsoid and returns its parameters. 
This can be used to analyze tissue geometry, mecanical stress, provide training databases for segmentation algorithms,...

![FitEllipsoid widget example](https://raw.githubusercontent.com/pierre-weiss/fitellipsoid_napari/main/images/screenshot.jpg)

----------------------------------

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `fitellipsoid` via [pip]:

    conda create -n fitellipsoid-env python=3.11
    conda activate fitellispoid-env
    pip install -U 'napari[all]'
    pip install fitellipsoid
    napari

## ð§ª Usage Instructions

1. **Open your 3D image stack** in Napari.

2. **Launch the FitEllipsoid plugin** from the plugin menu.

3. **Select the point layer** created by the plugin and begin clicking along the boundary of your object:
   - ð±ï¸ **Left-click** to add a point  
   - ð±ï¸ **Right-click** to remove the last added point  

4. **Once you've added at least 10 points**, click on the **""Fit Ellipsoid""** button.

5. A **blue ellipsoid** will be fitted and displayed.  
   - â If the shape fits well, you're done with that object.  
   - â If it doesn't, return to the corresponding point layer and add or adjust points.

6. **Repeat** the process for all objects you'd like to segment.  
   The plugin automatically adds a new point layer after each fit.

7. When you're finished, **save the results** as a `.csv` file and optionally export a segmentation mask.



## Contributors

- **Pierre Weiss** - Project lead, core plugin development
- **ClÃ©ment Cazorla** - Added the segmentation mask generation

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""fitellipsoid"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']",,,,fitellipsoid.FitEllipsoidWidget,,,,
46,fish-scan,fish-scan,Fish Scan,1.1.0,2024-08-14,2024-11-12,Arianna Ravera,ariannaravera22@gmail.com,"Copyright (c) 2024, Arianna Ra...",https://github.com/ariannaravera/fish-scan/issues,https://pypi.org/project/fish-scan/,,https://github.com/ariannaravera/fish-scan,Plugin to enhance fish detection and analysis for underwater research,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'opencv-python', 'matplotlib', 'scikit-learn', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# fish-scan

[![License BSD-3](https://img.shields.io/pypi/l/fish-scan.svg?color=green)](https://github.com/ariannaravera/fish-scan/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/fish-scan.svg?color=green)](https://pypi.org/project/fish-scan)
[![Python Version](https://img.shields.io/pypi/pyversions/fish-scan.svg?color=green)](https://python.org)
[![tests](https://github.com/ariannaravera/fish-scan/workflows/tests/badge.svg)](https://github.com/ariannaravera/fish-scan/actions)
[![codecov](https://codecov.io/gh/ariannaravera/fish-scan/branch/main/graph/badge.svg)](https://codecov.io/gh/ariannaravera/fish-scan)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/fish-scan)](https://napari-hub.org/plugins/fish-scan)

Plugin to enhance fish detection and analysis for underwater research

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `fish-scan` via [pip]:

    pip install fish-scan



To install latest development version :

    pip install git+https://github.com/ariannaravera/fish-scan.git


## Tutorial

### 1. Color correction

With this tool you can correct colors in your image.

1.	Open your image in napari by grabbing and dropping it or opening from the menu
2.	Click on âSelect the areaâ to select a rectagular area of the color you wanna correct
3.	Draw the rectangle in the area in which you have that color, eg. white area, as in the example below
4.	Select the color name in the dropdown box, eg. in this case white
5.	Click on âCorrect colorâ
6.	If youâre satisfied of the correction made, it is IMPORTANT to select as input âImageâ(first box) the name of the new generated image (usually, âCurrect_corrected_...)*
7.	Cuntinue your colors corrections re-starting from step 2

#### Nomenclature:
- you MUSH have your original image with its original name (in this case âGroup2_FishID_25Aprilâ¦â)
- then, once you start correcting the image, the new generated images will be called as âCurrent_corrected_*original-name*â
- if you perform the correction more times, your previous corrected image will be named âPrevious_corrected_*original-name*â and the new generated always âCurrent_corrected_*original-name*â.

This allows you to keep as âpreviousâ the result that you already liked and approved, while the âcurrentâ you can play and experiment new corrections. 
Be aware that if you select as input image of the correction âpreviousâ this means that you didnât like the âcurrentâ one and it will be overwrite (while the âpreviousâ remain the same), otherwise if you liked the âcurrentâ and you use it as input image of the new correction, then the âcurrentâ will become âpreviousâ and the new result âcurrentâ.
At anytime if you want you can re-start from the original image by selecting it as input image (original image is NEVER changed).
â
### 2. Set Scale
With this tool you can automatically measure your fish if a scale is in the image.

1.	Click on âSelect 1 cmâ and draw a line on the scale represeting 1cm, as in this example:
 
2.	Click on âSet scaleâ and your fish will be automaticall measure in your final analysis with this scale
â
### 3. Segmentation & Analysis
With this tool you can segment your fish.

Steps:
1.	Select the âImageâ you want to analyse (be aware of the nomenclature*)
2.	Click âSelect fish areaâ button
3.	Start drawing your mask with the brush (yellow arrow below). I suggest to start drwaing the fish contours and then with the paint bucket (red arrow below) fill the inside. Adjust it with the eraser (orange arrow below) if needed
    
4.	Select the output folder you want the results saved in by clicking âBrowseâ
5.	Finally, click on âAnalyse the fishâ to generate your analysis

Here is an example of the results you obtain from it:
â¢	two graphs per image,
o	one representing the percentage of the 3 dominant color you want to study (black, white and orange) 
 
o	one with the composition of the real RGB values found in the image (the ones that are categorized in the 3 main classes you have in graph 1)
 

â¢	one csv file in which there are the number of black, white and orange pixels, their percentages (same values of graph 1), the length of the fish in pixels (always provided) and the length converted in cm (if a scale was provided).
o	If in the output folder chosen there were already a previously created csv we will append to that the new info, otherwise a new csv is created.
 


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""fish-scan"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/ariannaravera/fish-scan/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/ariannaravera/fish-scan/issues', 'Documentation, https://github.com/ariannaravera/fish-scan#README.md', 'Source Code, https://github.com/ariannaravera/fish-scan', 'User Support, https://github.com/ariannaravera/fish-scan/issues']",fish-scan.get_reader,fish-scan.write_multiple,fish-scan.analysis,fish-scan.make_sample_data,['*.npy'],,['.npy']
47,featureforest,featureforest,Feature Forest,0.1.2,2024-10-10,2025-07-28,"Mehdi Seifi, Vera Galinova","Mehdi Seifi <mehdi.seifi@fht.org>, Vera Galinova <vera.galinova@fht.org>",BSD-3-Clause,https://github.com/juglab/featureforest,https://pypi.org/project/featureforest/,https://featureforest.github.io/,,A napari plugin for segmentation using vision transformer features,>=3.10,"['h5py', 'iopath>=0.1.10', 'magicgui', 'matplotlib', 'napari[all]', 'numpy<2.2', 'opencv-python', 'pims', 'pooch', 'pynrrd', 'qtpy', 'scikit-image', 'scikit-learn', 'scipy', 'tifffile', 'timm', 'torch>=2.5.1', 'torchvision>=0.20.1', 'tqdm>=4.66.1', ""mkdocs-material; extra == 'dev'"", ""pre-commit; extra == 'dev'"", ""pytest; extra == 'dev'"", ""pytest-cov; extra == 'dev'"", ""sybil; extra == 'dev'"", ""tox; extra == 'dev'"", ""tox-gh-actions; extra == 'dev'""]","# Feature Forest

[![License BSD-3](https://img.shields.io/pypi/l/featureforest.svg?color=green)](https://github.com/juglab/featureforest/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/featureforest.svg?color=green)](https://pypi.org/project/featureforest)
![PyPI - Downloads](https://img.shields.io/pypi/dm/featureforest)
[![Python Version](https://img.shields.io/pypi/pyversions/featureforest.svg?color=green)](https://python.org)
[![tests](https://github.com/juglab/featureforest/workflows/tests/badge.svg)](https://github.com/juglab/featureforest/actions)
[![codecov](https://codecov.io/gh/juglab/featureforest/branch/main/graph/badge.svg)](https://codecov.io/gh/juglab/featureforest)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/featureforest)](https://napari-hub.org/plugins/featureforest)
<!--[![Downloads](https://pepy.tech/badge/featureforest)](https://pepy.tech/project/featureforest)-->

**A napari plugin for making image annotation using feature space of vision transformers and random forest classifier.**  
We developed a *napari* plugin to train a *Random Forest* model using extracted features of vision foundation models and just a few scribble labels provided by the user as input. This approach can do the segmentation of desired objects almost as well as manual segmentations but in a much shorter time with less manual effort.  

----------------------------------

## Documentation
You can check the documentation [here](https://juglab.github.io/featureforest/) (â ï¸ work in progress!).  

## Installation
We provided `install.sh` for Linux & Mac OS users, and `install.bat` for Windows users.  
First you need to clone the repo:  
```bash
git clone https://github.com/juglab/featureforest
cd ./featureforest
```
Now run the installation script:  
```bash
# Linux or Mac OS
sh ./install.sh
```
```bash
# Windows
./install.bat
```

For developers that want to contribute to FeatureForest, you need to use this command to install the `dev` dependencies:  
```bash
pip install -U ""featureforest[dev]""
```
And make sure you have `pre-commit` installed in your environment, before committing changes:  
```bash
pre-commit install
```

For more detailed installation guide, check out [here](https://juglab.github.io/featureforest/install/).


## Cite us

Seifi, Mehdi, Damian Dalle Nogare, Juan Battagliotti, Vera Galinova, Ananya Kediga Rao, AI4Life Horizon Europe Programme Consortium, Johan Decelle, Florian Jug, and Joran Deschamps. ""FeatureForest: the power of foundation models, the usability of random forests."" bioRxiv (2024): 2024-12. [DOI: 10.1101/2024.12.12.628025](https://www.biorxiv.org/content/10.1101/2024.12.12.628025v1.full)


## License

Distributed under the terms of the [BSD-3] license,
""featureforest"" is free and open source software.  

## Issues

If you encounter any problems, please [file an issue](https://github.com/juglab/featureforest/issues/new) along with a detailed description.  

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[conda]: https://conda.io/projects/conda/en/latest/index.html
[mamba]: https://mamba.readthedocs.io/en/latest/installation/mamba-installation.html
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'License :: OSI Approved :: BSD License', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['homepage, https://featureforest.github.io/', 'repository, https://github.com/juglab/featureforest']",,,featureforest.make_feature_extractor_widget,,,,
48,grabber-ift,grabber-ift,grabber-ift,0.2.2,2021-12-12,2021-12-14,JordÃ£o Bragantini,jordao.bragantini@gmail.com,MIT,,https://pypi.org/project/grabber-ift/,UNKNOWN,UNKNOWN,A tool for contour-based segmentation correction (2D only).,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'pyift (>=0.0.4)', 'opencv-python-headless (>=4.4.0)', 'scipy (>=1.7.2)']","# Grabber: A Tool to Improve Convergence in Interactive Image Segmentation

[![License](https://img.shields.io/pypi/l/grabber.svg?color=green)](https://github.com/LIDS-UNICAMP/grabber/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/grabber.svg?color=green)](https://pypi.org/project/grabber)
[![Python Version](https://img.shields.io/pypi/pyversions/grabber.svg?color=green)](https://python.org)
[![tests](https://github.com/LIDS-UNICAMP/grabber/workflows/tests/badge.svg)](https://github.com/LIDS-UNICAMP/grabber/actions)
[![codecov](https://codecov.io/gh/LIDS-UNICAMP/grabber/branch/master/graph/badge.svg)](https://codecov.io/gh/LIDS-UNICAMP/grabber)

A tool for contour-based segmentation correction (2D only).

This repository provides a demo code of the paper:
> **Grabber: A Tool to Improve Convergence in Interactive Image Segmentation**
> [JordÃ£o Bragantini](https://jookuma.github.io/), Bruno Moura, [Alexandre X. FalcÃ£o](http://lids.ic.unicamp.br/), [FÃ¡bio A. M. Cappabianco](https://scholar.google.com/citations?user=qmH9VEEAAAAJ&hl=en&oi=ao)

https://user-images.githubusercontent.com/21022743/145699960-57da06a5-668f-4e81-82b5-7f3d3ddf8ee3.mp4

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `grabber-ift` via [pip]:

    pip install grabber-ift


## Known Limitations

This implementation doesn't support the items below, feel free to open a PR to add them.

- It only support 2D image, supporting 3D images isn't trivial, but it could be applied per slice with minor changes.

## Citation

If this work was useful for your research, please cite our paper:

```
@article{bragantini2020grabber,
  title={Grabber: A Tool to Improve Convergence in Interactive Image Segmentation,
  author={Bragantini, Jord{\~a}o and Bruno Moura, Falc{\~a}o, Alexandre Xavier and Cappabianco, F{\'a}bio AM,
  journal={Pattern Recognition Letters},
  year={2020}
}
```

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""grabber"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']",,,,grabber-ift.GrabberWidget,,,,
49,harpy-analysis,harpy-analysis,harpy,0.2.0,2024-12-09,2025-05-29,dambi,,Academic Non-commercial Softwa...,https://github.com/saeyslab/harpy/issues,https://pypi.org/project/harpy-analysis/,,,single-cell spatial proteomics analysis that makes you happy,"<3.13,>=3.10","['crick', 'dask<=2024.11.2,>=2024.4.1', 'datasets>=2.16.0', 'distributed', 'flowsom', 'geopandas>=1.0.1', 'lazy-loader>=0.4', 'leidenalg>=0.9.1', 'magicgui', 'nptyping', 'ome-zarr>=0.9.0', 'omegaconf==2.3.0', 'pyrootutils', 'rasterio>=1.3.2', 'scanpy>=1.9.1', 'seaborn>=0.12.2', 'session-info2', 'spatialdata-io>=0.1.6', 'spatialdata>=0.2.6', 'universal-pathlib', 'voronoi-diagram-for-polygons>=0.1.6', 'xarray-dataclasses>=1.9.1', 'xarray>=2024.10.0', ""basicpy>=1.0.0; extra == 'basic'"", ""jax>=0.4.6; extra == 'basic'"", ""jaxlib>=0.4.6; extra == 'basic'"", ""asv; extra == 'benchmark'"", ""cellpose>=2.2.3; extra == 'cellpose'"", ""hydra-colorlog>=1.2.0; extra == 'cli'"", ""hydra-core>=1.2.0; extra == 'cli'"", ""hydra-submitit-launcher>=1.2.0; extra == 'cli'"", ""submitit>=1.4.5; extra == 'cli'"", ""flowsom; extra == 'clustering'"", ""scikit-learn>=1.3.1; extra == 'clustering'"", ""asv; extra == 'dev'"", ""bokeh; extra == 'dev'"", ""cellpose>=2.2.3; extra == 'dev'"", ""datasets; extra == 'dev'"", ""flowsom; extra == 'dev'"", ""hydra-colorlog>=1.2.0; extra == 'dev'"", ""hydra-core>=1.2.0; extra == 'dev'"", ""hydra-submitit-launcher>=1.2.0; extra == 'dev'"", ""instanseg-torch>=0.0.8; extra == 'dev'"", ""ipython; extra == 'dev'"", ""ipywidgets; extra == 'dev'"", ""joypy; extra == 'dev'"", ""myst-nb; extra == 'dev'"", ""napari-spatialdata>=0.2.6; extra == 'dev'"", ""napari[all]>=0.4.18; extra == 'dev'"", ""nbconvert; extra == 'dev'"", ""opencv-python; extra == 'dev'"", ""pre-commit; extra == 'dev'"", ""pytest; extra == 'dev'"", ""pytest-cov; extra == 'dev'"", ""pytest-qt; extra == 'dev'"", ""scikit-learn>=1.3.1; extra == 'dev'"", ""spatialdata-plot<0.2.9; extra == 'dev'"", ""sphinx-autodoc-typehints; extra == 'dev'"", ""sphinx-book-theme>=1.0.0; extra == 'dev'"", ""sphinx-copybutton; extra == 'dev'"", ""sphinx-design; extra == 'dev'"", ""sphinx-rtd-theme; extra == 'dev'"", ""sphinx>=4.5; extra == 'dev'"", ""sphinxcontrib-bibtex>=1.0.0; extra == 'dev'"", ""squidpy; extra == 'dev'"", ""submitit>=1.4.5; extra == 'dev'"", ""supervenn>=0.5.0; extra == 'dev'"", ""textalloc; extra == 'dev'"", ""tox; extra == 'dev'"", ""tqdm; extra == 'dev'"", ""twine>=4.0.2; extra == 'dev'"", ""myst-nb; extra == 'docs'"", ""sphinx-autodoc-typehints; extra == 'docs'"", ""sphinx-book-theme>=1.0.0; extra == 'docs'"", ""sphinx-copybutton; extra == 'docs'"", ""sphinx-design; extra == 'docs'"", ""sphinx-rtd-theme; extra == 'docs'"", ""sphinx>=4.5; extra == 'docs'"", ""sphinxcontrib-bibtex>=1.0.0; extra == 'docs'"", ""bokeh; extra == 'extra'"", ""cellpose>=2.2.3; extra == 'extra'"", ""flowsom; extra == 'extra'"", ""hydra-colorlog>=1.2.0; extra == 'extra'"", ""hydra-core>=1.2.0; extra == 'extra'"", ""hydra-submitit-launcher>=1.2.0; extra == 'extra'"", ""instanseg-torch>=0.0.8; extra == 'extra'"", ""ipython; extra == 'extra'"", ""ipywidgets; extra == 'extra'"", ""joypy; extra == 'extra'"", ""napari-spatialdata>=0.2.6; extra == 'extra'"", ""napari[all]>=0.4.18; extra == 'extra'"", ""nbconvert; extra == 'extra'"", ""opencv-python; extra == 'extra'"", ""scikit-learn>=1.3.1; extra == 'extra'"", ""spatialdata-plot<0.2.9; extra == 'extra'"", ""squidpy; extra == 'extra'"", ""submitit>=1.4.5; extra == 'extra'"", ""supervenn>=0.5.0; extra == 'extra'"", ""textalloc; extra == 'extra'"", ""tqdm; extra == 'extra'"", ""instanseg-torch>=0.0.8; extra == 'instanseg'"", ""napari-spatialdata>=0.2.6; extra == 'napari'"", ""napari[all]>=0.4.18; extra == 'napari'"", ""bokeh; extra == 'notebook'"", ""ipython; extra == 'notebook'"", ""ipywidgets; extra == 'notebook'"", ""joypy; extra == 'notebook'"", ""nbconvert; extra == 'notebook'"", ""spatialdata-plot<0.2.9; extra == 'notebook'"", ""supervenn>=0.5.0; extra == 'notebook'"", ""textalloc; extra == 'notebook'"", ""tqdm; extra == 'notebook'"", ""opencv-python; extra == 'opencv'"", ""cellpose>=2.2.3; extra == 'segmentation'"", ""instanseg-torch>=0.0.8; extra == 'segmentation'"", ""datasets; extra == 'test'"", ""opencv-python; extra == 'test'"", ""pytest; extra == 'test'"", ""pytest-cov; extra == 'test'"", ""pytest-qt; extra == 'test'"", ""tox; extra == 'test'""]","<!-- These badges won't work while the GitHub repo is private:
[![License BSD-3](https://img.shields.io/pypi/l/harpy.svg?color=green)](https://github.com/saeyslab/harpy/raw/main/LICENSE)
[![Python Version](https://img.shields.io/pypi/pyversions/harpy-analysis.svg?color=green)](https://python.org)
[![codecov](https://codecov.io/gh/saeyslab/harpy/graph/badge.svg?token=7UXMDWVYFZ)](https://codecov.io/gh/saeyslab/harpy)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/harpy)](https://napari-hub.org/plugins/harpy)
-->

# **Harpy: single-cell spatial proteomics analysis that makes you happy** <img src=""./docs/_static/img/logo.png"" align =""right"" alt="""" width =""150""/>

[![PyPI](https://img.shields.io/pypi/v/harpy-analysis.svg)](https://pypi.org/project/harpy-analysis)
[![Build Status](https://github.com//saeyslab/harpy/actions/workflows/build.yaml/badge.svg)](https://github.com//saeyslab/harpy/actions/)
[![documentation badge](https://readthedocs.org/projects/harpy/badge/?version=latest)](https://harpy.readthedocs.io/en/latest/)

Note: This package is still under very active development.

## Installation

**Recommended** for end-users. Install the latest `harpy-analysis` [PyPI package](https://pypi.org/project/harpy-analysis) with the `extra` dependencies in a local Python environment:

```bash
uv venv --python=3.12 # set python version
source .venv/bin/activate # activate the virtual environment
uv pip install 'harpy-analysis[extra]' # use uv to pip install dependencies
python -c 'import harpy; print(harpy.__version__)' # check if the package is installed
```

If you're a developer, read the contribution guide. Checkout the docs for more [installation instructions](https://github.com/saeyslab/harpy/blob/main/docs/installation.md).

## Tutorials

Tutorials are available [here](https://harpy.readthedocs.io/en/latest/).

## Usage

[Learn](https://github.com/saeyslab/harpy/blob/main/docs/usage.md) how Harpy can be integrated into your workflow in different ways.

## Contributing

See [here](https://github.com/saeyslab/harpy/blob/main/docs/contributing.md) for info on how to contribute to Harpy.

## References

- https://github.com/ashleve/lightning-hydra-template

## License

Check the [license](https://github.com/saeyslab/harpy/blob/main/LICENSE). Harpy is free for academic usage.
For commercial usage, please contact Saeyslab.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/saeyslab/harpy/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/saeyslab/harpy/issues', 'Documentation, https://github.com/saeyslab/harpy#README.md', 'Source Code, https://github.com/saeyslab/harpy', 'User Support, https://github.com/saeyslab/harpy/issues']",,,harpy-analysis.widgets.wizard_widget,,,,
50,guanine-crystal-analysis,guanine-crystal-analysis,Guanine Crystal Analysis,0.0.2,2022-07-26,2023-05-30,Mara Lampert,mara_harriet.lampert@mailbox.tu-dresden.de,BSD-3-Clause,https://github.com/biapol/guanine-crystal-analysis/issues,https://pypi.org/project/guanine-crystal-analysis/,,https://github.com/biapol/guanine-crystal-analysis,"A plugin for the guanine crystal segmentation, classification and characterization in the zebrafish eye",>=3.8,"['numpy', 'magicgui', 'qtpy', 'apoc', 'scikit-image', 'pandas', 'napari-simpleitk-image-processing', 'napari-skimage-regionprops', 'pyclesperanto-prototype', 'scikit-learn', 'napari-workflows', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# guanine-crystal-analysis

[![License BSD-3](https://img.shields.io/pypi/l/guanine-crystal-analysis.svg?color=green)](https://github.com/biopo/guanine-crystal-analysis/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/guanine-crystal-analysis.svg?color=green)](https://pypi.org/project/guanine-crystal-analysis)
[![Python Version](https://img.shields.io/pypi/pyversions/guanine-crystal-analysis.svg?color=green)](https://python.org)
[![tests](https://github.com/biopo/guanine-crystal-analysis/workflows/tests/badge.svg)](https://github.com/biopo/guanine-crystal-analysis/actions)
[![codecov](https://codecov.io/gh/biopo/guanine-crystal-analysis/branch/main/graph/badge.svg)](https://codecov.io/gh/biopo/guanine-crystal-analysis)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/guanine-crystal-analysis)](https://napari-hub.org/plugins/guanine-crystal-analysis)

A plugin for guanine crystal segmentation and classification in the zebrafish eye. More precisely, it provides a workflow that measures on guanine crystal labels and sorts out overlaying partially segmented crystals during classification.

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Usage 

This plugin is suited for users who
- want to derive size-, shape and intensity-based parameters from individual guanine crystals
- struggle with partially segmented or overlapping crystals
- want to investigate further the size and shape of these guanine crystals

This plugin is not suited for users who 
- are interested in further investigations of intensity of guanine crystals

You can find the plugin in napari under `Plugins` â `guanine-crystal-analysis`

### Image Input

This plugin can be used on individual 2D slices of z-stacks as the workflow was developed on such input.
Therefore, the quality of the result might differ on differing input, like crops or maximum projections.

### 1. Normalization

You can normalize the image selecting `Normalization` where you only need to specify your input image and click on the `Run` button. 

![](img/plugin/normalization.png)

Normalizing the image helps to adjust the intensity values and needs to be applied here because the object segmenter is only trained on normalized images.

### 2. Segmentation

When selecting `Segmentation`, you need to select the normalized image and a minimum pixel count of label images and click on the `Run` button again.
![](img/plugin/segmentation.png)
This avoids having too small and unhelpful labels and is set by default to 50 pixels. 
For the training of the model, an [APOC](https://github.com/haesleinhuepf/apoc) pixel classifier was used.

### 3. Analyze Image

Under `Analyze Image`, you can extract features from your image and label image by selecting them and clicking on the `Run` button.  
![](img/plugin/analyzeimage.png)
The extracted features are a combination of the two libraries [napari-skimage-regionprops](https://github.com/haesleinhuepf/napari-skimage-regionprops) and [napari-simpleitk-image-processing](https://github.com/haesleinhuepf/napari-simpleitk-image-processing). They can be devided into size-, shape-, and intensity-based parameters: 

| **size** | **shape**                 | **intensity**  
|----------|---------------------------|-------------------|
|![](img/plugin/size.png)      	|![](img/plugin/shape.png)              	|![](img/plugin/intensity.png)  	|
| area     	| aspect ratio              	| maximum intensity 	|
|          	| perimeter                 	| mean intensity    	|
|          	| major-axis-length         	| minimum intensity 	|
|          	| minor-axis-length         	| median            	|
|          	| circularity               	| sum               	|
|          	| solidity                  	| variance          	|
|          	| eccentricity              	|                   	|
|          	| roundness                 	|                   	|
|          	| perimeter-on-border       	|                   	|
|          	| perimeter-on-border-ratio 	|                   	|

You can find a glossary with an explanation of these features [in this blog post](https://focalplane.biologists.com/2023/05/03/feature-extraction-in-napari/)
Some of the guanine crystals are not correctly segmented because of overlay or interference patterns. This problem is addressed with the help of a classification step demonstrated next

### 4. Classify Objects

You can divide the crystal labels into predicted (blue) and discarded (brown) crystal labels using `Classify Objects`. There you can choose classifiers trained on intensity-, shape- and/or size-based parameters with the help of the checkboxes.
![](img/plugin/classifyobjects.png)
For the training of the model, an [APOC](https://github.com/haesleinhuepf/apoc) object classifier was used.
It is recommended to later on not measure the parameters that the classifier was trained on, but other ones.

### 5. Bad Label Exclusion

Now, you can get rid of the discarded (brown) labels for further analysis using `Bad Label Exclusion`. Select the two label images of segmentation and classification result and press the `Run` button again. 
![](img/plugin/badlabelexclusion.png)
The result is a label image with only the predicted (blue) labels which are relabeled sequentially. If you want to derive measurements on these predicted labels, you can just use  `Analyze Image` again.

### ""Analyze Deluxe""

You can also do all the explained steps in one click using the `Analyze Deluxe` function.
![](img/plugin/analyzedeluxe.png)


## Installation

You can install `guanine-crystal-analysis` via [pip]:

    pip install guanine-crystal-analysis



To install latest development version :

    pip install git+https://github.com/biopo/guanine-crystal-analysis.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## Acknowledgements
This project was done in collaboration with the [Rita Mateus Laboratory](https://www.ritamateus.com/). The images shown in the documentation and in the demo jupyter notebooks were acquired there. 
This project was supported by the Deutsche Forschungsgemeinschaft under Germanyâs Excellence Strategy â EXC2068 - Cluster of Excellence ""Physics of Life"" of TU Dresden. 
This project has been made possible in part by grant number [2021-240341 (Napari plugin accelerator grant)](https://chanzuckerberg.com/science/programs-resources/imaging/napari/improving-image-processing/) from the Chan Zuckerberg Initiative DAF, an advised fund of the Silicon Valley Community Foundation.


## License

Distributed under the terms of the [BSD-3] license,
""guanine-crystal-analysis"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/biopo/guanine-crystal-analysis/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/biapol/guanine-crystal-analysis/issues', 'Documentation, https://github.com/biapol/guanine-crystal-analysis#README.md', 'Source Code, https://github.com/biapol/guanine-crystal-analysis', 'User Support, https://github.com/biapol/guanine-crystal-analysis/issues']",,,guanine-crystal-analysis.normalization,guanine-crystal-analysis.make_sample_data,,,
51,hipocount-napari,hipocount-napari,hipocount-napari,0.0.1,2024-07-23,2024-07-23,Borys Olifirov,omnia.fatum@gmail.com,MIT,https://github.com/wisstock/hipocount-napari/issues,https://pypi.org/project/hipocount-napari/,,,Quantitative analysis of immunofluorescence images of hippocampal slices,>=3.8,['napari'],"hipocount-napari
================

Quantitative analysis of immunofluorescence images of hippocampal slices
","['Framework :: napari', 'Development Status :: 3 - Alpha', 'License :: OSI Approved :: MIT License', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Image Recognition', 'Topic :: Utilities']","['Documentation, https://github.com/wisstock/hipocount-napari', 'Source Code, https://github.com/wisstock/hipocount-napari', 'Bug Tracker, https://github.com/wisstock/hipocount-napari/issues', 'User Support, https://github.com/wisstock/hipocount-napari/issues']",,,hipocount-napari.stack_process_widget,,,,
52,generate-dense-patches,generate-dense-patches,Generate Dense Patches,0.0.2,2023-09-12,2023-09-12,Aayush Bhatawadekar,asbhatawadekar@gmail.com,BSD-3-Clause,https://github.com/volume-em/generate-dense-patches/issues,https://pypi.org/project/generate-dense-patches/,,https://github.com/volume-em/generate-dense-patches,A simple plugin to create a lot of training data from a 3D volume and mask,>=3.8,"['napari >=0.4.18', 'napari-plugin-engine >=0.2.0', 'numpy ==1.22', 'scikit-image >=0.19', 'magicgui', 'imagecodecs', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# generate-dense-patches

[![License BSD-3](https://img.shields.io/pypi/l/generate-dense-patches.svg?color=green)](https://github.com/volume-em/generate-dense-patches/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/generate-dense-patches.svg?color=green)](https://pypi.org/project/generate-dense-patches)
[![Python Version](https://img.shields.io/pypi/pyversions/generate-dense-patches.svg?color=green)](https://python.org)
[![tests](https://github.com/volume-em/generate-dense-patches/workflows/tests/badge.svg)](https://github.com/volume-em/generate-dense-patches/actions)
[![codecov](https://codecov.io/gh/volume-em/generate-dense-patches/branch/main/graph/badge.svg)](https://codecov.io/gh/volume-em/generate-dense-patches)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/generate-dense-patches)](https://napari-hub.org/plugins/generate-dense-patches)

A simple plugin to create a lot of training data from a 3D volume and mask. For help with this plugin please open an issue, for issues with napari specifically raise an issue here instead.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

It's recommended to have installed napari and pyqt through conda. 

    conda install napari pyqt

Then to install this plugin via [pip]:

    pip install generate-dense-patches



To install latest development version :

    pip install git+https://github.com/volume-em/generate-dense-patches.git


## Usage
To use this plugin with napari:
1. Drag and drop an image and/or segmentation mask (tif) into the viewer.
2. Open ""Plugins"" Toolbar and select ""Generate dense patches"" and click ""Generate 2D Patches""

This plugin works to create a lot of 2D training data by generating an $n^3$ cube, rotating every $\theta$ slices and saving every (step size) slice of the generated volume.

3. Make sure the ""save directory box"", ""step size"", ""rotation theta"", and ""patch size"" is filled in

If no point is placed, then the center of the image will be used as the center of the cube. If a point is placed, then the center of the cube will be the point.

4. Press run and wait for the patches to be generated.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""generate-dense-patches"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/volume-em/generate-dense-patches/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/volume-em/generate-dense-patches/issues', 'Documentation, https://github.com/volume-em/generate-dense-patches#README.md', 'Source Code, https://github.com/volume-em/generate-dense-patches', 'User Support, https://github.com/volume-em/generate-dense-patches/issues']",,,generate-dense-patches.make_patches_widget,,,,
53,iacs-ipac-reader,iacs-ipac-reader,iacs-ipac-reader,0.0.13,2022-01-21,2022-04-12,Chenqi Zhang,cqzhang@g.ecc.u-tokyo.ac.jp,BSD-3-Clause,https://github.com/zcqwh/iacs_ipac_reader/issues,https://pypi.org/project/iacs-ipac-reader/,,https://github.com/zcqwh/iacs_ipac_reader,A reader plugin for read iacs/ipac images and export .rtdc files.,>=3.7,"['h5py (>=3.5.0)', 'napari (>=0.4.12)', 'napari-plugin-engine (>=0.2.0)', 'numpy (>=1.21.4)', 'opencv-contrib-python-headless (>=4.4.0.46)', 'openpyxl (>=3.0.9)', 'sklearn (>=0.0)', 'PyQt5 (==5.12.3)', 'pandas (>=1.4.0)']","# iacs_ipac_reader

[![License](https://img.shields.io/pypi/l/iacs_ipac_reader.svg?color=green)](https://github.com/zcqwh/iacs_ipac_reader/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/iacs_ipac_reader.svg?color=green)](https://pypi.org/project/iacs_ipac_reader)
[![Python Version](https://img.shields.io/pypi/pyversions/iacs_ipac_reader.svg?color=green)](https://python.org)
[![tests](https://github.com/zcqwh/iacs_ipac_reader/workflows/tests/badge.svg)](https://github.com/zcqwh/iacs_ipac_reader/actions)
[![codecov](https://codecov.io/gh/zcqwh/iacs_ipac_reader/branch/main/graph/badge.svg)](https://codecov.io/gh/zcqwh/iacs_ipac_reader)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/iacs_ipac_reader)](https://napari-hub.org/plugins/iacs_ipac_reader)

A plugin used a convolutional neural network (CNN) to distinguish single platelets, platelet clusters, and white blood cells and performed classical image analysis for each subpopulation individually. Based on the derived single-cell features for each population, a Random Forest (RF) model was trained and used to classify COVID-19 associated thrombosis and non-COVID-19 associated thrombosis.

More information about IACS/iPAC.  
__IACS__: DOI: [10.1016/j.cell.2018.08.028](https://www.sciencedirect.com/science/article/pii/S0092867418310444)   
__iPAC__: DOI: [10.7554/eLife.52938](https://elifesciences.org/articles/52938)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `iacs_ipac_reader` via [pip]:

    pip install iacs_ipac_reader



To install latest development version :

    pip install git+https://github.com/zcqwh/iacs_ipac_reader.git


## Introduction

The iacs-ipac-reader plugin mainly include 3 functional tabs:

* iPAC
* IACS
* AID classif.



### iPAC image contour tracker
<center>Interface of iPAC contour tracker</center>    

![ipac.](https://github.com/zcqwh/iacs_ipac_reader/blob/main/Tutorial/pictures/ipac.png?raw=true ""iPAC"")

### IACS image contour tracker
<center>Interface of IACS contour tracker</center>    

![iacs.](https://github.com/zcqwh/iacs_ipac_reader/blob/main/Tutorial/pictures/iacs.png?raw=true ""IACS"")

### AID classif.
<center>Interface of AID classif.</center>     
 
![AID_classif.](https://github.com/zcqwh/iacs_ipac_reader/blob/main/Tutorial/pictures/classifier.jpg?raw=true ""AID classif"")



## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""iacs_ipac_reader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/zcqwh/iacs_ipac_reader/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/



","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/zcqwh/iacs_ipac_reader/issues', 'Documentation, https://github.com/zcqwh/iacs_ipac_reader#README.md', 'Source Code, https://github.com/zcqwh/iacs_ipac_reader', 'User Support, https://github.com/zcqwh/iacs_ipac_reader/issues']",,,iacs-ipac-reader.iacs_ipac_reader,,,,
54,ilastik-napari,ilastik-napari,ilastik plugin for napari,0.2.4,2023-02-28,2024-04-17,Emil Melnikov,Emil Melnikov <emilmelnikov@gmail.com>,MIT,https://github.com/ilastik/ilastik-napari,https://pypi.org/project/ilastik-napari/,,,ilastik plugin for napari,>=3.8,"['napari >=0.4.13', 'numpy >=1.20', 'qtpy', 'scikit-learn', 'sparse']","# ilastik-napari

[Napari][napari] plugin for interactive pixel classification.
Designed to be similar to the pixel classification workflow in [classic ilastik][ilastik].

## Installation

This plugin requires you to use a _conda_ environment. The environment manager conda comes in a few different forms.
If you haven't used conda before, you can find more information in the [conda user guide][conda-user-guide].
You can use whichever variant you prefer, as the resulting environment should be the same, but we recommend the [_mambaforge_][mambaforge] variant as it is usually the fastest.
When using mambaforge, the `mamba` command usually replaces the `conda` command one would otherwise use.

Once you have installed mambaforge, set up a conda environment with napari and the _fastfilters_ package, and then use pip to install _ilastik-napari_:
```shell
mamba create -y -c ilastik-forge -c conda-forge -n my-napari-env napari fastfilters
mamba activate my-napari-env
pip install ilastik-napari
```

Finally, run napari:
```shell
napari
```
That's it! You should be able to find the ilastik-napari plugin in the Plugins menu.

If you prefer to __install napari using pip__ instead of conda:
Make sure to install `napari[all]`.
Unless you want to [choose a PyQt implementation other than _PyQt5_][napari-pyqt], in which case you should leave out the `[all]` extra.

## Usage

As a prerequisite, make sure you understand the [napari basics][napari-quickstart].

1. Open your image, or use a sample in _File - Open Sample_.

   ![Use a sample image](https://ilastik.org/assets/ilastik-napari/image-sample.png ""Use a sample image"")

2. Activate the plugin in the _Plugins_ menu.

   ![Activate the plugin](https://ilastik.org/assets/ilastik-napari/activation.png ""Activate the plugin"")

3. In _layer list_, create a new _Labels_ layer.

   ![Labels layer](https://ilastik.org/assets/ilastik-napari/labels-layer.png ""Labels layer"")

4. In _layers control_, switch to the _paint_ action.

   ![Paint action](https://ilastik.org/assets/ilastik-napari/paint-action.png ""Paint action"")

5. Draw your background labels.

   ![Paint the background](https://ilastik.org/assets/ilastik-napari/draw-background.png ""Paint the background"")

6. Switch to a new label.

   ![Switch label](https://ilastik.org/assets/ilastik-napari/new-label.png ""Switch label"")

7. Draw your foreground labels.

   ![Paint cells](https://ilastik.org/assets/ilastik-napari/draw-cells.png ""Paint cells"")

8. Select output types you need, and click _Run_.

   ![Plugin interface](https://ilastik.org/assets/ilastik-napari/interface.png ""Plugin interface"")

9. The plugin will create one layer for each output type, which you save as normal napari layers.

   ![Example output](https://ilastik.org/assets/ilastik-napari/example.png ""Example output"")

## Development

Create a development environment:
```
mamba create -y -n ilastik-napari-dev -c ilastik-forge fastfilters setuptools-scm conda-build anaconda-client
conda activate napari-ilastik-dev
pip install -e .
```

Build conda package:
```
conda activate napari-ilastik-dev
mamba build -c ilastik-forge conda-recipe
anaconda upload /path/to/the/new/package.tar.bz2
```

Build wheel and sdist packages:
```
conda activate napari-ilastik-dev
pip install build twine
python -m build
python -m twine upload --repository testpypi dist/*
```

[napari]: https://napari.org/
[ilastik]: https://www.ilastik.org/
[conda-user-guide]: https://docs.conda.io/projects/conda/en/latest/user-guide/index.html
[miniconda]: https://docs.conda.io/en/latest/miniconda.html
[mambaforge]: https://github.com/conda-forge/miniforge#mambaforge
[napari-quickstart]: https://napari.org/tutorials/fundamentals/quick_start.html
[napari-pyqt]: https://napari.org/stable/plugins/best_practices.html#don-t-include-pyside2-or-pyqt5-in-your-plugin-s-dependencies
","['Development Status :: 2 - Pre-Alpha', 'Environment :: Plugins', 'Intended Audience :: End Users/Desktop', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: MIT License', 'Framework :: napari', 'Operating System :: MacOS', 'Operating System :: MacOS :: MacOS X', 'Operating System :: Microsoft :: Windows', 'Operating System :: POSIX', 'Operating System :: POSIX :: Linux', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: Implementation :: CPython', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Image Processing']","['homepage, https://github.com/ilastik/ilastik-napari']",,,ilastik-napari.pixel_classification,,,,
55,imaxt-multiscale-plugin,imaxt-multiscale-plugin,IMAXT Multiscale Image Napari Plugin,0.3.1,2022-07-27,2023-05-31,Eduardo Gonzalez Solares,E.GonzalezSolares@ast.cam.ac.uk,LGPL-3.0-only,,https://pypi.org/project/imaxt-multiscale-plugin/,https://gitlab.developers.cam.ac.uk/astronomy/camcead/imaxt/imaxt-multiscale-plugin,https://gitlab.developers.cam.ac.uk/astronomy/camcead/imaxt/imaxt-multiscale-plugin,A simple plugin to use with napari,>=3.8,"['numpy', 'magicgui', 'qtpy', 'xarray', 'dask', 'astropy', 'zarr', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# IMAXT multiscale napari plugin

[![License GNU LGPL v3.0](https://img.shields.io/pypi/l/imaxt-multiscale-plugin.svg?color=green)](https://github.com/eg266/imaxt-multiscale-plugin/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/imaxt-multiscale-plugin.svg?color=green)](https://pypi.org/project/imaxt-multiscale-plugin)
[![Python Version](https://img.shields.io/pypi/pyversions/imaxt-multiscale-plugin.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/imaxt-multiscale-plugin)](https://napari-hub.org/plugins/imaxt-multiscale-plugin)

A napari plugin to visualize multi-resolution images created with the IMAXT mosaic pipeline.

----------------------------------------------------

## Installation

You can install `imaxt-multiscale-plugin` via [pip]:

    pip install imaxt-multiscale-plugin


## Usage

Run [napari] with the name of the sample to visualize either a local path:

    napari /storage/imaxt/eglez/processed/stpt/20220606_PDX_AB559_GFP_005503_100x15um

or a sample in S3 storage:

    napari s3://imaxtgw/stpt/20220608_DI_PDX_SA535_Tum_5223_04280_100x15um
    
## Screenshots

![Alt text](https://gitlab.developers.cam.ac.uk/astronomy/camcead/imaxt/imaxt-multiscale-plugin/-/raw/main/assets/napari1.png ""a title"")
![Alt text](https://gitlab.developers.cam.ac.uk/astronomy/camcead/imaxt/imaxt-multiscale-plugin/-/raw/main/assets/napari2.png ""a title"")
![Alt text](https://gitlab.developers.cam.ac.uk/astronomy/camcead/imaxt/imaxt-multiscale-plugin/-/raw/main/assets/napari3.png ""a title"")
![Alt text](https://gitlab.developers.cam.ac.uk/astronomy/camcead/imaxt/imaxt-multiscale-plugin/-/raw/main/assets/napari4.png ""a title"")

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU LGPL v3.0] license,
""imaxt-multiscale-plugin"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU Lesser General Public License v3 (LGPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']",,imaxt-multiscale-plugin.get_reader,imaxt-multiscale-plugin.write_single_image,imaxt-multiscale-plugin.make_qwidget,,['*'],['.npy'],"['.tif', '.tiff']"
56,image-composer,Image-Composer,Image-Composer,0.0.19,2022-01-10,2022-01-12,"Marc Boucsein, Robin Koch",,BSD-3,https://github.com/MBPhys/Image-Composer,https://pypi.org/project/Image-Composer/,,https://github.com/MBPhys/Image-Composer,A napari plugin in order to compose a background image with a foreground image,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy']","# Image-Composer

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/Image-Composer/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/Image-Composer.svg?color=green)](https://pypi.org/project/Image-Composer)
[![Python Version](https://img.shields.io/pypi/pyversions/Image-Composer.svg?color=green)](https://python.org)


A napari plugin in order to compose a background image with a foreground image.

----------------------------------

## Installation

You can install `Image-Composer` via [pip]:

    pip install Image-Composer

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""Image-Composer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/Image-Composer/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,Image-Composer.Composer,,,,
57,hesperos,hesperos,Hesperos application,0.2.1,2022-05-30,2023-06-27,Charlotte Godard,charlotte.godard@pasteur.fr,BSD-3-Clause,https://github.com/chgodard/hesperos,https://pypi.org/project/hesperos/,,https://github.com/chgodard/hesperos,A plugin to manually or semi-automatically segment medical data and correct previous segmentation data.,>=3.8,"['numpy', 'qtpy', 'tifffile', 'scikit-image', 'scikit-learn', 'SimpleITK', 'pandas', 'napari (<0.4.15)', 'napari-plugin-engine', 'imageio-ffmpeg', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","<div align=""justify"">
    
# HESPEROS PLUGIN FOR NAPARI

[![License](https://img.shields.io/pypi/l/hesperos.svg?color=green)](https://github.com/DBC/hesperos/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/hesperos.svg?color=green)](https://pypi.org/project/hesperos)
[![Python Version](https://img.shields.io/pypi/pyversions/hesperos.svg?color=green)](https://python.org)
[![tests](https://github.com/DBC/hesperos/workflows/tests/badge.svg)](https://github.com/DBC/hesperos/actions)
[![codecov](https://codecov.io/gh/DBC/hesperos/branch/main/graph/badge.svg)](https://codecov.io/gh/DBC/hesperos)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/hesperos)](https://napari-hub.org/plugins/hesperos)

A Napari plugin for pre-defined manual segmentation or semi-automatic segmentation with a one-shot learning procedure. The objective was to simplify the interface as much as possible so that the user can concentrate on annotation tasks using a pen on a tablet, or a mouse on a computer. 
    
This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

    
# Table of Contents
- [Installation and Usage](#installation-and-usage)
    * [Automatic installation](#automatic-installation)
    * [Manual installation](#manual-installation)
    * [Upgrade Hesperos version](#upgrade-hesperos-version)
- [Hesperos: *Manual Segmentation and Correction* mode](#hesperos-manual-segmentation-and-correction-mode)
    * [Import and adjust your image](#import-and-adjust-your-image-use-panel-1)
    * [Layer controls](#layer-controls)
    * [Annotate your image](#annotate-your-image-use-panel-2)
    * [Select slices of interest](#select-slices-of-interest-use-panel-3----only-displayed-for-the-shoulder-bones-category)
    * [Export annotations](#export-annotations-use-panel-3----or-4-if-the-shoulder-bones-category-is-selected)
- [Hesperos: *OneShot Segmentation* mode](#hesperos-oneshot-segmentation-mode)
    * [Import and adjust your image](#import-and-adjust-your-image-use-panel-1)
    * [Annotate your image](#annotate-your-image-use-panel-2)
    * [Run automatic segmentation](#run-automatic-segmentation-use-panel-3)
    * [Export annotations](#export-annotations-use-panel-4)

        
# Installation and Usage
The Hesperos plugin is designed to run on Windows (11 or less) and MacOS with Python 3.8 / 3.9 / 3.10.
     
    
## Automatic installation
1. Install [Anaconda] and unselect *Add to PATH*. Keep in mind the path where you choose to install anaconda.
2. Only download the *script_files* folder for [Windows](/script_files/for_Windows/) or [Macos](/script_files/for_Windows/). 
3. Add your Anaconda path in these script files:
    1. <ins>For Windows</ins>: 
    Right click on the .bat files (for [installation](/script_files/for_Windows/install_hesperos_env.bat) and [running](/script_files/for_Windows/run_hesperos.bat)) and select *Modify*. Change *PATH_TO_ADD* with your Anaconda path. Then save the changes.
        > for exemple:
        ```
        anaconda_dir=C:\Users\chgodard\anaconda3
        ```
    2. <ins>For Macos</ins>:
        1. Right click on the .command files (for [installation](/script_files/for_Macos/install_hesperos_env.command) and [running](/script_files/for_Macos/run_hesperos.command)) and select *Open with TextEdit*. Change *PATH_TO_ADD* with your Anaconda path. Then save the changes.
            > for exemple:
            ```
            source ~/opt/anaconda3/etc/profile.d/conda.sh
            ```
        2. In your terminal, change the permissions to allow the following .command files to be run (change *PATH* with the path of your .command files): 
            ``` 
            chmod u+x PATH/install_hesperos_env.command 
            chmod u+x PATH/run_hesperos.command 
            ```
4. Double click on the **install_hesperos_env file** to create a virtual environment in Anaconda with python 3.9 and Napari 0.4.14. 
    > /!\ The Hesperos plugin is not yet compatible with Napari versions superior to 0.4.14.
5. Double click on the **run_hesperos file** to run Napari from your virtual environment.
6. In Napari: 
    1. Go to *Plugins/Install Plugins...*
    2. Search for ""hesperos"" (it can take a while to load).
    3. Install the **hesperos** plugin.
    4. When the installation is done, close Napari. A restart of Napari is required to finish the plugin installation.
7. Double click on the **run_hesperos file** to run Napari.
8. In Napari, use the Hesperos plugin with *Plugins/hesperos*.

    
## Manual installation
1. Install [Anaconda] and unselect *Add to PATH*.
2. Open your Anaconda prompt command.
3. Create a virtual environment with Python 3.8 / 3.9 / 3.10:
    ```
    conda create -n hesperos_env python=3.9
    ```
4. Install the required Python packages in your virtual environment:
    ```
    conda activate hesperos_env
    conda install -c conda-forge napari=0.4.14 
    conda install -c anaconda pyqt
    pip install hesperos
    ```
    > /!\ Hesperos plugin is not yet compatible with napari version superior to 0.4.14.
5. Launch Napari:
    ```
    napari
    ```
    
## Upgrade Hesperos version
1. Double click on the **run_hesperos file** to run Napari. 
2. In Napari: 
    1. Go to *Plugins/Install Plugins...*
    2. Search for ""hesperos"" (it can take a while to load).
    3. Click on *Update* if a new version of Hesperos has been found. You can check the latest version of Hesperos in the [Napari Hub](https://www.napari-hub.org/plugins/hesperos).
    4. When the installation is done, close Napari. A restart of Napari is required to finish the plugin installation.
   
    
# Hesperos: *Manual Segmentation and Correction* mode
    
 The ***Manual Segmentation and Correction*** mode of the Hesperos plugin is a simplified and optimized interface to do basic 2D manual segmentation of several structures in a 3D image using a mouse or a stylet with a tablet.

    
 <img src=""https://user-images.githubusercontent.com/49953723/193262711-710673f2-5b53-4eb6-a7c7-6dada9d28d92.PNG"" width=""1000px""/>
    
## Import and adjust your image *(use Panel 1)*
The Hesperos plugin can be used with Digital Imaging and COmmunications in Medicine (DICOM), Neuroimaging Informatics Technology Initiative (NIfTI) or Tagged Image File Format (TIFF) images. To improve performances, use images that are located on your own disk.

1. To import data:
    - use the <img src=""https://user-images.githubusercontent.com/49953723/193262334-3c28e733-36ab-4504-9a6d-acd298c15994.PNG"" width=""100px""/> button for *(.tiff, .tif, .nii or .nii.gz)* image files.
    - use the <img src=""https://user-images.githubusercontent.com/49953723/193262624-149a4461-fbac-4498-a2b8-33bdd88e3a9f.PNG"" width=""100px""/> button for a DICOM serie. /!\ Folder with multiple DICOM series is not supported.  
2. After the image has loaded, a slider appears that allows to zoom in/out: <img src=""https://user-images.githubusercontent.com/49953723/193262738-7e6e68a9-0890-4e18-92a9-dbf2168a6bb5.PNG"" width=""100px""/>. Zooming is also possible with the <img src=""https://user-images.githubusercontent.com/49953723/193262725-7d4f7b09-d119-45cf-a9d4-c42c5f848c1a.PNG"" width=""25px""/> button in the layer controls panel. 
3. If your data is a DICOM serie, you have the possibility to directly change the contrast of the image (according to the Hounsfield Unit):
    - by choosing one of the two predefined contrasts: *CT bone* or *CT Soft* in <img src=""https://user-images.githubusercontent.com/49953723/193262708-17e1d301-0a9a-497f-9feb-613e69893c06.PNG"" width=""150px""/>.
    - by creating a custom default contrast with the <img src=""https://user-images.githubusercontent.com/49953723/193262707-466917b4-b885-429b-9924-6481fa6410bb.PNG"" width=""30px""/> button and selecting *Custom Contrast*. Settings can be exported as a .json file with the <img src=""https://user-images.githubusercontent.com/49953723/193262709-e1ad5321-1f60-4b60-a715-7c494670e1cd.PNG"" width=""30px""/> button.
    - by loading a saved default contrast with the <img src=""https://user-images.githubusercontent.com/49953723/193262710-c9f66354-f896-4e59-8718-70e5509875af.PNG"" width=""30px""/> button and selecting *Custom Contrast*.
4. In the bottom left corner of the application you also have the possibility to: 
    - <img src=""https://user-images.githubusercontent.com/49953723/193262716-d9947eb9-d87f-4251-af76-2d906cd36018.PNG"" width=""25px""/>: change the order of the visible axis (for example go to sagittal, axial or coronal planes).
    - <img src=""https://user-images.githubusercontent.com/49953723/193262717-12afbfb1-49ae-4a77-a83e-5bc99850734a.PNG"" width=""25px""/>: transpose the 3D image on the current axis being displayed.


## Layer controls

When data is loading, two layers are created: the *`image`* layer and the *`annotations`* layer. Order in the layer list correspond to the overlayed order. By clicking on these layers you will have acces to different layer controls (at the top left corner of the application). All actions can be undone/redone with the Ctrl-Z/Shift-Ctrl-Z keyboard shortcuts. You can also hide a layer by clicking on its eye icon on the layer list.
    
    
<ins>For the *image* layer:</ins>
- *`opacity`*: a slider to control the global opacity of the layer.
- *`contrast limits`*: a double slider to manually control the contrast of the image (same as the <img src=""https://user-images.githubusercontent.com/49953723/193262708-17e1d301-0a9a-497f-9feb-613e69893c06.PNG"" width=""150px""/> option for DICOM data).
    

<ins>For the *annotations* layer:</ins>
- <img src=""https://user-images.githubusercontent.com/49953723/193262718-30882770-59eb-4d2b-9cfe-8b88537560c4.PNG"" width=""25px""/>: erase brush to erase all labels at once (if *`preserve labels`* is not selected) or only erase the selected label (if *`preserve labels`* is selected).
- <img src=""https://user-images.githubusercontent.com/49953723/193262722-6bb6e6a4-ae7a-4ad1-b7f8-898e54ad62c3.PNG"" width=""25px""/>: paint brush with the same color than the *`label`* rectangle.
- <img src=""https://user-images.githubusercontent.com/49953723/193262719-f816b21e-78fd-4ba7-b415-30a461cbd652.PNG"" width=""25px""/>: fill bucket with the same color than the *`label`* rectangle.
- <img src=""https://user-images.githubusercontent.com/49953723/193262725-7d4f7b09-d119-45cf-a9d4-c42c5f848c1a.PNG"" width=""25px""/>: select to zoom in and out with the mouse wheel (same as the zoom slider at the top right corner in Panel 1).
- *`label`*: a colored rectangle to represent the selected label.  
- *`opacity`*: a slider to control the global opacity of the layer.  
- *`brush size limits`*: a slider to control size of the paint/erase brush.    
- *`preserve labels`*: if selected, all actions are applied only on the selected label (see the *`label`* rectangle); if not selected, actions are applied on all labels.
- *`show selected`*: if selected, only the selected label will be display on the layer; if not selected, all labels are displayed.
   
    
>*Remark*: a second option for filling has been added
>1. Drawn the egde of a closed shape with the paint brush mode.  
>2. Double click to activate the fill bucket.  
>3. Click inside the closed area to fill it.  
>4. Double click on the filled area to deactivate the fill bucket and reactivate the paint brush mode.
    

## Annotate your image *(use Panel 2)*
    
Manual annotation and correction on the segmented file is done using the layer controls of the *`annotations`* layer. Click on the layer to display them. /!\ You have to choose a structure to start annotating *(see 2.)*.
1. To modify an existing segmentation, you can directy open the segmented file with the <img src=""https://user-images.githubusercontent.com/49953723/193262702-df3b4fb8-63d0-4a1b-b1c9-8391cf8c3f22.PNG"" width=""130px""/> button. The file needs to have the same dimensions as the original image. 
    > /!\ Only .tiff, .tif, .nii and .nii.gz files are supported as segmented files.  
    
2. Choose a structure to annotate in the drop-down menu
    - *`Fetus`*: to annotate pregnancy image.
    - *`Shoulder`*: to annotate bones and muscles for shoulder surgery.
    - *`Shoulder Bones`*: to annotate only few bones for shoulder surgery.
    - *`Feta Challenge`*: to annotate fetal brain MRI with the same label than the FeTA Challenge (see ADD LIEN WEB).
    
> When selecting a structure, a new panel appears with a list of elements to annotate. Each element has its own label and color. Select one element in the list to automatically activate the paint brush mode with the corresponding color (color is updated in the *`label`* rectangle in the layer controls panel).
    
3. All actions can be undone with the <img src=""https://user-images.githubusercontent.com/49953723/193265848-8c458035-609a-433e-aa82-5d9588971425.PNG"" width=""30px""/> button or Ctrl-Z.
    
4. If you need to work on a specific slice of your 3D image, but also have to explore the volume to understand some complex structures, you can use the locking option to facilitate the annotation task.
    - <ins>To activate the functionality</ins>: 
        1. Go to the slice of interest.
        2. Click on the <img src=""https://user-images.githubusercontent.com/49953723/193262706-40f3dbca-5589-406d-81e8-e150ae8bfab6.PNG"" width=""30px""/> button => will change the button to <img src=""https://user-images.githubusercontent.com/49953723/193262703-2b2ea2dc-24fa-438b-a75c-3aa42b210f53.PNG"" width=""30px""/> and save the layer index.
        3. Scroll in the z-axis to explore the data (with the mouse wheel or the slider under the image).
        4. To go back to your slice of interest, click on the <img src=""https://user-images.githubusercontent.com/49953723/193262703-2b2ea2dc-24fa-438b-a75c-3aa42b210f53.PNG"" width=""30px""/> button.
    - <ins>To deactivate the functionality</ins> (or change the locked slice index): 
        1. Go to the locked slice.
        2. Click on the <img src=""https://user-images.githubusercontent.com/49953723/193262703-2b2ea2dc-24fa-438b-a75c-3aa42b210f53.PNG"" width=""30px""/> button  => change the button to <img src=""https://user-images.githubusercontent.com/49953723/193262706-40f3dbca-5589-406d-81e8-e150ae8bfab6.PNG"" width=""30px""/> and ""unlock"" the slice.


## Select slices of interest *(use Panel 3 -- only displayed for the Shoulder Bones category)*

This panel will only be displayed if the *`Shoulder Bones`* category is selected. A maxiumum of 10 slices can be selected in a 3D image and the corresponding z-indexes will be integrated in the metadata during the exportation of the segmentation file.
   
   > /!\ Metadata integration is available only for exported .tiff and .tif files and with the *`Unique`* save option. 

- <img src=""https://user-images.githubusercontent.com/49953723/201736039-4ed10553-4a4b-4d5e-9d61-826dc139e437.png"" width=""25px""/> : to add the currently displayed z-index in the drop-down menu.
- <img src=""https://user-images.githubusercontent.com/49953723/201736105-a9c45264-412a-453b-8475-5a9ab856b07d.png"" width=""25px""/> : to remove the currently displayed z-index from the drop-down menu.
- <img src=""https://user-images.githubusercontent.com/49953723/201736152-319d8559-dbfc-4e52-aeb3-e8e34445f67a.png"" width=""25px""/> : to go to the z-index selected in the drop-down menu. The icon will be checked when the currently displayed z-index matches the selected z-index in the drop-down menu.
- <img src=""https://user-images.githubusercontent.com/49953723/201733835-7bee453a-bc07-416f-8b95-aaf803683cac.png"" width=""100px""/> : a drop-down menu containing the list of selected z-indexes. Select a z-index from the list to work with it more easily.


## Export annotations *(use Panel 3 -- or 4 if the Shoulder Bones category is selected)*
    
1. Annotations can be exported as .tif, .tiff, .nii or .nii.gz file with the <img src=""https://user-images.githubusercontent.com/49953723/201735102-113f64b7-4da4-40ee-b058-9900268d270d.png"" width=""95px""/> button in one of the two following saving mode:
    - *`Unique`*: segmented data is exported as a unique 3D image with corresponding label ids (1-2-3-...). This file can be re-opened in the application.
    - *`Several`*: segmented data is exported as several binary 3D images (0 or 255), one for each label id.
2. <img src=""https://user-images.githubusercontent.com/49953723/193262699-95758bdb-ac40-439b-8959-d924781a2368.PNG"" width=""100px""/>: delete annotation data.
3. *`Automatic segmentation backup`*: if selected, the segmentation data will be automatically exported as a unique 3D image when the image slice is changed.
    > /!\ This process can slow down the display if the image is large.

# Hesperos: *OneShot Segmentation* mode
    
 The ***OneShot Segmentation*** mode of the Hesperos plugin is a 2D version of the VoxelLearning method implemented in DIVA (see [our Github](https://github.com/DecBayComp/VoxelLearning) and the latest article [GuÃ©rinot, C., Marcon, V., Godard, C., et al. (2022). New Approach to Accelerated Image Annotation by Leveraging Virtual Reality and Cloud Computing. _Frontiers in Bioinformatics_. doi:10.3389/fbinf.2021.777101](https://www.frontiersin.org/articles/10.3389/fbinf.2021.777101/full)).
    

The principle is to accelerate the segmentation without prior information. The procedure consists of:
1. A **rapid tagging** of few pixels in the image with two labels: one for the structure of interest (named positive tags), and one for the other structures (named negative tags).
2. A **training** of a simple random forest classifier with these tagged pixels and their features (mean, gaussian, ...).
3. An **inference** of all the pixels of the image to automatically segment the structure of interest. The output is a probability image (0-255) of belonging to a specific class.
4. Iterative corrections if needed.
    
<img src=""https://user-images.githubusercontent.com/49953723/193262714-8699cd59-3825-4d71-b27a-bbcad1e36d55.PNG"" width=""1000px""/>

    
## Import and adjust your image *(use Panel 1)*
    
Same panel as the *Manual Segmentation and Correction* mode *(see [panel 1 description](#import-and-adjust-your-image-use-panel-1))*.
   
    
## Annotate your image *(use Panel 2)*
    
Annotations and corrections on the segmented file is done using the layer controls of the *`annotations`* layer. Click on the layer to display them. Only two labels are available: *`Structure of interest`* and *`Other`*. 

The rapid manual tagging step of the one-shot learning method aims to learn and attribute different features to each label.
<img align=""right"" src=""https://user-images.githubusercontent.com/49953723/193262735-5dce56fb-8a2c-4aeb-9ee7-9727122d8089.PNG"" width=""220px""/> 
To achieve that, the user has to:
- with the label *`Structure of interest`*, tag few pixels of the structure of interest.
- with the label *`Other`*, tag the greatest diversity of uninteresting structures in the 3D image (avoid tagging too much pixels).

> see the exemple image with *`Structure of interest`* label in red and *`Other`* label in cyan.
    
1. To modify an existing segmentation, you can directy open the segmented file with the <img src=""https://user-images.githubusercontent.com/49953723/193266118-dfd241f6-8f0b-4cb9-94e7-5e74a3ce8b6e.PNG"" width=""130px""/> button. The file needs to have the same dimensions as the original image. 
    > /!\ Only .tiff, .tif, .nii and .nii.gz files are supported as segmented files. 
2. All actions can be undone with the <img src=""https://user-images.githubusercontent.com/49953723/193265848-8c458035-609a-433e-aa82-5d9588971425.PNG"" width=""30px""/> button or Ctrl-Z.

    
## Run automatic segmentation *(use Panel 3)*

From the previously tagged pixels, features are extracted and used to train a basic classifier : the Random Forest Classifier (RFC). When the training of the pixel classifier is done, it is applied to each pixel of the complete volume and outputs a probability to belong to the structure of interest.

To run training and inference, click on the <img src=""https://user-images.githubusercontent.com/49953723/193262731-719c226a-f7c5-4252-b2bb-fade4ab7f5b3.PNG"" width=""115px""/> button:
1. You will be asked to save a .pckl file which corresponds to the model.
2. A new status will appears under the *Panel 4* : *`Computing...`*. You must wait for the message to change to: *`Ready`* before doing anything in the application (otherwise the application may freeze or crash).
3. When the processing is done, two new layers will appear:
    - the *`probabilities`* layer which corresponds to the direct probability (between 0 and 1) of a pixel to belong to the structure of interest. This layer is disabled by default, to enable it click on its eye icon in the layer list.
    - the *`segmented probabilities`* layer which corresponds to a binary image obtained from the probability image normed and thresholded according to a value manually defined with the *`Probability threshold`* slider: <img src=""https://user-images.githubusercontent.com/49953723/193262730-6998c8a5-92f1-4ff1-bbf5-6972a373afd2.PNG"" width=""80px""/>.

>Remark: If the output is not perfect, you have two possibilities to improve the result:
>1. Add some tags with the paint brush to take in consideration unintersting structures or add information in critical areas of your structure of interest (such as in thin sections). Then, run the training and inference process again. /!\ This will overwrite all previous segmentation data.
>2. Export your segmentation data and re-open it with the *Manual Annotation and Correction* mode of Hesperos to manually erase or add annotations.
    
    
## Export annotations *(use Panel 4)*
    
1. Segmented probabilites can be exported as .tif, .tiff, .nii or .nii.gz file with the <img src=""https://user-images.githubusercontent.com/49953723/193262734-57159a97-2f46-4aba-b3bf-b55a35dfacbd.PNG"" width=""105px""/> button. The image is exported as a unique 3D binary image (value 0 and 255). This file can be re-opened in the application for correction.
2. Probabilities can be exported as .tif, .tiff, .nii or .nii.gz file with the <img src=""https://user-images.githubusercontent.com/49953723/193262733-26e37392-55b2-4c36-9287-b2f5d8d30e03.PNG"" width=""105px""/> button as a unique 3D image. The probabilities image is normed between 0 and 255.
3. <img src=""https://user-images.githubusercontent.com/49953723/193266056-9514b648-b3e0-43f5-901a-a45fa1390f00.PNG"" width=""100px""/>: delete annotation data.


# License

Distributed under the terms of the [BSD-3] license, **Hesperos** is a free and open source software.

    
[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[Anaconda]: https://www.anaconda.com/products/distribution#Downloads
[VoxelLearning]: https://github.com/DecBayComp/VoxelLearning
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: MacOS :: MacOS X', 'Operating System :: Microsoft :: Windows', 'License :: OSI Approved :: BSD License']","['Documentation, https://github.com/chgodard/hesperos/blob/main/README.md', 'Source Code, https://github.com/chgodard/hesperos']",,,hesperos.make_manual_segmentation_widget,,,,
58,iterseg,iterseg,iterseg,0.3.0,2023-12-01,2024-03-24,Abigail S McGovern & Juan Nunez-Iglesias,Abigail.McGovern1@monash.edu,BSD-3-Clause,https://github.com/abigailmcgovern/iterseg/issues,https://pypi.org/project/iterseg/,,https://github.com/abigailmcgovern/iterseg,napari plugin for iteratively improving unet-watershed segmentation,>=3.7,"['numpy', 'dask', 'torch', 'scikit-image', 'pandas', 'ome-zarr', 'zarr', 'matplotlib', 'napari', 'umetrix', 'numba', 'scipy', 'seaborn']","# iterseg

[![License](https://img.shields.io/pypi/l/iterseg.svg?color=green)](https://github.com/abigailmcgovern/iterseg/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/iterseg.svg?color=green)](https://pypi.org/project/iterseg)
[![Python Version](https://img.shields.io/pypi/pyversions/iterseg.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/iterseg)](https://napari-hub.org/plugins/iterseg)

napari plugin for iteratively improving a deep learning-based unet-watershed segmentation. 

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation
Install iterseg using pip. Assuming you have python and pip installed (e.g., via miniconda), you can install iterseg with only one line, typed into terminal (MacOS/Linux) or annaconda prompt (Windows). We recomend installing into a [new environment](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#) as some of our dependencies may not play well in the sandpit with certain versions of packages that may exist in a prexisting one. 

```bash
pip install iterseg napari
```


## Opening iterseg
Once `iterseg` is installed, you can access it through the napari viewer, which you can open from the command line (e.g., terminal (MacOS), anaconda prompt (Windows), git bash (Windows), etc.). To open napari simply type into the command line:
```bash
napari
```

## Loading data
Once you've opened napari, you can load image, labels, or shapes data through the `load_data` widget. to open the widget go to **plugins/iterseg/load_data** at the top left of your screen (MacOS) or viewer (Windows). 

 ![find the widgets](https://github.com/AbigailMcGovern/iterseg/blob/main/docs/images/load_data_find.png)

Once the widget appears at the right of the napari window, enter the name you want to give the data you are loading (this will appear in the layers pannel on the left of the window). Choose the type of layer you want to load (Image, Labels, or Shapes: segmentations are loaded as labels layer). You can load a folder of files or a zarr file using ""choose directory"" (zarrs are recognised as a folder of files) or you can load a tiff file using ""choose file"". You can tell the program what the scale of the 3D frames will be in (in the format (z, y, x)).

 ![load data](https://github.com/AbigailMcGovern/iterseg/blob/main/docs/images/load_data.png)

If you are using a single image file (3D, 4D, 5D - ctzyx) or a directory of 3D images (zyx), for ""data type"" choose ""individual frames"". If you are using a directory of 4D images (tzyx) choose ""image stacks"". If you are loading a file that is 4D or 5D and want to load time points (4D: tzyx, czyx) or channels (5D: ctzyx) as individual layers, select ""split channels"". 

## Segmenting images

You can segment data using the ""segment_data"" widget, which can be found at **plugins/iterseg/segment_data**. Once the widget appears, you can choose (1) the image layer you want to segment, (2) the folder into which to save the data, (3) the name you want to give the output file, (4) the type of segmentation to use, (5: optionally) the path to a neural network or configuration file, (6: optionally) a layer produced during training which contains metadata pointing to the trained neual network, (7) chunk size (the size of the neural network input), (8) margin (the margin of overlap between chunks). There is also an optional tickbox for debugging. If this is selected, errors will be easier to identify but you won't be able to interact with the viewer until the segmentation is done. 

 ![segmentation in progress](https://github.com/AbigailMcGovern/iterseg/blob/main/docs/images/segmenting_in_progress.png)

  ![segmented data](https://github.com/AbigailMcGovern/iterseg/blob/main/docs/images/segmented_data.png)

Segmented images can be used to more quickly generate ground truth for training, to assess segmentation quality, or for downstream analyses. 

### Segmentation algorithms
#### Affinity U-Net Watershed
The affinity U-net watershed is a feature based instance segmentation algorithm. A trained U-net predicts an edge affinity graph (basically boundaries in the x, y, and z axes), a map of centre points, and a mask that specifies which pixesl belong to objects. The feature map is fed to a modified watershed algorithm. The object centres are used to find seeds for the watershed and the affinity graph is used to find bounaries between objects. If you train a network using `iterseg`, you can select the outputted network file to segment. Otherwise, if one is not selected, a network we have trained to detect platelets will be used. This might be appropriate for small objects with high anisotropy. 

#### DoG Blob Segmentation
The DoG blob segmentation uses a difference of Gaussian (DoG) filter to find blob shaped objects. The DoG filter is used to find object seeds, a foreground mask, and is fed to a watershed to label objects. This algorithm cannot be trained but can be configured with a configuration file. An example configuration file can be seen in the example folder in this repository. Please see the Segmentation_config.md file for more details. 

## Generating ground truth
We include two tools that are useful for generating ground truth: ""save frames"" and ""ground truth from ROI"". 

### Save frames

The first tool is ""save frames"" can be found at **plugins/iterseg/save_frames**. It enables you to save frames of interest from a  series of segmented images or timeseries. 

 ![save frames](https://github.com/AbigailMcGovern/iterseg/blob/main/docs/images/save_frames.png)

### Ground truth from ROI

The ""ground truth from ROI"" tool can be found at **plugins/iterseg/ground_truth_from_ROI**. This tool enables you to take a small portion of corrected data and place it into a new frame, which can be used for training. The new data can be tiled in the new frame to overrepresent the data in the training data set. At present, the ROI must be selected by adding a shapes layer (added using the icon circled in orange), then adding a rectangle (blue circle).

 ![make an ROI](https://github.com/AbigailMcGovern/iterseg/blob/main/docs/images/generate_ROI.png)

 The rectangle will be used to select a region of the xy-plane. This can be seen in 3D below. 

 ![2D ROI in 3D](https://github.com/AbigailMcGovern/iterseg/blob/main/docs/images/roi_before_3D.png)

 At present, the entire z stack above and below the rectangle will be used to generate ground truth. We aim to incorporate 3D bounding boxes in the future. If multiple ROIs are selected, multiple new image frames will be made, each with a single ROI. When you generate ground truth from the shapes layer, you are able to select the desired shapes layer, image layer, and labels layer. Additionally, you can choose how many times you want to tile the ROI and how much padding to leave between. Tiling will start at the top right and progress right before moving to the next row. You will also be able to choose the save name and the folder into which to save the data. 

 ![ground truth from ROI](https://github.com/AbigailMcGovern/iterseg/blob/main/docs/images/gt_from_ROI.png)

## Training a network
`iterseg` includes a widget for training a u-net for the u-net affinity watershed. The training widget can be found at **plugins/iterseg/train_from_viewer**. Before training, you will need to load the images and ground truth you want to train from. The images and ground truth should each be a series of 3D frames that are stacked into a layer (we suggest loading from a series of frames in a directory). Once loaded, you are able to select a layer as the ground truth and a layer as the image data. You can tell the program what the scale of the output frames will be (in the format (z, y, x)). You can select what type of center prediction to use (we suggest centredness), what type of prediction to use for the mask, and what extent of affinities you want to train (if n = 1, the network will predict only the direct boundaries between objects in each axis, if greater than 1 the network will still predict the direct boundaires but will also predict where there is a new object n steps away - can be used as collateral learning to enhance training). Affinities extent is developmental. Please submit an issue for any problems. 

 ![train from viewer](https://github.com/AbigailMcGovern/iterseg/blob/main/docs/images/train_from_viewer.png)

For the U-net training, we allow you to choose the learning rate for the [ADAM optimiser](https://arxiv.org/abs/1412.6980) used to train the network. You can also choose between binary cross entropy loss ([BCELoss](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html)) and Dice loss ([DICELoss](https://arxiv.org/abs/1707.03237v3)). We have found in our data that BCE loss works better. You can also choose how many chunks of data are produced from each frame (n each) and how many epochs you want to train for the training will be done in n_each * n_frames batches with a minibatch size of 1. 

In the future we hope to expand this training widget to enable training other types of networks. Please get involved if you feel you can help with this. 

## Assessing segmentations
`iterseg` includes widgets for assessing and comparing segmentations. If you want to assess segmentation quality, you will need to load a ground truth and a segmentation to assess. Once loaded, you can select the ground truth and segmentation (model segmentation) using the widget found in **plugins/iterseg/assess_segmentation**. You can select which metrics you want to assess. The metrics we enable are:
- **Variation of information (VI):** VI is a two part measure. It includes a measure of undersegmentation and oversegmentation. Undersegmentation is a measure of the amount of new information you get from looking at the ground truth if you have already seen the segmentation. It can be interpreted as the proportion of objects that are incorrectly merged. Oversegmentation is a measure of the amount of new information you get from looking at the segmentation if you have already seen the ground truth. It can be interpreted as the proportion of objects that are incorrectly split. For more info please see the [scikit-image documentation](https://scikit-image.org/docs/stable/api/skimage.metrics.html#skimage.metrics.variation_of_information). 
- **Object count difference (OD):** Object count difference is simply the difference in number of objects between a ground truth and the assessed segmentation (card(ground truth) - card(segmentation)). 
- **Average precision (AP):** Average precision  Average precision is a combined measure of how accurate the model is at finding true positive (real) objects (we call this precision) and how many of ground truth real objects it found (this is called recall). The assessment of whether an object is TP, FP, and FN depends on the threashold of overlap between objects. Here we use the intersection of union (IoU), which is the proportion of overlap between the bounding boxes of ground truth and model segemented objects. AP is assessed using different IoU thresholds (from 0.35-0.95). The resultant data will be plotted as IoU by AP. 

  - Precision = TP / (TP + FP)Recall = TP / (TP + FN). 
  - Abbreviations: FN, false negative; TP, true positive; FP, false 


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""iterseg"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/abigailmcgovern/iterseg/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/abigailmcgovern/iterseg/issues', 'Documentation, https://github.com/abigailmcgovern/iterseg#README.md', 'Source Code, https://github.com/abigailmcgovern/iterseg', 'User Support, https://github.com/abigailmcgovern/iterseg/issues']",iterseg.load_ome_zarr,,iterseg.train_from_viewer,,['*.ome.zarr'],,
59,image-part-selecter,Image-Part-Selecter,Image-Part-Selecter,0.0.7,2022-01-12,2022-01-12,"Marc Boucsein, Robin Koch",,BSD-3,https://github.com/MBPhys/Image-Part-Selecter,https://pypi.org/project/Image-Part-Selecter/,,https://github.com/MBPhys/Image-Part-Selecter,A napari plugin in order to select parts of images,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy']","# Image-Part-Selecter

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/Image-Part-Selecter/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/Image-Part-Selecter.svg?color=green)](https://pypi.org/project/Image-Part-Selecter)
[![Python Version](https://img.shields.io/pypi/pyversions/Image-Part-Selecter.svg?color=green)](https://python.org)


A napari plugin in order to select parts of images

----------------------------------

## Installation

You can install `Image-Part-Selecter` via [pip]:

    pip install Image-Part-Selecter

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""Image-Part-Selecter"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/Image-Part-Selecter/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,Image-Part-Selecter.Selecter,,,,
60,in-silico-fate-mapping,in-silico-fate-mapping,In Silico Fate Mapping,0.1.3,2023-02-27,2025-02-14,Jordao Bragantini,jordao.bragantini@czbiohub.org,BSD-3-Clause,https://github.com/royerlab/in-silico-fate-mapping/issues,https://pypi.org/project/in-silico-fate-mapping/,,https://github.com/royerlab/in-silico-fate-mapping,TODO,>=3.8,"['numpy', 'pandas', 'scikit-learn', 'zarr', 'magicgui', 'qtpy', 'napari', 'click', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'pyqt5; extra == ""testing""']","# in silico fate mapping

[![License BSD-3](https://img.shields.io/pypi/l/in-silico-fate-mapping.svg?color=green)](https://github.com/royerlab/in-silico-fate-mapping/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/in-silico-fate-mapping.svg?color=green)](https://pypi.org/project/in-silico-fate-mapping)
[![Python Version](https://img.shields.io/pypi/pyversions/in-silico-fate-mapping.svg?color=green)](https://python.org)
[![tests](https://github.com/royerlab/in-silico-fate-mapping/workflows/tests/badge.svg)](https://github.com/royerlab/in-silico-fate-mapping/actions)
[![codecov](https://codecov.io/gh/royerlab/in-silico-fate-mapping/branch/main/graph/badge.svg)](https://codecov.io/gh/royerlab/in-silico-fate-mapping)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/in-silico-fate-mapping)](https://napari-hub.org/plugins/in-silico-fate-mapping)


Interactive in silico fate mapping from tracking data.

This napari plugin estimates the cell fates from tracking data by building a radial regression model per time point. The user can select an area of interest using a `Points` layer; the algorithm will advent the probed coordinates forward (or backward) in time, showing the estimated fate.

Video example below:

https://user-images.githubusercontent.com/21022743/216478216-89c1c35f-2ce4-44e8-adb8-9aeea75b5833.mp4

## Installation

We suggest you create a fresh conda environment to avoid conflicts with your existing package.
To do this, you need to:

    conda create -n fatemap python=3.11
    conda activate fatemap

And then, you can install `in-silico-fate-mapping` via [pip] and other additional useful packages:

    pip install napari-ome-zarr napari[all] in-silico-fate-mapping

To install the latest development version :

    pip install git+https://github.com/royerlab/in-silico-fate-mapping.git


## IO file format

This plugin does not depend on a specific file format, the only requirement is using a `Track` layer from napari.

Despite this, we ship a reader and writer interface. It supports `.csv` files with the following reader `track_id, t, (z), y, x`, `z` is optional.
Such that each tracklet has a unique `track_id` and it's composed of a sequence o time and spatial coordinates.

This is extremely similar to how napari store tracks, more information can be found [here](https://napari.org/stable/howtos/layers/tracks.html).

Divisions are not supported at the moment.

## Usage Example

### Minimal example

Minimal example using a track file following the convention described above.

```python3
import napari
import pandas as pd
from in_silico_fate_mapping.fate_mapping import FateMapping

tracks = pd.read_csv(""tracks.csv"")

fate_map = FateMapping(radius=5, n_samples=25, bind_to_existing=False, sigma=1)
fate_map.data = tracks[[""track_id"", ""t"", ""z"", ""y"", ""x""]]

source = tracks[tracks[""t""] == 0].sample(n=1)

tracks = fate_map(source[[""t"", ""z"", ""y"", ""x""]])

napari.view_tracks(tracks)
napari.run()
```

### Zebrahub example

Zebrafish embryo tail example. This example requires the package `napari-ome-zarr`.

```python3
import napari
import pandas as pd
from in_silico_fate_mapping import FateMappingWidget

image_path = ""http://public.czbiohub.org/royerlab/zebrahub/imaging/single-objective/ZSNS001_tail.ome.zarr""
tracks_path = ""http://public.czbiohub.org/royerlab/zebrahub/imaging/single-objective/ZSNS001_tail_tracks.csv""

viewer = napari.Viewer()
viewer.window.add_dock_widget(FateMappingWidget(viewer))

viewer.open(image_path, plugin=""napari-ome-zarr"")

tracks = pd.read_csv(tracks_path)
viewer.add_tracks(tracks[[""track_id"", ""t"", ""z"", ""y"", ""x""]])
viewer.add_points(name=""Markers"", ndim=4)

napari.run()
```

## Citing

If used please cite:

```
@article{lange2023zebrahub,
  title={Zebrahub-Multimodal Zebrafish Developmental Atlas Reveals the State Transition Dynamics of Late Vertebrate Pluripotent Axial Progenitors},
  author={Lange, Merlin and Granados, Alejandro and VijayKumar, Shruthi and Bragantini, Jordao and Ancheta, Sarah and Santhosh, Sreejith and Borja, Michael and Kobayashi, Hirofumi and McGeever, Erin and Solak, Ahmet Can and others},
  journal={bioRxiv},
  pages={2023--03},
  year={2023},
  publisher={Cold Spring Harbor Laboratory}
}
```

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/royerlab/in-silico-fate-mapping/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/royerlab/in-silico-fate-mapping/issues', 'Documentation, https://github.com/royerlab/in-silico-fate-mapping#README.md', 'Source Code, https://github.com/royerlab/in-silico-fate-mapping', 'User Support, https://github.com/royerlab/in-silico-fate-mapping/issues']",in-silico-fate-mapping.get_reader,in-silico-fate-mapping.write_tracks,in-silico-fate-mapping.make_fate_map,,['*.csv'],['.csv'],
61,koopa-viz,koopa-viz,Koopa,0.0.5,2022-09-29,2023-04-28,Bastian Eichenberger,bastian@eichenbergers.ch,MIT,https://github.com/bbquercus/koopa/issues,https://pypi.org/project/koopa-viz/,,https://github.com/bbquercus/koopa,Vizualization plugin for koopa image analysis,>=3.8,"['numpy', 'pandas', 'pyarrow', 'qtpy', 'tifffile', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","[![License MIT](https://img.shields.io/pypi/l/koopa-viz.svg?color=green)](https://github.com/bbquercus/koopa/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/koopa-viz.svg?color=green)](https://pypi.org/project/koopa-viz)
[![Python Version](https://img.shields.io/pypi/pyversions/koopa-viz.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/koopa-viz)](https://napari-hub.org/plugins/koopa-viz)

# koopa-viz

Vizualization plugin for koopa image analysis

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

More information can be found on the official [GitHub repo].

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[GitHub repo]: https://github.com/bbquercus/koopa
[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[file an issue]: https://github.com/bbquercus/koopa/issues
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/bbquercus/koopa/issues', 'Documentation, https://github.com/bbquercus/koopa#README.md', 'Source Code, https://github.com/bbquercus/koopa', 'User Support, https://github.com/bbquercus/koopa/issues']",,,koopa-viz.make_qwidget,,,,
62,lsfm-fusion-napari,LSFM-fusion-napari,Leonardo-Fuse,0.2.0,2024-12-13,2025-07-02,lennart kowitz,lennart.kowitz@isas.de,"Copyright (c) 2024, lennart ko...",https://github.com/peng-lab/lsfm_fusion_napari/issues,https://pypi.org/project/LSFM-fusion-napari/,,,A simple plugin to fuse microscopy images in napari,>=3.10,"['numpy', 'qtpy', 'bioio', 'leonardo_toolset', 'napari[all]', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# lsfm_fusion_napari

[![License BSD-3](https://img.shields.io/pypi/l/lsfm_fusion_napari.svg?color=green)](https://github.com/peng-lab/lsfm_fusion_napari/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/lsfm_fusion_napari.svg?color=green)](https://pypi.org/project/lsfm_fusion_napari)
[![Python Version](https://img.shields.io/pypi/pyversions/lsfm_fusion_napari.svg?color=green)](https://python.org)
[![tests](https://github.com/peng-lab/lsfm_fusion_napari/workflows/tests/badge.svg)](https://github.com/peng-lab/lsfm_fusion_napari/actions)
[![codecov](https://codecov.io/gh/peng-lab/lsfm_fusion_napari/branch/main/graph/badge.svg)](https://codecov.io/gh/peng-lab/lsfm_fusion_napari)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/lsfm_fusion_napari)](https://napari-hub.org/plugins/lsfm_fusion_napari)

A simple plugin to fuse LSFM images

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `lsfm_fusion_napari` via [pip]:

    pip install lsfm_fusion_napari



To install latest development version :

    pip install git+https://github.com/peng-lab/lsfm_fusion_napari.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""lsfm_fusion_napari"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/peng-lab/lsfm_fusion_napari/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/peng-lab/lsfm_fusion_napari/issues', 'Documentation, https://github.com/peng-lab/lsfm_fusion_napari#README.md', 'Source Code, https://github.com/peng-lab/lsfm_fusion_napari', 'User Support, https://github.com/peng-lab/lsfm_fusion_napari/issues']",,LSFM-fusion-napari.write_tiff,LSFM-fusion-napari.make_qwidget,,,['.tiff'],
63,lsfm-destripe-napari,LSFM-destripe-napari,Leonardo-DeStripe,0.3.0,2024-12-12,2025-07-02,lennart kowitz,lennart.kowitz@isas.de,"Copyright (c) 2024, Lennart Ko...",https://github.com/peng-lab/lsfm_destripe_napari/issues,https://pypi.org/project/LSFM-destripe-napari/,,,A simple plugin to destripe microscopy images in napari,>=3.10,"['numpy', 'qtpy', 'scikit-image', 'bioio', 'leonardo_toolset', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# lsfm_destripe_napari

[![License BSD-3](https://img.shields.io/pypi/l/lsfm_destripe_napari.svg?color=green)](https://github.com/peng-Lab/lsfm_destripe_napari/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/lsfm_destripe_napari.svg?color=green)](https://pypi.org/project/lsfm_destripe_napari)
[![Python Version](https://img.shields.io/pypi/pyversions/lsfm_destripe_napari.svg?color=green)](https://python.org)
[![tests](https://github.com/peng-Lab/lsfm_destripe_napari/workflows/tests/badge.svg)](https://github.com/peng-Lab/lsfm_destripe_napari/actions)
[![codecov](https://codecov.io/gh/peng-Lab/lsfm_destripe_napari/branch/main/graph/badge.svg)](https://codecov.io/gh/peng-Lab/lsfm_destripe_napari)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/lsfm_destripe_napari)](https://napari-hub.org/plugins/lsfm_destripe_napari)

A simple plugin to destripe microscopy images

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `lsfm_destripe_napari` via [pip]:

    pip install lsfm_destripe_napari



To install latest development version :

    pip install git+https://github.com/peng-Lab/lsfm_destripe_napari.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""lsfm_destripe_napari"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/peng-Lab/lsfm_destripe_napari/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/peng-lab/lsfm_destripe_napari/issues', 'Documentation, https://github.com/peng-lab/lsfm_destripe_napari#README.md', 'Source Code, https://github.com/peng-lab/lsfm_destripe_napari', 'User Support, https://github.com/peng-lab/lsfm_destripe_napari/issues']",LSFM_destripe_napari.get_reader,LSFM_destripe_napari.write_tiff,LSFM_destripe_napari.make_qwidget,,"['*.tif', '*.tiff']",['.tiff'],
64,label-creator,Label-Creator,Label-Creator,0.0.9,2022-01-12,2022-01-21,"Marc Boucsein, Robin Koch",,BSD-3,https://github.com/MBPhys/Label-Creator,https://pypi.org/project/Label-Creator/,,https://github.com/MBPhys/Label-Creator,A napari plugin for generation of Label-Layers according to selected image data shapes,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'dask']","# Label-Creator

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/Label-Creator/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/Label-Creator.svg?color=green)](https://pypi.org/project/Label-Creator)
[![Python Version](https://img.shields.io/pypi/pyversions/Label-Creator.svg?color=green)](https://python.org)


A napari plugin for generation of Label-Layers according to selected image data shapes.

----------------------------------

## Installation

You can install `Label-Creator` via [pip]:

    pip install Label-Creator

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""Label-Creator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/Label-Creator/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,Label-Creator.Creator,,,,
65,lasso-3d,lasso-3d,Lasso,0.0.1,2025-01-09,2025-01-09,Lorenz Lamm,lorenz.lamm@gmail.com,"Copyright (c) 2024, Lorenz Lam...",https://github.com/LorenzLamm/lasso-3d/issues,https://pypi.org/project/lasso-3d/,,,3D lasso tool to select large 3D areas,>=3.9,"['magicgui', 'membrain-seg', 'napari-mrcfile-reader', 'numpy', 'pyqt5', 'qtpy', 'scipy', 'scikit-image', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# lasso-3d

[![License BSD-3](https://img.shields.io/pypi/l/lasso-3d.svg?color=green)](https://github.com/LorenzLamm/lasso-3d/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/lasso-3d.svg?color=green)](https://pypi.org/project/lasso-3d)
[![Python Version](https://img.shields.io/pypi/pyversions/lasso-3d.svg?color=green)](https://python.org)
[![tests](https://github.com/LorenzLamm/lasso-3d/workflows/tests/badge.svg)](https://github.com/LorenzLamm/lasso-3d/actions)
[![codecov](https://codecov.io/gh/LorenzLamm/lasso-3d/branch/main/graph/badge.svg)](https://codecov.io/gh/LorenzLamm/lasso-3d)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/lasso-3d)](https://napari-hub.org/plugins/lasso-3d)

3D lasso tool to select large 3D areas

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


## Lasso tool

This repository allows to draw 3D lassos, generate masks from these, and then mask out the image.
For instructions on how to use the plugin, please refer to the [Usage instructions](./docs/Usage.md).

<div style=""text-align: center;"">
<img src=""https://github.com/user-attachments/assets/88851e09-6f10-4219-9b45-6f608c3e10b6"" alt=""lasso_gif"" width=""75%"" />
</div>

How it works: A polygon is drawn and a mask is generated via:
### Mask via rotation
Steps:
1. Rotate and project polygon to 2D and create a pixel mask
2. Create a 3D mask by stacking the pixel mask along z
3. Rotate 3D mask s.t. it is aligned with the original polygon

This performed more efficiently than the other methods:

### Mask via projection
Steps:
1. Project all points onto the hyperplane defined by the polygon
2. Rotate all points and the polygon s.t. they are in a horizontal plane and remove z component
3. Create a binary pixel mask of the polygon
4. Check which point projections are within the polygon mask
5. reshape mask to original tomogram size

### Mask via mesh voxelization
Steps:
1. Move polygon along its normal in both directions until end of tomogram shape --> front & back polygons
2. Define a surface by combining front & back polygons into a triangular mesh
3. Voxelize the surface, giving the outline of the cone
4. Fill holes to receive a filled cone

### Mask via attaching slices
Steps:
1. Rotate and project polygon to 2D and generate a pixel mask (2D)
2. Get indices of pixel mask and rotate them back to 3D space
3. Do that for many pixel mask, varying the z-component --> will be moved into tomogram along the polygon normal
4. Binary closing to get rid of holes from integer conversion

## Installation

pip install .
<!-- You can install `lasso-3d` via [pip]:

    pip install lasso-3d



To install latest development version :

    pip install git+https://github.com/LorenzLamm/lasso-3d.git -->


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""lasso-3d"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/LorenzLamm/lasso-3d/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/LorenzLamm/lasso-3d/issues', 'Documentation, https://github.com/LorenzLamm/lasso-3d#README.md', 'Source Code, https://github.com/LorenzLamm/lasso-3d', 'User Support, https://github.com/LorenzLamm/lasso-3d/issues']",,,lasso-3d.make_qwidget,,,,
66,layer-data-replace,Layer-Data-Replace,Layer-Data-Replace,0.0.5,2022-01-13,2022-01-13,"Marc Boucsein, Robin Koch",,BSD-3,https://github.com/MBPhys/Layer-Data-Replace,https://pypi.org/project/Layer-Data-Replace/,,https://github.com/MBPhys/Layer-Data-Replace,A napari plugin in order to replace parts of the data of a layer by another one,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'dask']","# Layer-Data-Replace

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/Layer-Data-Replace/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/Layer-Data-Replace.svg?color=green)](https://pypi.org/project/Layer-Data-Replace)
[![Python Version](https://img.shields.io/pypi/pyversions/Layer-Data-Replace.svg?color=green)](https://python.org)


A napari plugin in order to replace parts of the data of a layer by another one.

----------------------------------

## Installation

You can install `Layer-Data-Replace` via [pip]:

    pip install Layer-Data-Replace

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""Layer-Data-Replace"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/Layer-Data-Replace/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,Layer-Data-Replace.Replace,,,,
67,manini,manini,Manini,0.0.11,2023-11-04,2024-09-18,Herearii Metuarea,herearii.metuarea@gmail.com,BSD-3-Clause,https://github.com/hereariim/manini/issues,https://pypi.org/project/manini/,,https://github.com/hereariim/manini,"An user-friendly plugin that enables to annotate images from a pre-trained model (segmentation, classification, detection) given by an user.",>=3.8,"['numpy', 'magicgui', 'qtpy', 'napari', 'scikit-image', 'pandas', 'opencv-python-headless', 'tensorflow', 'PyQt5', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'pytest-xvfb; extra == ""testing""', 'numpy; extra == ""testing""', 'magicgui; extra == ""testing""', 'qtpy; extra == ""testing""', 'scikit-image; extra == ""testing""', 'pandas; extra == ""testing""', 'opencv-python-headless; extra == ""testing""', 'tensorflow; extra == ""testing""']","# manini

[![License BSD-3](https://img.shields.io/pypi/l/manini.svg?color=green)](https://github.com/hereariim/manini/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/manini.svg?color=green)](https://pypi.org/project/manini)
[![Python Version](https://img.shields.io/pypi/pyversions/manini.svg?color=green)](https://python.org)
[![tests](https://github.com/hereariim/manini/workflows/tests/badge.svg)](https://github.com/hereariim/manini/actions)
[![codecov](https://codecov.io/gh/hereariim/manini/branch/main/graph/badge.svg)](https://codecov.io/gh/hereariim/manini)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/manini)](https://napari-hub.org/plugins/manini)

Manini (**MA**chi**N**e **IN**ference  & Correct**I**on) is thought as a tool to boost the collaborative contribution of end-users to the assessment of deep learning model during their testing phase.
It is a user-Friendly plugin that enables to manually correct the result of an inference of deep learning model by an end-user. The plugin covers the following informational tasks: segmentation, classification and object detection.

## White paper

Herearii Metuarea, David Rousseau. [Toward more collaborative deep learning project management in plant phenotyping. ](https://essopenarchive.org/doi/full/10.22541/essoar.169876925.51005273/v1)

ESS Open Archive . October 31, 2023.
DOI: 10.22541/essoar.169876925.51005273/v1

----------------------------------

This plugin was written by Herearii Metuarea, PHENET engineer at LARIS (French laboratory located in Angers, France) in Imhorphen team (bioimaging research group lead) under the supervision by David Rousseau (Full professor). This plugin was designed in the context of the european project INVITE and PHENET.

![Screenshot from 2023-11-13 00-13-13](https://github.com/hereariim/manini/assets/93375163/c602e802-71b9-48ec-a9f2-cec3e4fa8220)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html!

-->

## Installation

You can install `manini` via [pip]:

    pip install manini

To install latest development version :

    pip install git+https://github.com/hereariim/manini.git


## Description

This plugin is a tool to perform image inference. The inference is open to the model for image segmentation (binary or multiclass), image classification and object detection. The dimension of image should be the same size with the input of model.
Currently compatible with tensorflow h5 models and torch torchscript models. In this format, the model file must contain all the elements of the model (architecture, weights, etc). Several ongoing developments, feel free to contact us if you have some request.

## Contact

Imhorphen team, bioimaging research group

42 rue George Morel, Angers, France

- Pr David Rousseau, david.rousseau@univ-angers.fr
- Herearii Metuarea, herearii.metuarea@univ-angers.fr 

### Scheme

![manini](https://github.com/hereariim/manini/assets/93375163/636a5e15-da0f-4387-8f37-b8ca89b4482b)

#### Input

The user must deposit two items (+1 optional item). 

- A compressed file (.zip) containing the images in RGB

```
.
âââ input.zip
    âââ im_1.JPG
    âââ im_2.JPG 
    âââ im_3.JPG
    ...
    âââ im_n.JPG
```

- A model file (.h5 , pt or torchscript) which is the segmentation model
- A text file (.txt) containing the names of the classes (optional)

The Ok button is used to validate the imported elements. The Run button is used to launch the segmentation.

#### Process

Correction is made by selecting some classes displayed in a widget :

- Paint panel for image segmentation

- Table for image classification

- Bounding box panel for object detection

#### Output

##### Segmentation + Detection

The plugin suggest 'Export' widget. When user select image and mask, the Save button allows you to obtain data in a compressed file. This file contains folders containing the images and their mask.

##### Classification

The Save button allows you to obtain a csv file. This file is the table on which the user had made his modifications.

#### Tutorial

Please, you can learn better if you watch a video tutorial below.

Presentation video of the context where the plugin was developped : [MANINI Napari Plugin Part 1](https://www.youtube.com/watch?v=ltbMIhApwRk)

Tutorial video to get started : [MANINI Napari Plugin Part 2](https://www.youtube.com/watch?v=HU21VQpvRAM)


## License

Distributed under the terms of the [BSD-3] license,
""manini"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hereariim/manini/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hereariim/manini/issues', 'Documentation, https://github.com/hereariim/manini#README.md', 'Source Code, https://github.com/hereariim/manini', 'User Support, https://github.com/hereariim/manini/issues']",,,manini.manini_widget,,,,
68,large-image-viewer,Large-Image-Viewer,Large Image Viewer,1.1.0,2023-08-08,2023-08-21,Nima Mojtahedi,nima.mojtahedi@wysscenter.ch,MIT,https://github.com/WyssCenter/Large-Image-Viewer/issues,https://pypi.org/project/Large-Image-Viewer/,,https://github.com/WyssCenter/Large-Image-Viewer,A simple plugin to view large images,>=3.8,"['numpy', 'dask[array]', 'dask-image', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# Large-Image-Viewer

[![License MIT](https://img.shields.io/pypi/l/Large-Image-Viewer.svg?color=green)](https://github.com/WyssCenter/Large-Image-Viewer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/Large-Image-Viewer.svg?color=green)](https://pypi.org/project/Large-Image-Viewer)
[![Python Version](https://img.shields.io/pypi/pyversions/Large-Image-Viewer.svg?color=green)](https://python.org)
[![tests](https://github.com/WyssCenter/Large-Image-Viewer/workflows/tests/badge.svg)](https://github.com/WyssCenter/Large-Image-Viewer/actions)
[![codecov](https://codecov.io/gh/WyssCenter/Large-Image-Viewer/branch/main/graph/badge.svg)](https://codecov.io/gh/WyssCenter/Large-Image-Viewer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/Large-Image-Viewer)](https://napari-hub.org/plugins/Large-Image-Viewer)

A simple plugin to view large images

----------------------------------

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `Large-Image-Viewer` via [pip]:

    pip install Large-Image-Viewer



To install latest development version :

    pip install git+https://github.com/WyssCenter/Large-Image-Viewer.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""Large-Image-Viewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/WyssCenter/Large-Image-Viewer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/




# Napari Large Image Viewer Plugin

The Napari Large Image Viewer Plugin is a powerful extension for the [napari](https://napari.org/) image visualization software. This plugin is designed to enable the visualization of large TIFF | TIF  files directly from disk, without the need to load the entire image into RAM. This is particularly useful when working with large datasets that exceed the available memory of your system.


## Features

- **Efficient Large Image Visualization**: The plugin allows you to open and visualize large files that are too big to fit into memory. It utilizes efficient memory-mapping techniques to display image data without fully loading it into RAM.

- **Interactive Exploration**: With the Napari Large Image Viewer Plugin, you can interactively explore large datasets using familiar zooming, panning, and slicing actions.

- **Quick Installation**: Installing the plugin is simple and straightforward, and it seamlessly integrates with the napari environment.

- **User-Friendly Interface**: The plugin provides an intuitive user interface that integrates seamlessly into the napari interface, making it easy to use for both beginners and experienced users.

## Installation

1. **Prerequisites**: Make sure you have [napari](https://napari.org/) installed on your system. If not, you can install it using:

   ```bash
   pip install napari
   ```

2. **Install the Plugin**: You can install the plugin directly from GitHub using pip:

   ```bash
   pip install git+https://github.com/WyssCenter/Large-Image-Viewer.git
   ```

3. **Launch napari**: Launch napari from your terminal:

   ```bash
   napari
   ```

4. **Activate the Plugin**: Once napari is launched, go to the `Plugins` menu and select `Large Image Viewer` to activate the plugin.

5. **Open Large TIFF | TIF  File**: With the plugin activated, you can now open a large file by dragging and dropping it to the napari viewer.

## Usage

1. Open a Large TIFF | TIF  File: Follow the installation instructions above to open a large TIFF | TIF  file using the plugin.

2. Explore the Image: Once the image is loaded, you can use the mouse to zoom in/out, pan, and interactively explore the data. You can also adjust the colormap, contrast, and other visualization settings from the napari interface.

3. Slicing and Navigation: Use the slicing and navigation tools in napari to navigate through different sections of the large file.

4. Save Visualizations: You can save snapshots or screenshots of the current visualization using the napari interface.

## Contributions

Contributions to the Napari Large Image Viewer Plugin are welcome! If you encounter issues or have suggestions for improvements, please open an issue on the [GitHub repository](https://github.com/WyssCenter/Large-Image-Viewer.git).

## License

This plugin is licensed under the [MIT License](LICENSE).

## Contact

For any inquiries or questions, you can reach out to the author at nima.mojtahedi@wysscenter.ch
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/WyssCenter/Large-Image-Viewer/issues', 'Documentation, https://github.com/WyssCenter/Large-Image-Viewer#README.md', 'Source Code, https://github.com/WyssCenter/Large-Image-Viewer', 'User Support, https://github.com/WyssCenter/Large-Image-Viewer/issues']",Large-Image-Viewer.get_reader,,,,"['*.tiff', '*.tif']",,
69,microscope-napari,microscope-napari,microscope-napari,0.0.5,2024-06-21,2024-10-15,Nanobiosensorics,horvath.robert@energia.mta.hu,BSD-3,https://github.com/Nanobiosensorics/microscope-napari,https://pypi.org/project/microscope-napari/,,https://github.com/Nanobiosensorics/microscope-napari,Nanobiosensorics microscopic napari plugin.,>=3.7,"['napari', 'napari-plugin-engine>=0.1.4', 'cellpose>0.6.3', 'imagecodecs', 'sphinx>=3.0; extra == ""docs""', 'sphinxcontrib-apidoc; extra == ""docs""', 'sphinx-rtd-theme; extra == ""docs""', 'sphinx-prompt; extra == ""docs""', 'sphinx-autodoc-typehints; extra == ""docs""', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# Installation

Napari needs to be set up on your machine in order to install this plugin.

If you do not have napari installed it can be done following [this article](https://napari.org/stable/tutorials/fundamentals/installation.html).

## Napari plugin manager (recommended)

Search for `microscope-napari` and click install. 
After completed napari needs to be restarted to activate the plugin.

![kÃ©p](https://github.com/Nanobiosensorics/microscope-napari/assets/65455148/5438235d-522e-458e-806d-89eaaa027be2)

## Pip package manager

You can install the plugin in the environment where napari is set up with command.
```
pip install microscope-napari
```
If you have a conda environment use anaconda prompt.

# Usage

You can access plugin's functionalities in the upper menu.

![kÃ©p](https://github.com/Nanobiosensorics/microscope-napari/assets/65455148/dace1014-6ac0-4797-b0b5-00a56cbc6b61)

## Cellpose

Images can be segmented with custom and built-in cellpose models.

![kÃ©p](https://github.com/Nanobiosensorics/microscope-napari/assets/65455148/82d300b9-c523-4b0a-bf44-0f3bfdadae07)

For further information make sure to check out [cellpose](https://github.com/MouseLand/cellpose) and [cellpose-napari](https://github.com/MouseLand/cellpose-napari) plugin.

## Cell counting

Cell counts in pictures can be obtained with cellpose models and average intensity regression models.
Any number of napari image layers can be selected to be evaluated.

### Cellpose model

Without enabling regression model counting the default used method is cellpose segmenting.
The lower settings are for cellpose only.

Cell masks can be output to verify the accuracy of results.

Our custom cellpose models can be accessed [there](https://drive.google.com/drive/folders/1-2SRK_AIlcSODebPoigKA7kbn5cb5s2o?usp=sharing).

![kÃ©p](https://github.com/user-attachments/assets/00d1336f-eeb4-4074-87a6-70d9cd866c07)

### Average intensity regression model

For these models we should enable the regression model counting feature.
The lower settings are irrelevant now, cell masks will not be output.
It is only used for counting cells in images.

Our regression models can be accessed [there](https://drive.google.com/drive/folders/1-5uAXN1W5lbE2Pw6Tsa1lR5BYqmPgdEP?usp=sharing).

![kÃ©p](https://github.com/user-attachments/assets/7d733347-ceed-4780-9bea-154c8faf3d4d)


","['Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License', 'Framework :: napari']",,,,microscope-napari.widgets.segmentation,microscope-napari.samples.rgb_3D,,,
70,midi-app-controller,midi-app-controller,midi-app-controller,0.1.1,2024-06-05,2024-11-13,,,Unavailable,https://github.com/midi-app-controller/midi-app-controller,https://pypi.org/project/midi-app-controller/,,,Control napari with a MIDI controller.,>=3.9,"['napari>=0.4.19', 'python-rtmidi>=1.5.8', 'pyyaml>=6.0.1', 'pydantic>=2.7.1', 'appdirs>=1.4.4', 'qtpy>=2.4.1', 'superqt>=0.6.5', 'midi-app-controller[testing]; extra == ""dev""', 'pre-commit>=3.7.0; extra == ""dev""', 'pytest>=8.2.0; extra == ""testing""', 'pytest-cov>=5.0.0; extra == ""testing""', 'pytest-qt>=4.0.2; extra == ""testing""', 'napari[all]; extra == ""testing""', 'flexparser!=0.4.0; extra == ""testing""']","# midi-app-controller

[![codecov](https://codecov.io/gh/midi-app-controller/midi-app-controller/graph/badge.svg?token=YALMD0PQ80)](https://codecov.io/gh/midi-app-controller/midi-app-controller)
[![Documentation Status](https://readthedocs.org/projects/midi-app-controller/badge/?version=latest)](https://midi-app-controller.readthedocs.io/en/latest/?badge=latest)
[![PyPI version](https://badge.fury.io/py/midi-app-controller.svg)](https://badge.fury.io/py/midi-app-controller)

midi-app-controller is an app, that allows user to control all applications using 'pyapp-kit/app-model' with a USB MIDI controller.

## Documentation

Documentation at https://midi-app-controller.readthedocs.io/en/latest/.

## Usage (napari)

MIDI App Controller is a package designed to integrate MIDI controllers with Python Qt apps using app-model. As of now, it is used most commonly with [napari](https://napari.org), a viewer for multi-dimensional images. We will show how to use MIDI App Controller with napari but getting started with other applications should look very similar.

### Installation

To install MIDI App Controller in your environment (where Python and napari are already installed), use this command:

```
pip install midi-app-controller
```

napari will automatically detect the package and install the plugin next time it starts.

To install the newest development version, clone the GitHub repo and [install it as a local package](#installing).

### Setup

Launch the plugin from the _Plugins_ menu.

![](docs/img/plugins-menu.png)

A panel will open to the side.

![](docs/img/midi-status.png)

#### Controller

If your MIDI controller is supported out of the box, you can simply select the appropriate model. If not, you will need to tell MIDI App Controller how to interact with this model of controller by creating a [controller schema](controllers.md).

Once you have selected the controller schema, you can select binds schema.

#### MIDI ports

If they haven't been selected automatically, select MIDI input and output ports that correspond to your physical controller.

### Start handling

After a controller and bindings are selected, you can click ""Start handling"". This will start a thread that listens to all input from the controller and invokes appropriate commands. You can close the panel with the settings, the thread will work in the background until you click ""Stop handling"".

### Edit binds

Click ""Edit binds"" to open dialog where you can configure bindings by choosing which physical buttons and knobs on your controller correspond to which commands in the application. Think of it like configuring keyboard shortcuts.

![](docs/img/edit-binds.png)

All configurations are simple YAML files which you can copy, share, or edit manually. You can click ""Reveal in explorer"" to see the exact location of the currently chosen config file. You shouldn't edit built-in presets stored in the package directory; when you edit a built-in preset in the graphical user interface, a copy will automatically be created.

After you save changes, if you have already started handling, you need to click ""Restart handling"" to start a new server with the changes applied.

## Usage without GUI

The library can be also controlled using the singleton of [`StateManager`](api_reference.md) class:
```python
from midi_app_controller.state.state_manager import get_state_manager

state = get_state_manager()
# Now the library can be controlled using `state`.
```

## Development

### Installing
```sh
python3 -m pip install -e .
```

### Testing
```sh
python3 -m pip install -e .[testing]
python3 -m pytest --cov .
```

### Testing docs
```sh
mkdocs serve -a localhost:8080
```

### Using pre-commit
```sh
python3 -m pip install -e .[dev]
pre-commit install
```
","['Framework :: napari', 'License :: OSI Approved :: BSD License', 'Programming Language :: Python']","['Source Code, https://github.com/midi-app-controller/midi-app-controller', 'Documentation, https://midi-app-controller.readthedocs.io']",,,midi-app-controller.midi_status,,,,
71,mikro-napari,mikro-napari,Mikro Napari,0.1.63,2022-10-11,2024-01-23,jhnnsrs,jhnnsrs@gmail.com,CC BY-NC 3.0,https://github.com/jhnnsrs/mikro-napari,https://pypi.org/project/mikro-napari/,,https://github.com/jhnnsrs/mikro-napari,A napari plugin to interact with and provide functionality for a connected arkitekt server,">=3.8,<=3.12","['arkitekt[fluss,mikro,reaktion,rekuest,unlok] (>=0.5.58)']","# mikro-napari

[![codecov](https://codecov.io/gh/jhnnsrs/mikro-napari/branch/master/graph/badge.svg?token=UGXEA2THBV)](https://codecov.io/gh/jhnnsrs/mikro-napari)
[![PyPI version](https://badge.fury.io/py/mikro-napari.svg)](https://pypi.org/project/mikro-napari/)
[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://pypi.org/project/mikro-napari/)
![Maintainer](https://img.shields.io/badge/maintainer-jhnnsrs-blue)
[![PyPI pyversions](https://img.shields.io/pypi/pyversions/mikro-napari.svg)](https://pypi.python.org/pypi/mikro-napari/)
[![PyPI status](https://img.shields.io/pypi/status/mikro-napari.svg)](https://pypi.python.org/pypi/mikro-napari/)

mikro napari enables napari on the mikro/arkitekt platform

# DEVELOPMENT

## Idea

This is a napari plugin, that provides a simple user interface to use napari with mikro you can view and annotate
data on the mikro platform (synchronised between all of your napari instances) and use napari within arkitekt workflows
(can be extended with other plugins)

## Install

Simple install this plugin via naparis plugin-manager and enable it. 
Login with your local mikro/arkitekt platform and start using it in workflows

You can also install mikro-napari directly in your enviroment 

```bash
pip install mikro-napari napari[pyqt5]
```


","['Framework :: napari', 'License :: Other/Proprietary License', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11']","['Repository, https://github.com/jhnnsrs/mikro-napari']",,,mikro-napari.arkitekt_widget,,,,
72,mitoclass,mitoclass,Mitoclass,0.1.1.post3,2025-07-30,2025-07-30,Jules Malard,Jules Malard <malardjules2@gmail.com>,"GNU GENERAL PUBLIC LICENSE
   ...",https://github.com/ImHorPhen/mitoclass/issues,https://pypi.org/project/mitoclass/,,,"Mitoclass is a napari plugin for classifying mitochondrial morphology from microscopy images: it allows preprocessing data, training or using a model, predicting classes (connected, fragmented, intermediate), visualizing overlays and 3D summaries, and managing a prediction history.",>=3.10,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'tifffile', 'tensorflow', 'pandas', 'scikit-learn', 'plotly', 'napari[all]', 'napari[all]; extra == ""all""', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari[qt]; extra == ""testing""']","
# <img src=""https://raw.githubusercontent.com/Jmlr2/MitoClassif/main/assets/mitoclass.png"" alt=""MitoClass logo"" height=""60"" style=""vertical-align: middle;""> Mitoclass

[![License: GPLâ¯v3](https://img.shields.io/badge/License-GPL%20v3-blue.svg)](LICENSE)  
[![PyPI](https://img.shields.io/pypi/v/mitoclass.svg)](https://pypi.org/project/mitoclass/)  
[![Pythonâ¯â¥â¯3.10](https://img.shields.io/badge/python-%3E%3D3.10-blue.svg)]()  
[![napariâhub](https://img.shields.io/badge/napari--hub-mitoclass-orange.svg)](https://github.com/napari/napari-hub)

<p align=""left"">
  <img src=""https://raw.githubusercontent.com/Jmlr2/MitoClassif/main/assets/imhorphen.png"" alt=""IMHORPHEN"" height=""70"" style=""margin: 0 20px;"">
  <img src=""https://raw.githubusercontent.com/Jmlr2/MitoClassif/main/assets/LARIS.png"" alt=""LARIS"" height=""70"" style=""margin: 0 20px;"">
  <img src=""https://raw.githubusercontent.com/Jmlr2/MitoClassif/main/assets/ua.png"" alt=""UniversitÃ© d'Angers"" height=""70"" style=""margin: 0 20px;"">
</p>

---

## 1&nbsp;&nbsp;Overview

**Mitoclass** is a *napari* plugin for the qualitative assessment of mitochondrial network morphology.  
Inference is **patchâwise**: each 2âD patchâobtained from a maximumâintensity projection of 3âD stacksâis classified as **connected**, **fragmented**, or **intermediate**.

---

## 2&nbsp;&nbsp;Key features

| Module | Description |
|--------|-------------|
| Patchâbased inference | Analyse an image folder *or* the active napari layer. |
| RGBA heatmaps | Overlay prediction maps as semiâtransparent layers in napari. |
| Global statistics | Compute the proportion of pixels assigned to each morphology and identify the dominant class. |
| 3âD graph | Interactive Plotly scatter plot of connected / fragmented / intermediate proportions per image. |

---

## 3&nbsp;&nbsp;Requirements

* **Python**Â â¥Â 3.10  
* **OS**Â : Windows, Linux or macOS  
* **Hardware**Â : CPU is sufficient; GPU (CUDAÂ 11+) is recommended for large datasets

---

## 4&nbsp;&nbsp;Installation

### 4.1Â Â PyPI

```bash
pip install mitoclass
```

### 4.2Â Â Reproducible *conda* environment

```bash
conda create -n mitoclass python=3.10
conda activate mitoclass

# (Optional) GPU acceleration
conda install -c conda-forge cudnn=8.9 cuda11.8 tensorflow

pip install mitoclass
```

*AppleÂ Silicon*: install `tensorflow-macos`.

### 4.3Â Â Preâtrained model

Download the model (`.h5`) from  
<https://github.com/Jmlr2/MitoClassif/releases>

---

## 5&nbsp;&nbsp;Usage

### 5.1Â Â Graphical interface

```bash
napari
```

1. Open **Plugins â Mitoclass**.  
2. Select the four required paths:  

   | Field | Purpose |
   |-------|---------|
   | **Input dir** | Folder of images to analyse (`.tif`, `.tiff`, `.stk`, `.png`). |
   | **Output dir** | Destination folder for CSV and graph files. |
   | **Heatmaps dir** | Folder where heatmaps (`*_map.tif`) will be written. |
   | **Model file** | Preâtrained Keras model (`.h5`). |

3. Click **Run inference**. A progress bar tracks the number of processed images.  
4. After completion:  
   * **Show heatmaps** adds the newly generated `*_map.tif` layers to napari.  
   * **Show 3D graph** opens `graph3d.html`, displaying the connected/fragmented/intermediate proportions.

*Tip*: Without an *Input dir* you may run **Infer active layer**; results are still saved to *Output dir* and *Heatmaps dir*.

### 5.2Â Â Output structure

| Folder | File(s) | Content |
|--------|---------|---------|
| **Output dir** | `predictions.csv` | Pixel proportion for each class (*connected*, *fragmented*, *intermediate*) and the dominant morphology, one line per image. |
|                | `graph3d.html` | Interactive 3âD Plotly graph of class proportions. |
| **Heatmaps dir** | `*_map.tif` | One RGBA heatmap per image, ready to overlay in napari. |

---

## 6&nbsp;&nbsp;Licence

This project is released under the **GNUÂ GPLâ¯v3** licence.  
See the [LICENSE](LICENSE) file for details.
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/ImHorPhen/mitoclass/issues', 'Documentation, https://github.com/ImHorPhen/mitoclass#README.md', 'Source Code, https://github.com/ImHorPhen/mitoclass', 'User Support, https://github.com/ImHorPhen/mitoclass/issues']",,,mitoclass.open_main_widget,,,,
73,mmv-h4tracks,mmv-h4tracks,MMV_H4Tracks,1.2.0,2024-03-22,2025-02-24,"Lennart Kowitz, Justin Sonneck","Lennart Kowitz <lennart.kowitz@isas.de>, Justin Sonneck <justin.sonneck@isas.de>","Copyright (c) 2022, lennart ko...",https://github.com/MMV-Lab/mmv_h4tracks/issues,https://pypi.org/project/mmv-h4tracks/,,,Human in the loop 2d cell migration analysis,>=3.9,"['numpy', 'npe2', 'napari-plugin-engine>=0.1.4', 'napari', 'zarr', 'cellpose==2.1.0', 'matplotlib', 'aicsimageio', 'scipy>=1.11.0']","# MMV_H4Tracks

[![License](https://img.shields.io/pypi/l/mmv_h4tracks.svg?color=green)](https://github.com/MMV-Lab/mmv_h4tracks/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/mmv_h4tracks.svg?color=green)](https://pypi.org/project/mmv_h4tracks)
[![Python Version](https://img.shields.io/pypi/pyversions/mmv_h4tracks.svg?color=green)](https://python.org)
[![tests](https://github.com/MMV-Lab/mmv_h4tracks/workflows/tests/badge.svg)](https://github.com/MMV-Lab/mmv_h4tracks/actions)
[![codecov](https://codecov.io/gh/MMV-Lab/mmv_h4tracks/branch/main/graph/badge.svg)](https://codecov.io/gh/MMV-Lab/mmv_h4tracks)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/mmv_h4tracks)](https://napari-hub.org/plugins/mmv_h4tracks)

MMV_H4Tracks (Human4Tracks) is a plugin to use with napari for segmenting and tracking cells, which additionally enables user-friendly manual curation of segmentation and tracks and various options for analyzing and evaluating the results.

We have tested MMV_H4Tracks intensively under Linux and Windows, for Mac there may be problems with parallel computing, which are on our roadmap and will be fixed in a future version.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!-- ## Usage
Load a zarr-file consisting of Image, Label and Tracks layer. -->

## Installation

You can install `mmv_h4tracks` via [pip]:

    pip install mmv_h4tracks


By default, CPU is used for segmentation computing. We did our best to optimize the CPU computing time, but still recommend GPU computing for better performance. For more detailed instructions on how to install GPU support look [here](https://github.com/MouseLand/cellpose#gpu-version-cuda-on-windows-or-linux).

<!-- 

To install latest development version :

    pip install git+https://github.com/MMV-Lab/mmv_h4tracks.git -->


## Documentation
This plugin was developed to analyze 2D cell migration. It includes the function of segmenting 2D videos using [Cellpose](https://github.com/MouseLand/cellpose) (both CPU and GPU implemented) and then tracking them using different automatic tracking algorithms, depending on the use case. For both segmentation and tracking, we have implemented user-friendly options for manual curation after automatic processing. In conjunction with napari's inherent functionalities, our plugin provides the capability to automatically track data and subsequently process the tracks in three different ways based on the reliability of the automated results. Firstly, any potentially existing incorrect tracks can be rectified in a user-friendly manner, thereby maximizing the evaluation of available information. Secondly, unreliable tracks can be selectively deleted, and thirdly, individual tracks can be manually or semi-automatically created for particularly challenging data, ensuring reliable results. In addition, the manually curated results can be compared with the automatic results in order to obtain a score for the quality of the automatic results. In essence, our tool aims to offer a valuable supplement to the existing fully automated tracking tools and a user-friendly means to analyze videos where fully automated tracking has been previously challenging.

Common metrics such as speed, cell size, velocity, etc... can then be extracted, plotted and exported from the tracks obtained in this way. Furthermore, the plugin incorporates a functionality to assess the automatic tracking outcomes using a [quality score](https://doi.org/10.1371/journal.pone.0144959). Since automated tracking may not be consistently 100% accurate, presenting a quality measure alongside scientific discoveries becomes essential. This supplementary metric offers researchers valuable insights into the dependability of the produced tracking results, fostering informed data interpretation and decision-making in the analysis of cell migration.

More detailed information and instructions on each topic can be found in the following sections.

### Get started

To load your raw data, you can simply drag & drop them into napari. Ensure that the 'Image' combobox displays the correct layer afterward, see example: 

![Comboboxes](https://github.com/MMV-Lab/mmv_h4tracks/blob/main/docs/figures/combobox.png?raw=true)

To load your own segmentation, you can do equivalent.

The ""save as"" button can be used to save the existing layers (raw, segmentation, tracks) in a single .zarr file, which can be loaded again later using the ""load"" button. The ""save"" button overwrites the loaded .zarr file.

The computation mode is used to set how many of the available CPU cores (40% or 80%) are to be used for computing the CPU segmentation and tracking and therefore has a direct impact on performance.


### Segmentation

For segmentation, we use the state of the art instance segmentation method Cellpose. We provide a model that we trained and has proven successful for our application ([see more information](https://doi.org/10.1038/s41467-023-43765-3)).


#### Automatic instance segmentation

To start automatic segmentation, a model must first be selected. Automatic segmentation can then be started via ""Run Segmentation"". The ""Preview"" option offers the possibility of segmenting the first 5 frames first in order to obtain an estimate of the expected results, as the computation - depending on the data and hardware - can be time-consuming.


##### Custom models

The plugin supports adding custom Cellpose models. To do so, simply click on ""Add custom Cellpose model"", enter a name to be displayed, select the model path and pass the required parameters. Click [here](https://cellpose.readthedocs.io/en/latest/api.html#id0) for more information about the parameters.


To train your own Cellpose model, [this](https://cellpose.readthedocs.io/en/latest/train.html) might be helpful.
In future versions, we plan to support fine-tuning of Cellpose models within the plugin. 


#### Manual curation

We provide different options to correct the automatic segmentation:

- `Remove cell` - Click on a cell to remove it. Be aware that removing a cell will split the track the cell belongs to, potentially affecting subsequent tracking.
- `Next free ID` - Loads the next free label ID, then a false negative cell can be manually annotated using the paint mode.
- `Select ID` - Click on a cell to load its ID, then this cell can be corrected manually using the paint mode.
- `Merge cell` - Click on 2 different fragments of the same cell to harmonize their ID. Note: This has no effect on the annotation itself.
- `Separate` - Click on a cell to assign a new ID to it.


### Tracking

The plugin supports both coordinate-based (LAP) and overlap-based tracking. Overlap-based tracking requires more computation, but can also be used in particularly complicated data for individual cells.
In our experience, coordinate-based tracking has proven itself in cases with reliable segmentation. Overlap-based tracking serves as a useful complement in cases where the segmentation is not of sufficient quality.

If necessary, overlap-based tracking can also be used for single cells. To do this, simply click on the cell after clicking the button.

#### Manual curation

To correct tracks, the plugin allows you to link or unlink them. For both options, first click on the corresponding button and then on the cell in the respective frame. The action must then be confirmed using the previously clicked button, which now displays ""confirm"".

To unlink, all you need to do is click on the cell in the first and last frame. So if the cell is tracked from frame 1-100 and the track between frames 1-10 is to be deleted, it is sufficient to click on the cell in frames 1 and 10. If the track is to be deleted between frames 40-60, it is sufficient to click in frames 40 and 60. In this scenario, the rest of the track is then split, i.e. once into a track from frame 1-40 and once into a track from frame 60-100.

In contrast, to link cells, the corresponding cell in each frame must be clicked. This must be done for all frames, so the track must be gapless.

#### Visualize & filter tracks

The displayed tracks can be filtered by entering specific track IDs. Click on the ""Show all tracks"" button to display all tracks again.

Individual tracks can be deleted using the delete function. Note: These are permanently deleted and cannot be restored without re-tracking. In addition, all displayed tracks can be deleted.

### Analysis

The plugin supports the calculation of various metrics, which can be divided into two categories: migration-based (such as speed, direction, ...) and shape-based (such as size, eccentricity, ...). Through the use of these metrics, a comprehensive understanding of the available data can be obtained.

All these metrics can be exported to a .csv file. In addition, the tracks can be filtered with a movement minimum (in pixels) and a minimum track length (in frames). Note: All existing tracks are exported in any case, but their results are presented separately.
 
The plugin offers the option of filtering the existing tracks according to the metrics. To do this, the corresponding metric can be selected in the plot area and a scatter plot of the data points will be generated using the plot button. Individual data points (/tracks) that are to be displayed can be circled with the mouse and all tracks that are not circled will be hidden. Note: No tracks are deleted in this process. Hiding tracks triggers the filter function in the tracking section, the ""Show all tracks"" button can display all tracks again as described above.


### Evaluation

To be aware of the accuracy of your automatic tracking and segmentation results, we have implemented an option to evaluate your automatic results. Evaluation is always carried out against the latest results of automatic segmentation and automatic tracking or previously created results loaded via the plugin's own load function. We may implement the option to evaluate external segmentations in the future, but for now you can use save and load as a workaround.

To evaluate results, at least two consecutive frames must be manually corrected first. The plugin saves the previously mentioned automatic or loaded results in the background, so no activation via button or similar is necessary before manual correction.

The range of frames to be evaluated can be set, for which the results for segmentation and tracking can be calculated independently of each other. 


#### Segmentation evaluation

In order to evaluate the segmentation results, a segmentation must first be loaded via the plugin's load function (drag & drop via napari is not sufficient) or computed within the plugin. This can then be corrected manually. For IoU, Dice and Average Precision 50 scores are then calculated for the frames specified by the user. These results are not exported automatically and must therefore be noted down by users themselves.

#### Tracking evaluation

As for the evaluation of the segmentation, tracking results loaded via the plugin or obtained within the plugin are required. At least 2 consecutive frames must be corrected manually so that a score can be calculated for the quality of the tracking results. More information can be found [here](https://doi.org/10.1371/journal.pone.0144959).


### Assistant

The assistant tab serves to facilitate the identification of errors within segmentation and tracking. It is divided into filters and segmentation adaptation.

Recommended filter strategy:
1. ""Show noteworthy tracks"" to discover tracks that are not close to the edge and emerge or disappear after the movie starts. Tracks must be gapless, and resulting hits can be indications of errors.
2. ""Show small cells"" to double-check if there is any noise/pollution segmented.
3. ""Show untracked cells"" to identify untracked segmented instances. 

The other filters can provide additional support.

The segmentation adaptation functions supplement useful functions with respect to segmentation. ""Align segmentation IDs"" adapts the label IDs with regard to the tracking IDs (the label IDs are then no longer arbitrary). ""Relabel cells"" ensures that the labels within a frame are unique, which helps eliminate accidental errors during manual segmentation correction.


## Hotkeys

Here's an overview of the hotkeys. All of them can also be found in the corresponding tooltips. 

- `W` - Load next free segmentation ID
- `G` - Overlap-based single cell tracking 
- `H` - Separate cells
- `Q` - Select cell ID 


## Development plan

We will continue to develop the plugin and implement new features in the future. Some of our plans in arbitrary order:

- Feedback (progress bar) for computationally intensive functions
- Support of lineages
- Support training custom Cellpose models within the plugin
- Model optimization to further optimize segmentation computation
- Support evaluation of external segmentations
- Improve robustness of Mac computing
- ...

If you have a feature request, please [file an issue].

## Resources

The following resources may be of interest:

- [napari](https://napari.org/)
- [Cellpose](https://doi.org/10.1038/s41592-020-01018-x)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""mmv_h4tracks"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/MMV-Lab/mmv_h4tracks/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 5 - Production/Stable', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Homepage, https://github.com/MMV-Lab/mmv_h4tracks', 'Bug Tracker, https://github.com/MMV-Lab/mmv_h4tracks/issues', 'Documentation, https://github.com/MMV-Lab/mmv_h4tracks#README.md', 'Source Code, https://github.com/MMV-Lab/mmv_h4tracks', 'User Support, https://github.com/MMV-Lab/mmv_h4tracks/issues']",,,mmv_h4tracks.make_qwidget,,,,
74,mmv-playground,MMV-playground,MMV-playground,0.1.4,2025-01-30,2025-01-31,Peter Lampen,lampen@isas.de,"Copyright (c) 2024, Peter Lamp...",https://github.com/MMV-Lab/MMV-playground/issues,https://pypi.org/project/MMV-playground/,,,Napari plugin for 2D microscopy segmentation,>=3.9,"['aicssegmentation', 'itk', 'napari', 'numpy', 'qtpy', 'scikit-image', 'scipy', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# MMV-playground

[![License BSD-3](https://img.shields.io/pypi/l/MMV-playground.svg?color=green)](https://github.com/MMV-Lab/MMV-playground/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/MMV-playground.svg?color=green)](https://pypi.org/project/MMV-playground)
[![Python Version](https://img.shields.io/pypi/pyversions/MMV-playground.svg?color=green)](https://python.org)
[![tests](https://github.com/MMV-Lab/MMV-playground/workflows/tests/badge.svg)](https://github.com/MMV-Lab/MMV-playground/actions)
[![codecov](https://codecov.io/gh/MMV-Lab/MMV-playground/branch/main/graph/badge.svg)](https://codecov.io/gh/MMV-Lab/MMV-playground)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/MMV-playground)](https://napari-hub.org/plugins/MMV-playground)

This plugin is aimed at researchers in biology and medicine who want to segment and analyze 2D microscopy images. It offers intuitive tools for common pre-processing and analysis tasks.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `MMV-playground` via [pip]:

    pip install MMV-playground

To install latest development version :

    pip install git+https://github.com/MMV-Lab/MMV-playground.git

## Documentation

This plugin for the graphics software Napari is designed to analyze two-dimensional microscopy images. Images should be provided in grayscale format, as colored images are not supported. The plugin includes seven core functions for image analysis:

1. Intensity normalization  
2. Smoothing  
3. Background correction  
4. Spot-shape filter  
5. Filament-shape filter  
6. Thresholding  
7. Topology-preserving thinning  

We provide an [introduction](https://github.com/MMV-Lab/MMV-playground/blob/main/docs/introduction.md) to explain the different functions of this plugin.

### **How to Start and Use the Plugin**

To start the plugin, open Napari, go to the ""Plugins"" menu, and select ""MMV-playground (MMV-playground)."" The MMV-playground interface will appear on the right-hand side of the Napari window, displaying seven buttons, each corresponding to one of the available functions. Clicking a button opens a dialog box where you can select an image, adjust the parameters for the chosen function, and execute it by pressing the ""Run"" button. Clicking the function button again collapses the dialog box.

### Screenshot

Here is a preview of the MMV-playground plugin in action:

![MMV-playground Plugin Screenshot](https://raw.githubusercontent.com/MMV-Lab/MMV-playground/main/docs/images/plugin_screenshot.png)

---

### **Intensity Normalization**

This function adjusts the image intensity to enhance contrast and improve uniformity. Two percentage values are required:  
- *Lower percentage (0â5%)*: Defines the darkest portion of the image to ignore as background noise, which is set to a fixed value.  
- *Upper percentage (95â100%)*: Specifies the brightest portion of the image to be capped, preventing overexposure.  

The plugin calculates the respective percentiles based on these values. Intensities below the lower percentile are clipped, and those above the upper percentile are also capped. Finally, all pixel intensities are rescaled to the range [0, 1].

---

### **Smoothing**

This function reduces noise to enhance image clarity. Two methods are available:  
- *Gaussian smoothing*  
- *Edge-preserving smoothing*: Retains edges (e.g., cell boundaries) while reducing noise.  

---

### **Background Correction**

This function removes uneven illumination or background artifacts using a filter. The key parameter is:  
- *Kernel size (1â100)*: Determines the spatial scale of the background correction. Smaller kernel sizes remove local noise, while larger sizes correct for broader illumination variations.  

The [scipy.ndimage.white_tophat] function is used to perform the correction, making this method effective for images with dark backgrounds.

---

### **Spot-Shape Filter**

This filter detects circular structures, such as cell nuclei or fluorescent spots. It is based on the [scipy.ndimage.gaussian_laplace] function and requires:  
- *Sigma (Ï)*: Controls the size of the spots to detect. Smaller sigma values target smaller spots, while larger values focus on larger structures.

---

### **Filament-Shape Filter**

This filter highlights elongated structures like cytoskeletal fibers or blood vessels. Using the [aicssegmentation.core.vessel.vesselness2D] function, the key parameter is:  
- *Sigma (Ï)*: Specifies the width of the detected filaments. Lower values detect thinner structures, while higher values identify thicker ones.

---

### **Thresholding**

This function segments the image into binary regions by separating the signal from the background. Users can choose one of four thresholding methods:  
- *Otsu*: Best for images with clear separation between background and signal intensities.  
- *Li*: Suitable for uniformly illuminated images.  
- *Triangle*: Effective for asymmetrical intensity distributions.  
- *Sauvola*: Ideal for images with uneven illumination.  

The result is a binary image where pixels above the threshold are set to 1 (signal), and all others are set to 0 (background).

---

### **Topology-Preserving Thinning**

This function extracts the skeleton of structures while maintaining their connectivity. Two parameters are required:  
- *Minimum thickness (0.5â5)*: Defines the smallest allowable thickness of structures before thinning.  
- *Thin (1â5)*: Controls the degree of thinning, reducing structure width while preserving topology (e.g., network connections).  

This is particularly useful for analyzing vascular or cellular networks.

---

### **What Is Missing?**

Currently, unit tests are not implemented, and internal documentation of the source code is still in progress.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""MMV-playground"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/MMV-Lab/MMV-playground/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

[scipy.ndimage.gaussian_filter]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter.html
[itk.GradientAnisotropicDiffusionImageFilter]: https://itk.org/Doxygen/html/classitk_1_1GradientAnisotropicDiffusionImageFilter.html
[scipy.ndimage.white_tophat]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.white_tophat.html
[scipy.ndimage.gaussian_laplace]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_laplace.html
[aicssegmentation.core.vessel.vesselness2D]: https://allencell.github.io/aics-segmentation/aicssegmentation.core.html
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/MMV-Lab/MMV-playground/issues', 'Documentation, https://github.com/MMV-Lab/MMV-playground#README.md', 'Source Code, https://github.com/MMV-Lab/MMV-playground', 'User Support, https://github.com/MMV-Lab/MMV-playground/issues']",,,MMV-playground.make_mmv_playground,,,,
75,mmv-h4cells,mmv-h4cells,Cell Analyzer,1.1.0,2024-10-24,2024-10-24,Lennart Kowitz,lennart.kowitz@isas.de,BSD-3-Clause,https://github.com/MMV-Lab/mmv_h4cells/issues,https://pypi.org/project/mmv-h4cells/,,https://github.com/MMV-Lab/mmv_h4cells,A simple plugin to help with analyzing cells in napari,>=3.8,"['numpy', 'qtpy', 'scikit-image', 'scipy', 'aicsimageio', 'opencv-python', 'pandas', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# MMV_H4Cells

[![License BSD-3](https://img.shields.io/pypi/l/mmv_h4cells.svg?color=green)](https://github.com/MMV-Lab/mmv_h4cells/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/mmv_h4cells.svg?color=green)](https://pypi.org/project/mmv_h4cells)
[![Python Version](https://img.shields.io/pypi/pyversions/mmv_h4cells.svg?color=green)](https://python.org)
[![tests](https://github.com/MMV-Lab/mmv_h4cells/workflows/tests/badge.svg)](https://github.com/MMV-Lab/mmv_h4cells/actions)
[![codecov](https://codecov.io/gh/MMV-Lab/mmv_h4cells/branch/main/graph/badge.svg)](https://codecov.io/gh/MMV-Lab/mmv_h4cells)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/mmv_h4cells)](https://napari-hub.org/plugins/mmv_h4cells)

A simple plugin to help with analyzing cells in napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `mmv_h4cells` via [pip]:

    pip install mmv_h4cells



To install latest development version :

    pip install git+https://github.com/MMV-Lab/mmv_h4cells.git


## Documentation

This plugin was developed for semi-automatic cell analysis to determine cell sizes of individual cells.

The core functionality includes the option to include or exclude individual (cell) instances in the evaluation via the include/exclude button. After a decision has been made, the plugin automatically centers on the next instance and a new decision can be made. In addition, you can include multiple cells at the same time using the ""select multiple"" function. It is also possible to analyze entire ROIs at once.
 
### Get started

To get started, an instance segmentation must be loaded. This can be done simply via drag & drop. A raw image of the original data is optional, but certainly helps when deciding whether to include or exclude.
Once the layers have been loaded into napari, the plugin can be started.
If you have only interrupted the evaluation and exported the previous results, you can now import them again (the segmentation must be reloaded into napari). 

### Analysis

The analysis can be started by clicking on the ""Start analysis"" button. The next instance ID to be evaluated is shown next to ""Start analysis at"". To change the region of interest to be evaluated, a different ID can be entered there and the plugin will center on this within the next 2 decisions. Decisions are made by clicking the Include/Exclude button. If an instance is not completely recognized correctly, you can use the paint function of napari to correct this manually and then include the instance as usual using the button. The undo function can be used to undo the last decision and the ""Draw own cell"" button allows you to add unrecognized cells manually. This must be done cell by cell and confirmed each time using the button. The plugin does not allow other existing instances to be painted over. If this happens by mistake, a warning is displayed, oberlapping pixels are highlighted and users can either cancel via the cancel button within the warning or close the warning and correct this manually. 

When an instance is included, the respective instance is written to a segmentation layer, which can be exported using the export function. In addition, the ID, the size and the centroid are exported as a .csv file. We also export a .zarr file, which makes it possible to re-import previously exported results, for example to pause the analysis. To enable a smooth re-import, the .csv and the .zarr file must have the same name stem, so please either do not rename the files or rename them in the same way. 

For a better overview, the included/excluded/remaining instances can be viewed using the buttons at the bottom.

#### Select multiple cells

We also support the option of including several cells at once. To do so, the respective IDs must be entered at the bottom next to ""Include"" and then selected using the ""Select multiple"". This works by entering comma-separated IDs, so *1,5,100,17* would be a valid entry.

#### Select ROI

Entire ROIs can also be analyzed. To do this, simply enter the corner pixels in the ""Range x"" and ""Range y"" fields. All cells > the threshold are included; if, for example, cells that lie exactly at the edge of the ROI and are partially cut off are to be excluded, a corresponding threshold must be set.

Note: Exported ROIs cannot be re-imported.

### Hotkeys

- `k` - Include
- `g` - Exclude
- `j` - Change visibility of all label layers for better inspection
- `h` - Undo

### Don'ts

This is a tool for analyzing cells. However, we do not catch every possible error and in order for the tool to run stable, it is important to avoid some operations:

- Do not create new layers during the analysis.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""mmv_h4cells"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/MMV-Lab/mmv_h4cells/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/MMV-Lab/mmv_h4cells/issues', 'Documentation, https://github.com/MMV-Lab/mmv_h4cells#README.md', 'Source Code, https://github.com/MMV-Lab/mmv_h4cells', 'User Support, https://github.com/MMV-Lab/mmv_h4cells/issues']",mmv_h4cells.get_reader,mmv_h4cells.write_multiple,mmv_h4cells.make_qwidget,,['*.npy'],,['.npy']
76,misic-napari,misic-napari,misic-napari,0.2.3,2021-12-07,2022-12-15,"S. Panigrahi & L. Espinosa, IAM, LCB",spanigrahi@imm.cnrs.fr,MIT,https://github.com/pswap/misic,https://pypi.org/project/misic-napari/,,https://github.com/pswap/misic,Segmentation of bacteria agnostic to imaging modality,>=3.6,"['tensorflow', 'termcolor']","# misic-napari

<!-- [![License](https://img.shields.io/pypi/l/misic-napari-plugin.svg?color=green)](https://github.com/pswap/misic-napari-plugin/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/misic-napari-plugin.svg?color=green)](https://pypi.org/project/misic-napari-plugin)
[![Python Version](https://img.shields.io/pypi/pyversions/misic-napari-plugin.svg?color=green)](https://python.org)
[![tests](https://github.com/pswap/misic-napari-plugin/workflows/tests/badge.svg)](https://github.com/pswap/misic-napari-plugin/actions)
[![codecov](https://codecov.io/gh/pswap/misic-napari-plugin/branch/master/graph/badge.svg)](https://codecov.io/gh/pswap/misic-napari-plugin) -->

----------------------------------

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

A napari plugin for [MiSiC](https://elifesciences.org/articles/65151). Segmentation of bacteria in dense colonies. 
The plugin provides acces to preprocessing of the image like scaling, gamma correction, sharpness and noise variance that can improve the segmentation of bacteria irrespective of the imaging modality.

## Install Napari
Install napari either the bundled app or through [pip/conda]
https://napari.org/#installation

## Installation

Install `misic-napari` through plugin manager in napari.

Or

You can install `misic-napari` via [pip] in the napari console:

    pip install misic-napari

## Tutorial
Note: 
The image should be in the format [n,row,col] or [row,col], i.e., a single image or a stack. Hyper-stacks are not supported yet. 

#### get_width


Creates a Shapes layer with name 'cell-width' where the cell width can be hand drawn using line drawing tools in the shapes layer. This need not be precise and can be adjusted later. Click `get_cell_width` to obtain the desired mean cell width. This will be used to scale the image accordingly before segmentation.
 
#### segment

This can be used to quickly set the parameters that can be later used to segment the whole stack.

```
use_roi
```
A square ROI of side 256 is created by default for quickly checking adjusting the segmentation parameters. The roi can be resized or moved in the `roi` shapes layer.

```
light_background
```
True; for phase-contrast images.

False; for bright-field and fluorescence images.

```
use_local_noise
```
If checked, this adds noise to image with local variance. In this case, a noise_var of around 0.1 works well. If unchecked, this adds noise with global variance of noise_var/100. Adding may help in removing false positives.

```
gaussian_laplace
```
Useful when segmenting fluorescence images. 

```
adjust_scale
```
Fine-tuning the scale around ([0.8,1.2]) the scale obtained from cell-width determined in `get_cell_width`.

```
noise_var
```
Amount of noise to be added to the image at the preprocessing step. This helps reduce the False Positives and, in many cases, to separate cells effectively. 
```
gamma
```
gamma correction 

```
sharpness_scale and sharpness_amount
```
Unsharp mask based sharpness with sigma = sharpness_scale and amount = sharpness_amount



### segment_stack
Segments the entire stack using the parameters that were obtained in ""segment"".


### save
The parameters can be saved in a json file. 

## License

Distributed under the terms of the [MIT] license,
""misic-napari"" is free and open source software

## Cite
```
@article {10.7554/eLife.65151,
article_type = {journal},
title = {Misic, a general deep learning-based method for the high-throughput cell segmentation of complex bacterial communities},
author = {Panigrahi, Swapnesh and Murat, DorothÃ©e and Le Gall, Antoine and Martineau, EugÃ©nie and Goldlust, Kelly and Fiche, Jean-Bernard and Rombouts, Sara and NÃ¶llmann, Marcelo and Espinosa, Leon and Mignot, TÃ¢m},
editor = {Xiao, Jie and Storz, Gisela and Hensel, Zach},
volume = 10,
year = 2021,
month = {sep},
pub_date = {2021-09-09},
pages = {e65151},
citation = {eLife 2021;10:e65151},
doi = {10.7554/eLife.65151},
url = {https://doi.org/10.7554/eLife.65151},
abstract = {Studies of bacterial communities, biofilms and microbiomes, are multiplying due to their impact on health and ecology. Live imaging of microbial communities requires new tools for the robust identification of bacterial cells in dense and often inter-species populations, sometimes over very large scales. Here, we developed MiSiC, a general deep-learning-based 2D segmentation method that automatically segments single bacteria in complex images of interacting bacterial communities with very little parameter adjustment, independent of the microscopy settings and imaging modality. Using a bacterial predator-prey interaction model, we demonstrate that MiSiC enables the analysis of interspecies interactions, resolving processes at subcellular scales and discriminating between species in millimeter size datasets. The simple implementation of MiSiC and the relatively low need in computing power make its use broadly accessible to fields interested in bacterial interactions and cell biology.},
keywords = {Deep learning, image analysis, microscopy, myxococcus xanthus, biofilms},
journal = {eLife},
issn = {2050-084X},
publisher = {eLife Sciences Publications, Ltd},
}
```
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']",,,,misic-napari.get_width,,,,
77,mmv-regionseg,mmv-regionseg,MMV-Region Segmentation,0.3.0,2025-03-21,2025-04-10,Peter Lampen,Peter Lampen <lampen@isas.de>,"Copyright (c) 2025, Peter Lamp...",https://github.com/MMV-Lab/mmv-regionseg/issues,https://pypi.org/project/mmv-regionseg/,,,Napari plugin for the segmentation of regions by flood,>=3.9,"['napari', 'numpy', 'qtpy', 'scikit-image', 'tifffile', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# mmv-regionseg

[![License BSD-3](https://img.shields.io/pypi/l/mmv-regionseg.svg?color=green)](https://github.com/MMV-Lab/mmv-regionseg/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/mmv-regionseg.svg?color=green)](https://pypi.org/project/mmv-regionseg)
[![Python Version](https://img.shields.io/pypi/pyversions/mmv-regionseg.svg?color=green)](https://python.org)
[![tests](https://github.com/MMV-Lab/mmv-regionseg/workflows/tests/badge.svg)](https://github.com/MMV-Lab/mmv-regionseg/actions)
[![codecov](https://codecov.io/gh/MMV-Lab/mmv-regionseg/branch/main/graph/badge.svg)](https://codecov.io/gh/MMV-Lab/mmv-regionseg)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/mmv-regionseg)](https://napari-hub.org/plugins/mmv-regionseg)

A Napari plugin for the segmentation of regions by flood_fill

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `mmv-regionseg` via [pip]:

    pip install mmv-regionseg



To install latest development version :

    pip install git+https://github.com/MMV-Lab/mmv-regionseg.git

## Documentation

**MMV-RegionSeg** is a Napari plugin designed to segment three-dimensional image data based on the gray value of a selected seed point. Neighboring voxels are assigned to the same class if their intensity is similar to that of the seed point or falls within a defined tolerance range.

---

### Launching the Plugin

1. Open Napari.
2. Go to the **Plugins** menu.
3. Select **MMV-RegionSeg** from the dropdown.

This opens a widget on the right-hand side of the Napari window, featuring several buttons, labels, and a slider.

### Screenshot

Here is a preview of the MMV-RegionSeg plugin in action:

![MMV-RegionSeg Plugin Screenshot](https://raw.githubusercontent.com/MMV-Lab/MMV-RegionSeg/main/docs/images/plugin_screenshot.png)

---

### Loading Image Data

Click the **""Read image""** button to load a 3D image in TIFF format. A standard OS file dialog will open. Once the image is selected, Napari will display it as an **image layer**.

---

### Adjusting Tolerance

A **slider** below the image loading button allows you to set the gray value tolerance (range: **1â50**):

- **Low tolerance**: May result in incomplete region filling.
- **High tolerance**: May include undesired regions.

> â ï¸ Choosing the right tolerance often requires trial and error.

---

### Selecting Seed Points

Click **""Select seed points""** to activate a new **points layer** in Napari. You can then define seed points by clicking directly in the viewer.

- Each seed point is visualized.
- Multiple seed points added in one step are treated as a single class.
- Use Napariâs **Layer Controls** to move or delete seed points.

---

### Segmentation Options

After placing seed points, you can choose between two segmentation methods:

#### Flood

Click **""Flood""** to perform segmentation using  
`skimage.segmentation.flood(...)`.  
This identifies neighboring voxels within the tolerance range and saves them to a new **label layer**.

You can repeat this process for other classes by selecting new seed points. Each class will have its own label layer.

#### Growth

Click **""Growth""** to visualize the segmentation **step by step**.  
This simulates the growth of a region, similar to a cell colony expanding in a Petri dish.

---

### Resetting for New Segmentation

After a label layer is created for a class, the **points layer is removed**, allowing you to define new seed points without affecting the existing segmentation results.

---

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""mmv-regionseg"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/MMV-Lab/mmv-regionseg/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Homepage, https://github.com/MMV-Lab/mmv-regionseg', 'Bug Tracker, https://github.com/MMV-Lab/mmv-regionseg/issues', 'Documentation, https://github.com/MMV-Lab/mmv-regionseg#README.md', 'Source Code, https://github.com/MMV-Lab/mmv-regionseg', 'User Support, https://github.com/MMV-Lab/mmv-regionseg/issues']",,,mmv-regionseg.make_mmv_regionseg,,,,
78,mobiofox,mobiofox,MOBIOFOX,0.1.0,2025-07-21,2025-07-21,Adrian Surojit MÃ¼ller,a.s.mueller@student.vu.nl,"Copyright (c) 2025, Adrian Sur...",https://github.com/OwlSurojit/mobiofox/issues,https://pypi.org/project/mobiofox/,,,A napari plugin implementing a pipeline for MOrphometric BIOgenicity analysis of purported microFOssil (P)XCT scans.,>=3.10,"['numpy', 'napari', 'magicgui', 'matplotlib', 'qtpy', 'scikit-image', 'scipy', 'pandas', 'scikit-learn', 'sip', 'meshio', 'seaborn', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# MOBIOFOX
[![License BSD-3](https://img.shields.io/pypi/l/mobiofox.svg?color=green)](https://github.com/OwlSurojit/mobiofox/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/mobiofox.svg?color=green)](https://pypi.org/project/mobiofox)
[![Python Version](https://img.shields.io/pypi/pyversions/mobiofox.svg?color=green)](https://python.org)
[![tests](https://github.com/OwlSurojit/mobiofox/workflows/tests/badge.svg)](https://github.com/OwlSurojit/mobiofox/actions)
[![codecov](https://codecov.io/gh/OwlSurojit/mobiofox/branch/main/graph/badge.svg)](https://codecov.io/gh/OwlSurojit/mobiofox)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/mobiofox)](https://napari-hub.org/plugins/mobiofox)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

A napari plugin implementing a pipeline for MOrphometric BIOgenicity analysis of purported microFOssil (P)XCT scans.
----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `mobiofox` via [pip]:

    pip install mobiofox



To install latest development version :

    pip install git+https://github.com/OwlSurojit/mobiofox.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""mobiofox"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/OwlSurojit/mobiofox/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 5 - Production/Stable', 'Framework :: napari', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/OwlSurojit/mobiofox/issues', 'Documentation, https://github.com/OwlSurojit/mobiofox#README.md', 'Source Code, https://github.com/OwlSurojit/mobiofox', 'User Support, https://github.com/OwlSurojit/mobiofox/issues']",mobiofox.read_scan,,mobiofox.morphometry_pipeline_widget,,,,
79,motile-plugin,motile-plugin,Motile,2.0.1,2024-05-23,2024-11-04,Caroline Malin-Mayor,Caroline Malin-Mayor <malinmayorc@janelia.hhmi.org>,BSD 3-Clause,https://github.com/funkelab/motile-napari-plugin/issues,https://pypi.org/project/motile-plugin/,,,Tracking with motile,>=3.10,"['napari[all]', 'numpy', 'magicgui', 'qtpy', 'scikit-image', 'motile >=0.3', 'motile-toolbox >=0.3.5', 'pydantic', 'tifffile[all]', 'fonticon-fontawesome6', 'pyqtgraph', 'lxml-html-clean', ""myst-parser ; extra == 'docs'"", ""sphinx ; extra == 'docs'"", ""sphinx-autoapi ; extra == 'docs'"", ""sphinx-rtd-theme ; extra == 'docs'"", ""sphinxcontrib-video ; extra == 'docs'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'""]","# Motile Napari Plugin

[![tests](https://github.com/funkelab/motile-napari-plugin/workflows/tests/badge.svg)](https://github.com/funkelab/motile-napari-plugin/actions)
[![codecov](https://codecov.io/gh/funkelab/motile-napari-plugin/branch/main/graph/badge.svg)](https://codecov.io/gh/funkelab/motile-napari-plugin)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/motile-plugin)](https://napari-hub.org/plugins/motile-plugin)

The full documentation of the plugin can be found [here](https://funkelab.github.io/motile_napari_plugin/).

A plugin for tracking with [motile](https://github.com/funkelab/motile) in napari.
Motile is a library that makes it easy to solve tracking problems using optimization
by framing the task as an Integer Linear Program (ILP).
See the motile [documentation](https://funkelab.github.io/motile)
for more details on the concepts and method.

----------------------------------

## Installation

This plugin depends on [motile](https://github.com/funkelab/motile), which in
turn depends on gurobi and ilpy. These dependencies must be installed with
conda before installing the plugin with pip.

    conda create -n motile-plugin python=3.10
    conda activate motile-plugin
    conda install -c conda-forge -c funkelab -c gurobi ilpy
    pip install motile-plugin

## Issues

If you encounter any problems, please
[file an issue](https://github.com/funkelab/motile-napari-plugin/issues)
along with a detailed description.
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/funkelab/motile-napari-plugin/issues', 'Documentation, https://funkelab.github.io/motile_napari_plugin/']",,,motile-plugin.main_app,motile-plugin.Fluo_N2DL_HeLa,,,
80,mousechd-napari,mousechd-napari,MouseCHD,0.0.4,2023-11-18,2025-01-16,Hoa Nguyen,ntthoa.uphcm@gmail.com,MIT,https://github.com/hnguyentt/mousechd-napari/issues,https://pypi.org/project/mousechd-napari/,,https://github.com/hnguyentt/mousechd-napari,A tool for heart segmentation and congenital heart defect detection in mice.,>=3.9,"['setuptools', 'packaging', 'mousechd', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""']","# Napari plugin for MouseCHD project

![](https://raw.githubusercontent.com/hnguyentt/mousechd-napari/master/assets/demo.gif)

*Tool for heart segmentation and congenital heart defect detection in mice.*

## Installation

There are several ways to run the plugin: (1) from bundle, (2) Containers (Docker or Apptainer), (3) from code

### From Bundle

(1) Install Napari by following this instruction https://napari.org/stable/tutorials/fundamentals/installation.html#install-as-a-bundled-app

(2) Install `mousechd-napari` plugin:
    * Run Napari
    * `Plugins` --> `Install/Uninstall Plugins ...` --> Search for `mousechd-napari` --> Click on `install`.

(3) Restart Napari to run the plugin


### Containers
#### Docker
##### Pull docker
```
sudo docker pull hoanguyen93/mousechd-napari
```

##### Run MouseCHD Plugin
* Run plugin with local resources:

    ```
    sudo docker run --gpus all -v <path/to/home/on/host>:<path/to/home/on/host> -it --rm -p 9876:9876 -p 6006:6006 hoanguyen93/mousechd-napari
    ```

    <details>
    <summary>Example:</summary>

    ```
    sudo docker run --gpus all -v /home/hnguyent:/home/hnguyent -it --rm -p 9876:9876 -p 6006:6006 hoanguyen93/mousechd-napari
    ```

    </details>

    Open this link on your browser: [http://localhost:9876/](http://localhost:9876/)

* Run plugin with server resources:

    * Follow [this instruction](./docs/server_setup.md) to setup running on server.
    * Copy ~/.ssh folder to a temporary location, for example in ~/Downloads: `cp -r ~/.ssh ~/Downloads/`
    * Change ownership for temporary ~/Downloads/.ssh folder: `chown -R root:root ~/Downloads/.ssh`
    * Run docker: `udo docker run --gpus all -v <path/to/home/on/host>:<path/to/home/on/host> -v /home/hnguyent/Downloads/.ssh:/root/.ssh:ro -it --rm -p 9876:9876 -p 6006:6006 hoanguyen93/mousechd-napari`
    * Open this link on your browser: [http://localhost:9876/](http://localhost:9876/)

##### Known issues
* The plugin in docker container can't display 3D view, please choose 2D view to display the sample and images.

#### Apptainer (Singularity)
If you want to run with server resource, follow [this instruction](./docs/server_setup.md) to setup running on server.

* Download Apptainer image `mousechd-napari.sif` from (Zenodo)[https://zenodo.org/records/14652180] or simply: `wget https://zenodo.org/records/14652180/files/mousechd-napari.sif`
* Run the plugin: 
```
apptainer exec \
    --nv \
    --bind /tmp/.X11-unix:/tmp/.X11-unix \
    --env DISPLAY=$DISPLAY \
    <path/to/mousechd-napari.sif> napari
```

### From code

```bash
conda create -n mousechd_napari python=3.9
conda activate mousechd_napari
pip install ""napari[all]""
pip install mousechd-napari
napari
```

## How to use
Please find details instruction in folder [docs](https://github.com/hnguyentt/mousechd-napari/tree/master/docs)
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hnguyentt/mousechd-napari/issues', 'Documentation, https://github.com/hnguyentt/mousechd-napari#README.md', 'Source Code, https://github.com/hnguyentt/mousechd-napari', 'User Support, https://github.com/hnguyentt/mousechd-napari/issues']",mousechd-napari.get_reader,,mousechd-napari.widget,mousechd-napari.sample,"['*.nrrd', '*.nii.gz', '*.dcm']",,
81,msi-explorer,MSI-Explorer,MSI-Explorer,1.0.1,2023-07-20,2024-03-13,lennart kowitz,lennart.kowitz@isas.de,BSD-3-Clause,https://github.com/MMV-Lab/MSI-Explorer/issues,https://pypi.org/project/MSI-Explorer/,,https://github.com/MMV-Lab/MSI-Explorer,a napari plug-in for biochemical annotation of mass spectrometry imaging data,>=3.8,"['numpy', 'qtpy', 'pyimzml', 'matplotlib', 'vaex', 'opencv-python', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# MSI-Explorer

[![License BSD-3](https://img.shields.io/pypi/l/MSI-Explorer.svg?color=green)](https://github.com/MMV-Lab/MSI-Explorer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/MSI-Explorer.svg?color=green)](https://pypi.org/project/MSI-Explorer)
[![Python Version](https://img.shields.io/pypi/pyversions/MSI-Explorer.svg?color=green)](https://python.org)
[![tests](https://github.com/MMV-Lab/MSI-Explorer/workflows/tests/badge.svg)](https://github.com/MMV-Lab/MSI-Explorer/actions)
[![codecov](https://codecov.io/gh/MMV-Lab/MSI-Explorer/branch/main/graph/badge.svg?token=LR8CU032ZD)](https://codecov.io/gh/MMV-Lab/MSI-Explorer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/MSI-Explorer)](https://napari-hub.org/plugins/MSI-Explorer)

# User Manual

The MSI-Explorer napari plugin is a powerful tool designed for targeted biochemical annotations in MSI data. This user manual provides a comprehensive guide on how to install, use, and explore the functionalities of the plugin within the napari platform. It covers data import, visualization, mean intensity calculation, region of interest (ROI) analysis, annotation with selected databases and pre-processing such as noise reduction and normalization. 

[MSI-Explorer] 
 
## Installation

Install napari by using this command.
   
     pip install ""napari[all]""

You can install `MSI-Explorer` via [pip]:
   
     pip install MSI-Explorer

## Usage
Start napari from the console with:

    napari

Navigate to `Plugins -> MSI-Explorer (MSI-Explorer)`
![Plugin](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/104718fa-227e-4117-9b52-f674a265d218)

### 1. Uploading and visualization of mass spectrometry imaging data
- Select imzml file using `Load imzML`.
- Metadata can be checked by `View Metadata`.
![Uploading MSI data_v1](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/a4783643-cf8e-4c68-af8e-03f264a48573)

![Visualization of MSI data_v1](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/5e37c375-d430-419a-9038-9980e858c482)


####
Upon uploading profile mode data, a pop-up appears prompting you to convert it to centroid mode.
Selecting `Yes` converts the data, while `No` keeps it in its original profile format.

![profile_centroid](https://github.com/nmmtsaw/MSI-Explorer-Manual/assets/127961719/5eecf5c2-e9b5-45da-a620-6dfaad058faf)

### 2. Calculating mean (average) intensity
- To calculate the mean spectrum, click on `Show true mean spectrum`.
- Clicking `Show image` will create an image view of the currently plotted data
- To export the plotted data as .csv file, click `Export spectrum data`.
- To save the spectrum plot as image, click `Export spectrum plot`.

![Calculating mean spectrum](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/2e921e00-75cf-4925-a9de-01d093277a06)

![Calculating mean spectrum_v1](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/19a713e3-a9ff-4e0c-be6b-545fb29991c6)


#### 2.1. Calculating mean (average) intensity of selected m/z value
To focus on a specific m/z value, zoom in on the spectrum plot. The figure will be as
shown as below.
![Calculating mean spectrum specific mz_v1](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/ba47080a-f439-4dc2-96b9-1f82ee5acbc3)

It is recommended to use `Multi` panel view.
The image can be displayed by `Show image` and the data can be exported as `.csv` file by using `Export spectrum data`.

### 3. Pre-processing
The pre-processing capabilities of MSI-Explorer enhance data quality and prepare MSI data for downstream analysis. Pre-processing steps involve: 


#### (a) Noise reduction
Users can choose their desired level of noise reduction (shown as a percentage) for their experiment. 

![Noise reduction_v1](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/9ce5e428-fe46-4f5f-a53f-7186c9f5ca8c)

#### (b) Normalization
The normalization methods that the user can apply are 
- Total ion current (TIC)
- Root mean square (RMS)
- Medium
- Reference peak (or internal standard)

![normalization_v1](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/972b30af-8425-46e4-bb54-705df52c725a)

#### (c) Hotspot removal
Hotspot removal can also be applied using a default threshold of 99.99%.
![hotspot removal_v1](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/c9d279fa-d03b-499d-857d-6953ba7ea253)


After pre-processing steps are chosen, click `Execute` and `Show true mean spectrum` to calculate the mean intensity.

The figure shows the spectrum and image of the TIC normalization with 3% noise reduction and hotspot removal for the 99.9% quantile.
![pre-processed_v1](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/d1068382-f6e2-4af9-9c5b-949fb87ac90c)


### 4. Database
To use the database search, click on `Select` and a pop-up window will appear. There,
select `Metabolite_database_ver2`, which is a built-in database, and click `Confirm`.

![Database](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/928fa260-196e-4034-8ddd-0944c751c77e)

The features of the database function are
1. Charge (neutral, positive or negative)
2. Adduct (based on the charge chosen)
3. Range of the m/z value for the image display
4. custom search with molecule name or m/z value

![Database_search](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/ca7d943a-1b6b-4cba-bf4d-934ee574cc61)

Users can customize the database with exact mass, molecule name, or molecular formula. The format should be as shown in the table and the headers are not needed in the database.

Exact mass | Molecule name | Molecula formula
------- | -------- | --------
176.0950 | Cotinine | C10H12N2O
174.1117 | Arginine | C6H14N4O2
244.0881 | Biotin | C10H16N2O3S

### 5. Region of interest (ROI) selection
- To select the ROI, click on `Select ROI for mean spectrum`. Adjust the brush size and label color. You can fill the area by using paint icon. 
- Then click on the `Calculate ROI mean spectrum`.
- You can export as `.csv` file by using `Export spectrum data`.
- If one m/z is needed, just zoom-in the spectrum plot window and export.
- Before selecting the second ROI, remove the first selected area by using eraser or label 0.

![ROI selection_v1](https://github.com/nmmtsaw/MSI-Explorer_User-Manual/assets/127961719/e79ca007-a0b5-4ba7-8cea-ae5e8ad6dd7d)


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""MSI-Explorer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/MMV-Lab/MSI-Explorerissues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/MMV-Lab/MSI-Explorer/issues', 'Documentation, https://github.com/MMV-Lab/MSI-Explorer#README.md', 'Source Code, https://github.com/MMV-Lab/MSI-Explorer', 'User Support, https://github.com/MMV-Lab/MSI-Explorer/issues']",msi_explorer.get_reader,MSI-Explorer.write_multiple,MSI-Explorer.make_qwidget,,['*.imzML'],,['.npy']
82,morphometrics,morphometrics,morphometrics,0.0.8,2022-03-17,2023-02-02,Kevin Yamauchi,kevin.yamauchi@gmail.com,BSD-3-Clause,https://github.com/kevinyamauchi/morphometrics/issues,https://pypi.org/project/morphometrics/,,https://github.com/kevinyamauchi/morphometrics,A plugin for quantifying shape and neighborhoods from images.,>=3.9,"['glasbey', 'imageio (!=2.11.0,!=2.22.1,>=2.5.0)', 'leidenalg', 'napari-skimage-regionprops', 'napari', 'numba', 'numpy', 'qtpy', 'pandas', 'pooch', 'pyclesperanto-prototype (>=0.8.0)', 'pymeshfix', 'pyqtgraph', 'scanpy', 'scikit-image (>0.19.0)', 'scikit-learn (>=0.24.2)', 'tqdm', 'trimesh[easy]', ""pre-commit ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'""]","# morphometrics

[![License](https://img.shields.io/pypi/l/morphometrics.svg?color=green)](https://github.com/morphometrics/morphometrics/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/morphometrics.svg?color=green)](https://pypi.org/project/morphometrics)
[![Python Version](https://img.shields.io/pypi/pyversions/morphometrics.svg?color=green)](https://python.org)
[![tests](https://github.com/morphometrics/morphometrics/workflows/tests/badge.svg)](https://github.com/morphometrics/morphometrics/actions)
[![codecov](https://codecov.io/gh/morphometrics/morphometrics/branch/main/graph/badge.svg)](https://codecov.io/gh/morphometrics/morphometrics)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/morphometrics)](https://napari-hub.org/plugins/morphometrics)

A plugin for quantifying shape and neighborhoods from images.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

### conda environment file
You can install `morphometrics` via our conda environment file. To do so, first install anaconda or miniconda on
your computer. Then, download the [`environment.yml file`](https://raw.githubusercontent.com/kevinyamauchi/morphometrics/master/environment.yml) (right click the link and ""Save as...""). In your terminal,
navigate to the directory you downloaded the `environment.yml` file to:

```bash
cd <path/to/downloaded/environment.yml>
```

Then create the `morphometrics` environment using

```bash
conda env create -f environment.yml
```

Once the environment has been created, you can activate it and use `morphometrics` as described below.

```bash
conda activate morphometrics
```

If you are on Mac OS or Linux install the following:

Mac:

```bash
conda install -c conda-forge ocl_icd_wrapper_apple
```

Linux:

```bash
conda install -c conda-forge ocl-icd-system
```


### Development installation

To install latest development version :

    pip install git+https://github.com/kevinyamauchi/morphometrics.git

## Example applications
<table border=""0"">
<tr><td>


<img src=""https://github.com/kevinyamauchi/morphometrics/raw/main/resources/surface_distance_measurement.gif""
width=""300""/>

</td><td>

[measure the distance between surfaces](https://github.com/kevinyamauchi/morphometrics/blob/main/examples/surface_distance_measurement.ipynb)

</td></tr><tr><td>

<img src=""https://github.com/kevinyamauchi/morphometrics/raw/main/resources/region_props_plugin.png""
width=""300""/>

</td><td>

[napari plugin for measuring properties of segmented objects (regionprops)](https://github.com/kevinyamauchi/morphometrics/blob/main/examples/measure_with_widget.py)

</td></tr><tr><td>

<img src=""https://github.com/kevinyamauchi/morphometrics/raw/main/resources/object_classification.png""
width=""300""/>

</td><td>

[object classification](https://github.com/kevinyamauchi/morphometrics/blob/main/examples/object_classification.ipynb)

</td></tr><tr><td>

<img src=""https://github.com/kevinyamauchi/morphometrics/raw/main/resources/mesh_object.png""
width=""300""/>

</td><td>

[mesh binary mask](https://github.com/kevinyamauchi/morphometrics/blob/main/examples/mesh_binary_mask.ipynb)


</td></tr></table>


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""morphometrics"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kevinyamauchi/morphometrics/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kevinyamauchi/morphometrics/issues', 'Documentation, https://github.com/kevinyamauchi/morphometrics#README.md', 'Source Code, https://github.com/kevinyamauchi/morphometrics', 'User Support, https://github.com/kevinyamauchi/morphometrics/issues']",,,morphometrics.QtMeasurementWidget,morphometrics.make_simple_labeled_cube,,,
83,morphometrics-engine,morphometrics-engine,morphometrics engine,0.0.1,2022-10-23,2022-10-23,Kevin Yamauchi,kevin.yamauchi@gmail.com,BSD-3-Clause,https://github.com/morphometrics/morphometrics-engine/issues,https://pypi.org/project/morphometrics-engine/,,https://github.com/morphometrics/morphometrics-engine,A morphometrics measurement engine.,>=3.8,"['napari', 'napari-skimage-regionprops', 'numpy', 'magicgui', 'pandas', 'qtpy', 'superqt', 'tqdm', 'toolz', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# morphometrics-engine

[![License BSD-3](https://img.shields.io/pypi/l/morphometrics-engine.svg?color=green)](https://github.com/morphometrics/morphometrics-engine/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/morphometrics-engine.svg?color=green)](https://pypi.org/project/morphometrics-engine)
[![Python Version](https://img.shields.io/pypi/pyversions/morphometrics-engine.svg?color=green)](https://python.org)
[![tests](https://github.com/morphometrics/morphometrics-engine/workflows/tests/badge.svg)](https://github.com/morphometrics/morphometrics-engine/actions)
[![codecov](https://codecov.io/gh/morphometrics/morphometrics-engine/branch/main/graph/badge.svg)](https://codecov.io/gh/morphometrics/morphometrics-engine)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/morphometrics-engine)](https://napari-hub.org/plugins/morphometrics-engine)

A morphometrics measurement engine.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `morphometrics-engine` via [pip]:

    pip install morphometrics-engine



To install latest development version :

    pip install git+https://github.com/morphometrics/morphometrics-engine.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""morphometrics-engine"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/morphometrics/morphometrics-engine/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/morphometrics/morphometrics-engine/issues', 'Documentation, https://github.com/morphometrics/morphometrics-engine#README.md', 'Source Code, https://github.com/morphometrics/morphometrics-engine', 'User Support, https://github.com/morphometrics/morphometrics-engine/issues']",,,morphometrics-engine.QtMeasurementWidget,,,,
84,multireg,multireg,Multiplex Registration,0.0.18,2023-06-09,2024-12-19,GaÃ«lle Letort,gaelle.letort@pasteur.fr,BSD-3-Clause,,https://pypi.org/project/multireg/,,https://gitlab.pasteur.fr/gletort/multireg,Registration of 3D multiplex images with one common chanel,>=3.8,"['numpy', 'napari<=0.4.18', 'magicgui', 'qtpy', 'pyqt5', 'tifffile', 'imaris-ims-file-reader', 'czifile', 'itk==5.3.0', 'itk-registration', 'itk-elastix']","# multireg

[![License BSD-3](https://img.shields.io/pypi/l/multireg.svg?color=green)](https://gitlab.pasteur.fr/gletort/multireg/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/multireg.svg?color=green)](https://pypi.org/project/multireg)
[![Python Version](https://img.shields.io/pypi/pyversions/multireg.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/multireg)](https://napari-hub.org/plugins/multireg)

Registration of 3D multiplex images with one common chanel, based on itk-elastix.

Napari plugin to align 3D stacks that have one common field of view in one chanel used to calculate the alignement. The plugin will apply the registration to all other chanels and output one final stack with all the aligned chanels.

The stacks **must have one common chanel** (typically cell junctions and nuclei) that is used to calculate the registration transformation. It can be rotated, translated, deformed, and with a wider field of view. 
Then the calculated transformation is applied to all the other chanels for each stack.

The final result is **one multi-chanel 3D stack**, with the first chanel being an average (or not) of the common chanel and each other chanel the registered chanels from the multiple stacks. The common chanel can be averaged between the different chanels, which improves its quality.

The plugin save and load files to a folder named `aligned` and created in the same directory as the source images.

Example of usage of this module is in the case of imaging the same cells with washing out or moving the sample in between. The corresponding cells will not be at the same position in the new stacks, and can even be deformed by the procedure. This plugin realign the images based on one common chanel on which the transformation is calculated. 

----------------------------------
## Installation

* You can install the plugin directly in `Napari` by going to `Plugins>Install/Uninstall plugins` and search for `multireg`

* Or you can install `multireg` via [pip]:

    pip install multireg


## Usage

You can launch `multireg` in napari by going to `Plugins>multireg: do multiplex registration`.

### Fixed image
It will open a prompt to ask you to select the reference (fixed) image, compared to which all other images will be aligned.
Then you have to choose the `reference chanel` that will be used in all the stacks to calculate the alignement. So this chanel should be common to all stacks.

![](https://gitlab.pasteur.fr/gletort/multireg/raw/main/imgs/plugin_step0.png)

#### Reference points
The first part of the registration relies on reference points manually selected, because the common field of view can be quite far from each other in the acquisition. So first a affine registration is applied to bring close the region of interest between the two stacks to match. 
<br> *Note that if your stacks did not move a lot then you could calculate the transformation without using the reference points. There's an option in the alignement calculation panel for this.*

![](https://gitlab.pasteur.fr/gletort/multireg/raw/main/imgs/plugin_fixedpoints.png)

You have to manually placed a few reference points (4-5 should be enough). Try to spread them in the image (in x,y and z) on landmarks to recognize them in other images. 

To add a new reference point, click on the ""plus"" sign in the left panel. To select one, click on the arrow icon (or press 3), then on the point. You can move the point in x and y. To move it in z, press `u` for up and `d` for down. 

When all points are placed, save them. The **points have to be saved** to be correctly loaded by the alignement calculation step.
Then click on `Fixed points done` to continue to the next step.


### Moving images
Then you can choose one of the images you want to align with the reference image. Its chanel that is common to the fixed image should be the same chanel, selected in the first step (the `reference chanel`). Select the file of the moving image to align by clicking on `select file`. This will open the new image and go to the step of placing the moving points in this image.

When you will have process all the moving images, you can click on `All done` to finish the plugin by creating the [resulting stack](#create-resulting-image).

![moving image step](https://gitlab.pasteur.fr/gletort/multireg/raw/main/imgs/plugin_movingimg.png)

#### Moving points
You now have to locate where the region of interest (the fixed image) is in your new image and find the landmarks referenced in the fixed image are in this new image. This allows the plugin to put together the region of interest in the two images in a first step, before to fine-tune the registration.

For each point placed in the fixed image, place the corresponding point in the moving image. By default, the moving points are placed close to the fixed points. 
* Each point must have the same label (number) as its corresponding fixed points to associate them correctly. You can change a point label by selecting it and putting the new value in `param` and clicking on `update`.


* When a point is selected, you can drag it to its desired location. To move it in the Z direction, you can press `u` to move it to the next Z (up direction) and `d` (down) to the previous Z. The viewed slice will also move, following the point new position, when you do so.

* You can click on `side_by_side_view` to see the two images (fixed and moving) with their placed points at the same time.

* You can click on `two_windows_view` to see the fixed image and points in a separate Napari window. This allows to have visualize separatly the fixed and moving images and points, and thus to see different z-slices or zoom for each image. The new window will be closed automatically by the plugin if you unselect this option or when you click on `Moving done`.

![two window](https://gitlab.pasteur.fr/gletort/multireg/raw/main/imgs/twowin.png)

When all the moving points have been correctly placed, click on `Save points` to save this positions and let it be usable by the alignement step. The points **have to be saved** in the point file to be correctly loaded in the alignement step.

### Alignement calculation
This step is the core of the plugin. The transformation necessary to change the moving image to match with the fixed image on the `reference chanel` is calculated based on [itk-elastix](https://pypi.org/project/itk-elastix/) python module. It is decomposed in two steps. 

1. First a global **affine registration** is performed, based on the correspondance between the reference and moving points (`do rigid` option). This allows to locate the fixed image postion within the moving image and apply a first **shearing, scaling, rotation and translation** to super-impose the region of interest. 

2. The second step fine-tunes the registration. It doesn't use the reference points (except if rigid transformation was not selected) anymore but calculate the matching based on the images local intensities. **Non-rigid transformation** based on B-spline is performed at this step, thus allowing to compensate for **local deformations** in the moving image (`do bspline` option).

The option `use reference points` determines if the previously placed reference points should be used or if the registration is only based on intensities matching. It's possible to use only the intensities if the two images are not so far away from each other. The reference points will be used only in the first pass (either rigid or bspline) when both are selected. If only one is selected, the points will be used on the selected transformation.

The option `strong_weight_points` allows to give more importance to reference points than to intensities matching when calculating the registration. The weights will be 0.2 for the intensity metric and 0.8 for points metric. Note that if both rigid and bspline transformations are selected, the second transformation (bspline) do not use the points.

![apply alignement step](https://gitlab.pasteur.fr/gletort/multireg/raw/main/imgs/interm.png)


You can click on `show advanced parameters` to tune the parameters of the non rigid transformation. After calculating the registration, the plugin will add a new layer, which is the moving image after alignement, so you can check the sucess of the regristration. `show intermediate_layer` will also add the moving image aligned after the first step only (the points matching with affine registration).

![calculate alignement step](https://gitlab.pasteur.fr/gletort/multireg/raw/main/imgs/align.png)


### Apply alignement
Once the calculated registration is satisfying, you can apply it to all the chanels of your moving image, or only to a few. By default, all chanels are selected in the `Apply alignement` panel, but you can unselect the chanels that you don't want to align in the parameter `align chanels`. 
When you click on `Align images`, the plugin will apply the transformation on the selected chanels of the moving image and save each of them in the `aligned` folder as individual `.tif` files. 

![apply alignement step](https://gitlab.pasteur.fr/gletort/multireg/raw/main/imgs/goalign.png)

### Create resulting image
This step allows to save a single 3D multi-chanels stack with all the aligned chanels. 

The common chanel present in all the images can be averaged together after alignement to obtain a much less noisy image. By default, the aligned `reference chanel` of all the images are averaged together to create the final image first chanel. However, it is possible to unselect some images in the first panel (`average chanels` parameter) if you do not wish to use all the images or do an average.

![create result image](https://gitlab.pasteur.fr/gletort/multireg/raw/main/imgs/create.png)

Then each aligned chanel of all the images that were not the reference chanel are stacked together in the final resulting image. Here also, if you don't want to keep all the other chanels in the resulting image, you can unselect the one that you don't want stacked, in the `add_chanels` parameter. 
All the aligned chanels have been previously saved in the `aligned` folder. If `delete_files` is checked (default) all these interemediate files will be deleted and only the final resulting stack will be saved in that folder.

You will end-up with a final 3D multi-chanels stack, saved as a `.tif` file in the `aligned` folder, with the same name as your fixed image. It can have a lot of chanels if you stacked together multiple images.
In napari, you can separate the chanels by right clicking on the layer and select `Split stack`. 
In Fiji, you can make the stack as a composite to see the chanels with different colors.

![final image](https://gitlab.pasteur.fr/gletort/multireg/raw/main/imgs/reslayer.png)

## License
Distributed under the terms of the [BSD-3] license,
""multireg"" is free and open source software

## Plugin initialization
This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://gitlab.pasteur.fr/gletort/multireg/issues', 'Documentation, https://gitlab.pasteur.fr/gletort/multireg#README.md', 'Source Code, https://gitlab.pasteur.fr/gletort/multireg']",,,multireg.registration,,,,
85,napam,napam,NaPaM,0.1.4,2024-04-26,2025-02-10,Jaison John,jjohn@stjude.org,BSD-3-Clause,https://github.com/JB4Jaison/napam,https://pypi.org/project/napam/,,,A plugin that allows you to run macros (i.e. python scripts) on the images for any kind of image processing.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'matplotlib', 'QScintilla', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'qtpy; extra == ""testing""', 'QScintilla; extra == ""testing""']","# napam

[![License BSD-3](https://img.shields.io/pypi/l/napam.svg?color=green)](https://github.com/JB4Jaison/napam/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napam.svg?color=green)](https://pypi.org/project/napam)
[![Python Version](https://img.shields.io/pypi/pyversions/napam.svg?color=green)](https://python.org)
[![codecov](https://codecov.io/gh/JB4Jaison/NaPaM/graph/badge.svg?token=5NEDOJB5V1)](https://codecov.io/gh/JB4Jaison/NaPaM)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napam)](https://napari-hub.org/plugins/napam)

A plugin that allows you to run macros on the images for any kind of image processing.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napam` via [pip]:

    pip install napam

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

# Demo
This is to demonstrate how the plugin can be used to run any script on an image.
<video src=""https://github.com/user-attachments/assets/24bebe67-8186-4189-8679-2148cbe26859"" width=""352"" height=""720""></video>

## License

Distributed under the terms of the [BSD-3] license,
""napam"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/JB4Jaison/napam/issues', 'Source Code, https://github.com/JB4Jaison/napam']",,,napam.make_macro_widget,,,,
86,movement,movement,movement,0.8.2,2025-03-10,2025-07-22,"Nikoloz Sirmpilatze, Chang Huan Lo, SofÃ­a MiÃ±ano","Nikoloz Sirmpilatze <niko.sirbiladze@gmail.com>, Chang Huan Lo <changhuan.lo@ucl.ac.uk>, SofÃ­a MiÃ±ano <s.minano@ucl.ac.uk>",BSD-3-Clause,https://github.com/neuroinformatics-unit/movement,https://pypi.org/project/movement/,,,Analysis of body movement,>=3.11.0,"['numpy<2.3.0,>=2.0.0', 'pandas', 'h5py', 'attrs', 'pooch', 'tqdm', 'shapely', 'sleap-io', 'xarray[accel,io,viz]', 'PyYAML', 'napari-video', 'pyvideoreader>=0.5.3', 'qt-niu', 'loguru', 'pynwb', 'ndx-pose>=0.2.1', 'napari[all]>=0.6.0; extra == ""napari""', 'pytest; extra == ""dev""', 'pytest-cov; extra == ""dev""', 'pytest-mock; extra == ""dev""', 'coverage; extra == ""dev""', 'tox; extra == ""dev""', 'mypy; extra == ""dev""', 'pre-commit; extra == ""dev""', 'ruff; extra == ""dev""', 'codespell; extra == ""dev""', 'setuptools_scm; extra == ""dev""', 'pandas-stubs; extra == ""dev""', 'types-attrs; extra == ""dev""', 'check-manifest; extra == ""dev""', 'types-PyYAML; extra == ""dev""', 'types-requests; extra == ""dev""', 'pytest-qt; extra == ""dev""', 'movement[napari]; extra == ""dev""']","[![Python Version](https://img.shields.io/pypi/pyversions/movement.svg)](https://pypi.org/project/movement)
[![PyPI Version](https://img.shields.io/pypi/v/movement.svg)](https://pypi.org/project/movement)
[![Conda Forge Version](https://anaconda.org/conda-forge/movement/badges/version.svg)](https://anaconda.org/conda-forge/movement)
[![License](https://img.shields.io/badge/License-BSD_3--Clause-orange.svg)](https://opensource.org/licenses/BSD-3-Clause)
[![CI](https://img.shields.io/github/actions/workflow/status/neuroinformatics-unit/movement/test_and_deploy.yml?label=CI)](https://github.com/neuroinformatics-unit/movement/actions)
[![codecov](https://codecov.io/gh/neuroinformatics-unit/movement/branch/main/graph/badge.svg?token=P8CCH3TI8K)](https://codecov.io/gh/neuroinformatics-unit/movement)
[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/neuroinformatics-unit/movement/gh-pages?filepath=notebooks/examples)
[![Code style: Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/format.json)](https://github.com/astral-sh/ruff)
[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)
[![project chat](https://img.shields.io/badge/zulip-join_chat-brightgreen.svg)](https://neuroinformatics.zulipchat.com/#narrow/stream/406001-Movement/topic/Welcome!)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.12755724.svg)](https://zenodo.org/doi/10.5281/zenodo.12755724)

# movement

A Python toolbox for analysing animal body movements across space and time.


![](docs/source/_static/movement_overview.png)

## Quick install

Create and activate a conda environment with movement installed (including the GUI):
```bash
conda create -n movement-env -c conda-forge movement napari pyqt
conda activate movement-env
```


> [!Note]
> Read the [documentation](https://movement.neuroinformatics.dev) for more information, including [full installation instructions](https://movement.neuroinformatics.dev/user_guide/installation.html) and [examples](https://movement.neuroinformatics.dev/examples/index.html).

## Overview

Deep learning methods for motion tracking have revolutionised a range of
scientific disciplines, from neuroscience and biomechanics, to conservation
and ethology. Tools such as
[DeepLabCut](https://www.mackenziemathislab.org/deeplabcut) and
[SLEAP](https://sleap.ai/) now allow researchers to track animal movements
in videos with remarkable accuracy, without requiring physical markers.
However, there is still a need for standardised, easy-to-use methods
to process the tracks generated by these tools.

`movement` aims to provide a consistent, modular interface for analysing
motion tracks, enabling steps such as data cleaning, visualisation,
and motion quantification. We aim to support all popular animal tracking
frameworks and file formats.

Find out more on our [mission and scope](https://movement.neuroinformatics.dev/community/mission-scope.html) statement and our [roadmap](https://movement.neuroinformatics.dev/community/roadmaps.html).

<!-- Start Admonitions -->

> [!Tip]
> If you prefer analysing your data in R, we recommend checking out the
> [animovement](https://roald-arboel.com/animovement/) toolbox, which is similar in scope.
> We are working together with its developer
> to gradually converge on common data standards and workflows.

<!-- End Admonitions -->

## Join the movement

Contributions to movement are absolutely encouraged, whether to fix a bug, develop a new feature, or improve the documentation.
To help you get started, we have prepared a detailed [contributing guide](https://movement.neuroinformatics.dev/community/contributing.html).

- [Chat with the team on Zulip](https://neuroinformatics.zulipchat.com/#narrow/stream/406001-Movement).
- [Open an issue](https://github.com/neuroinformatics-unit/movement/issues) to report a bug or request a new feature.
- [Follow this Zulip topic](https://neuroinformatics.zulipchat.com/#narrow/channel/406001-Movement/topic/Community.20Calls) to receive updates about upcoming Community Calls.

## Citation

If you use movement in your work, please cite the following Zenodo DOI:

> Nikoloz Sirmpilatze, Chang Huan Lo, SofÃ­a MiÃ±ano, Brandon D. Peri, Dhruv Sharma, Laura Porta, IvÃ¡n Varela & Adam L. Tyson (2024). neuroinformatics-unit/movement. Zenodo. https://zenodo.org/doi/10.5281/zenodo.12755724

## License
âï¸ [BSD 3-Clause](./LICENSE)

## Package template
This package layout and configuration (including pre-commit hooks and GitHub actions) have been copied from the [python-cookiecutter](https://github.com/neuroinformatics-unit/python-cookiecutter) template.
","['Development Status :: 3 - Alpha', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License', 'Framework :: napari']","['Homepage, https://github.com/neuroinformatics-unit/movement', 'Bug Tracker, https://github.com/neuroinformatics-unit/movement/issues', 'Documentation, https://movement.neuroinformatics.dev/', 'Source Code, https://github.com/neuroinformatics-unit/movement', 'User Support, https://neuroinformatics.zulipchat.com/#narrow/stream/406001-Movement']",,,movement.make_widget,,,,
87,napari-3d-registration,napari-3D-registration,napari 3D registration,0.2.1,2025-07-08,2025-07-08,Leo Guignard,leo.guignard@univ-amu.fr,MIT,https://github.com/GuignardLab/napari-3D-registration/issues,https://pypi.org/project/napari-3D-registration/,,https://github.com/GuignardLab/napari-3D-registration,A plugin to help registering fluorescent movies in space and time,>=3.8,"['numpy', 'magicgui', 'qtpy', '3D-registration', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-3D-registration

[![License MIT](https://img.shields.io/pypi/l/napari-3D-registration.svg?color=green)](https://github.com/GuignardLab/napari-3D-registration/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-3D-registration.svg?color=green)](https://pypi.org/project/napari-3D-registration)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-3D-registration.svg?color=green)](https://python.org)
[![tests](https://github.com/GuignardLab/napari-3D-registration/workflows/tests/badge.svg)](https://github.com/GuignardLab/napari-3D-registration/actions)
[![codecov](https://codecov.io/gh/GuignardLab/napari-3D-registration/branch/main/graph/badge.svg)](https://codecov.io/gh/GuignardLab/napari-3D-registration)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-3D-registration)](https://napari-hub.org/plugins/napari-3D-registration)

A plugin to help registering fluorescent movies in space and time

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-3D-registration` via [pip]:

    pip install napari-3D-registration



To install latest development version :

    pip install git+https://github.com/GuignardLab/napari-3D-registration.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-3D-registration"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/GuignardLab/napari-3D-registration/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/GuignardLab/napari-3D-registration/issues', 'Documentation, https://github.com/GuignardLab/napari-3D-registration#README.md', 'Source Code, https://github.com/GuignardLab/napari-3D-registration', 'User Support, https://github.com/GuignardLab/napari-3D-registration/issues']",,,napari-3D-registration.make_time_registration_widget,,,,
88,napari-3dtimereg,napari-3dtimereg,3D Movies Registration,0.0.11,2024-04-05,2025-01-08,GaÃ«lle Letort,gaelle.letort@pasteur.fr,BSD-3-Clause,,https://pypi.org/project/napari-3dtimereg/,,https://gitlab.pasteur.fr/gletort/napari-3dtimereg,Registration of 3D movies applied to all channels,>=3.8,"['numpy', 'napari', 'magicgui', 'qtpy', 'tifffile', 'imaris_ims_file_reader', 'czifile', 'itk==5.3.0', 'itk-registration', 'itk-elastix', 'pydantic<=1.10.14']","# napari-3dtimereg

[![License BSD-3](https://img.shields.io/pypi/l/napari-3dtimereg.svg?color=green)](https://gitlab.pasteur.fr/gletort/napari-3dtimereg/-/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-3dtimereg.svg?color=green)](https://pypi.org/project/napari-3dtimereg)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-3dtimereg.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-3dtimereg)](https://napari-hub.org/plugins/napari-3dtimereg)

Temporal registration of 2D/3D movies on one channel based on [itk-elastix](https://pypi.org/project/itk-elastix/), and transpose alignement to the other channels.

Adaptated from [multireg](https://gitlab.pasteur.fr/gletort/multireg) for temporal movies.
For a tutorial on using `elastix` for registration, see [this tutorial](https://m-albert.github.io/elastix_tutorial/intro.html).


----------------------------------
## Installation

* You can install the plugin directly in `Napari` by going to `Plugins>Install/Uninstall plugins` and search for `napari-3dtimereg`

* Or you can install `napari-3dtimereg` via [pip]:

    pip install napari-3dtimereg


## Usage

You can launch `3dtimereg` in napari by going to `Plugins>Do 3D movie registration (napari-3dtimereg)`.

### Choose movie and reference chanel

First, choose select the movie that you want to register. The plugin will create a folder `aligned` in the folder of your selected movie where the results will be saved.

Choose the color chanel on which to calculate the registration (`reference chanel`). Color chanels are numbered from 0 to nchanels, and you can see their respective number in the layer list on the left panel of Napari. Click on `Update` when the correct chanel is selected to go to the registration calculation step.

### Calculate temporal alignement

The registration is calculated iteratively from one frame to another. Thus the first frame is not moved and all the other frames are aligned to it.
You can tune several parameters in this plugin:

![parameters screenshot](./imgs/parameters.png ""Registration parameters"")

The other parameters are parameters to use [itk-elastix](https://elastix.lumc.nl/) to calculate the registration.
* `show log`: to see the log of Elastix calculation
* `do rigid`: performs a rigid (affine) transformation step, that allowed to correct for translations/rotations.
* `do bspline`: performs a b-spline based transformation step, that allowed for local deformations in the image.
* `show advanced parameters`: to control the parameters used in the rigid and/or bspline transformations. These parameters control the size of the local registrations calculated, the resolutions at which the transformations are calculated, and can thus greatly impact the results.
* `final order`: is the final order of the B-Splines used for the registration. 
* `resolution`: is the number of consecutives resolutions at which the registration will be made. First the registration is made at the lowest level of resolution, correcting global deformations/motions, then at each step, the registration is done on higher resolution, allowing to correct for more local deformations.
* `final spacing`: is the physical spacing of the smallest resolution.
* `iterations`: are the maximum number of iterations allowed to minimize the distance between the two images for each resolution and type of registration.

If both rigid and bspline transformations, the program first applies the rigid transformation to allow for a global registration of the images. Then it will performs the second step of b-spline transformation that can includes local deformations.

For each frame, after calculating the registration on the reference chanel, the plugin will apply the calculated transformation to all the other color chanels of the initial movie. All results are saved as separated images in the `aligned` folder during the computation.

### Create the final aligned movie

When all frames have been processed, each color chanel and each frame have been saved in the `aligned` folder as separated images. This is usefull to calculate the registration on large movies without having to keep all the intermediates and calculated images in memory. You can directly use these separated images, or reconstruct a single composite movie of the result.

If you click on `Concatenate aligned images` on the plugin interface, the plugin will create a single composite movie from the aligned images, save it and delete the separated images in the `aligned` folder. 

## License

Distributed under the terms of the [BSD-3] license, ""napari-3dtimereg"" is free and open source software


[napari]: https://github.com/napari/napari
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://gitlab.pasteur.fr/gletort/napari-3dtimereg/issues', 'Documentation, https://gitlab.pasteur.fr/gletort/napari-3dtimereg#README.md', 'Source Code, https://gitlab.pasteur.fr/gletort/napari-3dtimereg']",,,napari-3dtimereg.registration,,,,
89,napari-activelearning,napari-activelearning,Active Learning,0.1.0,2024-07-31,2025-05-30,Fernando Cervantes (The Jackson Laboratory),fernando.cervantes@jax.org,MIT,https://github.com/TheJacksonLaboratory/activelearning,https://pypi.org/project/napari-activelearning/,,,An active learning plugin for fine tuning of deep learning models.,>=3.10,"['napari', 'numpy', 'dask[array]', 'magicgui', 'qtpy', 'scikit-image', 'tifffile', 'tensorstore==0.1.59', 'ome-zarr==0.9.0', 'zarr<3.0.0,>=2.12.0', 'zarrdataset>=0.2.1', 'cellpose>=3.0.0; extra == ""cellpose""', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# Active Learning tools for ML models fine-tuning
Active learning tools for fine-tuning ML models

[![License MIT](https://img.shields.io/pypi/l/napari-activelearning.svg?color=green)](https://github.com/TheJacksonLaboratory/activelearning/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-activelearning.svg?color=green)](https://pypi.org/project/napari-activelearning)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-activelearning.svg?color=green)](https://python.org)
[![tests](https://github.com/TheJacksonLaboratory/activelearning/workflows/tests/badge.svg)](https://github.com/TheJacksonLaboratory/activelearning/actions)
[![codecov](https://codecov.io/gh/TheJacksonLaboratory/activelearning/branch/main/graph/badge.svg)](https://codecov.io/gh/TheJacksonLaboratory/napari-activelearning)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-activelearning)](https://napari-hub.org/plugins/napari-activelearning)

A plugin for running a complete active learning workflow

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-activelearning` via [pip]:

    pip install napari-activelearning




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-activelearning"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Homepage, https://github.com/TheJacksonLaboratory/activelearning']",,,napari-activelearning.make_image_groups_manager_widget,,,,
90,napari-afmreader,napari-afmreader,AFMReader,0.0.1,2025-06-07,2025-06-07,"TopoStats Team, Max Gamill","TopoStats Team <topostats@sheffield.ac.uk>, Max Gamill <mcgamill1@sheffield.ac.uk>",GNU GPLv3 only,https://github.com/AFM-SPM/napari-afmreader/issues,https://pypi.org/project/napari-afmreader/,,,Napari plugin using AFMReader to load various Atomic Force Microscopy Images.,>=3.10,"['afmreader', 'magicgui', 'napari[all]', 'qtpy', 'tox', 'pytest; extra == ""tests""', 'pytest-cov; extra == ""tests""', 'pytest-qt; extra == ""tests""', 'qtpy; extra == ""tests""', 'black; extra == ""dev""', 'codespell; extra == ""dev""', 'pre-commit; extra == ""dev""', 'pylint; extra == ""dev""', 'ruff; extra == ""dev""', 'build; extra == ""pypi""', 'setuptools_scm[toml]; extra == ""pypi""', 'wheel; extra == ""pypi""']","# napari-AFMReader

<div align=""center"">

[![PyPI version](https://badge.fury.io/py/napari-afmreader.svg)](https://badge.fury.io/py/napari-afmreader)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/napari-afmreader)
[![Code style:
Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Code style: flake8](https://img.shields.io/badge/code%20style-flake8-456789.svg)](https://github.com/psf/flake8)
[![codecov](https://codecov.io/gh/AFM-SPM/napari-afmreader/branch/dev/graph/badge.svg)](https://codecov.io/gh/AFM-SPM/napari-afmreader)
[![pre-commit.ci
status](https://results.pre-commit.ci/badge/github/AFM-SPM/napari-afmreader/main.svg)](https://results.pre-commit.ci/latest/github/AFM-SPM/napari-afmreader/main)
[![fair-software.eu](https://img.shields.io/badge/fair--software.eu-%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8F%20%20%E2%97%8B-yellow)](https://fair-software.eu)

</div>
<div align=""center"">

[![Downloads](https://static.pepy.tech/badge/napari-afmreader)](https://pepy.tech/project/napari-afmreader)
[![Downloads](https://static.pepy.tech/badge/napari-afmreader/month)](https://pepy.tech/project/napari-afmreader)
[![Downloads](https://static.pepy.tech/badge/napari-afmreader/week)](https://pepy.tech/project/napari-afmreader)

</div>
<div align=""center"">

| [Installation](#installation) | [Usage](#usage) | [Licence](#licence) | [Citation](#citation) |

</div>

A [Napari](https://napari.org/) plugin to read in Atomic Force Microscopy (AFM) files using
[AFMReader](https://github.com/AFM-SPM/AFMReader.git).

You can drag and drop your favourite AFM image files directly into the Napari viewer to use the awesome tools the image
analysis community have developed over at the [Napari Hub](https://www.napari-hub.org/) to analyse your images using
open-source software and a GUI!

| File Extension | Supported by AFMReader | Description              |
| -------------- | ---------------------- | ------------------------ |
| `.asd`         | â                     | High-speed AFM format.   |
| `.gwy`         | â                     | Gwyddion saved format.   |
| `.ibw`         | â                     | Igor binary-wave format. |
| `.jpk`         | â                     | JPK instruments format.  |
| `.spm`         | â                     | Bruker spm format.       |
| `.stp`         | â                     | Homemade stp format.     |
| `.top`         | â                     | Homemade top format.     |
| `.topostats`   | â                     | topostats output format. |

## Installation

### Via Napari-Hub

This software should be installable directly from Napari!

All you need to do is:

1. [Install Napari](https://napari.org/stable/tutorials/fundamentals/installation.html) into an environment.
2. Open Napari by typing `napari` into your command line with your Napari environment activated.

   ```bash
   napari
   ```

3. Go to `Plugins` > `Install/Uninstall Plugins`, and search for `napari-afmreader`.

### Via Git

Occasionally the Napari-Hub version of `napari-AFMReader` may not be the most up-to-date. This is when you might want
to install both the most up-to-date `AFMReader` and `napari-AFMReader` versions via Git.

`napari-AFMReader` has been designed to need minimal maintenance, with most of the new file type additions being solely
added to AFMReader.

1. With [Git installed](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git) on your machine, clone both the
   `AFMReader` and `napari-AFMReader` repositories:

   ```bash
   git clone https://github.com/AFM-SPM/AFMReader.git
   ```

   ```bash
   git clone https://github.com/AFM-SPM/napari-AFMReader.git
   ```

2. Activate your Python environment (e.g. Conda) and install the dependencies for each - make sure that the `AFMReader`
   dependency is installed second to overwrite the possibly outdated `afmreader` package!

   ```bash
   cd napari-AFMReader
   pip install .
   cd ..
   ```

   ```bash
   cd AFMReader
   pip install .
   ```

3. Now when you open Napari via the `napari` command, it should use the latest version of `AFMReader`, and
   `napari-AFMReader`.

   ```bash
   napari
   ```

## Usage

This package should be fairly straight-forward and intuitive to use, requiring you to:

1. Drag and drop your supported AFM file into the Napari Viewer.

2. Type in the name of the channel you would like to use. You may not need to specify a channel for e.g. `.stp`, or the
   channel may refer to image key in the `.napari-afmreader` file.\*.

   \*_Possible channel names will not appear at first due to the order in which AFMReader processes an image. Thus,
   when provided with an non-existent channel name, the dialogue box will then return a list of possible channels to
   choose from._

## Licence

**This software is licensed as specified by the [GPL License](COPYING) and [LGPL License](COPYING.LESSER).**

## Citation

Please use the [Citation File Format](https://citation-file-format.github.io/) which is available in this repository.
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: End Users/Desktop', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/AFM-SPM/napari-afmreader/issues', 'Documentation, https://github.com/AFM-SPM/napari-afmreader#README.md', 'Source Code, https://github.com/AFM-SPM/napari-afmreader', 'User Support, https://github.com/AFM-SPM/napari-afmreader/issues']",napari-afmreader.get_reader,,,,"['*.asd', '*.gwy', '*.ibw', '*.jpk', '*.spm', '*.stp', '*.top', '*.topostats']",,
91,napari-3d-counter,napari-3d-counter,3D Counter,0.5.0,2023-10-18,2025-07-20,Peter Newstein,peternewstein@gmail.com,GPL-3.0-or-later,https://github.com/pnewstein/napari-3d-counter/issues,https://pypi.org/project/napari-3d-counter/,,https://github.com/pnewstein/napari-3d-counter,A simple plugin for counting objects in 3D images,>=3.10,"['numpy', 'qtpy', 'pandas', 'scikit-image', 'napari==0.6.2', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-3d-counter

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-3d-counter.svg?color=green)](https://github.com/pnewstein/napari-3d-counter/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-3d-counter.svg?color=green)](https://pypi.org/project/napari-3d-counter)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-3d-counter.svg?color=green)](https://python.org)
[![tests](https://github.com/pnewstein/napari-3d-counter/workflows/tests/badge.svg)](https://github.com/pnewstein/napari-3d-counter/actions)
[![codecov](https://codecov.io/gh/pnewstein/napari-3d-counter/branch/main/graph/badge.svg)](https://codecov.io/gh/pnewstein/napari-3d-counter)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-3d-counter)](https://napari-hub.org/plugins/napari-3d-counter)

A simple plugin for counting objects in 3D images

![small](https://github.com/pnewstein/napari-3d-counter/assets/30813691/9d524c31-f23b-4b34-bcb6-ec3bb415cdae)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-3d-counter` via [pip]:

    pip install napari-3d-counter


To install latest development version :

    pip install git+https://github.com/pnewstein/napari-3d-counter.git


##  Count3D Usage

Count3D can be launched from the plugin menu

### Adding a cell

You can add a cell of the currently selected cell type by clicking on the viewer.

- Ensure that `Point adder` layer is selected
- Ensure that `Add points` tool is selected
- Click on the viewer where you would like the point to be added

The counter on the current cell type's button will be incremented



https://github.com/pnewstein/napari-3d-counter/assets/30813691/745d495e-1d18-43dd-aa5e-e9ecd835cdae


### Changing cell type

You can change the currently selected cell type by clicking on that cell type's
button. This change will be reflected in the GUI. Additionally, the keyboard
shortcut for that cell type can be used. Keyboard shortcuts are listed on the
button, and are ""q"", ""w"", ""e"", ""r"", ""t"", ""y"" by default


https://github.com/pnewstein/napari-3d-counter/assets/30813691/844d04ce-2795-4226-a98b-d5fe5a0b131e


### Undo last added cell

The undo button (shortcut u) will remove last added cell, regardless of
cell type


https://github.com/pnewstein/napari-3d-counter/assets/30813691/c04ca5e3-9f48-4dd5-89e5-a9866b353e03


### Remove a particular cell

To remove a particular cell. Change to the layer containing the cell you would
like to remove. Then select the `select points` tool to select the points to
delete, then use `Delete selected points` to delete those points

This change will be reflected in the counts.


https://github.com/pnewstein/napari-3d-counter/assets/30813691/d0787cba-9b23-46d5-9cd3-21a4ad73460a



### Change appearance of a cell type

Changes to the name or edge color of a points layer will be reflected in the
previously added points, as well as the GUI. Features that are editable in this way include:
    - face color
    - edge color
    - symbol
    - size


https://github.com/pnewstein/napari-3d-counter/assets/30813691/6c495270-d4c4-473e-9091-8d2e0f8e2764


### Save configuration

Use the `Make launch_cell_count.py` button to create a python script that will
launch napari with 3DCounter added to the dock and current cell type appearances
already loaded


https://github.com/pnewstein/napari-3d-counter/assets/30813691/3448652d-3064-4900-8bbe-e88d75667108


### Save cells

Use the ""Save cells"" button to save the cell coordinates for all layers into a
csv file


https://github.com/pnewstein/napari-3d-counter/assets/30813691/38b30f2a-cc83-46c2-8b19-4d44715c07c5


### Load cells

Use the ""Load cells"" button to load the cells from a csv file into new layers


https://github.com/pnewstein/napari-3d-counter/assets/30813691/7df74688-85b1-4b61-aa51-dab179763832


### Launch with saved configuration

To run Count3D with custom configuration, paste the following code into your napari ipython console

```python
from napari_3d_counter import Count3D, CellTypeConfig

cell_type_config = [
    # The first celltype is called ""cq+eve+"" and should be green
    CellTypeConfig(
        name=""cq+eve+"",
        color=""g""
    ),
    # The first celltype is called ""cq+eve-"" and should be cyan
    CellTypeConfig(
        name=""cq+eve-"",
        color=""c""
    ),
    # The first celltype is called ""cq-eve+"" and should be red
    CellTypeConfig(
        name=""cq-eve+"",
        color=""r""
    ),
]
# Launch the plugin with configuration
viewer.window.add_dock_widget(Count3D(viewer, cell_type_config=cell_type_config))
```

##  Auxiliary plugins
### Reconstruct Selected
One use case of Napari 3D Counter is to visualize a subset of labeled cells.
For example, automated process label your cells of interest as well as a set of
off-target cells, and you would like to visualize only your cells of interest.
This can be accomplished by using Napari 3D Counter to count your cells of
interest, and some other process to create labels (perhaps
[nsbatwm](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes))
and using Reconstruct Selected to create a new image layer of those labels
which have been counted as a particular cell type.

### Ingress Points
This plugin takes a points layer and adds the points to the selected cell_type
layer. This can be usefull if you want to manualy count cells after cell identification.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-3d-counter"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/pnewstein/napari-3d-counter/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/pnewstein/napari-3d-counter/issues', 'Documentation, https://github.com/pnewstein/napari-3d-counter#README.md', 'Source Code, https://github.com/pnewstein/napari-3d-counter', 'User Support, https://github.com/pnewstein/napari-3d-counter/issues']",,,napari-3d-counter.make_count3d,,,,
92,napari-accelerated-pixel-and-object-classification,napari-accelerated-pixel-and-object-classification,napari-accelerated-pixel-and-object-classification,0.14.1,2021-10-02,2023-11-04,Robert Haase,robert.haase@tu-dresden.de,BSD-3,https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification,https://pypi.org/project/napari-accelerated-pixel-and-object-classification/,,https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification,Pixel and label classification using OpenCL-based Random Forest Classifiers,>=3.7,"['napari-plugin-engine >=0.1.4', 'numpy', 'apoc >=0.12.0', 'napari-tools-menu >=0.1.17', 'napari-time-slicer', 'superqt', 'imageio !=2.22.1', 'napari >=0.4.11', 'napari-assistant >=0.4.7']","# napari-accelerated-pixel-and-object-classification (APOC)

[![License](https://img.shields.io/pypi/l/napari-accelerated-pixel-and-object-classification.svg?color=green)](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-accelerated-pixel-and-object-classification.svg?color=green)](https://pypi.org/project/napari-accelerated-pixel-and-object-classification)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-accelerated-pixel-and-object-classification.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-accelerated-pixel-and-object-classification/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-accelerated-pixel-and-object-classification)
[![Development Status](https://img.shields.io/pypi/status/napari-accelerated-pixel-and-object-classification.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-accelerated-pixel-and-object-classification)](https://napari-hub.org/plugins/napari-accelerated-pixel-and-object-classification)
[![DOI](https://zenodo.org/badge/412525441.svg)](https://zenodo.org/badge/latestdoi/412525441)
 
[clesperanto](https://github.com/clEsperanto/pyclesperanto_prototype) meets [scikit-learn](https://scikit-learn.org/stable/) to classify pixels and objects in images, on a [GPU](https://en.wikipedia.org/wiki/Graphics_processing_unit) using [OpenCL](https://www.khronos.org/opencl/) in [napari].

![](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/screencast.gif)
The processed example image was kindly acquired by Daniela Vorkel, Myers lab, MPI-CBG / CSBD ([Download full video](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/demo_lund.mp4))

For using the accelerated pixel and object classifiers in python, check out [apoc](https://github.com/haesleinhuepf/apoc).
Training classifiers from pairs of image and label-mask folders is explained in 
[this notebook](https://github.com/haesleinhuepf/apoc/blob/main/demo/train_on_folders.ipynb).
For executing APOC's pixel and object classifiers in [Fiji](https://fiji.sc) using [clij2](https://clij.github.io) please read the documentation of the [corresponding Fiji plugin](https://github.com/clij/clijx-accelerated-pixel-and-object-classification). Table classifiers and object mergers are not compatible with Fiji yet.

![](https://github.com/clij/clijx-accelerated-pixel-and-object-classification/raw/main/docs/screenshot.png)



## Usage

### Object and Semantic Segmentation

Starting point is napari with at least one image layer and one labels layer (your annotation).

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/object_segmentation_starting_point.png)

You find Object and Semantic Segmentation in the `Tools > Segmentation / labeling`. When starting those, the following graphical user interface will show up.

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/object_and_semantic_segmentation.png)

1. Choose one or multiple images to train on. These images will be considered as multiple channels. Thus, they need to be spatially correlated. 
   Training from multiple images showing different scenes is not (yet) supported from the graphical user interface. Check out [this notebook](https://github.com/haesleinhuepf/apoc/blob/main/demo/demp_pixel_classifier_continue_training.ipynb) if you want to train from multiple image-annotation pairs.
2. Select a file where the classifier should be saved. If the file exists already, it will be overwritten.
3. Select the ground-truth annotation labels layer. 
4. Select which label corresponds to foreground (not available in Semantic Segmentation)
5. Select the feature images that should be considered for segmentation. If segmentation appears pixelated, try increasing the selected sigma values and untick `Consider original image`.
6. Tree depth and number of trees allow you to fine-tune how to deal with manifold regions of different characteristics. The higher these numbers, the longer segmentation will take. In case you use many images and many features, high depth and number of trees might be necessary. (See also `max_depth` and `n_estimators` in the [scikit-learn documentation of the Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).
7. The estimation of memory consumption allows you to tune the configuration to your GPU-hardware. Also consider the GPU-hardware of others who want to use your classifier.
8. Click on Run when you're done with configuring. If the segmentation doesn't fit after the first execution, consider fine-tuning the ground-truth annotation and try again.

A successful segmentation can for example look like this:

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/object_segmentation_result.png)

After your classifier has been trained successfully, click on the ""Application / Prediction"" tab. If you apply the classifier again, python code will be generated. 
You can use this code for example to apply the same classifier to a folder of images. If you're new to this, check out [this notebook](https://github.com/BiAPoL/Bio-image_Analysis_with_Python/blob/main/image_processing/12_process_folders.ipynb).

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/code_generation.png)

A pre-trained classifier can be [applied from scripts as shown in the example notebook](https://github.com/haesleinhuepf/apoc/blob/main/demo/demo_object_segmenter.ipynb) or from the `Tools > Segmentation / labeling > Object segmentation (apply pretrained, APOC)`.

### Integration with the napari-assistant

Pre-trained models can also be assembled to workflows using the [napari-assistant](https://www.napari-hub.org/plugins/napari-assistant). You find APOC-operations in the categories `Filter`, `Label` and `Label Filters`:

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/assistant.png)

### Semantic segmentation

Users can also generate semantic segmentation label images where the label identifier corresponds to a class the pixel has been allocated to. 
The tool can be found in the menu `Tools > Segmentation / labeling > Semantic segmentation (APOC)`.
It works analogously like the Object Segmenter, just without the need to specify the class identifier that objects correspond to.

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/semantic_segmentation.png)

### Probability maps

The tool for generating probability maps (`Tools > Filtering > Probability Mapper (APOC)` menu) works analogously to the Object Segmenter as well. 
The only difference is that the result image is not a label image but an intensity image where the intensity represents the probability (between 0 and 1)
that a pixel belongs to a given class. In this example: The raw image (grey) has been annotated with three classes: background (black, label 1), foreground (white, label 2) and edges (grey, label 3).
The probability mapper was configured to create probability image (shown in green) for edges (label 3):

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/probability_mapper.png)

### Classifier statistics

While training, you can also activate the `Show classifier statistics` checkbox. 
When doing so, it is recommended to increase the number of trees so that the measurements are more reliable, especially when selecting many features.
This will open a small table after training where you can see how large the share of decision trees are for each analysed feature image.

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/classifier_statistics.png)

It is recommended to turn on/off the features that hold a very large share (green) or a very small share (magenta) of trees in the random forest. 
Retrain the classifier to see how the features influence the decision making.

Note: Multiple of these parameters may be correlated. 
If you select 11 feature images, which all allow to make the pixel classification similarly, but 10 of those are correlated, these 10 may appear with a share of about 0.05 while the 11th parameter has a share of 0.5. 
Thus, study these values with care.

### Merging objects

After segmentation, you can merge labeled objects using the `Tools > Segmentation post-processing > Merge objects (APOC)` menu. 
Annotate label edges that should be merged with intensity 1 and those which should be kept with intensity 2 in a blank label image.
Select which features should be considered for merging:
* `touch_portion`: The relative amount an object touches another. E.g. in a symmetric, honey-comb like tissue, neighboring cells have a touch-portion of `1/6` to each other.
* `touch_count`: The number of pixels where object touch. When using this parameter, make sure that images used for training and prediction have the same voxel size.
* `mean_touch_intensity`: The mean average intensity between touching objects. When using this parameter, make sure images used for training and prediction are normalized the same way.
* `centroid_distance`: The distance (in pixels or voxels) between centroids of labeled objects. 
* `mean_intensity_difference`: The absolute difference between the mean intensity of the two objects. This measurement allows differentiating bright and dark object and [not] merging them.
* `standard_deviation_intensity_difference`: The absolute difference between the standard deviation of the two objects. This measurement allows to differentiate [in]homogeneous objects and [not] merge them.
* `area_difference`: The difference in area/volume/pixel-count allows differentiating small and large objects and [not] merging them.
* `mean_max_distance_to_centroid_ratio_difference`: This parameter is a shape descriptor, similar to elongation, allowing to differentiate roundish and elongate object and [not] merging them.

Note: most features are recommended to be used in isotropic images only.

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/merge_objects.gif)

For training, use an image with equivalized intensity (1), an over-segmented label image (2) and annotations (3). When drawing annotations in a new labels layer, make sure to misguide the algorithm draw on edges of touching objects a 1 if those should be merged and a 2 if they should be kept. Make sure there are no 1/2 annotation circles on both: labels which should be merged and kept.

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/merge_objects2.png)

### Object classification

Click the menu `Tools > Segmentation post-processing > Object classification (APOC)`. 

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/menu.png)

This user interface will be shown:

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/object_classifier_gui.png)

1. The image layer will be used for intensity based feature extraction (see below).
2. The labels layer should be contain the segmentation of objects that should be classified. 
   You can use the Object Segmenter explained above to create this layer.
3. The annotation layer should contain manual annotations of object classes. 
   You can draw lines crossing single and multiple objects of the same kind. 
   For example draw a line through some elongated objects with label ""1"" and another line through some rather roundish objects with label ""2"".
   If these lines touch the background, that will be ignored.
4. Tree depth and number of trees allow you to fine-tune how to deal with manifold objects of different characteristics. The higher these numbers, the longer classification will take. In case you use many features, high depth and number of trees might be necessary. (See also `max_depth` and `n_estimators` in the [scikit-learn documentation of the Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).
5. Select the right features for training. For example, for differentiating objects according to their shape as suggested above, select ""shape"".
   The features are extracted using clEsperanto and are shown by example in [this notebook](https://github.com/clEsperanto/pyclesperanto_prototype/blob/master/demo/tissues/parametric_maps.ipynb).
6. Click on the `Run` button. If classification doesn't perform well in the first attempt, try changing selected features.  

If classification worked well, it may for example look like this. Note the two thick lines which were drawn to annotate elongated and roundish objects with brown and cyan:

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/object_classification_result.png)

A pre-trained model can later be applied [from scripts as shown in the example notebook](https://github.com/haesleinhuepf/apoc/blob/main/demo/cell_classification.ipynb) or using the menu `Tools > Segmentation post-processing > Object classification (apply pretrained, APOC)`.

### Object selection

Analogously to object classification, the object selector removes all objects from a label image that do not belong to a specified class.
It can be found in the menu `Tools > Segmentation post-processing > Object selection (APOC)`. 

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/select_objects.gif)


### Feature correlation matrix

When training object classifiers it is crucial to investigate to which degree features are correlated and select the right, ideally uncorrelated features to classify objects robustly.
After measuring features with any compatible napari plugin listed below, you can visualize the feature correlation matrix using the menu `Tools > Measurement tables > Show feature correlation matrix (pandas, APOC)` and by selecting the labels layer which has been analyzed.
Before computing the correlation matrix, all rows containing [NaN](https://en.wikipedia.org/wiki/NaN) values are removed.
For further details, please refer to the [documentation of the underlying function in pandas](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html).

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/feature_correlation_matrix.png)

### Surface Vertex Classification (SVeC)

When using napari-APOC in combination with [napari-process-points-and-surfaces>=0.3.3](https://github.com/haesleinhuepf/napari-process-points-and-surfaces), 
one can also classify vertices. Therefore, use for example the menu `Measurement > Surface quality table (vedo, nppas)` to determine quantitative measurements
and the menu `Surfaces > Annotate surface manually (nppas)` for manual annotations. It is recommended to annotate the entire surface with value 1 as background, and specific regions of interest with integer numbers > 1.
After measurements have been extracted and annotations were made, start SVeC from the `Surfaces > Surface vertex classification (custom properties, APOC)` menu. It can be used like the Object Classifier explained above.

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/demo_vertex_classification.gif)

[Download full video](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/demo_vertex_classification.mp4)

### Classifier statistics
After classifier training, you can study the share of the individual features/measurements and how they are correlated by activating the checkboxes `Show classifier statistics` and `Show feature correlation matrix`.

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/correlation_matrix2.png)

This can help understanding how the classifier works. Furthermore, you can accelerate the classifier by reducing the number of correlated features.

### Object classification from custom measurements

You can also classify labeled objects according to custom measurements. For deriving those measurements, you can use these napari plugins:

* [morphometrics](https://www.napari-hub.org/plugins/morphometrics)
* [PartSeg](https://www.napari-hub.org/plugins/PartSeg)
* [napari-simpleitk-image-processing](https://www.napari-hub.org/plugins/napari-simpleitk-image-processing)
* [napari-cupy-image-processing](https://www.napari-hub.org/plugins/napari-cupy-image-processing)
* [napari-pyclesperanto-assistant](https://www.napari-hub.org/plugins/napari-pyclesperanto-assistant)
* [napari-skimage-regionprops](https://www.napari-hub.org/plugins/napari-skimage-regionprops)

Furthermore, if you use napari from Python, you can also create a dictionary or pandas DataFrame with measurements and store it in the `labels_layer.features` to make them available in the object classifier.

After labels have been measured, you can start the `Object Classifier (custom properties, APOC)` from the `Tools > Segmentation post-processing` menu:

![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/table_row_classifier_gui.png)

1. Select the labels layers that has been measured.
2. The annotation layer should contain manual annotations of object classes. 
   You can draw lines crossing single and multiple objects of the same kind. 
   For example draw a line through some elongated objects with label ""1"" and another line through some rather roundish objects with label ""2"".
   If these lines touch the background, that will be ignored.
3. Select the measurements / features that should be used for object classification.
4. Use the `Update Measurements` button in case you did new measurements after Object classifier dialog was opened.
5. Enter the filename of the classifier to be trained here. This file will be overwritten in case it existed already.
6. Tree depth and number of trees allow you to fine-tune how to deal with manifold objects of different characteristics. The higher these numbers, the longer classification will take. In case you use many features, high depth and number of trees might be necessary. (See also `max_depth` and `n_estimators` in the [scikit-learn documentation of the Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).
7. The classification result will be stored under this name in the labels-layer's properties.
8. Choose if the results table should be shown. Choose if classifier statistics should be shown. [Read more about classifier statistics](https://haesleinhuepf.github.io/BioImageAnalysisNotebooks/27_cell_classification/forest_statistics.html).
9. Click on `Run` to start training and prediction.

You can also train those classifiers from Python and reuse them: [Read more about using the TableRowClassifier from python](https://haesleinhuepf.github.io/BioImageAnalysisNotebooks/27_cell_classification/apoc_simpleitk_object_classification.html)

### Classifier statistics and correlation matrix
After classifier training, you can study the share of the individual features/measurements and how they are correlated by activating the checkboxes `Show classifier statistics` and `Show correlation matrix`.
![img.png](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/raw/main/images/correlation_matrix.png)

This can help understanding how the classifier works. Furthermore, you can accelerate the classifier by reducing the number of correlated features.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

It is recommended to install the plugin in a conda environment. Therefore install conda first, e.g. [mini-conda](https://docs.conda.io/en/latest/miniconda.html).
If you never worked with conda before, reading this [short introduction](https://github.com/BiAPoL/Bio-image_Analysis_with_Python/blob/main/conda_basics/01_conda_environments.md) might be helpful.

Optional: Setup a fresh conda environment, activate it and install napari:

```
conda create --name napari_apoc python=3.9
conda activate napari_apoc
conda install napari
```

If your conda environment is set up, you can install `napari-accelerated-pixel-and-object-classification` using [pip]. Note: you need [pyopencl](https://documen.tician.de/pyopencl/) first.

```
conda install -c conda-forge pyopencl
pip install napari-accelerated-pixel-and-object-classification
```

Mac-users please also install this:

    conda install -c conda-forge ocl_icd_wrapper_apple
    
Linux users please also install this:
    
    conda install -c conda-forge ocl-icd-system


## Contributing
 
Contributions, feedback and suggestions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## Similar software
There are other napari plugins and other software with similar functionality for interactive classification of pixels and objects.

* [napari-feature-classifier](https://github.com/fractal-napari-plugins-collection/napari-feature-classifier)
* [napari-buds](https://www.napari-hub.org/plugins/napari-buds)
* [ilastik](https://www.ilastik.org/)
* [Fiji's Trainable Weka Segmentation](https://imagej.net/plugins/tws/)
* [scikit-learn](https://scikit-learn.org/stable/)

## License

Distributed under the terms of the [BSD-3] license,
""napari-accelerated-pixel-and-object-classification"" is free and open source software

## Issues

If you encounter any problems, please [open a thread on image.sc](https://image.sc) along with a detailed description and tag [@haesleinhuepf](https://github.com/haesleinhuepf).

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification/issues', 'Documentation, https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification', 'Source Code, https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification', 'User Support, https://forum.image.sc/tag/clij']",,,napari-accelerated-pixel-and-object-classification.ObjectSegmentation,,,,
93,napari-affinities,napari-affinities,napari Affinities,0.1.3,2022-06-12,2022-11-27,William Patton,will.hunter.patton@gmail.com,MIT,https://github.com/pattonw/napari-affinities/issues,https://pypi.org/project/napari-affinities/,,https://github.com/pattonw/napari-affinities,"A plugin for creating, visualizing, and processing affinities",>=3.7,"['numpy', 'zarr', 'magicgui', 'bioimageio.core', 'gunpowder', 'matplotlib', 'torch', 'lsds']","# napari-affinities

[![License](https://img.shields.io/pypi/l/napari-affinities.svg?color=green)](https://github.com/pattonw/napari-affinities/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-affinities.svg?color=green)](https://pypi.org/project/napari-affinities)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-affinities.svg?color=green)](https://python.org)
[![tests](https://github.com/pattonw/napari-affinities/workflows/tests/badge.svg)](https://github.com/pattonw/napari-affinities/actions)
[![codecov](https://codecov.io/gh/pattonw/napari-affinities/branch/main/graph/badge.svg)](https://codecov.io/gh/pattonw/napari-affinities)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-affinities)](https://napari-hub.org/plugins/napari-affinities)

A plugin for creating, visualizing, and processing affinities

---

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You will need a conda environment for everything to run
smoothly. Supported python versions are 3.7, 3.8, 3.9.

### pip
You can install `napari-affinities` via [pip]:

    `pip install napari-affinities`

To install latest development version :

    `pip install git+https://github.com/pattonw/napari-affinities.git`

Install torch according to your system [(follow the instructions here)](https://pytorch.org/get-started/locally/). For example with cuda 10.2 available, run:

    conda install pytorch torchvision cudatoolkit=10.2 -c pytorch

Install conda requirements:

    conda install -c conda-forge affogato

### conda

If you install via conda, there are fewer steps since
affogato and pytorch will be installed for you.

You can install `napari-affinities` via [conda]:

    `conda install -c conda-forge napari-affinities`

### Download example model:

#### 2D:

[epithelial example model](https://oc.embl.de/index.php/s/zfWMKu7HoQnSJLs)
Place the model zip file wherever you want. You can open it in the plugin with the ""load from file"" button.

#### 3D

[lightsheet example model](https://owncloud.gwdg.de/index.php/s/LsShICsOcilqPRs)
Unpack the tar file into test data (`lightsheet_nuclei_test_data` (an hdf5 file)) and model (`LightsheetNucleusSegmentation.zip` (a bioimageio model)).
Move the data into sample_data which will enable you to load the ""Lightsheet Sample"" data in napari.
Place the model zip file anywhere you want. You can open it in the plugin with the ""load from file"" button.

##### Workarounds to be fixed:

1. you need to update the `rdf.yaml` in the `LightsheetNucleusSegmentation.zip` with the following:
   - ""shape"" for ""input0"" should be updated with a larger minimum input size and ""output0"" should be updated with a larger halo. If not fixed, there will be significant tiling artifacts.
   - (Optional) ""output0"" should be renamed to affinities. The plugin supports multiple outputs and relies on names for figuring out which one is which. If unrecognized names are provided we assume the outputs are ordered (affinities, fgbg, lsds) but this is less reliable than explicit names.
2. This model also generates foreground in the same array as affinities, i.e. a 10 channel output `(fgbg, [-1, 0, 0], [0, -1, 0], [0, 0, -1], [-2, 0, 0], ...)`. Although predictions will work, post processing such as mutex watershed will break unless you manually separate the first channel.

## Use

Requirements for the model:

1. Bioimageio packaged pytorch model
2. Outputs with names ""affinities"", ""fgbg""(optional) or ""lsds""(optional)
   - if these names are not used, it will be assumed that the outputs are affinities, fgbg, then lsds in that order

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-affinities"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[mit]: http://opensource.org/licenses/MIT
[bsd-3]: http://opensource.org/licenses/BSD-3-Clause
[gnu gpl v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[gnu lgpl v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[apache software license 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[mozilla public license 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/pattonw/napari-affinities/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[pypi]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/pattonw/napari-affinities/issues', 'Documentation, https://github.com/pattonw/napari-affinities#README.md', 'Source Code, https://github.com/pattonw/napari-affinities', 'User Support, https://github.com/pattonw/napari-affinities/issues']",,,napari-affinities.make_mutex_watershed_widget,napari-affinities.sample_epithelial,,,
94,napari-3d-ortho-viewer,napari-3d-ortho-viewer,Ortho Viewer Widget,0.1.5,2023-11-21,2023-11-21,Niklas Netter,niknett@gmail.com,MIT,https://github.com/gatoniel/napari-3d-ortho-viewer/issues,https://pypi.org/project/napari-3d-ortho-viewer/,,https://github.com/gatoniel/napari-3d-ortho-viewer,Napari 3D Ortho Viewer - an ortho viewer for napari for 3D images,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-3d-ortho-viewer

[![License](https://img.shields.io/pypi/l/napari-3d-ortho-viewer.svg?color=green)](https://github.com/gatoniel/napari-3d-ortho-viewer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-3d-ortho-viewer.svg?color=green)](https://pypi.org/project/napari-3d-ortho-viewer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-3d-ortho-viewer.svg?color=green)](https://python.org)
[![tests](https://github.com/gatoniel/napari-3d-ortho-viewer/workflows/tests/badge.svg)](https://github.com/gatoniel/napari-3d-ortho-viewer/actions)
[![codecov](https://codecov.io/gh/gatoniel/napari-3d-ortho-viewer/branch/main/graph/badge.svg)](https://codecov.io/gh/gatoniel/napari-3d-ortho-viewer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-3d-ortho-viewer)](https://napari-hub.org/plugins/napari-3d-ortho-viewer)

Napari 3D Ortho Viewer - an ortho viewer for napari for 3D images

----------------------------------

https://github.com/gatoniel/napari-3d-ortho-viewer/assets/40384506/4296dc11-ea37-40a0-8b17-eeb77480672f

This plugin is heavily inspired by [ortho-view-napari].

Check out this post on image.sc (https://forum.image.sc/t/napari-visualization-in-3-planes/57768) for more infos about multiview support in [napari].

This viewer has some additional features:
- double click to jump to specific position in all slices
- additional 3d view of 3d stack with lines or planes indicating current position

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-3d-ortho-viewer` via [pip]:

    pip install napari-3d-ortho-viewer



To install latest development version :

    pip install git+https://github.com/gatoniel/napari-3d-ortho-viewer.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-3d-ortho-viewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/gatoniel/napari-3d-ortho-viewer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[ortho-view-napari]: https://github.com/JoOkuma/ortho-view-napari
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/gatoniel/napari-3d-ortho-viewer/issues', 'Documentation, https://github.com/gatoniel/napari-3d-ortho-viewer#README.md', 'Source Code, https://github.com/gatoniel/napari-3d-ortho-viewer', 'User Support, https://github.com/gatoniel/napari-3d-ortho-viewer/issues']",,,napari-3d-ortho-viewer.make_ortho_viewer_widget,,,,
95,napari-aicsimageio,napari-aicsimageio,napari-aicsimageio,0.7.2,2020-12-14,2022-08-22,"Eva Maxfield Brown, Talley Lambert","Eva Maxfield Brown <evamaxfieldbrown@gmail.com>, Talley Lambert <talley.lambert@gmail.com>",GPLv3,https://github.com/AllenCellModeling/napari-aicsimageio/issues,https://pypi.org/project/napari-aicsimageio/,,,AICSImageIO bindings for napari,>=3.8,"['aicsimageio[all] (>=4.6.3)', 'fsspec[http] (>=2022.7.1)', 'napari (>=0.4.11)', 'psutil (>=5.7.0)', 'aicspylibczi (>=3.0.5)', 'bioformats-jar', 'readlif (>=0.6.4)', ""black (>=19.10b0) ; extra == 'dev'"", ""coverage (>=5.1) ; extra == 'dev'"", ""docutils (<0.16,>=0.10) ; extra == 'dev'"", ""flake8-debugger (>=3.2.1) ; extra == 'dev'"", ""flake8-pyprojecttoml ; extra == 'dev'"", ""flake8 (>=3.8.3) ; extra == 'dev'"", ""ipython (>=7.15.0) ; extra == 'dev'"", ""isort (>=5.7.0) ; extra == 'dev'"", ""mypy (>=0.800) ; extra == 'dev'"", ""pytest-runner (>=5.2) ; extra == 'dev'"", ""twine (>=3.1.1) ; extra == 'dev'"", ""wheel (>=0.34.2) ; extra == 'dev'"", ""PyQt5 ; extra == 'test'"", ""pytest (>=5.4.3) ; extra == 'test'"", ""pytest-qt (~=4.0) ; extra == 'test'"", ""pytest-cov (>=2.9.0) ; extra == 'test'"", ""pytest-raises (>=0.11) ; extra == 'test'"", ""pytest-xvfb (~=2.0) ; extra == 'test'"", ""quilt3 (~=3.4.0) ; extra == 'test'""]","# napari-aicsimageio

[![License](https://img.shields.io/pypi/l/napari-aicsimageio.svg?color=green)](https://github.com/AllenCellModeling/napari-aicsimageio/raw/main/LICENSE)
[![Build Status](https://github.com/AllenCellModeling/napari-aicsimageio/workflows/Build%20Main/badge.svg)](https://github.com/AllenCellModeling/napari-aicsimageio/actions)
[![Code Coverage](https://codecov.io/gh/AllenCellModeling/napari-aicsimageio/branch/main/graph/badge.svg)](https://codecov.io/gh/AllenCellModeling/napari-aicsimageio)

AICSImageIO bindings for napari

---

## Features

-   Supports reading metadata and imaging data for:
    -   `OME-TIFF`
    -   `TIFF`
    -   `CZI` (Zeiss)
    -   `LIF` (Leica)
    -   `ND2` (Nikon)
    -   `DV` (DeltaVision)
    -   Any formats supported by [aicsimageio](https://github.com/AllenCellModeling/aicsimageio)
    -   Any formats supported by [bioformats](https://github.com/tlambert03/bioformats_jar)
        -   `SLD` (Slidebook)
        -   `SVS` (Aperio)
        -   [Full List](https://docs.openmicroscopy.org/bio-formats/6.5.1/supported-formats.html)
    -   Any additional format supported by [imageio](https://github.com/imageio/imageio)
        -   `PNG`
        -   `JPG`
        -   `GIF`
        -   `AVI`
        -   [Full List](https://imageio.readthedocs.io/en/v2.4.1/formats.html)

_While upstream `aicsimageio` is released under BSD-3 license, this plugin is released under GPLv3 license because it installs all format reader dependencies._

## Installation

**Stable Release:** `pip install napari-aicsimageio` or `conda install napari-aicsimageio -c conda-forge`<br>
**Development Head:** `pip install git+https://github.com/AllenCellModeling/napari-aicsimageio.git`

### Reading Mode Threshold

This image reading plugin will load the provided image directly into memory if it meets
the following two conditions:

1. The filesize is less than 4GB.
2. The filesize is less than 30% of machine memory available.

If either of these conditions isn't met, the image is loaded in chunks only as needed.

### Use napari-aicsimageio as the Reader for All File Formats

If you want to force napari to always use this plugin as the reader for all file formats,
try running this snippet:

```python
from napari.settings import get_settings

get_settings().plugins.extension2reader = {'*': 'napari-aicsimageio', **get_settings().plugins.extension2reader}
```

For more details, see [#37](https://github.com/AllenCellModeling/napari-aicsimageio/issues/37).

## Examples of Features

#### General Image Reading

All image file formats supported by
[aicsimageio](https://github.com/AllenCellModeling/aicsimageio) will be read and all
raw data will be available in the napari viewer.

In addition, when reading an OME-TIFF, you can view all OME metadata directly in the
napari viewer thanks to `ome-types`.

![screenshot of an OME-TIFF image view, multi-channel, z-stack, with metadata viewer](https://raw.githubusercontent.com/AllenCellModeling/napari-aicsimageio/main/images/ome-tiff-with-metadata-viewer.png)

#### Multi-Scene Selection

When reading a multi-scene file, a widget will be added to the napari viewer to manage
scene selection (clearing the viewer each time you change scene or adding the
scene content to the viewer) and a list of all scenes in the file.

![gif of drag and drop file to scene selection and management](https://raw.githubusercontent.com/AllenCellModeling/napari-aicsimageio/main/images/scene-selection.gif)

#### Access to the AICSImage Object and Metadata

![napari viewer with console open showing `viewer.layers[0].metadata`](https://raw.githubusercontent.com/AllenCellModeling/napari-aicsimageio/main/images/console-access.png)

You can access the `AICSImage` object used to load the image pixel data and
image metadata using the built-in napari console:

```python
img = viewer.layers[0].metadata[""aicsimage""]
img.dims.order  # TCZYX
img.channel_names  # [""Bright"", ""Struct"", ""Nuc"", ""Memb""]
img.get_image_dask_data(""ZYX"")  # dask.array.Array
```

The napari layer metadata dictionary also stores a shorthand
for the raw image metadata:

```python
viewer.layers[0].metadata[""raw_image_metadata""]
```

The metadata is returned in whichever format is used by the underlying
file format reader, i.e. for CZI the raw metadata is returned as
an `xml.etree.ElementTree.Element`, for OME-TIFF the raw metadata is returned
as an `OME` object from `ome-types`.

Lastly, if the underlying file format reader has an OME metadata conversion function,
you may additionally see a key in the napari layer metadata dictionary
called `""ome_types""`. For example, because the AICSImageIO
`CZIReader` and `BioformatsReader` both support converting raw image metadata
to OME metadata, you will see an `""ome_types""` key that stores the metadata transformed
into the OME metadata model.

```python
viewer.layers[0].metadata[""ome_types""]  # OME object from ome-types
```

#### Mosaic Reading

When reading CZI or LIF images, if the image is a mosaic tiled image, `napari-aicsimageio`
will return the reconstructed image:

![screenshot of a reconstructed / restitched mosaic tile LIF](https://raw.githubusercontent.com/AllenCellModeling/napari-aicsimageio/main/images/tiled-lif.png)

## Development

See [CONTRIBUTING.md](CONTRIBUTING.md) for information related to developing the code.

For additional file format support, contributed directly to
[AICSImageIO](https://github.com/AllenCellModeling/aicsimageio).
New file format support will become directly available in this
plugin on new `aicsimageio` releases.

## Citation

If you find `aicsimageio` _(or `napari-aicsimageio`)_ useful, please cite as:

> AICSImageIO Contributors (2021). AICSImageIO: Image Reading, Metadata Conversion, and Image Writing for Microscopy Images in Pure Python [Computer software]. GitHub. https://github.com/AllenCellModeling/aicsimageio

_Free software: GPLv3_
","['Development Status :: 5 - Production/Stable', 'Intended Audience :: Science/Research', 'Framework :: napari', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Scientific/Engineering']","['Homepage, https://github.com/AllenCellModeling/napari-aicsimageio', 'Bug Tracker, https://github.com/AllenCellModeling/napari-aicsimageio/issues', 'Documentation, https://github.com/AllenCellModeling/napari-aicsimageio#README.md', 'User Support, https://github.com/AllenCellModeling/napari-aicsimageio/issues']",napari-aicsimageio.get_reader,,,,"['*.1sc', '*.2fl', '*.3fr', '*.acff', '*.acqp', '*.afi', '*.afm', '*.aim', '*.al3d', '*.ali', '*.am', '*.amiramesh', '*.ano', '*.apl', '*.arf', '*.array-like', '*.arw', '*.avi', '*.bay', '*.bif', '*.bin', '*.bip', '*.bmp', '*.bmq', '*.bsdf', '*.bufr', '*.bw', '*.c01', '*.cap', '*.cat', '*.cfg', '*.ch5', '*.cif', '*.cine', '*.cr2', '*.crw', '*.cs1', '*.csv', '*.ct', '*.ct.img', '*.cur', '*.cut', '*.cxd', '*.czi', '*.dat', '*.db', '*.dc2', '*.dcm', '*.dcr', '*.dcx', '*.dds', '*.df3', '*.dicom', '*.dm2', '*.dm3', '*.dng', '*.drf', '*.dsc', '*.dti', '*.dv', '*.ecw', '*.emf', '*.eps', '*.epsi', '*.erf', '*.exp', '*.exr', '*.fake', '*.fdf', '*.fff', '*.ffr', '*.fid', '*.fit', '*.fits', '*.flc', '*.flex', '*.fli', '*.fpx', '*.frm', '*.ftc', '*.fts', '*.ftu', '*.fz', '*.g3', '*.gbr', '*.gdcm', '*.gel', '*.gif', '*.gipl', '*.grey', '*.grib', '*.h5', '*.hdf', '*.hdf5', '*.hdp', '*.hdr', '*.hed', '*.his', '*.htd', '*.htm', '*.html', '*.hx', '*.i2i', '*.ia', '*.icns', '*.ico', '*.ics', '*.ids', '*.iff', '*.iim', '*.iiq', '*.im', '*.im3', '*.img', '*.imggz', '*.ims', '*.inf', '*.inr', '*.ipl', '*.ipm', '*.ipw', '*.j2c', '*.j2k', '*.jfif', '*.jif', '*.jng', '*.jp2', '*.jpc', '*.jpe', '*.jpeg', '*.jpf', '*.jpg', '*.jpk', '*.jpx', '*.jxr', '*.k25', '*.kc2', '*.kdc', '*.klb', '*.koa', '*.l2d', '*.labels', '*.lbm', '*.lei', '*.lfp', '*.lfr', '*.lif', '*.liff', '*.lim', '*.lms', '*.lsm', '*.mdb', '*.mdc', '*.mef', '*.mgh', '*.mha', '*.mhd', '*.mic', '*.mkv', '*.mnc', '*.mnc2', '*.mng', '*.mod', '*.mos', '*.mov', '*.mp4', '*.mpeg', '*.mpg', '*.mpo', '*.mrc', '*.mri', '*.mrw', '*.msp', '*.msr', '*.mtb', '*.mvd2', '*.naf', '*.nd', '*.nd2', '*.ndpi', '*.ndpis', '*.nef', '*.nhdr', '*.nia', '*.nii', '*.nii.gz', '*.niigz', '*.npz', '*.nrrd', '*.nrw', '*.obf', '*.oib', '*.oif', '*.oir', '*.ome', '*.ome.tif', '*.ome.tiff', '*.orf', '*.par', '*.pbm', '*.pcd', '*.pcoraw', '*.pct', '*.pcx', '*.pef', '*.pfm', '*.pgm', '*.pic', '*.pict', '*.png', '*.pnl', '*.ppm', '*.pr3', '*.ps', '*.psd', '*.ptx', '*.pxn', '*.pxr', '*.qptiff', '*.qtk', '*.r3d', '*.raf', '*.ras', '*.raw', '*.rcpnl', '*.rdc', '*.rec', '*.rgb', '*.rgba', '*.rw2', '*.rwl', '*.rwz', '*.scan', '*.scn', '*.sdt', '*.seq', '*.sif', '*.sld', '*.sm2', '*.sm3', '*.spc', '*.spe', '*.spi', '*.sr2', '*.srf', '*.srw', '*.st', '*.sti', '*.stk', '*.stp', '*.svs', '*.swf', '*.sxm', '*.targa', '*.tfr', '*.tga', '*.thm', '*.tif', '*.tiff', '*.tim', '*.tnb', '*.top', '*.txt', '*.v', '*.vff', '*.vms', '*.vsi', '*.vtk', '*.vws', '*.wap', '*.wat', '*.wav', '*.wbm', '*.wbmp', '*.wdp', '*.webp', '*.wlz', '*.wmf', '*.wmv', '*.wpi', '*.xbm', '*.xdce', '*.xml', '*.xpm', '*.xqd', '*.xqf', '*.xv', '*.xys', '*.zfp', '*.zfr', '*.zip', '*.zpo', '*.zvi']",,
96,napari-aideveloper,napari-aideveloper,napari AIDeveloper,0.0.4,2022-05-20,2022-06-17,Chenqi Zhang,cqzhang@g.ecc.u-tokyo.ac.jp,BSD-3-Clause,https://github.com/zcqwh/napari-aideveloper/issues,https://pypi.org/project/napari-aideveloper/,,https://github.com/zcqwh/napari-aideveloper,"napari_aideveloper is a napari-plugin deived from AIDeveloper that allows you to train, evaluate and apply deep neural nets for image classification within a graphical user-interface (GUI).",>=3.8,"['numpy', 'magicgui', 'qtpy', 'dclab (>=0.39.9)', 'h5py (>=3.6.0)', 'Keras-Applications (>=1.0.8)', 'keras (>=2.8.0)', 'keras-metrics (>=1.1.0)', 'napari-plugin-engine (>=0.2.0)', 'napari (>=0.4.14)', 'onnx (>=1.11.0)', 'opencv-contrib-python-headless (>=4.5.5.62)', 'openpyxl (>=3.0.9)', 'pandas (>=1.4.1)', 'Pillow (>=9.1.1)', 'psutil (>=5.9.0)', 'pyqtgraph (>=0.12.3)', 'pytest (>=7.1.2)', 'scikit-learn (>=1.1.1)', 'scipy (>=1.8.0)', 'setuptools (>=58.0.4)', 'six (>=1.16.0)', 'tensorboard (>=2.8.0)', 'tensorflow (>=2.8.0)', 'tf2onnx (>=1.9.3)', 'xlrd (>=2.0.1)', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-aideveloper

[![License](https://img.shields.io/pypi/l/napari-aideveloper.svg?color=green)](https://github.com/zcqwh/napari-aideveloper/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-aideveloper.svg?color=green)](https://pypi.org/project/napari-aideveloper)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-aideveloper.svg?color=green)](https://python.org)
[![tests](https://github.com/zcqwh/napari-aideveloper/workflows/tests/badge.svg)](https://github.com/zcqwh/napari-aideveloper/actions)
[![codecov](https://codecov.io/gh/zcqwh/napari-aideveloper/branch/main/graph/badge.svg)](https://codecov.io/gh/zcqwh/napari-aideveloper)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-aideveloper)](https://napari-hub.org/plugins/napari-aideveloper)

[napari_aideveloper](https://www.napari-hub.org/plugins/napari-aideveloper) is a napari-plugin derived from [AIDeveloper](https://github.com/maikherbig/AIDeveloper) that allows you to train, evaluate, and apply deep neural nets for image classification within a graphical user-interface (GUI).


<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-aideveloper` via [pip]:

    pip install napari-aideveloper

## Introduction
### Main functions
* [Build](#build)
* [History](#history)

****

### Build 
#### 1. Load data
Drag and drop your data in .rtdc (HDF5) format into the file table and set the class and training/validation.
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/main/Tutorial/00_Load_data.gif?raw=true)

#### 2. Choose Neural Networks
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/main/Tutorial/01_choose%20NN.gif?raw=true)

#### 3. Set model storage path
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/main/Tutorial/02_save_model.gif?raw=true)

#### 4. Start fitting
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/main/Tutorial/03_start_fitting.gif?raw=true)
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/main/Tutorial/04_fitting.gif?raw=true)

#### Preview image
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/main/Tutorial/05_preview.gif?raw=true)

#### Image augmentation
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/main/Tutorial/06_augmentation.gif?raw=true)

****

### History
#### 1. Load meta data
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/development/Tutorial/GIF/History/01_Load_metadata.gif?raw=true)

#### 2. Check model details
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/development/Tutorial/GIF/History/02_model_detail.gif?raw=true)

#### 3. Rolling median & Linear fit
![alt Load_data](https://github.com/zcqwh/napari-aideveloper/blob/development/Tutorial/GIF/History/03_rolling_linear.gif?raw=true)






## Contributing

Contributions are very welcome. You can submit your pull request on [GitHub](https://github.com/zcqwh/napari-aideveloper/pulls). Tests can be run with [tox], please ensure the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-aideveloper"" is free and open source software

## Issues

If you encounter any problems, please [file an issue](https://github.com/zcqwh/napari-aideveloper/issues) along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/zcqwh/napari-aideveloper/issues', 'Documentation, https://github.com/zcqwh/napari-aideveloper#README.md', 'Source Code, https://github.com/zcqwh/napari-aideveloper', 'User Support, https://github.com/zcqwh/napari-aideveloper/issues']",,,napari-aideveloper.make_qwidget,,,,
97,napari-allencell-annotator,napari-allencell-annotator,napari-allencell-annotator,2.0.1,2022-07-27,2024-08-21,Allen Institute for Cell Science,,Unavailable,https://github.com/aics-int/napari-allencell-annotator/,https://pypi.org/project/napari-allencell-annotator/,,https://github.com/aics-int/napari-allencell-annotator/,A plugin that enables annotations provided by Allen Institute for Cell Science,>=3.9,"['napari >=0.4.9', 'napari-plugin-engine >=0.1.4', 'numpy', 'xarray >=2022.6.0', 'magicgui >=0.3.7', 'aicspylibczi >=3.0.5', 'fsspec >=2022.8.2', 'bioformats-jar', 'bfio', 'qtpy', 'bioio', 'bioio-ome-tiff', 'bioio-czi', 'bioio-ome-zarr', 'tifffile >=2021.8.30', 'bioio-imageio', ""napari >=0.4.9 ; extra == 'all'"", ""napari-plugin-engine >=0.1.4 ; extra == 'all'"", ""numpy ; extra == 'all'"", ""xarray >=2022.6.0 ; extra == 'all'"", ""magicgui >=0.3.7 ; extra == 'all'"", ""aicspylibczi >=3.0.5 ; extra == 'all'"", ""fsspec >=2022.8.2 ; extra == 'all'"", ""bioformats-jar ; extra == 'all'"", ""bfio ; extra == 'all'"", ""qtpy ; extra == 'all'"", ""bioio ; extra == 'all'"", ""bioio-ome-tiff ; extra == 'all'"", ""bioio-czi ; extra == 'all'"", ""bioio-ome-zarr ; extra == 'all'"", ""tifffile >=2021.8.30 ; extra == 'all'"", ""bioio-imageio ; extra == 'all'"", ""black >=19.10b0 ; extra == 'all'"", ""codecov >=2.0.22 ; extra == 'all'"", ""docutils <0.16,>=0.10 ; extra == 'all'"", ""flake8 >=3.7.7 ; extra == 'all'"", ""psutil >=5.7.0 ; extra == 'all'"", ""pytest >=4.3.0 ; extra == 'all'"", ""pytest-cov ==2.6.1 ; extra == 'all'"", ""pytest-raises >=0.10 ; extra == 'all'"", ""pytest-qt >=3.3.0 ; extra == 'all'"", ""quilt3 >=3.1.12 ; extra == 'all'"", ""pyqt5 ; extra == 'all'"", ""pytest-runner ; extra == 'all'"", ""bumpversion >=0.5.3 ; extra == 'all'"", ""gitchangelog >=3.0.4 ; extra == 'all'"", ""ipython >=7.5.0 ; extra == 'all'"", ""m2r >=0.2.1 ; extra == 'all'"", ""pytest-runner >=4.4 ; extra == 'all'"", ""Sphinx <3,>=2.0.0b1 ; extra == 'all'"", ""sphinx-rtd-theme >=0.1.2 ; extra == 'all'"", ""tox >=3.5.2 ; extra == 'all'"", ""twine >=1.13.0 ; extra == 'all'"", ""wheel >=0.33.1 ; extra == 'all'"", ""black >=19.10b0 ; extra == 'dev'"", ""bumpversion >=0.5.3 ; extra == 'dev'"", ""docutils <0.16,>=0.10 ; extra == 'dev'"", ""flake8 >=3.7.7 ; extra == 'dev'"", ""gitchangelog >=3.0.4 ; extra == 'dev'"", ""ipython >=7.5.0 ; extra == 'dev'"", ""m2r >=0.2.1 ; extra == 'dev'"", ""pytest >=4.3.0 ; extra == 'dev'"", ""pytest-cov ==2.6.1 ; extra == 'dev'"", ""pytest-raises >=0.10 ; extra == 'dev'"", ""pytest-runner >=4.4 ; extra == 'dev'"", ""pytest-qt >=3.3.0 ; extra == 'dev'"", ""quilt3 >=3.1.12 ; extra == 'dev'"", ""Sphinx <3,>=2.0.0b1 ; extra == 'dev'"", ""sphinx-rtd-theme >=0.1.2 ; extra == 'dev'"", ""tox >=3.5.2 ; extra == 'dev'"", ""twine >=1.13.0 ; extra == 'dev'"", ""wheel >=0.33.1 ; extra == 'dev'"", ""pytest-runner ; extra == 'setup'"", ""black >=19.10b0 ; extra == 'test'"", ""codecov >=2.0.22 ; extra == 'test'"", ""docutils <0.16,>=0.10 ; extra == 'test'"", ""flake8 >=3.7.7 ; extra == 'test'"", ""psutil >=5.7.0 ; extra == 'test'"", ""pytest >=4.3.0 ; extra == 'test'"", ""pytest-cov ==2.6.1 ; extra == 'test'"", ""pytest-raises >=0.10 ; extra == 'test'"", ""pytest-qt >=3.3.0 ; extra == 'test'"", ""quilt3 >=3.1.12 ; extra == 'test'"", ""pyqt5 ; extra == 'test'""]","# napari-allencell-annotator

[![License BSD-3](https://img.shields.io/pypi/l/napari-allencell-annotator.svg?color=green)](https://github.com/bbridge0200/napari-allencell-annotator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-allencell-annotator.svg?color=green)](https://pypi.org/project/napari-allencell-annotator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-allencell-annotator.svg?color=green)](https://python.org)
[![tests](https://github.com/bbridge0200/napari-allencell-annotator/workflows/tests/badge.svg)](https://github.com/bbridge0200/napari-allencell-annotator/actions)
[![codecov](https://codecov.io/gh/bbridge0200/napari-allencell-annotator/branch/main/graph/badge.svg)](https://codecov.io/gh/bbridge0200/napari-allencell-annotator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-allencell-annotator)](https://napari-hub.org/plugins/napari-allencell-annotator)

A plugin that enables image annotation/scoring and writes annotations to a .csv file. 
Plugin provided by the Allen Institute for Cell Science.

The Allen Cell Image Annotator plugin for napari provides an intuitive
graphical user interface to create annotation templates, annotate large 
image sets using these templates, and save image annotations to a csv file. 
The Allen Cell Image Annotator is a Python-based open source toolkit 
developed at the Allen Institute for Cell Science for both blind, unbiased and un-blind 
microscope image annotating. This toolkit supports easy image set selection
from a file finder and creation of annotation templates (text, checkbox, drop-down, spinbox, and point).
With napari's multi-dimensional image viewing capabilities, the plugin seamlessly allows users to
view each image and write annotations into the custom template.
Annotation templates can be written to a json file for sharing or re-using. After annotating,
the annotation template, image file list, and the annotation values 
are conveniently saved to csv file, which can be re-opened for further annotating. 

-   Supports the following image types:
    - `OME-TIFF`
    - `TIFF`
    - `CZI` 
    - `PNG` 
    - `JPEG`
    - `OME-ZARR`


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to files up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation using Command Line
### 1. Prerequisites

The plugin requires [Conda](https://docs.anaconda.com/anaconda/install/).
- [Installing on Windows ](https://docs.anaconda.com/anaconda/install/windows/) 
  - Follow the steps linked above except
  - On step 8, check top the box to add to PATH
  - ![Alt text](napari_allencell_annotator/assets/windowsstep8.png)
- [Installing on Mac ](https://docs.anaconda.com/anaconda/install/mac-os/) 

### 2. Install the plugin
Click the link corresponding to your OS.
#### [Windows](https://alleninstitute-my.sharepoint.com/:u:/g/personal/r_dhamrongsirivadh_alleninstitute_org/EexXIxeeIbNEs4KMjimcXOcBMn2J2QwxJhNEkOcRHC1eVg?e=JKa5WI)
- From the link above, click the three dots on the top menu bar and select download. 
- Open a file explorer and go to the Downloads folder. Use **Option 1** below. A prompt window should open and start installing. If this fails use **Option 2**. 
  - **Option 1**: Double-click the file _install_napari.sh_
  - **Option 2**: Search the file finder for Anaconda Prompt. Open version 3. Run the following commands one line at a time. 
    - conda create -n napari_annotator python=3.10 anaconda
    - conda activate napari_annotator
    - python -m pip install --upgrade pip
    - python -m pip install ""napari[all]""
    - python -m pip install napari-allencell-annotator
    - napari
  - **Still not working?** Try using conda forge instead of pip. 
    - Ex: conda install -c conda-forge napari instead of python -m pip install ""napari[all]""
#### [MacOS/Unix](https://alleninstitute-my.sharepoint.com/:u:/g/personal/r_dhamrongsirivadh_alleninstitute_org/ESeAYWwWFuRFhgpqgbiKQ6QBXdU8Dg8OU9ilpJ5VmoY-cA?e=BHpReg)
- From the link above, download the file. 
- Open terminal. 
- Run _chmod +x ./Downloads/install_napari.command_ 
  - If you get a file not found error try adjusting the path to match where install_napari.command was downloaded.
- Open finder, navigate to the file, double-click _install_napari.command_ . 
  - A terminal window should open and start installing. 
  

### 3. Launch the Plugin

Once the napari window opens, go to **Plugins**.
- If **napari-allencell-annotator** is listed click it to launch. 
- If it is not listed 
- **Install/Uninstall Plugins** â¨ check the box next to **napari-allencell-annotator** â¨ **close** â¨ **Plugins** â¨ **napari-allencell-annotator** .

### 4. Re-opening the Plugin After Installing
- Windows
  - Search for anaconda navigator in file finder
  - Click on navigator version 3
  - Once the navigator opens, click **Environments** on the left side
  - Click on the annotator environment and wait for it to load
  - Press the play button
  - Type _napari_ in the prompt that opens
  - Click **Plugins** â¨ **napari-allencell-annotator**
- MacOS
  - Open terminal
  - Run these commands one line at a time
    - conda activate napari_annotator
    - napari
  - Click **Plugins** â¨ **napari-allencell-annotator**

## Installation from Napari Hub
If you have previously installed Napari on your machine, you can follow these steps to install the plugin from Napari Hub.

### 1. Install the Plugin
- Open Napari
- Go to **Plugins** â¨ **Install/Uninstall Plugins...**
- Find **napari-allencell-annotator** in **Available Plugins**
- Click **Install**
- Close the window after the installation finishes

### 2. Launch the Plugin
- Click **Plugins** â¨ **napari-allencell-annotator**
  - You might have to restart Napari for the annotator to appear in the plugin list.
  - If you still can't see the plugin, go to **Install/Uninstall Plugins** â¨ check the box next to **napari-allencell-annotator**.

## Quick Start

1. Open napari
2. Start the plugin 
   - Open napari, go to **Plugins** â¨ **napari-allencell-annotator**.
3. Create or import annotations and add images to annotate.

For more detailed usage instructions, check out this [document](napari_allencell_annotator/assets/AnnotatorInstructions.pdf) 
## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-allencell-annotator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/bbridge0200/napari-allencell-annotator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,napari-allencell-annotator.MainView,,,,
98,napari-allencell-segmenter,napari-allencell-segmenter,napari-allencell-segmenter,2.1.12,2021-06-24,2023-06-21,Allen Institute for Cell Science,,BSD-3,https://github.com/AllenCell/napari-allencell-segmenter/issues,https://pypi.org/project/napari-allencell-segmenter/,,https://github.com/AllenCell/napari-allencell-segmenter,A plugin that enables 3D image segmentation provided by Allen Institute for Cell Science,>=3.7,"['napari (>=0.4.9)', 'napari-plugin-engine (>=0.1.4)', 'numpy', 'aicssegmentation (>=0.5.3)', 'magicgui (>=0.2.9)', 'aicsimageio (~=4.0.5)', 'opencv-python-headless (>=4.5.1)', 'importlib-metadata (==4.11.4)', 'npe2', ""napari (>=0.4.9) ; extra == 'all'"", ""napari-plugin-engine (>=0.1.4) ; extra == 'all'"", ""numpy ; extra == 'all'"", ""aicssegmentation (>=0.5.3) ; extra == 'all'"", ""magicgui (>=0.2.9) ; extra == 'all'"", ""aicsimageio (~=4.0.5) ; extra == 'all'"", ""opencv-python-headless (>=4.5.1) ; extra == 'all'"", ""importlib-metadata (==4.11.4) ; extra == 'all'"", ""npe2 ; extra == 'all'"", ""black (>=19.10b0) ; extra == 'all'"", ""codecov (>=2.0.22) ; extra == 'all'"", ""docutils (<0.16,>=0.10) ; extra == 'all'"", ""flake8 (>=3.7.7) ; extra == 'all'"", ""psutil (>=5.7.0) ; extra == 'all'"", ""pytest (>=4.3.0) ; extra == 'all'"", ""pytest-cov (==2.6.1) ; extra == 'all'"", ""pytest-raises (>=0.10) ; extra == 'all'"", ""pytest-qt (>=3.3.0) ; extra == 'all'"", ""quilt3 (>=3.1.12) ; extra == 'all'"", ""pytest-runner ; extra == 'all'"", ""bumpversion (>=0.5.3) ; extra == 'all'"", ""coverage (>=5.0a4) ; extra == 'all'"", ""gitchangelog (>=3.0.4) ; extra == 'all'"", ""ipython (>=7.5.0) ; extra == 'all'"", ""m2r (>=0.2.1) ; extra == 'all'"", ""pytest-runner (>=4.4) ; extra == 'all'"", ""Sphinx (<3,>=2.0.0b1) ; extra == 'all'"", ""sphinx-rtd-theme (>=0.1.2) ; extra == 'all'"", ""tox (==3.25.0) ; extra == 'all'"", ""twine (>=1.13.0) ; extra == 'all'"", ""wheel (>=0.33.1) ; extra == 'all'"", ""black (>=19.10b0) ; extra == 'dev'"", ""bumpversion (>=0.5.3) ; extra == 'dev'"", ""coverage (>=5.0a4) ; extra == 'dev'"", ""docutils (<0.16,>=0.10) ; extra == 'dev'"", ""flake8 (>=3.7.7) ; extra == 'dev'"", ""gitchangelog (>=3.0.4) ; extra == 'dev'"", ""ipython (>=7.5.0) ; extra == 'dev'"", ""m2r (>=0.2.1) ; extra == 'dev'"", ""pytest (>=4.3.0) ; extra == 'dev'"", ""pytest-cov (==2.6.1) ; extra == 'dev'"", ""pytest-raises (>=0.10) ; extra == 'dev'"", ""pytest-runner (>=4.4) ; extra == 'dev'"", ""pytest-qt (>=3.3.0) ; extra == 'dev'"", ""quilt3 (>=3.1.12) ; extra == 'dev'"", ""Sphinx (<3,>=2.0.0b1) ; extra == 'dev'"", ""sphinx-rtd-theme (>=0.1.2) ; extra == 'dev'"", ""tox (==3.25.0) ; extra == 'dev'"", ""twine (>=1.13.0) ; extra == 'dev'"", ""wheel (>=0.33.1) ; extra == 'dev'"", ""pytest-runner ; extra == 'setup'"", ""black (>=19.10b0) ; extra == 'test'"", ""codecov (>=2.0.22) ; extra == 'test'"", ""docutils (<0.16,>=0.10) ; extra == 'test'"", ""flake8 (>=3.7.7) ; extra == 'test'"", ""psutil (>=5.7.0) ; extra == 'test'"", ""pytest (>=4.3.0) ; extra == 'test'"", ""pytest-cov (==2.6.1) ; extra == 'test'"", ""pytest-raises (>=0.10) ; extra == 'test'"", ""pytest-qt (>=3.3.0) ; extra == 'test'"", ""quilt3 (>=3.1.12) ; extra == 'test'""]","# napari-allencell-segmenter

[![License](https://img.shields.io/pypi/l/napari-allencell-segmenter.svg?color=green)](https://github.com/AllenCell/napari-allencell-segmenter/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-allencell-segmenter.svg?color=green)](https://pypi.org/project/napari-allencell-segmenter)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-allencell-segmenter.svg?color=green)](https://python.org)
[![Anaconda](https://anaconda.org/conda-forge/napari-allencell-segmenter/badges/version.svg)](https://anaconda.org/conda-forge/napari-allencell-segmenter)
[![tests](https://github.com/AllenCell/napari-allencell-segmenter/workflows/tests/badge.svg)](https://github.com/AllenCell/napari-allencell-segmenter/actions)
[![codecov](https://codecov.io/gh/AllenCell/napari-allencell-segmenter/branch/main/graph/badge.svg)](https://codecov.io/gh/AllenCell/napari-allencell-segmenter)


A plugin that enables 3D image segmentation provided by Allen Institute for Cell Science

The Allen Cell & Structure Segmenter plugin for napari provides an intuitive graphical user interface to access the powerful segmentation capabilities of an open source 3D segmentation software package developed and maintained by the Allen Institute for Cell Science (classic workflows only with v1.0). â[The Allen Cell & Structure Segmenter](https://allencell.org/segmenter) is a Python-based open source toolkit developed at the Allen Institute for Cell Science for 3D segmentation of intracellular structures in fluorescence microscope images. This toolkit brings together classic image segmentation and iterative deep learning workflows first to generate initial high-quality 3D intracellular structure segmentations and then to easily curate these results to generate the ground truths for building robust and accurate deep learning models. The toolkit takes advantage of the high replicate 3D live cell image data collected at the Allen Institute for Cell Science of over 30 endogenous fluorescently tagged human induced pluripotent stem cell (hiPSC) lines. Each cell line represents a different intracellular structure with one or more distinct localization patterns within undifferentiated hiPS cells and hiPSC-derived cardiomyocytes.

More details about Segmenter can be found at https://allencell.org/segmenter

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

### Option 1 (recommended):

After you installed the lastest version of napari, you can go to ""Plugins"" --> ""Install/Uninstall Package(s)"". Then, you will be able to see all available napari plugins and you can find us by name `napari-allencell-segmenter`. Just click the ""install"" button to install the Segmenter plugin.

### Option 2:

You can also install `napari-allencell-segmenter` via [pip]:

    pip install napari-allencell-segmenter

## Quick Start

In the current version, there are two parts in the plugin: **workflow editor** and **batch processing**. The **workflow editor** allows users adjusting parameters in all the existing workflows in the lookup table, so that the workflow can be optimized on users' data. The adjusted workflow can be saved and then applied to a large batch of files using the **batch processing** part of the plugin. 

1. Open a file in napari (the plugin is able to support multi-dimensional data in .tiff, .tif. ome.tif, .ome.tiff, .czi)
2. Start the plugin (open napari, go to ""Plugins"" --> ""napari-allencell-segmenter"" --> ""workflow editor"")
3. Select the image and channel to work on
4. Select a workflow based on the example image and target segmentation based on user's data. Ideally, it is recommend to start with the example with very similar morphology as user's data.
5. Click ""Run All"" to execute the whole workflow on the sample data.
6. Adjust the parameters of steps, based on the intermediate results. For instruction on the details on each function and the effect of each parameter, click the tooltip button. A complete list of all functions can be found [here](https://github.com/AllenCell/aics-segmentation/blob/main/aicssegmentation/structure_wrapper_config/function_params.md)
7. Click ""Run All"" again after adjusting the parameters and repeat step 6 and 7 until the result is satisfactory.
8. Save the workflow
9. Close the plugin and open the **batch processing** part by (go to ""Plugins"" --> ""napari-allencell-segmenter"" --> ""batch processing"")
10. Load the customized workflow (or an off-the-shelf workflow) json file
11. Load the folder with all the images to process
12. Click ""Run""

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-allencell-segmenter"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/AllenCell/napari-allencell-segmenter/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 5 - Production/Stable', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Scientific/Engineering :: Information Analysis', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/AllenCell/napari-allencell-segmenter/issues', 'Documentation, https://github.com/AllenCell/napari-allencell-segmenter#README.md', 'Source Code, https://github.com/AllenCell/napari-allencell-segmenter', 'User Support, https://github.com/AllenCell/napari-allencell-segmenter/issues']",,,napari-allencell-segmenter.WorkflowEditorWidget,,,,
99,napari-amdtrk,napari-amdtrk,Amend segmentation and track,1.1.0,2023-04-08,2023-05-06,Yifan Gui,jeffgui9912@gmail.com,MIT,https://github.com/Jeff-Gui/napari-amdtrk-plugin,https://pypi.org/project/napari-amdtrk/,,https://github.com/Jeff-Gui/napari-amdtrk-plugin,Manually amend segmentation and track within napari,>=3.8,"['numpy (<1.24)', 'magicgui', 'qtpy', 'trackpy', 'pandas', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-amdtrk

[![License MIT](https://img.shields.io/pypi/l/napari-amdtrk.svg?color=green)](https://github.com/Jeff-Gui/napari-amdtrk/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-amdtrk.svg?color=green)](https://pypi.org/project/napari-amdtrk)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-amdtrk.svg?color=green)](https://python.org)
[![tests](https://github.com/Jeff-Gui/napari-amdtrk/workflows/tests/badge.svg)](https://github.com/Jeff-Gui/napari-amdtrk/actions)
[![codecov](https://codecov.io/gh/Jeff-Gui/napari-amdtrk/branch/main/graph/badge.svg)](https://codecov.io/gh/Jeff-Gui/napari-amdtrk)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-amdtrk)](https://napari-hub.org/plugins/napari-amdtrk)

Amend segmentation and track within napari manually.

<img src=""preview.png"" alt=""overview"" width=""900"" />


### [:eyes: watch a demo video](https://drive.google.com/file/d/1oHPdYcKv-QgOWylm21DnOF1NlVNsRIcL/view)

----------------------------------

### Input data structure

Napari-amdtrk reads an input directory which includes:
- An intensity image (`tif`) in txyc (or txy) format
- An object mask (`tif`) in txy format
- An object table (`csv`) with following essential columns:
    - frame: time frame
    - trackId: ID of the track, starting from 1
    - Center_of_the_object_0: x coordinate
    - Center_of_the_object_1: y coordinate
    - continuous_label: the corresponding label (intensity value) of the object in the object mask (You may use `skimage.measure.label` to get it from a binary mask).

- A config file named `config.yaml` (_other names are not allowed_)

    Within the config file, there should be:
    - intensity_suffix: suffix of the intensity image (e.g., for `foo_GFP.tif`, use `GFP` in the config). For multiple intensity images, separate them with commas (e.g., `GFP, mCherry`)
    - mask_suffix: suffix of the mask image
    - track_suffix: suffix of the tracked object table
    - frame_base: index of the first frame (either `0` or `1`)
    - stateCol: __optional__ column name for the cell state (e.g., cell cycle phase) in the object table. Leave blank if the object table does not contain it

__Napari-amdtrk will modify mask and track files in place.__ Other files are not affected.

---
### Quick start

1. Open `napari` GUI.
2. `File` > `Open folder` > choose `Amend segmentation and track`
3. `Plugins` > `napari-amdtrk: Amend track widget` > `Run`
4. In `layer list`, select the `segm` layer to start editing.

Please check out the demo video [here](https://drive.google.com/file/d/1oHPdYcKv-QgOWylm21DnOF1NlVNsRIcL/view) and the sample data (see below).

----------------------------------

### Sample data

To load sample data, `File` > `Open Sample` > `napari-amdtrk` > `basic tracks` or `complete cell cycle tracks`.

- basic tracks: simple cell tracks as essential input data.
- complete cell cycle tracks: cell tracks with additional cell cycle features.

The above operations will download data to `~/.amd_trk/_sample_data/` (__~230MB__). After downloading is finished, sample data will be loaded.

_Notes_
- Please cite this repository if using the plugin in your work (try `About` > `Cite this repository` upper right of this homepage).
  
- Sample data (cell track videos) have been published with [_pcnaDeep: a fast and robust single-cell tracking method using deep-learning mediated cell cycle profiling_](10.1093/bioinformatics/btac602). We acknowledge Dr Kuan Yoow Chan and members of his lab for generating the data. 

----------------------------------

### Keyboard shortcuts

- <kbd>&uarr;</kbd> and <kbd>&darr;</kbd>: toggle different operations
- <kbd>enter</kbd>: run the operation

- Available to a selected object:
  - <kbd>control</kbd> + <kbd>9</kbd>: shrink the object mask
  - <kbd>control</kbd> + <kbd>0</kbd>: expand the object mask


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

Please install `napari` GUI first:

    python -m pip install ""napari[all]""

You can install `napari-amdtrk` via [pip]:

    pip install napari-amdtrk


## License

Distributed under the terms of the [MIT] license,
""napari-amdtrk"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/Jeff-Gui/napari-amdtrk-plugin/issues', 'Documentation, https://github.com/Jeff-Gui/napari-amdtrk-plugin/blob/master/README.md', 'Source Code, https://github.com/Jeff-Gui/napari-amdtrk-plugin']",napari-amdtrk.get_reader,,napari-amdtrk.make_amdtrkwidget,,['*'],,
100,napari-animated-gif-io,napari-animated-gif-io,napari-animated-gif-io,0.1.2,2021-12-03,2022-04-15,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-animated-gif-io/issues,https://pypi.org/project/napari-animated-gif-io/,,https://github.com/haesleinhuepf/napari-animated-gif-io,Save 3D image stacks as animated gifs,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'imageio', 'napari-tools-menu', 'napari', 'microfilm']","# napari-animated-gif-io

[![License](https://img.shields.io/pypi/l/napari-animated-gif-io.svg?color=green)](https://github.com/haesleinhuepf/napari-animated-gif-io/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-animated-gif-io.svg?color=green)](https://pypi.org/project/napari-animated-gif-io)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-animated-gif-io.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-animated-gif-io/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-animated-gif-io/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-animated-gif-io/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-animated-gif-io)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-animated-gif-io)](https://napari-hub.org/plugins/napari-animated-gif-io)

Open and save 3D image stacks as animated gifs

You find the menus for opening and saving animated gifs in the `Tools > File Import/Export` menu:

![img.png](https://github.com/haesleinhuepf/napari-animated-gif-io/raw/main/docs/screenshot.png)

Furthermore, if in 3D view, you can save the current view with a little tilt animation as animated gif.
Under the hood this uses the [microfilm](https://github.com/guiwitz/microfilm) library.

![img.png](https://github.com/haesleinhuepf/napari-animated-gif-io/raw/main/docs/video.gif)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-animated-gif-io` via [pip]:

    pip install napari-animated-gif-io



To install latest development version :

    pip install git+https://github.com/haesleinhuepf/napari-animated-gif-io.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-animated-gif-io"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-animated-gif-io/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-animated-gif-io/issues', 'Documentation, https://github.com/haesleinhuepf/napari-animated-gif-io#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-animated-gif-io', 'User Support, https://github.com/haesleinhuepf/napari-animated-gif-io/issues']",,napari-animated-gif-io.napari_write_image,napari-animated-gif-io.napari_experimental_provide_function,,,,
101,napari-animation,napari-animation,napari-animation,0.0.9,2021-04-23,2025-07-23,"Nicholas Sofroniew, Alister Burt, Guillaume Witz, Faris Abouakil, Talley Lambert, napari",,BSD 3-Clause,https://github.com/napari/napari-animation,https://pypi.org/project/napari-animation/,,https://github.com/napari/napari-animation,A plugin for making animations in napari,>=3.10,"['imageio', 'imageio-ffmpeg', 'napari>=0.5', 'npe2', 'numpy', 'qtpy', 'scipy', 'tqdm>=4.56.0', 'superqt', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'tox; extra == ""testing""', 'sphinx>6; extra == ""doc""', 'sphinx-autobuild; extra == ""doc""', 'sphinx-external-toc; extra == ""doc""', 'sphinx-copybutton; extra == ""doc""', 'sphinx-gallery; extra == ""doc""', 'sphinx-favicon; extra == ""doc""', 'sphinxcontrib-video; extra == ""doc""', 'matplotlib; extra == ""doc""', 'myst-nb; extra == ""doc""', 'napari-sphinx-theme>=0.3.0; extra == ""doc""', 'pre-commit; extra == ""dev""', 'black; extra == ""dev""', 'ruff; extra == ""dev""', 'check-manifest; extra == ""dev""', 'pytest; extra == ""dev""', 'pytest-cov; extra == ""dev""', 'pytest-qt; extra == ""dev""', 'tox; extra == ""dev""', 'sphinx>6; extra == ""dev""', 'sphinx-autobuild; extra == ""dev""', 'sphinx-external-toc; extra == ""dev""', 'sphinx-copybutton; extra == ""dev""', 'sphinx-gallery; extra == ""dev""', 'sphinx-favicon; extra == ""dev""', 'sphinxcontrib-video; extra == ""dev""', 'matplotlib; extra == ""dev""', 'myst-nb; extra == ""dev""', 'napari-sphinx-theme>=0.3.0; extra == ""dev""']","# napari-animation

[![License](https://img.shields.io/pypi/l/napari-animation.svg?color=green)](https://github.com/napari/napari-animation/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-animation.svg?color=green)](https://pypi.org/project/napari-animation)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-animation.svg?color=green)](https://python.org)
[![tests](https://github.com/napari/napari-animation/actions/workflows/test_and_deploy.yml/badge.svg)](https://github.com/napari/napari-animation/actions)
[![codecov](https://codecov.io/gh/napari/napari-animation/branch/main/graph/badge.svg)](https://codecov.io/gh/napari/napari-animation)

**napari-animation** is a plugin for making animations in [napari](https://napari.org).

<p align=""center"">
  <img width=""500"" src=""https://user-images.githubusercontent.com/7307488/196110138-6c4663b1-67b2-4c79-97b7-57b706d1d49c.gif"">
</p>

----------------------------------

[Merlin Lange](https://twitter.com/Merlin_Lange) used *napari-animation* to create one of [Nature's best science images for September 2022](https://www.nature.com/immersive/d41586-022-03051-6/index.html)

----------------------------------

This plugin is built on [`naparimovie`](https://github.com/guiwitz/naparimovie) from [@guiwitz](https://github.com/guiwitz). `naparimovie` was submitted to napari in [PR#851](https://github.com/napari/napari/pull/780) before napari plugin infrastructure existed.

----------------------------------

## Overview

**napari-animation** provides a framework for the creation of animations in napari. The plugin contains:

- an easy to use GUI for creating animations interactively;
- a Python package for the programmatic creation of animations.

This plugin remains under development and contributions are very welcome, please open an issue to discuss potential improvements.

You can read the documentation at [https://napari.org/napari-animation](https://napari.org/napari-animation)

## Installation

### PyPI
`napari-animation` is available through the Python package index and can be installed using `pip`.

```sh
pip install napari-animation
```

```{warning}
`napari-animation` uses `ffmpeg` to export animations. If you are using a macOS arm64 computer (Apple Silicon e.g. M1, M2 processor)
the PyPI package does not include the needed binary for your platform. You will need to install `ffmpeg` using
`conda` from the [conda-forge channel](https://conda-forge.org/docs/#what-is-conda-forge) (`conda install -c conda-forge ffmpeg`)
or using [`homebrew`](https://brew.sh) (`brew install ffmpeg`).
```

### Conda
`napari-animation` is also available for install using `conda` through the [conda-forge channel](https://conda-forge.org/docs/#what-is-conda-forge).

```sh
conda install -c conda-forge napari-animation
```

### Local
You can clone this repository and install locally with

    pip install -e .

### Interactive use
**napari-animation** can be used interactively.

An animation is created by capturing [keyframes](https://en.wikipedia.org/wiki/Key_frame) containing the current viewer state.

<p align=""center"">
  <img width=""600"" src=""https://user-images.githubusercontent.com/7307488/196113682-96ce0da3-fa5c-411e-8fb1-52dc3a8f96b6.png"">
</p>

To activate the GUI, select **napari-animation: wizard** from the *plugins menu*

<p align=""center"">
  <img width=""200"" src=""https://user-images.githubusercontent.com/7307488/196114466-56cb5985-0d79-4cfa-96f1-38cf3ccfbc48.png"">
</p>

### Scripting

**napari-animation** can also be run programatically, allowing for reproducible, scripted creation of animations.

```python
from napari_animation import Animation

animation = Animation(viewer)

viewer.dims.ndisplay = 3
viewer.camera.angles = (0.0, 0.0, 90.0)
animation.capture_keyframe()
viewer.camera.zoom = 2.4
animation.capture_keyframe()
viewer.camera.angles = (-7.0, 15.7, 62.4)
animation.capture_keyframe(steps=60)
viewer.camera.angles = (2.0, -24.4, -36.7)
animation.capture_keyframe(steps=60)
viewer.reset_view()
viewer.camera.angles = (0.0, 0.0, 90.0)
animation.capture_keyframe()
animation.animate('demo.mov', canvas_only=False)
```

## Examples

Examples can be found in our [Examples gallery](https://napari.org/napari-animation/gallery), generated from [our example scripts](https://github.com/napari/napari-animation/tree/main/examples). Simple examples for both interactive and headless
use of the plugin follow.

## Contributing

Contributions are very welcome and a detailed contributing guide is coming soon.
In the meantime, clone this repository and install it in editable mode using `pip`:

```
pip install -e .
```
We recommend using a virtual environment, for example `conda`.


```{important}
Ensure you have a suitable Qt backend for napari! We recommend `PyQt5`.
For more information, see the napari [Qt backend installation guide](https://napari.org/stable/tutorials/fundamentals/installation.html#choosing-a-different-qt-backend)
```

To set up your development installation, clone this repository, navigate to the clone folder, and install napari-animation in editable mode using `pip`.

```sh
conda create -n nap-anim python=3.10
conda activate nap-anim
pip install -e "".[dev]"" PyQt5

```

Tests are run with `pytest`.
You can make sure your `[dev]` installation is working properly by running
`pytest .` from within the repository.

```{note}
We use [`pre-commit`](https://pre-commit.com) to sort imports and lint with
[`ruff`](https://github.com/astral-sh/ruff) and format code with
[`black`](https://github.com/psf/black) automatically prior to each commit.
To minmize test errors when submitting pull requests, please install `pre-commit`
in your environment as follows:

`pre-commit install`
```

## Documentation

The documentation is available at [https://napari.org/napari-animation](https://napari.org/napari-animation)

The documentation for napari-animation is built with [Sphinx](https://www.spinx-doc.org) and the [napari Sphinx Theme](https://github.com/napari/napari-sphinx-theme).

### Building docs locally

After installing the documentation dependencies with

```sh
pip install "".[doc]""
```

you can see a local version of the documentation by running

```sh
make docs
```

Open up the `docs/_build/index.html` file in your browser, and you'll see the home page of the docs being displayed.

### Deploying docs

The napari-animation documentation is automatically built and deployed to the website
whenever the main branch is updated, or a new release is tagged.
This is controlled by the [deploy_docs.yml](https://github.com/napari/napari-animation/blob/main/.github/workflows/deploy_docs.yml) github actions script.

You can also manually trigger a documenation re-build and deployment [from the github actions tab](https://github.com/napari/napari-animation/actions/workflows/deploy_docs.yml).

## License

Distributed under the terms of the [BSD-3 license](http://opensource.org/licenses/BSD-3-Clause),
`napari-animation` is free and open source software.

## Issues

If you encounter any problems, please [file an issue](https://github.com/napari/napari-animation/issues) along with a detailed description.

[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/napari/napari-animation/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Visualization', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,napari-animation.make_animation_widget,,,,
102,napari-annotate,napari-annotate,napari-annotate,0.0.2,2022-11-03,2023-06-05,Jules Scholler,jules.scholler@wysscenter.ch,MPL-2.0,,https://pypi.org/project/napari-annotate/,https://github.com/WyssCenter,https://github.com/WyssCenter,Annotate large 2D slides,>=3.8,"['numpy', 'napari[all]', 'napari-tools-menu', 'magic-class', 'napari-plugin-engine (>=0.1.4)']","Plugin for annotating TissueScope data.

The plugin will be automatically deployed on Pypi and Napari hub upon release on GitHub (assign a new tag for it to be pushed correctly.)
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)']",,,,napari-annotate.next_slide_huron,,,,
103,napari-annotation-project,napari-annotation-project,napari-annotation-project,0.2.0,2023-11-01,2025-04-08,Guillaume Witz,guillaume.witz@unibe.ch,BSD-3-Clause,https://github.com/guiwitz/napari-annotation-project/issues,https://pypi.org/project/napari-annotation-project/,,https://github.com/guiwitz/napari-annotation-project,A napari plugin to keep images and annotations as a re-loadable project,>=3.9,"['numpy', 'PyYAML', 'scikit-image', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-annotation-project

[![License](https://img.shields.io/pypi/l/napari-annotation-project.svg?color=green)](https://github.com/guiwitz/napari-annotation-project/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-annotation-project.svg?color=green)](https://pypi.org/project/napari-annotation-project)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-annotation-project.svg?color=green)](https://python.org)
[![tests](https://github.com/guiwitz/napari-annotation-project/workflows/tests/badge.svg)](https://github.com/guiwitz/napari-annotation-project/actions)
[![codecov](https://codecov.io/gh/guiwitz/napari-annotation-project/branch/main/graph/badge.svg)](https://codecov.io/gh/guiwitz/napari-annotation-project)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-annotation-project)](https://napari-hub.org/plugins/napari-annotation-project)

This napari plugin allows to define projects consisting of multiple images that can be annotated with labels and rectangular regions of interest (rois). Those rois can then be exported as series of cropped images and labels, typically to train Machine Learning models. Projects can be easily reopened in order to browse through images and their annotations. This package is a meant to be a *light-weight plugin which does not introduce any specific dependencies* and that should be easily installable in any environment already containing napari and other plugins.

## Usage
To start a project, you can just drag and drop files in the file list area. This prompts for the selection of a project folder. After that, more files (also from different folders) can be dragged and dropped to be included in the project. Files can optionally be copied to the project folder but this option has to be set **before adding files**. When selecting a file in the list, it is opened (using the default image reader or a reader plugin if installed) and two layers, one for rois, and one for annotations are added.

https://user-images.githubusercontent.com/4622767/147265874-57dcd956-4d54-4c76-9129-c1fc2837e6a4.mp4

### Adding rois
After selecting the ```rois``` layer, you can add rectangular rois to the image. If you need square rois of a specific size (as often needed in DL training) you can select the ```Fixed roi size``` option and then use the ```Add roi``` button. **Note that currently only 2D rois are supported**. If you work with nD images, the roi is therefore added to the **current selected 2D plane**.

### Adding annotations
After selecting the ```annotations``` layer, you can add annotations to your image. There are no restrictions here and you can e.g. add as many labels as you need.

### Info storage
All relevant information on project location, project files and rois is stored in a yaml file ```Parameters.yml```. Annotations are stored as 2D tiff files in the ```annotations``` as files named after the original files. **Note that at the moment if multiple files have the same name, this will cause trouble**. This parameter file is used when re-loading an existing project.

https://user-images.githubusercontent.com/4622767/147265984-adb6ee1f-9319-45c9-a9a4-735ade2a3905.mp4

## Exporting rois
Once you are satisfied with your annotations and rois, you can use the rois to export only the corresponing cropped rois of both the image and annotation layers. For this you can head to the ```Export``` tab. Here you can set the location of the export folder, set the names of the folders that will contain cropped images and cropped annotations, and finally set the prefix names for these two types of files. Files are exported as tif files. 

https://user-images.githubusercontent.com/4622767/147266002-9c4485c9-5bcc-4c64-9c92-6c06775e2711.mp4

## Installation


You can install `napari-annotation-project` via [pip]:

    pip install napari-annotation-project

To install latest development version :

    pip install git+https://github.com/guiwitz/napari-annotation-project.git

## Contributing

Contributions are very welcome. Tests can be run with [tox].

## License

Distributed under the terms of the [BSD-3] license,
""napari-annotation-project"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/guiwitz/napari-annotation-project/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/guiwitz/napari-annotation-project/issues', 'Documentation, https://github.com/guiwitz/napari-annotation-project#README.md', 'Source Code, https://github.com/guiwitz/napari-annotation-project', 'User Support, https://github.com/guiwitz/napari-annotation-project/issues']",,,napari-annotation-project.make_qwidget,,,,
104,napari-annotator,napari-annotator,Annotator,0.1.1,2022-03-07,2025-01-03,LoÃ¯c Sauteur,loic.sauteur@unibas.ch,"Copyright (c) 2025, LoÃ¯c Saute...",https://github.com/loicsauteur/napari-annotator/issues,https://pypi.org/project/napari-annotator/,,,A lightweight plugin extending label layer control,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'napari>=0.5.5', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-annotator

[![License BSD-3](https://img.shields.io/pypi/l/napari-annotator.svg?color=green)](https://github.com/loicsauteur/napari-annotator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-annotator.svg?color=green)](https://pypi.org/project/napari-annotator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-annotator.svg?color=green)](https://python.org)
[![tests](https://github.com/loicsauteur/napari-annotator/workflows/tests/badge.svg)](https://github.com/loicsauteur/napari-annotator/actions)
[![codecov](https://codecov.io/gh/loicsauteur/napari-annotator/branch/main/graph/badge.svg)](https://codecov.io/gh/loicsauteur/napari-annotator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-annotator)](https://napari-hub.org/plugins/napari-annotator)

A lightweight plugin extending label layer control.

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->
## Description
This lightweight plugin helps you navigate your labels layer. It is intended to ease your manual annotation work.
![Overview image](resources/image1.png)
- Select a label from the list.
- Toggle the visibility of individual label entries.
- Move to the centroid of a label at the current zoom.
- Change the color of individual labels.
- Erase all drawn pixels of a given label.
- Restore an erased label.

Version >=0.1.0 works for napari version >= 0.5.5

Version <0.1.0 should work for napari version < 0.4.19

## Usage
Start the plugin `Plugins > Annotator (Annotator)`.

The plugin will list available labels once a labels layer is selected and labels drawn.

Color shuffling for labels will not work, since the plugin sets the color mode of the layer to `direct`.
But you can always change the color of individual labels, using the color picker.

## Known limitations
1. Locating / moving to the center of a label only works on 2D/3D label layers, i.e.:
   1. single- / multi-channel 2D label layers.
   2. single-channel 3D label layers (the third dimension being either Z or T).
2. (Theoretical) maximum of 20'000 labels supported.
<!-- increasing the number is possible, but will introduce bigger lag, as each color/visibility change re-creates the colormap.-->
3. Restoring an erased labels is lost after switching between layers.




## Installation

You can install `napari-annotator` via [pip]:

    pip install napari-annotator


To install latest development version :

    pip install git+https://github.com/loicsauteur/napari-annotator.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-annotator"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.
Or open a thread on [forum.image.sc](https://forum.image.sc) with a detailed description
and a [@loicsauteur](https://github.com/loicsauteur) tag.


[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/loicsauteur/napari-annotator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/loicsauteur/napari-annotator/issues', 'Documentation, https://github.com/loicsauteur/napari-annotator#README.md', 'Source Code, https://github.com/loicsauteur/napari-annotator', 'User Support, https://github.com/loicsauteur/napari-annotator/issues']",,,napari-annotator.annotator,,,,
105,napari-apple,napari-apple,Apple,0.0.8,2022-06-23,2024-04-24,Herearii Metuarea,herearii.metuarea@gmail.com,BSD-3-Clause,https://github.com/hereariim/napari-apple/issues,https://pypi.org/project/napari-apple/,,https://github.com/hereariim/napari-apple,Detection of apple based on YOLOv4 model,>=3.8,"['numpy', 'magicgui', 'qtpy', 'opencv-python-headless', 'scikit-image', 'napari', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-apple

[![License BSD-3](https://img.shields.io/pypi/l/napari-apple.svg?color=green)](https://github.com/hereariim/napari-apple/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-apple.svg?color=green)](https://pypi.org/project/napari-apple)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-apple.svg?color=green)](https://python.org)
[![tests](https://github.com/hereariim/napari-apple/workflows/tests/badge.svg)](https://github.com/hereariim/napari-apple/actions)
[![codecov](https://codecov.io/gh/hereariim/napari-apple/branch/main/graph/badge.svg)](https://codecov.io/gh/hereariim/napari-apple)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-apple)](https://napari-hub.org/plugins/napari-apple)

Detection of apple based on YOLOv4-tiny model

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

Before you can operate the module, you must install the `napari-apple` module.

### Instruction for napari-module

You can install `napari-apple` via [pip]:

    pip install napari-apple

To install latest development version :

    pip install git+https://github.com/hereariim/napari-apple.git

## How does it works

Here, user drop its images in the napari windows. The plugin shows two widgets : 
- Image detection
- Export data

In Image detection, user select the interesting layer to detect apple. The ""Run"" button run the inference detection based on Yolov4-tiny model. At the end, the result is displayed on screen. User can correct freely the detection by removing or adding box in image.

In Export data, user export select the interesting shape layer and RGB image. A button ""Save to csv"" save bounding box coordinate in Yolo way into a text file.

![Capture d'Ã©cran 2024-04-24 114340](https://github.com/hereariim/napari-apple/assets/93375163/d8873a6a-8ebb-4686-bfe9-e7e7729378b1)


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-apple"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hereariim/napari-apple/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/hereariim/napari-apple/issues', 'Documentation, https://github.com/hereariim/napari-apple#README.md', 'Source Code, https://github.com/hereariim/napari-apple', 'User Support, https://github.com/hereariim/napari-apple/issues']",napari-apple.get_reader,napari-apple.write_multiple,napari-apple.image_detection,napari-apple.make_sample_data,['*.npy'],,['.npy']
106,napari-apr-viewer,napari-apr-viewer,napari-apr-viewer,1.0.1,2021-11-30,2023-11-08,Joel Jonsson,jonsson@mpi-cbg.de,Apache-2.0,,https://pypi.org/project/napari-apr-viewer/,None,,A simple plugin to view APR images in napari,>=3.8,"['numpy', 'pyapr >=1.0.0rc1', 'napari', 'napari-plugin-engine >=0.1.4', 'qtpy', 'magicgui']","# napari-apr-viewer

[![License](https://img.shields.io/pypi/l/napari-apr-viewer.svg?color=green)](https://github.com/AdaptiveParticles/napari-apr-viewer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-apr-viewer.svg?color=green)](https://pypi.org/project/napari-apr-viewer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-apr-viewer.svg?color=green)](https://python.org)
[![tests](https://github.com/AdaptiveParticles/napari-apr-viewer/workflows/tests/badge.svg)](https://github.com/AdaptiveParticles/napari-apr-viewer/actions)
[![codecov](https://codecov.io/gh/AdaptiveParticles/napari-apr-viewer/branch/main/graph/badge.svg)](https://codecov.io/gh/AdaptiveParticles/napari-apr-viewer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-apr-viewer)](https://napari-hub.org/plugins/napari-apr-viewer)

A simple plugin to create and view APR images in napari

## Usage

To get started, open an image of your choice (2D or 3D grayscale) in napari and open the `convert_image_to_apr` panel. Select the image layer to convert, an appropriate data type, and hit `Run`. 

**Note:** choosing a data type smaller than the input type may lead to overflow and thus erroneous results.

Conversion parameters can often be left to their default values, thanks to the automatic parameter tuning. For very noisy images, it is sometimes useful to increase the `smoothing` parameter. In order to get a more (or less) aggressive adaptation, change the `relative error` parameter.

![conversion.png](https://github.com/AdaptiveParticles/napari-apr-viewer/raw/main/docs/conversion.png)

To save the result to file, simply save the newly created layer using the `File` menu. We use the extension `.apr`, although the file is actually written in `hdf5` format (and can be opened/explored as such). In this example, the APR is roughly 80 times smaller than the original image on disk. APR files can be opened directly in napari, e.g. by drag and drop.

![apr_file.png](https://github.com/AdaptiveParticles/napari-apr-viewer/raw/main/docs/apr_file.png)

To better understand the workings of the APR on your data, you can use the `APR Viewer` panel to change the `View mode` for a selected APR layer to `level`. This shows you a visualization of the adaptive resolution. Particles in the brightest regions correspond exactly to pixels (lossless), while each shade darker corresponds to downsampling by a factor of 2 in each dimension.

![view_level.png](https://github.com/AdaptiveParticles/napari-apr-viewer/raw/main/docs/view_level.png)

The `Downsample` slider can be used to reduce the resolution of the displayed data for the selected layer. This can be used to explore large volumes in 3D, where rendering the full data requires too much memory. 

**Note:** We do not offer APR-native rendering at this time, so this step will reconstruct the entire pixel volume (at the selected resolution). Thus, for large volumes, be sure to increase the downsampling before toggling the 3D viewer. 

![view_3D.png](https://github.com/AdaptiveParticles/napari-apr-viewer/raw/main/docs/view_3D.png)

![view_3D_ds.png](https://github.com/AdaptiveParticles/napari-apr-viewer/raw/main/docs/view_3D_downsampled.png)

_The data shown in these examples was taken from the Platynereis-ISH-Nuclei-CBG dataset available [here](https://github.com/juglab/EmbedSeg/releases)._

&nbsp;

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-apr-viewer` via [pip]:

    pip install napari-apr-viewer

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-apr-viewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

[file an issue]: https://github.com/AdaptiveParticles/napari-apr-viewer/issues
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'License :: OSI Approved :: Apache Software License']",,napari-apr-viewer.napari_get_reader,napari-apr-viewer.napari_write_image,napari-apr-viewer.APRViewer,,['*'],,
107,napari-aphid,napari-aphid,Aphid,1.1.7,2023-01-13,2023-06-30,Herearii Metuarea,herearii.metuarea@gmail.com,BSD-3-Clause,https://github.com/hereariim/napari-aphid/issues,https://pypi.org/project/napari-aphid/,,https://github.com/hereariim/napari-aphid,A plugin to classify aphids by stage of development.,>=3.8,"['napari', 'numpy', 'magicgui', 'qtpy', 'opencv-python-headless', 'scikit-learn', 'scikit-image', 'h5py', 'matplotlib', 'pandas', 'scipy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-aphid

[![License BSD-3](https://img.shields.io/pypi/l/napari-aphid.svg?color=green)](https://github.com/hereariim/napari-aphid/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-aphid.svg?color=green)](https://pypi.org/project/napari-aphid)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-aphid.svg?color=green)](https://python.org)
[![tests](https://github.com/hereariim/napari-aphid/workflows/tests/badge.svg)](https://github.com/hereariim/napari-aphid/actions)
[![codecov](https://codecov.io/gh/hereariim/napari-aphid/branch/main/graph/badge.svg)](https://codecov.io/gh/hereariim/napari-aphid)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-aphid)](https://napari-hub.org/plugins/napari-aphid)

A plugin to classify aphids by stage of development.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started
and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-aphid` via [pip]:

    pip install napari-aphid

To install latest development version :

    pip install git+https://github.com/hereariim/napari-aphid.git

## Description

This plugin is a tool to count the number of aphids from two models developed on ilastik. Implemented in napari, this tool allows the correction of pixels and labels that are not well 
predicted. 

In this plugin we find our two main parts of the aphid counting model presented in two widgets. A third widget allows to save the updates applied on the segmentation mask.

This plugin is an use cas, dedicated to private use of french laboratory.

## Plugin input

### Segmentation

The user must give two objects as input:

- Compressed file in .zip format
- Ilastik pixel classification model in .ilp format

In particular, compressed file must be organized as follows:

```
.
âââ Country.zip
    âââ Country
        âââ Area1
        â   âââ Area1.im_1.tif
        â   âââ Area1.im_1.h5
        â   âââ Area1.im_2.tif 
        â   âââ Area1.im_2.h5  
        â   âââ Area1.im_3.tif
        â   âââ Area1.im_3.h5
        â   ...
        â   âââ Area1.im_n.tif
        â   âââ Area1.im_n.h5
        â
        âââ Area2
        â   âââ Area2.im_1.tif
        â   âââ Area2.im_1.h5
        â   âââ Area2.im_2.tif
        â   âââ Area2.im_2.h5
        â   âââ Area2.im_3.tif
        â   âââ Area2.im_3.h5
        â   ...
        â   âââ Area2.im_n.tif
        â   âââ Area2.im_n.h5
        â
        ...
        â
        âââ Arean
            âââ Arean.im_1.tif
            âââ Arean.im_1.h5
            âââ Arean.im_2.tif
            âââ Arean.im_2.h5
            âââ Arean.im_3.tif
            âââ Arean.im_3.h5
            ...
            âââ Arean.im_n.tif
            âââ Arean.im_n.h5
```

In each folder Area1, Area2, ..., Arean, we notice that **each tif image is accompanied by its h5 version**. The images in h5 format were generated by the Export h5 widget of the Ilastik plugin in the ImageJ software.

### Classification

The user must give the Ilastik object classification model in .ilp format.

## Widget: Image segmentation

This widget is a tool to segment a set of images. It takes as input a compressed file of images and an ilastik segmentation model. A Run button is used to start the image segmentation process. In the background, the console presents the progress status. This widget returns a menu which is a list of processed images. This list allows an RGB image and its segmentation mask to be displayed in the napari window.

![segmentation_cpe](https://user-images.githubusercontent.com/93375163/212323051-bc84d597-a9ff-46ca-b897-cb18a0e77b4c.png)

**User conduct :** In this widget, the user corrects the image with the annotation tools (brush and eraser only). With the brush, he/she has to add the same colour presented in the image. To obtain this colour, the user can take the color with the color picker tool. With the eraser, he/she erase colour not well predicted. Tous les annotations appliquÃ©es dans l'image doit Ãªtre sauvegarder avec le bouton *Save* du widget **Save modification**

## Widget: Save modification

This is the backup of the segmentation mask. It saves updates applied to the mask.

## Widget: Object classification

This widget is a tool to classify segmented images. It takes as input an ilastik object classification model. A Run button is used to start the classification process. In the background, the console shows the progress of the image processing. This widget returns a menu that lists the processed images. This list provides two elements. The first is the display of the selected image in the window. The second is the display of a table that shows the predicted classes for each object.

![classification_cpe](https://user-images.githubusercontent.com/93375163/212323369-32423622-4f41-4dcb-800b-39ff66be67f9.png)

**User conduct :** In this widget, the user corrects labels not well predicted in the table at the bottom right. He must not forget to save his correction with the Save button.
When the user has finished with all his images, he uses the Export button to import a quantitative table. This table contains for each image, the name of the aphid type and its size in pixels.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-aphid"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hereariim/napari-aphid/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hereariim/napari-aphid/issues', 'Documentation, https://github.com/hereariim/napari-aphid#README.md', 'Source Code, https://github.com/hereariim/napari-aphid', 'User Support, https://github.com/hereariim/napari-aphid/issues']",,,napari-aphid.process_segmentation,,,,
108,napari-annotatorj,napari-annotatorj,napari-annotatorj,0.0.8,2022-05-26,2023-12-14,Reka Hollandi,reka.hollandi@gmail.com,BSD-3-Clause,https://github.com/spreka/napari-annotatorj/issues,https://pypi.org/project/napari-annotatorj/,,https://github.com/spreka/napari-annotatorj,The napari adaptation of the ImageJ/Fiji plugin AnnotatorJ for easy image annotation.,>=3.7,"['napari', 'napari-plugin-engine >=0.1.4', 'numpy', 'roifile', 'scikit-image', 'opencv-python >=4.5.5', 'keras', 'tensorflow >=2.5.0', 'tifffile', 'imagecodecs', 'tqdm', 'pyqtgraph']","# napari-annotatorj

[![License](https://img.shields.io/pypi/l/napari-annotatorj.svg?color=green)](https://github.com/spreka/napari-annotatorj/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-annotatorj.svg?color=green)](https://pypi.org/project/napari-annotatorj)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-annotatorj.svg?color=green)](https://python.org)
[![tests](https://github.com/spreka/napari-annotatorj/workflows/tests/badge.svg)](https://github.com/spreka/napari-annotatorj/actions)
[![codecov](https://codecov.io/gh/spreka/napari-annotatorj/branch/main/graph/badge.svg)](https://codecov.io/gh/spreka/napari-annotatorj)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-annotatorj)](https://napari-hub.org/plugins/napari-annotatorj)

The napari adaptation of the ImageJ/Fiji plugin [AnnotatorJ](https://github.com/spreka/annotatorj) for easy image annotation.

![image](https://drive.google.com/uc?export=view&id=1fVfvanffTdrXvLE0m1Yo6FV5TAjh6sb2)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

Installation is possible with [pip](#pip), [napari](#bundled-napari-app) or [scripts](#script).
### Pip
You can install `napari-annotatorj` via [pip]:

    pip install napari[all]
	pip install napari-annotatorj



To install latest development version :

    pip install git+https://github.com/spreka/napari-annotatorj.git


On Linux distributions, the following error may arise upon napari startup after the installation of the plugin: `Could not load the Qt platform plugin âxcbâ in ââ even though it was found`. In this case, the manual install of `libxcb-xinerama0` for Qt is required:

	sudo apt install libxcb-xinerama0

### Bundled napari app
The bundled application version of [napari](https://github.com/napari/napari/releases) allows the pip install of plugins in the .zip distribution. After installation of this release, napari-annotatorj can be installed from the `Plugins --> Install/Uninstall plugins...` menu by searching for its name and clicking on the `Install` button next to it.

### Script
Single-file install is supported on [**Windows**](#windows) and [Linux](#linux) (currently). It will create a virtual environment named `napariAnnotatorjEnv` in the parent folder of the cloned repository, install the package via pip and start napari. It requires a valid Python install.

#### Windows
To start it, run in the Command prompt

	git clone https://github.com/spreka/napari-annotatorj.git
	cd napari-annotatorj
	install.bat

Or download [install.bat](https://github.com/spreka/napari-annotatorj/blob/main/install.bat) and run it from the Command prompt.

After install, you can use [startup_napari.bat](https://github.com/spreka/napari-annotatorj/blob/main/startup_napari.bat) to activate your installed virtual environment and run napari. Run it from the Command prompt with:

	startup_napari.bat


#### Linux
To start it, run in the Terminal

	git clone https://github.com/spreka/napari-annotatorj.git
	cd napari-annotatorj
	install.sh

Or download [install.sh](https://github.com/spreka/napari-annotatorj/blob/main/install.sh) and run it from the Terminal.

After install, you can use [startup_napari.sh](https://github.com/spreka/napari-annotatorj/blob/main/startup_napari.sh) to activate your installed virtual environment and run napari. Run it from the Terminal with:

	startup_napari.sh

***
## Intro

napari-annotatorj has several convenient functions to speed up the annotation process, make it easier and more fun. These *modes* can be activated by their corresponding checkboxes on the left side of the main AnnotatorJ widget.

- [Contour assist mode](#contour-assist-mode)
- [Edit mode](#edit-mode)
- [Class mode](#class-mode)
- [Overlay](#overlay)

Freehand drawing is enabled in the plugin. The ""Add polygon"" tool is selected by default upon startup. To draw a freehand object (shape) simply hold the mouse and drag it around the object. The contour is visualized when the mouse button is released.

See the [guide](#how-to-annotate) below for a quick start or a [demo](#demo). See [shortcuts](#shortcuts) for easy operation.

***
## How to annotate

1. Open --> opens an image
2. (Optionally) 
	- ... --> Select annotation type --> Ok --> a default tool is selected from the toolbar that fits the selected annotation type
	- The default annotation type is instance
	- Selected annotation type is saved to a config file
3. Start annotating objects
	- [instance](#instance-annotation): draw contours around objects
	- [semantic](#semantic-annotation): paint the objects' area
	- [bounding box](#bounding-box-annotation): draw rectangles around the objects
4. Save --> Select class --> saves the annotation to a file in a sub-folder of the original image folder with the name of the selected class

5. (Optionally)
	- Load --> continue a previous annotation
	- Overlay --> display a different annotation as overlay (semi-transparent) on the currently opened image
	- Colours --> select annotation and overlay colours
	- ... (coming soon) --> set options for semantic segmentation and *Contour assist* mode
	- checkboxes --> Various options
		- (default) Add automatically --> adds the most recent annotation to the ROI list automatically when releasing the left mouse button
		- Smooth (coming soon) --> smooths the contour (in instance annotation type only)
		- Show contours --> displays all the contours in the ROI list
		- Contours assist --> suggests a contour in the region of an initial, lazily drawn contour using the deep learning method U-Net
		- Show overlay --> displays the overlayed annotation if loaded with the Overlay button
		- Edit mode --> edits a selected, already saved contour in the ROI list by clicking on it on the image
		- Class mode --> assigns the selected class to the selected contour in the ROI list by clicking on it on the image and displays its contour in the class's colour (can be set in the Class window); clicking on the object a second time unclassifies it
	- [^] --> quick export in 16-bit multi-labelled .tiff format; if classified, also exports by classes

***
## Instance annotation
Allows freehand drawing of object contours (shapes) with the mouse as in ImageJ.

Shape contour points are tracked automatically when the left mouse button is held and dragged to draw a shape. The shape is closed when the mouse button is released, automatically, and added to the default shapes layer (named ""ROI""). In direct selection mode (from the layer controls panel), you can see the saved contour points. The slower you drag the mouse, the more contour points saved, i.e. the more refined your contour will be.

Click to watch demo video below.

[![instance-annot-demo](https://drive.google.com/uc?export=view&id=1sBg19d_hqGH-UI8irkrwame7ZjrldwHr)](https://drive.google.com/uc?export=view&id=1wELreE9MdCZq4Kf4oCWdxIw4e5o05XzK ""Click to watch instance annotation demo"")

***
## Semantic annotation
Allows painting with the brush tool (labels).

Useful for semantic (e.g. scene) annotation. Currently saves all labels to binary mask only (foreground-background).

***
## Bounding box annotation
Allows drawing bounding boxes (shapes, rectangles) around objects with the mouse.

Useful for object detection annotation.

***
## Contour assist mode
Assisted annotation via a pre-trained deep learning model's suggested contour.

1. initialize a contour with mouse drag around an object
2. the suggested contour is displayed automatically
3. modify the contour:
    - edit with mouse drag or 
    - erase holding ""Alt"" or
	- invert with pressing ""u""
4. finalize it
    - accept with pressing ""q"" or
    - reject with pressing ""Ctrl"" + ""Del""

- if the suggested contour is a merge of multiple objects, you can erase the dividing line around the object you wish to keep, and keep erasing (or splitting with the eraser) until the object you wish to keep is the largest, then press ""q"" to accept it
- this mode requires a Keras model to be present in the [model folder](#configure-model-folder)

Click to watch demo video below

[![contour-assist-demo](https://drive.google.com/uc?export=view&id=1Mw2fCPdm5WHBVRgNnp8fGNmqxI84F_9I)](https://drive.google.com/uc?export=view&id=1VTd6RScjNfAwi3vMk-bU87U4ucPmOO_M ""Click to watch contour assist demo"")

***
## Edit mode
Allows to modify created objects with a brush tool.

1. select an object (shape) to modify by clicking on it
2. an editing layer (labels layer) is created for painting automatically
3. modify the contour:
    - edit with mouse drag or 
    - erase holding ""Alt""
4. finalize it
    - accept with pressing ""q"" or
    - delete with pressing ""Ctrl"" + ""Del"" or
    - revert changes with pressing ""Esc"" (to the state before editing)

- if the edited contour is a merge of multiple objects, you can erase the dividing line around the object you wish to keep, and keep erasing (or splitting with the eraser) until the object you wish to keep is the largest, then press ""q"" to accept it

Click to watch demo video below

[![edit-mode-demo](https://drive.google.com/uc?export=view&id=1M-XdEWPXMsIOtO0ncyUtvGACS0SRX-3K)](https://drive.google.com/uc?export=view&id=10MQm53hblLKQlfBNrfUsi1vxvIdTbzCZ ""Click to watch edit mode demo"")

***
## Class mode
Allows to assign class labels to objects by clicking on shapes.

1. select a class from the class list to assign
2. click on an object (shape) to assign the selected class label to it
3. the contour colour of the clicked object will be updated to the selected class colour, plus the class label is updated in the text properties of object (turn on ""display text"" on the layer control panel to see the text properties as `objectID:(classLabel)` e.g. 1:(0) for the first object)

- optionally, you can set a default class for all currently unlabelled objects on the ROI (shapes) layer by selecting a class from the drop-down menu on the right to the text label ""Default class""
- class colours can be changed with the drop-down menu right to the class list; upon selection, all objects whose class label is the currently selected class will have their contour colour updated to the selected colour
- clicking on an object that has already been assigned a class label will unclassify it: assign the label *0* to it

Click to watch demo video below

[![class-mode-demo](https://drive.google.com/uc?export=view&id=1EV1cn_mySO11S_ZDFv6Dl1laAk30jGJk)](https://drive.google.com/uc?export=view&id=1uOmznUvfHEFvviWTtOnUHty8rkKyWR7Q ""Click to watch class mode demo"")

***
## Export
See also: [Quick export](#quick-export)

The exporter plugin AnnotatorJExport can be invoked from the Plugins menu under the plugin name `napari-annotatorj`. It is used for batch export of annotations to various formats directly suitable to train different types of deep learning models. See a [demonstrative figure](https://raw.githubusercontent.com/spreka/annotatorj/master/demos/annotation_and_export_types.png) in the [AnnotatorJ repository](https://github.com/spreka/annotatorj) and further description in its [README](https://github.com/spreka/annotatorj#export) or [documentation](https://github.com/spreka/annotatorj/blob/master/AnnotatorJ_documentation.pdf).

1. browse original image folder with either the
    - ""Browse original..."" button or
    - text input field next to it
2. browse annotation folder with either the
    - ""Browse annot..."" button or
    - text input field next to it
3. select the export options you wish to export the annotations to (see tooltips on hover for help)
    - at least one export option must be selected to start export
    - (optional) right click on the checkbox ""Coordinates"" to switch between the default COCO format and YOLO format; see [explanation](#coordinate-formats)
4. click on ""Export masks"" to start the export
    - this will open a progress bar in the napari window and close it upon finish

The folder structure required by the exporter is as follows:

```
image_folder
	|--- image1.png
	|--- another_image.png
	|--- something.png
	|--- ...

annotation_folder
	|--- image1_ROIs.zip
	|--- another_image_ROIs.zip
	|--- something_ROIs.zip
	|--- ...
```

Multiple export options can be selected at once, any selected will create a subfolder in the folder where the annotations are saved.


Click to watch demo video below

[![exporter-demo](https://drive.google.com/uc?export=view&id=1QoaJrI9pKziUzYwiZNdWlfRD7PcvJB9U)](https://drive.google.com/uc?export=view&id=1uJz-x_ypEOjc7SYPUTqrEt0ieyNLFy6u ""Click to watch exporter demo"")

***
## Quick export
Click on the ""[^]"" button to quickly save annotations and export to mask image. It saves the current annotations (shapes) to an ImageJ-compatible roi.zip file and a generated a 16-bit multi-labelled mask image to the subfolder ""masks"" under the current original image's folder.


***
## Coordinate formats
In the AnnotatorJExport plugin 2 coordinates formats can be selecting by right clicking on the Coordinates checkbox: COCO or YOLO. The default is COCO.

*COCO format*:
- `[x, y, width, height]` based on the top-left corner of the bounding box around the object
- coordinates are not normalized
- annotations are saved with header to 
    - .csv file
    - tab delimeted

*YOLO format*:
- `[class, x, y, width, height]` based on the center point of the bounding box around the object
- coordinates are normalized to the image size as floating point values between 0 and 1
- annotations are saved with header to
    - .txt file
    - whitespace delimeted
    - class is saved as the 1st column

***
## Overlay
A separate annotation file can be loaded as overlay for convenience, e.g. to compare annotations.

1. load another annotation file with the ""Overlay"" button

- (optional) switch its visibility with the ""Show overlay"" checkbox
- (optional) change the contour colour of the overlay shapes with the [""Colours"" button](#change-colours)

***
## Change colours
Clicking on the ""Colours"" button opens the Colours widget where you can set the annotation and overlay colours.

1. select a colour from the drop-down list either next to the text label ""overlay"" or ""annotation""
2. click the ""Ok"" button to apply changes

- contour colour of shapes on the annotation shapes layer (named ""ROI"") that already have a class label assigned to them will **not** be updated to the new annotation colour, only those not having a class label (the class label can be displayed with the ""display text"" checkbox on the layer controls panel as `objectID:(classLabel)` e.g. 1:(0) for the first object)
- contour colour of shapes on the overlay shapes layer (named ""overlay"") will all have the overlay colour set, regardless of any existing class information saved to the annotation file loaded as overlay

***
## Configure model folder
The Contour assist mode imports a pre-trained Keras model from a folder named *models* under exactly the path *napari_annotatorj*. This is automatically created on the first startup in your user folder:
- `C:\Users\Username\.napari_annotatorj` on Windows
- `\home\username\.napari_annotatorj` on Linux

A pre-trained model for nucleus segmentation is automatically downloaded from the GitHub repository of the [ImageJ version of AnnotatorJ](https://github.com/spreka/annotatorj/releases/tag/v0.0.2-model). The model will be saved to `[your user folder]\.napari_annotatorj\models\model_real.h5`. This location is printed to the console (command prompt or powershell on Windows, terminal on Linux).

(deprecated) When bulding from source the model folder is located at *path\to\napari-annotatorj\src\napari_annotatorj\models* whereas installing from pypi it is located at *path\to\virtualenv\Lib\site-packages\napari_annotatorj\models*.

The model must be in either of these file formats:
- config .json file + weights file: *model_real.json* and *model_real_weights.h5*
- combined weights file: *model_real.hdf5*

You can also train a new model on your own data in e.g. Python and save it with this code block:

```python
	# save model as json
	model_json=model.to_json()
	with open(âmodel_real.jsonâ, âwâ) as f:
		f.write(model_json)
	
	# save weights too
	model.save_weights(âmodel_real_weights.h5â)

```
You can also train in the [train widget](#Training).

This configuration will change in the next release to allow model browse and custom model name in an [options widget](#options).

***
## Training
To start training a new model or refine an existing one click the **Train** button on the right of the napari-annotatorj widget. This will open the training widget where you can set input paths and training options. During training a progress bar will show the epochs passed and plot the loss on a graph. See a [guide](#how-to-train) below.

The trained model will be saved to the `model` folder under the located training data folder which is named `training` by default when preparing data. Each new training will be saved to a new training folder with increased numbering e.g. `training_1`, `training_2` etc.

When an existing training data folder is browsed with the ""Browse train ..."" button, the `model` folder will be created under it without an additiona `training` folder.

After training is finished, a message is shown to indicate the newly trained model can be tested by drawing bounding boxes (rectangles) to initiate [contour assist](#contour-assist-mode) prediction. The presented region on the editing layer (Label layer) can be modified with the paint brush tool (automatically selected) as in [contour assist](#contour-assist-mode).

The trained model can be further refined by selecting the ""Retrain latest"" checkbox from the [training parameters](#training-parameters) (â button on the right).

To use this new model for annotation in [contour assist mode](#contour-assist-mode), you mush set the model path in the [Options widget](#options) or in the configuration file (see how to [here](#configure-model-folder)), then restart napari.

### How to train
1. On current annotation
	1. ""Use current annotation"" checkbox --> use this image and its current annotation for training
	2. Prep data --> prepare data to [suitable format](#training-data-format)
	3. (optional) â --> [set parameters](#training-parameters)
	4. Start --> start training
2. Additional data
	1. Select images and annotations to use for training
		- Browse original ... --> locate folder of original images
		- Browse annot ... --> locate folder of annotations
		- Prep data --> prepare data to [suitable format](#training-data-format)
	2. Browse train ... --> select already prepared training data
	3. (optional) â --> [set parameters](#training-parameters)
	4. Start --> start training

### Training data format
The data format expected by the training widget is as follows.

```
images
	|--- image1.png
	|--- another_image.png
	|--- something.png
	|--- ...

unet_masks
	|--- image1.tiff
	|--- another_image.tiff
	|--- something.tiff
	|--- ...
```

Masks are 8-bit binary (black and white) .tiff images that can be exported from the [Exporter widget](#export) selecting the Semantic (binary) export option. When the ""Prep data"" button is clicked in the Training widget, these folders are automatically created from the located annotation files and original images.

### Training parameters
The following configurable parameters can be set after clicking on the â icon:
| Parameter | Description | Default value |
| --------- | ----------- | ------------- |
| Epochs | number of epochs to train | 5 |
| Steps | number of steps in each epoch | 1 |
| Batch size | number of samples in an iteration| 1 |
| Image size | size of training images | 256 |
| Start from scratch | train a new model from scratch| `False` |
| Retrain latest | re-fine latest training | `False` |
| Write pred | write test image prediction to file| `False` |
| Test image | path to test image | `None`|

Note: by default CPU will be used for training. This can be changed to GPU in the [Options widget](#options) if your computer has a capable CUDA-device.

***
## Options
Settings found in the configuration file can be set in the Options widget opened with the ""..."" button on the right of the main plugin. For changes to take effect you must save your changes with the ""Ok"" button at the bottom of the Options widget.

The following options can be configured:
|Group|Option|Description|Default|Valid values|
|-----|------|-----------|-------|------------|
|General|Annotation type | see [instance](#instance-annotation), [bbox](#bounding-box-annotation), [semantic](#semantic-annotation) | instance |instance, bbox, semantic |
| |Remember annotation type|use the same annotation type on next startup|`True`|`True`, `False`|
| |Colours|select annotation and overlay colours; see [here](#change-colours)|white|white, red, green, blue, cyan, magenta, yellow, orange, black|
| |Classes|names of folders to save annotations when not classified*|normal|(any string)**|
|Semantic segmentation|Brush size|size of the brush|50|`int`|
|*Advanced settings*|
|Contour assist|Max distance|number of pixels to extend the initial contour with|17|`int`|
||Threshold|intensity threshold after prediction|||
||- gray||0.1|`float` in [0,1]|
||- R (red)||0.2|`float` in [0,1]|
||- G (green)||0.4|`float` in [0,1]|
||- B (blue)||0.2|`float` in [0,1]|
||Brush size|correction brush size|5|`int`|
||Method|contour assist prediction method|U-Net|U-Net, Classic***|
||Model|U-Net model to use for Contour assist prediction|||
||folder|path to the model folder|`user/.napari_annotatorj/models`|existing `models` folder path|
||.json file|name of the model .json file **without** extension|model_real|any string**|
||weights file|name of the model weights file|model_real_weights.h5|any string**|
||full file|name of the combined config+weights file|model_real.hdf5|any string**|
||Device|computation device to perform prediction|cpu|cpu,`int`****|
|Mask/text import|
||Auto mask load|load annotation files automatically when a new image is opened|`False`|`True`, `False`|
||Enable mask load|load instance annotation mask image|`False`|`True`, `False`|
||Enable text load|load object detection bounding box coordinate text file|`False`|`True`, `False`|
||Method|load as editable or overlay|load|load, overlay|
|Others|
||Save outlines|save image with annotations outlined|`False`|`True`, `False`|
||Show help on startup|show the help window upon every startup|`False`|`True`, `False`|
||Save annot times|save annotation times to text file*****|`False`|`True`, `False`|

*: right click the last element (other...) to add a new item to the list. When annotations are assigned class labels in [class mode](#class-mode), they will be saved to the folder `masks` by default.

**: do not use whitespace (' ') if possible

***: region growing classical algorithm

****: valid id of a GPU device e.g. `0` or `3`; if your computer has only one GPU the id is `0`

*****: currently disabled, used for development

***
## Demo
Run a demo of napari-annotatorj with sample data: a small 3-channel RGB image as original image and an ImageJ roi.zip file as annotations loaded.

```shell
    # from the napari-annotatorj folder
	python src/napari_annotatorj/load_imagej_roi.py
```
Alternatively, you can startup the napari-annotatorj plugin by running

```shell
    # from the napari-annotatorj folder
	python src/napari_annotatorj/startup_annotatorj.py
```

***
## Shortcuts

| Function | Shortcut |
| -------- | -------- |
| Contour assist | `a` |
| Class mode | `c` |
| Edit mode | `Shift` + `e` |
| Show contours | `Shift` + `v` |
| Accept Contour assist | `q` |
| Reject Contour assist | `Ctrl` + `del` |
| Invert Contour assist | `u` |
| Erase in Edit/Contour assist mode | `Alt` (hold) |
| Revert changes in Edit mode | `Esc` |


***
## Setting device for deep learning model prediction
The [Contour assist](#contour-assist-mode) mode uses a pre-trained U-Net model for suggesting contours based on a lazily initialized contour drawn by the user. The default configuration loads and runs the model on the CPU so all users can run it. It is possible to switch to GPU if you have:
- a CUDA-capable GPU in your computer
- nVidia's CUDA toolkit + cuDNN installed

See installation guide on [nVidia's website](https://developer.nvidia.com/cuda-downloads) according to your system.

To switch to GPU utilization, edit [_dock_widget.py](https://github.com/spreka/napari-annotatorj/blob/main/src/napari_annotatorj/_dock_widget.py#L112) and set to the device you would like to use. Valid values are `'cpu','0','1','2',...`. The default value is `cpu`. The default GPU device is `0` if your system has any CUDA-capable GPU. If the device you set cannot be found or utilized by the code, it will fall back to `cpu`. An informative message is printed to the console upon plugin startup.

***
## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-annotatorj"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/spreka/napari-annotatorj/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/spreka/napari-annotatorj/issues', 'Documentation, https://github.com/spreka/napari-annotatorj#README.md', 'Source Code, https://github.com/spreka/napari-annotatorj', 'User Support, https://github.com/spreka/napari-annotatorj/issues']",napari-annotatorj.get_reader,napari-annotatorj.write_labels,napari-annotatorj.AnnotatorJ,,['<EDIT_ME>'],['.tiff'],
109,napari-argos-archive-reader,napari-argos-archive-reader,Dioptic ARGOS Archive Reader,0.0.7,2024-01-03,2024-01-23,Volker Hilsenstein,hilsenstein@dioptic.de,MIT,https://github.com/dioptic/napari-argos-archive-reader/issues,https://pypi.org/project/napari-argos-archive-reader/,,https://github.com/dioptic/napari-argos-archive-reader,A plugin to read Dioptic ARGOS archive files,>=3.9,"['napari', 'numpy', 'scikit-image', 'pydantic', 'ruamel.yaml', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-argos-archive-reader

[![License MIT](https://img.shields.io/pypi/l/napari-argos-archive-reader.svg?color=green)](https://github.com/dioptic/napari-argos-archive-reader/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-argos-archive-reader.svg?color=green)](https://pypi.org/project/napari-argos-archive-reader)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-argos-archive-reader.svg?color=green)](https://python.org)
[![tests](https://github.com/dioptic/napari-argos-archive-reader/workflows/tests/badge.svg)](https://github.com/dioptic/napari-argos-archive-reader/actions)
[![codecov](https://codecov.io/gh/dioptic/napari-argos-archive-reader/branch/main/graph/badge.svg)](https://codecov.io/gh/dioptic/napari-argos-archive-reader)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-argos-archive-reader)](https://napari-hub.org/plugins/napari-argos-archive-reader)

A plugin to read Dioptic ARGOS archive files

----------------------------------

This repo contains a reader plugin for [DIOPTIC ARGOS](https://www.dioptic.de/en/argos-en/) Archive files, which
have `.zip` file extension.
Individual ARGOS layers are grouped into napari layer with stacks according to
their illumination, stage XY position and Z-stack information.

The plugin implements delayed reading using `dask.delayed` so that one can quickly
see the contents even for large archives with many layers. Note!: switching to
volume rendering or swapping axes can trigger the loading of all ARGOS layers, which
can take a long time for large archives.

[ARGOS](https://www.dioptic.de/en/argos-en/) is an automated system
for surface inspection according to ISO 10110-7.

This plugin is still experimental and does not support all features of ARGOS archives.

Currently, the plugin

* can read Argos matrix archives containing regular image layers including:
  * â segmentation masks
  * â Z-stack metadata
  * â Illumination metadata
  * â proper scaling and affine transformation of layers
* can read ââ Argos line scan (polar) archives with minimal support (no metadata parsing)
This has not been tested on many archives.

Not supported are:

* â annotated archives
* â pyramid image structures
* â Line segmentation metadata
* â color metadata
* â ...

## Usage

### Opening files

Simply drag and drop an ARGOS Archive `.zip` file onto the napari canvas or use `File->Open` to open it.

### Synchronizing contrast limits

By default, after reading an archive, each napari layer will have their own contrast limits, so you can
adjust these contrast limits individually.

The reader plugin registers a custom key binding after reading an ARGOS archive. Pressing the `s` key will allow
you to synchronize the contrast limits for a set of layers:

* If you select _a single_ napari layer corresponding to an image/stack from an ARGOS archive, all napari image
layers that were loaded from this archive now have their contrast limits synchronized, i.e. changing the
contrast limits of _any_ of them will adjust the contrast limits of _all_ of the layers belonging to the same
archive.
* If you select _multiple_ napari layers and press `s` all of these and only these napari layers will have
their contrast limits synchronized, regardless of whether they belong to the same ARGOS archive or not.

## Installation

If you have napari installed you can install the plugin from the napari hub through the `Plugins -> Plugin Manger` menu
entry. After waiting a short while for napari to retrieve the plugins available from the hub, simply enter ""argos"" in
the filter line entry field at the top to narrow down the plugin list and click install.

You can install `napari-argos-archive-reader` via [pip]:

    pip install napari-argos-archive-reader

To install latest development version :

    pip install git+https://github.com/dioptic/napari-argos-archive-reader.git

## License

Distributed under the terms of the [MIT] license,
""napari-argos-archive-reader"" is free and open source software

[MIT]: http://opensource.org/licenses/MIT
[pip]: https://pypi.org/project/pip/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/dioptic/napari-argos-archive-reader/issues', 'Documentation, https://github.com/dioptic/napari-argos-archive-reader#README.md', 'Source Code, https://github.com/dioptic/napari-argos-archive-reader', 'User Support, https://github.com/dioptic/napari-argos-archive-reader/issues']",napari-argos-archive-reader.get_reader,,,,['*.zip'],,
110,napari-arboretum,napari-arboretum,napari-arboretum,0.1.2,2021-05-11,2023-06-07,Alan R. Lowe,"""Alan R. Lowe"" <a.lowe@ucl.ac.uk>",Unavailable,https://github.com/lowe-lab-ucl/arboretum,https://pypi.org/project/napari-arboretum/,,,Track graph and lineage tree visualization with napari,>=3.8,"['matplotlib', 'napari-matplotlib (>=0.2.1)', 'napari (>=0.4.0)', 'numpy (>=1.17.3)', 'pandas', 'pooch (>=1)', 'qtpy', 'scikit-image', 'vispy']"," <!--[![Downloads](https://pepy.tech/badge/napari-arboretum)](https://pepy.tech/project/napari-arboretum)-->

[![License](https://img.shields.io/pypi/l/napari-arboretum.svg?color=green)](https://github.com/lowe-lab-ucl/arboretum/blob/main/LICENSE.md)
[![PyPI](https://img.shields.io/pypi/v/napari-arboretum.svg?color=green)](https://pypi.org/project/napari-arboretum)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-arboretum.svg?color=green)](https://python.org)
[![tests](https://github.com/lowe-lab-ucl/arboretum/workflows/tests/badge.svg)](https://github.com/lowe-lab-ucl/arboretum/actions)
[![codecov](https://codecov.io/gh/lowe-lab-ucl/arboretum/branch/main/graph/badge.svg?token=2M2HhM60op)](https://app.codecov.io/gh/lowe-lab-ucl/arboretum/tree/main)

# Arboretum



https://github.com/lowe-lab-ucl/arboretum/assets/8217795/d98c22c4-73bb-493a-9f8f-c224d615209d


_Automated cell tracking and lineage tree reconstruction_.

### Overview

A dockable widget for [Napari](https://github.com/napari/napari) for visualizing cell lineage trees.

Features:

- Lineage tree plot widget
- Integration with [btrack](https://github.com/quantumjot/btrack)

---

### Usage

Once installed, Arboretum will be visible in the `Plugins > Add Dock Widget > napari-arboretum` menu in napari. To visualize a lineage tree, (double) click on one of the tracks in a napari `Tracks` layer.

### Examples

You can use the example script to display some sample tracking data in napari and load the arboretum tree viewer:

```sh
python ./examples/show_sample_data.py
```

Alternatively, you can use _btrack_ to generate tracks from your image data. See the example notebook here:
https://github.com/quantumjot/btrack/blob/main/examples

---

### History

This project has changed considerably. The `Tracks` layer, originally developed for this plugin, is now an official layer type in napari. Read the napari documentation here:
https://napari.org/stable/api/napari.layers.Tracks.html

To view the legacy version of this plugin, visit the legacy branch:
https://github.com/quantumjot/arboretum/tree/v1-legacy
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python', 'Topic :: Scientific/Engineering :: Visualization']","['homepage, https://github.com/lowe-lab-ucl/arboretum']",,,napari-arboretum.Arboretum,,,,
111,napari-automatic-range,napari-automatic-range,Automatic Range,0.1.4,2025-07-17,2025-07-17,PacÃ´me Prompsy,pacome.prompsy@unil.ch,"GNU GENERAL PUBLIC LICENSE
   ...",https://github.com/pacomito/napari-automatic-range/issues,https://pypi.org/project/napari-automatic-range/,,,"An openâsource, reproducible intensityâscaling method that leverages the nuclear signal as an anchor to calibrate perâchannel contrast. ",>=3.10,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'AutomaticRange', 'napari[all]; extra == ""all""', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari[qt]; extra == ""testing""']","# napari-automatic-range

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-automatic-range.svg?color=green)](https://github.com/pacomito/napari-automatic-range/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-automatic-range.svg?color=green)](https://pypi.org/project/napari-automatic-range)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-automatic-range.svg?color=green)](https://python.org)
[![tests](https://github.com/pacomito/napari-automatic-range/workflows/tests/badge.svg)](https://github.com/pacomito/napari-automatic-range/actions)
[![codecov](https://codecov.io/gh/pacomito/napari-automatic-range/branch/main/graph/badge.svg)](https://codecov.io/gh/pacomito/napari-automatic-range)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-automatic-range)](https://napari-hub.org/plugins/napari-automatic-range)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

An openâsource, reproducible intensityâscaling method that leverages the nuclear signal as an anchor to calibrate perâchannel contrast. 

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-automatic-range` via [pip]:

```
pip install napari-automatic-range
```

If napari is not already installed, you can install `napari-automatic-range` with napari and Qt via:

```
pip install ""napari-automatic-range[all]""
```


To install latest development version :

```
pip install git+https://github.com/pacomito/napari-automatic-range.git
```



## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-automatic-range"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/pacomito/napari-automatic-range/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/pacomito/napari-automatic-range/issues', 'Documentation, https://github.com/pacomito/napari-automatic-range#README.md', 'Source Code, https://github.com/pacomito/napari-automatic-range', 'User Support, https://github.com/pacomito/napari-automatic-range/issues']",napari-automatic-range.get_reader,napari-automatic-range.write_multiple,napari-automatic-range.automatic_range_widget,napari-automatic-range.make_sample_data,['*.npy'],,['.npy']
112,napari-bacseg,napari-bacseg,BacSEG,1.1.2,2023-02-24,2024-11-13,Piers Turner,Piers Turner <piers.turner@physics.ox.ac.uk>,Unavailable,https://github.com/piedrro/napari-bacseg/issues,https://pypi.org/project/napari-bacseg/,,,"Bacterial segmentation and analysis platform than can inport/export files in multiple formats. Integrating many tools such as Cellpose, ColiCoords, Oufti/MicrobeTracker.",>=3.9,"['napari[all]==0.5.0', 'torch', 'torchvision', 'cellpose==3.0.1', 'opencv-python', 'picassosr==0.7.3', 'bactfit>=0.1.6', 'numpy', 'pyqt5', 'pyqt6', 'qtpy', 'scipy', 'natsort', 'tqdm', 'imagecodecs', 'tifffile', 'pandas', 'mat4py', 'glob2', 'matplotlib', 'scikit-image', 'roifile', 'openpyxl', 'shapely', 'colicoords', 'psutil', 'xmltodict', 'astropy', 'tiler', 'imageio-ffmpeg', 'aicspylibczi', 'czifile', 'omnipose', 'h5py', 'pyqtgraph', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-BacSEG

[![License BSD-3](https://img.shields.io/pypi/l/napari-bacseg.svg?color=green)](https://github.com/piedrro/napari-bacseg/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bacseg.svg?color=green)](https://pypi.org/project/napari-bacseg)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bacseg.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bacseg)](https://napari-hub.org/plugins/napari-bacseg)

Bacterial segmentation and analysis platform than can inport/export files in multiple formats. Integrating many tools such as Cellpose, ColiCoords, Oufti/MicrobeTracker.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installing BacSeg from PyPi

Create a new conda environment:

    conda create --name napari-bacseg python==3.9
    conda activate napari-bacseg
    conda install -c anaconda git
    conda update --all

Install `napari-bacseg` via [pip]:

    pip install napari-bacseg

Launch Napari:

    napari

Install latest version of 'napri-bacseg' from [pip]:

    pip install napari-bacseg --upgrade

Select **napari-bacseg** from the **Plugins** dropdown menu

## Installing BacSeg From GitHub

    conda create â-name napari-bacseg python==3.9
    conda activate napari-bacseg
    conda install -c anaconda git
    conda update --all

    pip install napari[all]

    pip install git+https://github.com/piedrro/napari-bacseg.git

## Updating BacSeg From Github
Once you have installed the plugin, you can update the plugin by running the following commands:

    pip install git+https://github.com/piedrro/napari-bacseg.git

## GPU Installation
 Once you have installed the plugin, you can install the GPU version of the plugin by running the following commands:

    pip uninstall torch torchvision torchaudio -y
    pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118

If the latest CUDA versions don't work, try an older version like cuda 11.3:

    pip uninstall torch torchvision torchaudio -y
    pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu113


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-bacseg"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/piedrro/napari-bacseg/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Framework :: napari', 'Environment :: Plugins', 'License :: OSI Approved :: BSD License', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent']","['Homepage, https://github.com/piedrro/napari-bacseg', 'Bug Tracker, https://github.com/piedrro/napari-bacseg/issues']",,,napari-bacseg.make_qwidget,,,,
113,napari-basicpy,napari-basicpy,BaSiCpy shadow correction in napari,0.0.3,2024-05-06,2024-05-06,Tim Morello,tdmorello@gmail.com,BSD-3-Clause,https://github.com/peng-lab/napari-basicpy/issues,https://pypi.org/project/napari-basicpy/,,https://github.com/tdmorello/napari-basicpy,BaSiCPy illumination correction for napari,>=3.8,"['basicpy >=1.2.0', 'numpy', 'qtpy', ""black ; extra == 'dev'"", ""flake8 ; extra == 'dev'"", ""flake8-black ; extra == 'dev'"", ""flake8-docstrings ; extra == 'dev'"", ""flake8-isort ; extra == 'dev'"", ""isort ; extra == 'dev'"", ""mypy ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""pydocstyle ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""tox ; extra == 'tox-testing'"", ""pytest ; extra == 'tox-testing'"", ""pytest-cov ; extra == 'tox-testing'"", ""pytest-qt ; extra == 'tox-testing'"", ""napari ; extra == 'tox-testing'"", ""pyqt5 ; extra == 'tox-testing'""]","# napari-basicpy

[![License](https://img.shields.io/pypi/l/napari-basicpy.svg?color=green)](https://github.com/tdmorello/napari-basicpy/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-basicpy.svg?color=green)](https://pypi.org/project/napari-basicpy)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-basicpy.svg?color=green)](https://python.org)
[![tests](https://github.com/tdmorello/napari-basicpy/workflows/tests/badge.svg)](https://github.com/tdmorello/napari-basicpy/actions)
[![codecov](https://codecov.io/gh/tdmorello/napari-basicpy/branch/main/graph/badge.svg)](https://codecov.io/gh/tdmorello/napari-basicpy)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-basicpy)](https://napari-hub.org/plugins/napari-basicpy)

BaSiCPy illumination correction for [napari]

## Example

![example](resources/example.gif)

----------------------------------

## Installation

### Recommended Installation Method

We highly recommend using a `conda` virtual environment to install and operate this plugin.

To use Python 3.9, for example:

    conda create -n basicpy -c conda-forge python=3.9 napari pyqt && \
    conda activate basicpy && \
    pip install napari-basicpy

For further instructions on installing `napari`, visit their [install guide](https://napari.org/stable/tutorials/fundamentals/installation).

---

**IMPORTANT NOTE FOR APPLE SILICON AND WINDOWS USERS:**

If the above instructions fail with Apple silicon (e.g., M1/M2 chip) or Windows, you may need to install the `jax` and `jaxlib` following the instruction [here](https://github.com/peng-lab/BaSiCPy#installation).

---

### Other Installation Methods

You can also install `napari-basicpy` via [pip]:

    pip install napari-basicpy


To install latest development version:

    pip install git+https://github.com/peng-lab/napari-basicpy.git

or

    pip install git+https://github.com/tdmorello/napari-basicpy.git

## Usage

### General Usage

This plugin expects a stack of tiles as input. Mosaic images should be deconstructed into their tiled components before processing. Individual tiles should be two-dimensional.

There are many options to customize the performance of BaSiCPy. Please refer to the BaSiCPy documentation on parameters [here](https://basicpy.readthedocs.io/en/latest/api.html#basicpy.basicpy.BaSiC) for details.

### Batch Processing

Coming soon...

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-basicpy"" is free and open source software

## Issues

If you encounter any problems, please [file an issue](https://github.com/peng-lab/napari-basicpy/issues) along with a detailed description.

[napari]: https://github.com/napari/napari
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause

[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/peng-lab/napari-basicpy/issues', 'Documentation, https://github.com/peng-lab/napari-basicpy#README.md', 'Source Code, https://github.com/peng-lab/napari-basicpy', 'User Support, https://github.com/peng-lab/napari-basicpy/issues']",,,napari-basicpy.shadow_correction,napari-basicpy.sample_data_random,,,
114,napari-assistant,napari-assistant,napari-assistant,0.6.0,2022-03-05,2025-05-02,"Robert Haase, Ryan Savill",robert.haase@uni-leipzig.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-assistant,https://pypi.org/project/napari-assistant/,,https://github.com/haesleinhuepf/napari-assistant/,A pocket calculator like interface to image processing in napari,>=3.9,"['napari-plugin-engine>=0.1.4', 'toolz', 'napari>=0.4.14', 'magicgui', 'numpy!=1.19.4', 'pyperclip', 'loguru', 'jupytext', 'jupyter', 'pandas', 'napari-time-slicer>=0.4.8', 'napari-workflows>=0.2.10']","# napari-assistant
[![License](https://img.shields.io/pypi/l/napari-assistant.svg?color=green)](https://github.com/haesleinhuepf/napari-assistant/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-assistant.svg?color=green)](https://pypi.org/project/napari-assistant)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-assistant.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-assistant/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-assistant/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-assistant/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-assistant)
[![Development Status](https://img.shields.io/pypi/status/napari-assistant.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-assistant)](https://napari-hub.org/plugins/napari-assistant)
[![DOI](https://zenodo.org/badge/463875112.svg)](https://zenodo.org/badge/latestdoi/463875112)


The napari-assistant is a [napari](https://github.com/napari/napari) meta-plugin for building image processing workflows. 

## Usage

After installing one or more napari plugins that use the napari-assistant as user interface, you can start it from the 
menu `Tools > Utilities > Assistant (na)` or run `naparia` from the command line. 

By clicking on the buttons in the assistant, you can setup a workflow for processing the images.

![img.png](https://github.com/haesleinhuepf/napari-assistant/raw/main/docs/napari-assistant-screenshot.png)

While setting up your workflow, you can at any point select a layer from the layer list (1) and change the parameters of
the corresponding operation (2). The layer will update when you change parameters and also all subsequent operations. 
You can also vary which operation is applied to the image (3). Also make sure the right input image layer is selected (4).

![img.png](https://github.com/haesleinhuepf/napari-assistant/raw/main/docs/design_workflows.png)

### Saving and loading workflows

You can also save and load workflows to disk. 

![img.png](https://github.com/haesleinhuepf/napari-assistant/raw/main/docs/save_and_load.png)

After loading a workflow, make sure that the right input images are selected.

### Code generation

The napari-assistant allows exporting the given workflow as Python script and Jupyter Notebook. 

![img.png](https://github.com/haesleinhuepf/napari-assistant/raw/main/docs/code_generator.png)

Furthermore, if you have the [napari-script-editor](https://www.napari-hub.org/plugins/napari-script-editor) installed,
you can also send the current workflow as code to the script editor from the same menu.

![img.png](https://github.com/haesleinhuepf/napari-assistant/raw/main/docs/napari_script_editor.png)

### Plugin generation

There is also a Napari plugin generator available. Check out [its documentation](https://github.com/haesleinhuepf/napari-assistant-plugin-generator) to learn how napari-assistant compatible plugins can be generated directly from within the assistant.

## Installation

It is recommended to install the napari-assistant via one of the plugins that use it as graphical user interface.
You find a complete list of plugins that use the assistant [on the napari-hub](https://www.napari-hub.org/?search=napari-assistant&sort=relevance).
Multiple of these plugins come bundled when installing [devbio-napari](https://www.napari-hub.org/plugins/devbio-napari).
Note: This plugin is not compatible with napari 0.6.0 and later.

## For developers

If you want to make your napari-plugin accessible from the napari-assistant, consider programming functions with a simple 
interface that consume images, labels, integers, floats and strings. Annotate input and return types, e.g. like this:
```python
def example_function_widget(image: ""napari.types.ImageData"") -> ""napari.types.LabelsData"":
    from skimage.filters import threshold_otsu
    binary_image = image > threshold_otsu(image)

    from skimage.measure import label
    return label(binary_image)
```

Furthermore, please add your function to the napari.yaml which uses [npe2](https://github.com/napari/npe2):
```
name: napari-npe2-test
display_name: napari-npe2-test
contributions:
  commands: 
    - id: napari-npe2-test.make_magic_widget
      python_name: napari_npe2_test._widget:example_magic_widget
      title: Make example magic widget
  widgets:
    - command: napari-npe2-test.make_magic_widget
      display_name: Segmentation / labeling > Otsu Labeling (nnpe2t)
```

To put it in the right button within the napari-assistant, please use one of the following prefixes for the `display_name`:
* `Filtering / noise removal > `
* `Filtering / background removal > `
* `Filtering > `
* `Image math > `
* `Transform > `
* `Projection > `
* `Segmentation / binarization > `
* `Segmentation / labeling > `
* `Segmentation post-processing > `
* `Measurement > `
* `Label neighbor filters > `
* `Label filters > `
* `Visualization > `

You find a fully functional example [here](https://github.com/haesleinhuepf/napari-npe2-test).

Last but not least, to make your napari-plugin is listed in the napari-hub when searching for ""napari-assistant"", make sure
you mention it in your `readme`.

## Feedback welcome!

The napari-assistant is developed in the open because we believe in the open source community. Feel free to drop feedback as [github issue](https://github.com/haesleinhuepf/napari-assistant/issues) or via [image.sc](https://image.sc)

## Contributing

Contributions are very welcome. Please ensure
the test coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-assistant"" is free and open source software

## Acknowledgements
This project was supported by the Deutsche Forschungsgemeinschaft under Germanyâs Excellence Strategy â EXC2068 - Cluster of Excellence ""Physics of Life"" of TU Dresden. 
This project has been made possible in part by grant number [2021-240341 (Napari plugin accelerator grant)](https://chanzuckerberg.com/science/programs-resources/imaging/napari/improving-image-processing/) from the Chan Zuckerberg Initiative DAF, an advised fund of the Silicon Valley Community Foundation.

[BSD-3]: http://opensource.org/licenses/BSD-3-Clause

","['Framework :: napari', 'License :: OSI Approved :: BSD License', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent']","['Bug Tracker, https://github.com/haesleinhuepf/napari-assistant/issues', 'Documentation, https://github.com/haesleinhuepf/napari-assistant/', 'Source Code, https://github.com/haesleinhuepf/napari-assistant', 'User Support, https://forum.image.sc/']",,,napari-assistant.Assistant,,,,
115,napari-bee-annotator,napari-bee-annotator,Bee annotator,0.0.1,2024-01-09,2024-01-09,Florian Aymanns,florian.aymanns@epfl.ch,BSD-3-Clause,https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator/issues,https://pypi.org/project/napari-bee-annotator/,,https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator,Napari plugin for the annotation of bee entering and leaving the hive.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","<img style=""float: right;"" src=""https://imaging.epfl.ch/resources/logo-for-gitlab.svg"">


# napari-bee-annotator
Developed by the [EPFL Center for Imaging](https://imaging.epfl.ch/) for the [Mobile Robotic Systems Group](https://www.epfl.ch/labs/mobots/) in Dec 2023.
This napari plugin provides an easy way for the researches to annotate honey bees leaving/entering the hive. The annotations will serve as ground truth for the validation of various automated animal tracking approaches.

[![License BSD-3](https://img.shields.io/pypi/l/napari-bee-annotator.svg?color=green)](https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bee-annotator.svg?color=green)](https://pypi.org/project/napari-bee-annotator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bee-annotator.svg?color=green)](https://python.org)
[![tests](https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator/workflows/tests/badge.svg)](https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator/actions)
[![codecov](https://codecov.io/gh/EPFL-Center-for-Imaging/napari-bee-annotator/branch/main/graph/badge.svg)](https://codecov.io/gh/EPFL-Center-for-Imaging/napari-bee-annotator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bee-annotator)](https://napari-hub.org/plugins/napari-bee-annotator)

## Installation

You can install `napari-bee-annotator` via [pip]:

    pip install napari-bee-annotator



To install latest development version :

    pip install git+https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator.git

## Getting started

1. Open napari with the plugin and your video using the following command `napari -w napari-bee-annotator --plugin video path/to/video.mp4`. Note that you need to have [napari_video](https://www.napari-hub.org/plugins/napari_video) installed to read `mp4` files.

2. Select the orientation of your video: horizontal/vertical refers to the direction of the bee's leaving/entering the hive.

3. Start annotating: A simple left click indicates a bee moving up or to the left depending on the orientation selected. You can hold down the shift key to annotate a bee moving down or to the right. Annotations can be deleted with a right click on the annotation you want to delete. To move to the next frame, you can either hold down `ctrl` and scroll with the mouse wheel or click on the play button. Playback parameters, such as the playback speed, can be changed by right clicking on the play button.

4. Saving and loading tracks: To save a tracks layer selected from the list of layers and click on `File > Save selected layers`. Choose a name and the csv extension. If you want to continue to work on the annotations for a specific video, you first have to load the corresponding csv file by clicking on `Open with Plugin > Open file(s)...`. Select the file you want to load and click on open. A dialog should pop up that asks you to select the reader to use for loading the csv file. Select `Bee annotator`. Lastly, you have to tell the plugin to interact with the layer you just loaded by selecting it in the `Tracks layer` drop down menu.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-bee-annotator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator/issues', 'Documentation, https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator#README.md', 'Source Code, https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator', 'User Support, https://github.com/EPFL-Center-for-Imaging/napari-bee-annotator/issues']",napari-bee-annotator.get_reader,napari-bee-annotator.write_single_tracks_layer,napari-bee-annotator.make_container_widget,,['*.csv'],['.csv'],
116,napari-bbox,napari-bbox,Bounding Box,0.0.9,2023-03-24,2024-12-19,David Bauer,dbauer@brc.hu,BSD-3-Clause,https://github.com/bauerdavid/napari-bbox/issues,https://pypi.org/project/napari-bbox/,,https://github.com/bauerdavid/napari-bbox,A new layer for bounding boxes in 2+ dimensions,>=3.9,"['numpy', 'qtpy', 'napari>=0.4.15', 'packaging', 'pandas', 'npe2', 'vispy', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-bbox

[![License BSD-3](https://img.shields.io/pypi/l/napari-bbox.svg?color=green)](https://github.com/bauerdavid/napari-bbox/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bbox.svg?color=green)](https://pypi.org/project/napari-bbox)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bbox.svg?color=green)](https://python.org)
[![tests](https://github.com/bauerdavid/napari-bbox/workflows/tests/badge.svg)](https://github.com/bauerdavid/napari-bbox/actions)
[![codecov](https://codecov.io/gh/bauerdavid/napari-bbox/branch/main/graph/badge.svg)](https://codecov.io/gh/bauerdavid/napari-bbox)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bbox)](https://napari-hub.org/plugins/napari-bbox)

A new layer for bounding boxes in 2+ dimensions

> **Note**: This plugin was originally part of [Annotation Toolbox](https://www.napari-hub.org/plugins/napari-nD-annotator), and was separated to allow other plugins to utilize it.

----------------------------------

## Demo


https://user-images.githubusercontent.com/36735863/227506511-d672ce5c-eab5-436f-a7fd-6080e118a9a8.mp4


This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-bbox` via [pip]:

    pip install napari-bbox



To install latest development version :

    pip install git+https://github.com/bauerdavid/napari-bbox.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-bbox"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.


[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/bauerdavid/napari-bbox/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/bauerdavid/napari-bbox/issues', 'Documentation, https://github.com/bauerdavid/napari-bbox#README.md', 'Source Code, https://github.com/bauerdavid/napari-bbox', 'User Support, https://github.com/bauerdavid/napari-bbox/issues']",napari-bbox.get_reader,,napari-bbox.create_bounding_box_layer_widget,,['*.csv'],,
117,napari-bfio,napari-bfio,Bfio,0.0.4,2023-08-18,2023-09-25,Sameeul B Samee,sameeul.samee@nih.gov,MIT,https://github.com/PolusAI/napari-bfio/issues,https://pypi.org/project/napari-bfio/,,https://github.com/PolusAI/napari-bfio,A plugin to read and write images using bfio within napari,>=3.8,"['numpy', 'bfio >=2.3.1', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-bfio

[![License MIT](https://img.shields.io/pypi/l/napari-bfio.svg?color=green)](https://github.com/PolusAI/napari-bfio/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bfio.svg?color=green)](https://pypi.org/project/napari-bfio)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bfio.svg?color=green)](https://python.org)
[![tests](https://github.com/PolusAI/napari-bfio/workflows/tests/badge.svg)](https://github.com/PolusAI/napari-bfio/actions)
[![codecov](https://codecov.io/gh/PolusAI/napari-bfio/branch/main/graph/badge.svg)](https://codecov.io/gh/PolusAI/napari-bfio)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bfio)](https://napari-hub.org/plugins/napari-bfio)

A plugin to read and write images using bfio within napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-bfio` via [pip]:

    pip install napari-bfio

`napari-bfio` depends on `bfio` package to read/write the data. By default, `bfio` package and the core dependencies (numpy, tifffile, imagecodecs, scyjava) are installed during the installation process of `napari-bfio`.

To install latest development version :

    pip install git+https://github.com/PolusAI/napari-bfio.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-bfio"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/PolusAI/napari-bfio/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/PolusAI/napari-bfio/issues', 'Documentation, https://github.com/PolusAI/napari-bfio#README.md', 'Source Code, https://github.com/PolusAI/napari-bfio', 'User Support, https://github.com/PolusAI/napari-bfio/issues']",napari-bfio.get_reader,napari-bfio.write_single_image,,,"['*.ome.tiff', '*.ome.tif', '*.ome.zarr', '*.tiff', '*.1sc', '*.2fl', '*.acff', '*.afi', '*.afm', '*.aim', '*.al3d', '*.ali', '*.am', '*.amiramesh', '*.apl', '*.arf', '*.avi', '*.bif', '*.bin', '*.bip', '*.bmp', '*.btf', '*.c01', '*.cfg', '*.ch5', '*.cif', '*.cr2', '*.crw', '*.cxd', '*.dat', '*.db', '*.dcm', '*.dib', '*.dicom', '*.dm2', '*.dm3', '*.dm4', '*.dti', '*.dv', '*.eps', '*.epsi', '*.exp', '*.fdf', '*.fff', '*.ffr', '*.fits', '*.flex', '*.fli', '*.frm', '*.gel', '*.gif', '*.grey', '*.h5', '*.hdf', '*.hdr', '*.hed', '*.his', '*.htd', '*.hx', '*.i2i', '*.ics', '*.ids', '*.im3', '*.img', '*.img', '*.ims', '*.inr', '*.ipl', '*.ipm', '*.ipw', '*.j2k', '*.jp2', '*.jpeg', '*.jpf', '*.jpg', '*.jpk', '*.jpx', '*.klb', '*.l2d', '*.labels', '*.lei', '*.lif', '*.liff', '*.lim', '*.lms', '*.lof', '*.lsm', '*.map', '*.mdb', '*.mea', '*.mnc', '*.mng', '*.mod', '*.mov', '*.mrc', '*.mrcs', '*.mrw', '*.msr', '*.mtb', '*.mvd2', '*.naf', '*.nd', '*.nd2', '*.ndpi', '*.ndpis', '*.nef', '*.nhdr', '*.nii', '*.nii.gz', '*.nrrd', '*.obf', '*.obsep', '*.oib', '*.oif', '*.oir', '*.omp2info', '*.par', '*.pbm', '*.pcoraw', '*.pcx', '*.pds', '*.pgm', '*.pic', '*.pict', '*.png', '*.pnl', '*.ppm', '*.pr3', '*.ps', '*.psd', '*.qptiff', '*.r3d', '*.raw', '*.rcpnl', '*.rec', '*.res', '*.scn', '*.sdt', '*.seq', '*.sif', '*.sld', '*.sldy', '*.sm2', '*.sm3', '*.spc', '*.spe', '*.spi', '*.st', '*.stk', '*.stp', '*.svs', '*.sxm', '*.tf2', '*.tf8', '*.tfr', '*.tga', '*.tif', '*.tif', '*.tiff', '*.tnb', '*.top', '*.txt', '*.v', '*.vff', '*.vms', '*.vsi', '*.vws', '*.wat', '*.wpi', '*.xdce', '*.xlef', '*.xqd', '*.xqf', '*.xv', '*.xys', '*.zfp', '*.zfr', '*.zvi']","['.ome.tiff', '.ome.tif', '.ome.zarr']","['.ome.tiff', '.ome.tif', '.ome.zarr']"
118,napari-bigfish,napari-bigfish,BigFISH smFISH Analysis,0.8,2023-04-07,2025-07-23,Volker Baecker,volker.baecker@mri.cnrs.fr,MIT,https://github.com/MontpellierRessourcesImagerie/napari-bigfish/issues,https://pypi.org/project/napari-bigfish/,,https://github.com/MontpellierRessourcesImagerie/napari-bigfish,A napari-plugin providing an alternative GUI for Big-FISH. Big-FISH is a python package for the analysis of smFISH images.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'pyperclip', 'big-fish', 'scikit-image', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']"," # napari-bigfish

[![License MIT](https://img.shields.io/pypi/l/napari-bigfish.svg?color=green)](https://github.com/MontpellierRessourcesImagerie/napari-bigfish/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bigfish.svg?color=green)](https://pypi.org/project/napari-bigfish)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bigfish.svg?color=green)](https://python.org)
[![tests](https://github.com/MontpellierRessourcesImagerie/napari-bigfish/workflows/tests/badge.svg)](https://github.com/MontpellierRessourcesImagerie/napari-bigfish/actions)
[![codecov](https://codecov.io/gh/MontpellierRessourcesImagerie/napari-bigfish/branch/main/graph/badge.svg)](https://codecov.io/gh/MontpellierRessourcesImagerie/napari-bigfish)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bigfish)](https://napari-hub.org/plugins/napari-bigfish)

A napari-plugin providing an alternative GUI for [Big-FISH](https://github.com/fish-quant/big-fish). Big-FISH is a python package for the analysis of smFISH images.

The plugin provides a graphical user interface for some of the functionality in Big-FISH. Currently implemented are:

 * Gaussian-background subtraction
 * FISH-spot detection with 
	* Elimination of duplicates
	* Auto-detection of threshold
* Dense-region decomposition

The plugin further implements by itself:

* Counting of spots per cell, inside and outside of the nucleus
* Batch processing on a list of images


You can find the user and the api-documentation of napari-bigfish [here](https://montpellierressourcesimagerie.github.io/napari-bigfish/).
 

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-bigfish` via [pip]:

    pip install napari-bigfish


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.


## License

Distributed under the terms of the [MIT] license,
""napari-bigfish"" is free and open source software


## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/MontpellierRessourcesImagerie/napari-bigfish/issues', 'Documentation, https://montpellierressourcesimagerie.github.io/napari-bigfish/', 'Source Code, https://github.com/MontpellierRessourcesImagerie/napari-bigfish', 'User Support, https://github.com/MontpellierRessourcesImagerie/napari-bigfish/issues']",,,napari-bigfish.make_qwidget,napari-bigfish.make_sample_data,,,
119,napari-bigwarp,napari-bigwarp,napari-bigwarp,0.0.1,2022-01-26,2022-01-26,Ben Kantor,benkantor@gmail.com,BSD-3-Clause,https://github.com/bkntr/napari-bigwarp/issues,https://pypi.org/project/napari-bigwarp/,,https://github.com/bkntr/napari-bigwarp,BigWarp-like interface for napari,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'opencv-contrib-python', 'opencv-python']","# napari-bigwarp

[![License](https://img.shields.io/pypi/l/napari-bigwarp.svg?color=green)](https://github.com/bkntr/napari-bigwarp/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bigwarp.svg?color=green)](https://pypi.org/project/napari-bigwarp)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bigwarp.svg?color=green)](https://python.org)
[![tests](https://github.com/bkntr/napari-bigwarp/workflows/tests/badge.svg)](https://github.com/bkntr/napari-bigwarp/actions)
[![codecov](https://codecov.io/gh/bkntr/napari-bigwarp/branch/main/graph/badge.svg)](https://codecov.io/gh/bkntr/napari-bigwarp)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bigwarp)](https://napari-hub.org/plugins/napari-bigwarp)

BigWarp-like interface for napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-bigwarp` via [pip]:

    pip install napari-bigwarp



To install latest development version :

    pip install git+https://github.com/bkntr/napari-bigwarp.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-bigwarp"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/bkntr/napari-bigwarp/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/bkntr/napari-bigwarp/issues', 'Documentation, https://github.com/bkntr/napari-bigwarp#README.md', 'Source Code, https://github.com/bkntr/napari-bigwarp', 'User Support, https://github.com/bkntr/napari-bigwarp/issues']",,,napari-bigwarp.BigWarpQWidget,,,,
120,napari-bioio-reader,napari-bioio-reader,Bioio Reader,0.2.0,2025-07-04,2025-07-04,Laurent Guerard,l.guerard42@gmail.com,"Copyright (c) 2025, Laurent Gu...",https://github.com/lguerard/napari-bioio-reader/issues,https://pypi.org/project/napari-bioio-reader/,,,A simple plugin to use the Bioio reader in napari,>=3.10,"['numpy', 'bioio', 'bioio-bioformats', 'scyjava', 'napari[all]<0.7,>=0.6.2', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""']","# napari-bioio-reader

[![License BSD-3](https://img.shields.io/pypi/l/napari-bioio-reader.svg?color=green)](https://github.com/lguerard/napari-bioio-reader/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bioio-reader.svg?color=green)](https://pypi.org/project/napari-bioio-reader)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bioio-reader.svg?color=green)](https://python.org)
[![tests](https://github.com/lguerard/napari-bioio-reader/workflows/tests/badge.svg)](https://github.com/lguerard/napari-bioio-reader/actions)
[![codecov](https://codecov.io/gh/lguerard/napari-bioio-reader/branch/main/graph/badge.svg)](https://codecov.io/gh/lguerard/napari-bioio-reader)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bioio-reader)](https://napari-hub.org/plugins/napari-bioio-reader)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

A simple plugin to use the Bioio reader in napari

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-bioio-reader` via [pip]:

    pip install napari-bioio-reader




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-bioio-reader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/lguerard/napari-bioio-reader/issues', 'Documentation, https://github.com/lguerard/napari-bioio-reader#README.md', 'Source Code, https://github.com/lguerard/napari-bioio-reader', 'User Support, https://github.com/lguerard/napari-bioio-reader/issues']",napari-bioio-reader.get_reader,,,,"['*.1sc', '*.2fl', '*.3fr', '*.acff', '*.acqp', '*.afi', '*.afm', '*.aim', '*.al3d', '*.ali', '*.am', '*.amiramesh', '*.ano', '*.apl', '*.arf', '*.array-like', '*.arw', '*.avi', '*.bay', '*.bif', '*.bin', '*.bip', '*.bmp', '*.bmq', '*.bsdf', '*.bufr', '*.bw', '*.c01', '*.cap', '*.cat', '*.cfg', '*.ch5', '*.cif', '*.cine', '*.cr2', '*.crw', '*.cs1', '*.csv', '*.ct', '*.ct.img', '*.cur', '*.cut', '*.cxd', '*.czi', '*.dat', '*.db', '*.dc2', '*.dcm', '*.dcr', '*.dcx', '*.dds', '*.df3', '*.dicom', '*.dm2', '*.dm3', '*.dng', '*.drf', '*.dsc', '*.dti', '*.dv', '*.ecw', '*.emf', '*.eps', '*.epsi', '*.erf', '*.exp', '*.exr', '*.fake', '*.fdf', '*.fff', '*.ffr', '*.fid', '*.fit', '*.fits', '*.flc', '*.flex', '*.fli', '*.fpx', '*.frm', '*.ftc', '*.fts', '*.ftu', '*.fz', '*.g3', '*.gbr', '*.gdcm', '*.gel', '*.gif', '*.gipl', '*.grey', '*.grib', '*.h5', '*.hdf', '*.hdf5', '*.hdp', '*.hdr', '*.hed', '*.his', '*.htd', '*.htm', '*.html', '*.hx', '*.i2i', '*.ia', '*.icns', '*.ico', '*.ics', '*.ids', '*.iff', '*.iim', '*.iiq', '*.im', '*.im3', '*.img', '*.imggz', '*.ims', '*.inf', '*.inr', '*.ipl', '*.ipm', '*.ipw', '*.j2c', '*.j2k', '*.jfif', '*.jif', '*.jng', '*.jp2', '*.jpc', '*.jpe', '*.jpeg', '*.jpf', '*.jpg', '*.jpk', '*.jpx', '*.jxr', '*.k25', '*.kc2', '*.kdc', '*.klb', '*.koa', '*.l2d', '*.labels', '*.lbm', '*.lei', '*.lfp', '*.lfr', '*.lif', '*.liff', '*.lim', '*.lms', '*.lsm', '*.mdb', '*.mdc', '*.mef', '*.mgh', '*.mha', '*.mhd', '*.mic', '*.mkv', '*.mnc', '*.mnc2', '*.mng', '*.mod', '*.mos', '*.mov', '*.mp4', '*.mpeg', '*.mpg', '*.mpo', '*.mrc', '*.mri', '*.mrw', '*.msp', '*.msr', '*.mtb', '*.mvd2', '*.naf', '*.nd', '*.nd2', '*.ndpi', '*.ndpis', '*.nef', '*.nhdr', '*.nia', '*.nii', '*.nii.gz', '*.niigz', '*.npz', '*.nrrd', '*.nrw', '*.obf', '*.oib', '*.oif', '*.oir', '*.ome', '*.ome.tif', '*.ome.tiff', '*.orf', '*.par', '*.pbm', '*.pcd', '*.pcoraw', '*.pct', '*.pcx', '*.pef', '*.pfm', '*.pgm', '*.pic', '*.pict', '*.png', '*.pnl', '*.ppm', '*.pr3', '*.ps', '*.psd', '*.ptx', '*.pxn', '*.pxr', '*.qptiff', '*.qtk', '*.r3d', '*.raf', '*.ras', '*.raw', '*.rcpnl', '*.rdc', '*.rec', '*.rgb', '*.rgba', '*.rw2', '*.rwl', '*.rwz', '*.scan', '*.scn', '*.sdt', '*.seq', '*.sif', '*.sld', '*.sm2', '*.sm3', '*.spc', '*.spe', '*.spi', '*.sr2', '*.srf', '*.srw', '*.st', '*.sti', '*.stk', '*.stp', '*.svs', '*.swf', '*.sxm', '*.targa', '*.tfr', '*.tga', '*.thm', '*.tif', '*.tiff', '*.tim', '*.tnb', '*.top', '*.txt', '*.v', '*.vff', '*.vms', '*.vsi', '*.vtk', '*.vws', '*.wap', '*.wat', '*.wav', '*.wbm', '*.wbmp', '*.wdp', '*.webp', '*.wlz', '*.wmf', '*.wmv', '*.wpi', '*.xbm', '*.xdce', '*.xml', '*.xpm', '*.xqd', '*.xqf', '*.xv', '*.xys', '*.zfp', '*.zfr', '*.zip', '*.zpo', '*.zvi']",,
121,napari-bil-data-viewer,napari-bil-data-viewer,napari-bil-data-viewer,0.6.0,2022-01-24,2024-02-28,Alan M Watson,alan.watson@pitt.edu,BSD-3-Clause,https://github.com/brain-image-library/napari-bil-data-viewer,https://pypi.org/project/napari-bil-data-viewer/,,https://github.com/brain-image-library/napari-bil-data-viewer,Napari plugin for viewing Brain Image Library datasets,>=3.8,"['napari[all]', 'napari-plugin-engine >=0.1.4', 'scikit-image', 'fsspec', 'requests', 'aiohttp', 'imagecodecs', 'beautifulsoup4', 'dask', 'neurom ==3.2.2', 'napari-ome-zarr ==0.5.2']","<p href=""https://www.brainimagelibrary.org/"">
    <align=""center"" width=""100%"">
    <img width=""100%"" src=""https://i.imgur.com/ljZKq8h.png"">
</p>


# Description

View datasets archived at the **[Brain Image Library](https://www.brainimagelibrary.org/)**.

**NOTE: This plugin is under early development.  Currently, only a subset of single-channel, fMOST datasets which include projections are available to view.  An example can be found [here]( https://download.brainimagelibrary.org/2b/da/2bdaf9e66a246844/mouseID_405429-182725/).



![Plugin Demo GIF](https://imgur.com/gkDCsMd.gif ""Plugin Demo GIF"")



### Features

* Multiscale Rendering
  * In datasets that include multiple resolution representations of the data, each resolution can be combined to improve the speed of browsing and user experience.  An example of a dataset with multiple resolution projections can be found [here](https://download.brainimagelibrary.org/2b/da/2bdaf9e66a246844/mouseID_405429-182725/).
  * All datasets included in the current release of napari-bil-data-viewer use multi-resolution datasets.
* 3D rendering of whole datasets.  The lowest resolution is used for rendering.  Currently, this is a limitation imposed by napari.
* The plugin does NOT require a BIL account as datasets are already accessible via https.

### Known Issues / limitations
* Currently the only datasets that are available are those which have been manually selected by the developers.  If you would like a specific dataset to be included please consider adding the dataset(s) to the [dataset_info.py](https://github.com/brain-image-library/napari-bil-data-viewer/blob/main/napari_bil_data_viewer/dataset_info.py) file and submitting a pull request.
* To inquire about this plugin please contact Brain Image Library support:  bil-support@psc.edu
* The plugin is still under development.  We appreciate all [reports of issues / errors](https://github.com/brain-image-library/napari-bil-data-viewer/issues) which occur during use.


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

Option #1: Install plugin via the napari plugin menu

1. Menu: Plugins >> Install/Uninstall Plugins
2. Search: napari-bil-data-viewer
3. Select install

Option #2:  Install a fresh python virtual environment

```bash
# Example of venv creation using conda
conda create -y -n bil-viewer python=3.8
conda activate bil-viewer

# Install napari-bil-data-viewer
pip install napari-bil-data-viewer

# Run Napari
napari
```

## Contributing

Please consider contributing to this project!  Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-bil-data-viewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/brain-image-library/napari-bil-data-viewer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

## Change Log:

##### <u>v0.1.0:</u>

Initial release.

<u>**v0.1.1 & v0.1.2:**</u>

Changes to documentation

<u>**v0.1.3:**</u>

Added all available summary fMOST datasets

<u>**v0.2.0:**</u>

Added support for SWC neuron tracings

<u>**v0.3.0:**</u>

Added support for multiscale OME zarr data

<u>**v0.4.0:**</u>

Add scale controls for layers

<u>**v0.4.2:**</u>

Add URL input to visualize image stacks (tif, tiff, jp2)

<u>**v0.5.0:**</u>

Split the plugin into 5 widgets:<br/>
- Load Curated Datasets
- Load Image Stack From URL
- Load Multiscale Data From URL
- Load Neuron Morphology From URL
- Layer Scale Controls

<u>**v0.5.1:**</u>

Add metadata link to curated datasets

<u>**v0.6.0:**</u>

Add widget to visualize histology RGB tiffs
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/brain-image-library/napari-bil-data-viewer/issues', 'Documentation, https://github.com/brain-image-library/napari-bil-data-viewer#README.md', 'Source Code, https://github.com/brain-image-library/napari-bil-data-viewer', 'User Support, https://github.com/brain-image-library/napari-bil-data-viewer']",napari-bil-data-viewer.napari_get_reader,,napari-bil-data-viewer.LoadCuratedDatasets,,['*'],,
122,napari-biomag-annotator,napari-biomag-annotator,BIOMAG Annotator,0.0.3,2024-01-11,2024-01-11,"Reka Hollandi, David Bauer",hunreka93@hotmail.com,BSD-3-Clause,https://github.com/biomag-lab/napari-biomag-annotator/issues,https://pypi.org/project/napari-biomag-annotator/,,https://github.com/biomag-lab/napari-biomag-annotator,An annotator tool collection by the BIOMAG group.,>=3.8,"['napari', 'napari-plugin-engine >=0.1.4', 'napari-annotatorj', 'napari-nD-annotator', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-biomag-annotator

[![License BSD-3](https://img.shields.io/pypi/l/napari-biomag-annotator.svg?color=green)](https://github.com/biomag-lab/napari-biomag-annotator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-biomag-annotator.svg?color=green)](https://pypi.org/project/napari-biomag-annotator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-biomag-annotator.svg?color=green)](https://python.org)
[![tests](https://github.com/biomag-lab/napari-biomag-annotator/workflows/tests/badge.svg)](https://github.com/biomag-lab/napari-biomag-annotator/actions)
[![codecov](https://codecov.io/gh/biomag-lab/napari-biomag-annotator/branch/main/graph/badge.svg)](https://codecov.io/gh/biomag-lab/napari-biomag-annotator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-biomag-annotator)](https://napari-hub.org/plugins/napari-biomag-annotator)

An annotator tool collection by the BIOMAG group.

This plugin allows object annotation on 2/3D images using 4 assisted annotation methods arising from two napari plugins:

- [napari-annotatorj](https://github.com/spreka/napari-annotatorj)
- [napari-nD-annotator](https://github.com/bauerdavid/napari-nD-annotator)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-biomag-annotator` via [pip]:

    pip install napari[all]
    pip install napari-biomag-annotator



To install latest development version :

    pip install git+https://github.com/biomag-lab/napari-biomag-annotator.git


On Linux distributions, the following error may arise upon napari startup after the installation of the plugin: `Could not load the Qt platform plugin âxcbâ in ââ even though it was found`. In this case, the manual install of `libxcb-xinerama0` for Qt is required:

    sudo apt install libxcb-xinerama0

### Bundled napari app
The bundled application version of [napari](https://github.com/napari/napari/releases) allows the pip install of plugins in the .zip distribution. After installation of this release, napari-annotatorj can be installed from the `Plugins --> Install/Uninstall plugins...` menu by searching for its name and clicking on the `Install` button next to it.

### Script
Single-file install is supported on [**Windows**](#windows) and [Linux](#linux) (currently). It will create a virtual environment named `napariAnnotatorEnv` in the parent folder of the cloned repository, install the package via pip and start napari. It requires a valid Python install.

#### Windows
To start it, run in the Command prompt

    git clone https://github.com/biomag-lab/napari-biomag-annotator.git
    cd napari-biomag-annotator
    install.bat

Or download [install.bat](https://github.com/biomag-lab/napari-biomag-annotator/blob/main/install.bat) and run it from the Command prompt.

After install, you can use [startup_napari.bat](https://github.com/biomag-lab/napari-biomag-annotator/blob/main/startup_napari.bat) to activate your installed virtual environment and run napari. Run it from the Command prompt with:

    startup_napari.bat


#### Linux
To start it, run in the Terminal

    git clone https://github.com/biomag-lab/napari-biomag-annotator.git
    cd napari-annotatorj
    install.sh

Or download [install.sh](https://github.com/biomag-lab/napari-biomag-annotator/blob/main/install.sh) and run it from the Terminal.

After install, you can use [startup_napari.sh](https://github.com/biomag-lab/napari-biomag-annotator/blob/main/startup_napari.sh) to activate your installed virtual environment and run napari. Run it from the Terminal with:

    startup_napari.sh

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-biomag-annotator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/biomag-lab/napari-biomag-annotator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/biomag-lab/napari-biomag-annotator/issues', 'Documentation, https://github.com/biomag-lab/napari-biomag-annotator#README.md', 'Source Code, https://github.com/biomag-lab/napari-biomag-annotator', 'User Support, https://github.com/biomag-lab/napari-biomag-annotator/issues']",napari-biomag-annotator.get_reader,napari-biomag-annotator.write_multiple,napari-biomag-annotator.BIOMAGAnnotator,,['*.npy'],,['.npy']
123,napari-bioformats,napari-bioformats,napari-bioformats,0.2.1,2021-06-25,2021-08-11,Talley Lambert,talley.lambert@gmail.com,GPL-3.0,https://github.com/tlambert03/napari-bioformats/issues,https://pypi.org/project/napari-bioformats/,,https://github.com/tlambert03/napari-bioformats,"Bioformats for napari, using pims",>=3.7,"['jpype1', 'napari-plugin-engine (>=0.1.4)', 'numpy', 'ome-types', 'pims', 'requests', ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-bioformats

[![License](https://img.shields.io/pypi/l/napari-bioformats.svg?color=green)](https://github.com/napari/napari-bioformats/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bioformats.svg?color=green)](https://pypi.org/project/napari-bioformats)
[![Conda](https://img.shields.io/conda/v/conda-forge/napari-bioformats)](https://anaconda.org/conda-forge/napari-bioformats)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bioformats.svg?color=green)](https://python.org)
[![tests](https://github.com/tlambert03/napari-bioformats/workflows/tests/badge.svg)](https://github.com/tlambert03/napari-bioformats/actions)
[![codecov](https://codecov.io/gh/tlambert03/napari-bioformats/branch/master/graph/badge.svg)](https://codecov.io/gh/tlambert03/napari-bioformats)

Bioformats plugin for napari using
[pims-bioformats](http://soft-matter.github.io/pims/v0.5/bioformats.html)

----------------------------------

## Use this plugin as a fallback!

Anyone coming to napari from the Fiji/ImageJ world will likely be aware of the
_incredible_ [Bio-Formats](https://docs.openmicroscopy.org/bio-formats/6.6.1/index.html)
library.  A heroic effort, built over years, to read
[more than a 100 file formats](https://docs.openmicroscopy.org/bio-formats/6.6.1/supported-formats.html).  Naturally, we want some of that goodness for `napari` ... hence this plugin.

**However:** it's important to note that this plugin _still_
requires having a java runtime engine installed.  This is easy enough to do
(the plugin will ask to install it for you if you're in a `conda` environment), but
it definitely makes for a more complicated environment setup, it's not very
""pythonic"", and the performance will likely not feel as snappy as a native ""pure""
python module.

So, before you reflexively install this plugin to fill that bio-formats
sized hole in your python heart, consider trying some of the other pure-python
plugins designed to read your format of interest:

- **Zeiss (.czi)**: [napari-aicsimageio](https://github.com/AllenCellModeling/napari-aicsimageio), [napari-czifile2](https://github.com/BodenmillerGroup/napari-czifile2)
- **Nikon (.nd2)**: [napari-nikon-nd2](https://github.com/cwood1967/napari-nikon-nd2), [nd2-dask](https://github.com/DragaDoncila/nd2-dask)
- **Leica (.lif)**: [napari-aicsimageio](https://github.com/AllenCellModeling/napari-aicsimageio)
- **Olympus (.oif)**: no plugin?  (but see [oiffile](https://pypi.org/project/oiffile/) )
- **DeltaVision (.dv, .mrc)**: [napari-dv](https://github.com/tlambert03/napari-dv)

> *if you have a pure-python reader for a bio-formats-supported file format that
you'd like to see added to this list, please open an issue*

## Installation

The easiest way to install `napari-bioformats` is via [conda], from the
[conda-forge] channel:

    conda install -c conda-forge napari-bioformats

It is also possible to install via [pip], but you will need to have a working
JVM installed, and may need to set the `JAVA_HOME` environment variable

    pip install napari-bioformats

### First Usage

The first time you attempt to open a file with napari-bioformats, you will
likely notice a long delay as pims downloads the `loci_tools.jar` (speed will
depend on your internet connection). Subsequent files should open more quickly.

## License

Distributed under the terms of the [GPLv3] license,
""napari-bioformats"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

_This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template._

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[GPLv3]: https://opensource.org/licenses/GPL-3.0
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/tlambert03/napari-bioformats/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[conda]: https://docs.conda.io/en/latest/
[conda-forge]: https://conda-forge.org
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/tlambert03/napari-bioformats/issues', 'Documentation, https://github.com/tlambert03/napari-bioformats#README.md', 'Source Code, https://github.com/tlambert03/napari-bioformats', 'User Support, https://github.com/tlambert03/napari-bioformats/issues']",napari-bioformats.napari_get_reader,,,,['*'],,
124,napari-bioimageio,napari-bioimageio,BioImage.IO Model Manager,0.1.3,2022-07-05,2022-07-07,,,Unavailable,,https://pypi.org/project/napari-bioimageio/,None,,,>=3.7,"['napari', 'bioimageio.core (>=0.5.1)', 'PyYAML (>=6.0)']","# napari-bioimageio

napari plugin for managing AI models in the [BioImage Model Zoo](https://bioimage.io).

> **WARNING**: This is an alpha release. The API may change in future versions, and please feel free to create issues to report bugs or provide feedbacks.

![](assets/screenshot-model-manager-1.png)

## Installation

```
pip install napari-bioimageio
```

(If you don't have napari installed, run `pip install napari[pyqt5]`)

## Usage

This library is meant for helping developers to ease the handling of models in napari.

We provide a set of API functions for managing and selecting models.
### `show_model_manager()`
Show the model manager with a model list pulled from the BioImage Model Zoo, the user can explore all the available models, download or remove models.

### `show_model_selector(filter=None)`
Display a dialog for selecting models from the BioImage Model Zoo, the user can either select an existing model or download from the BioImage Model Zoo.

The selecte model information (a dictionary) will be returned if the user selected a model, otherwise it returns `None`.

Once the user selected the model, you can access the name, and also the file path to the model resource description file (via the `rdf_source` key). With the `bioimageio.core` library (installed via `pip install bioimageio.core` or `conda install -c conda-forge bioimageio.core`), you can run inference directly, the following examples shows how to implement it:

```python
# Popup a model selection dialog for choosing the model
model_info = show_model_selector(filter=nuclear_segmentation_model_filter)

if model_info:
  self.nucseg_model_source = model_info[""rdf_source""]
  # Load model 
  model_description = bioimageio.core.load_resource_description(model_info[""rdf_source""])
  input_image = imageio.imread(""./my-image.tif"")

  with bioimageio.core.create_prediction_pipeline(
      bioimageio_model=model_description
  ) as pipeline:
    output_image = bioimageio.core.prediction.predict_with_padding(
        pipeline, input_image, padding=padding
    )
```
Note: To run the models, you need to setup the conda environment properly according to the [installation guide of bioimageio.core](https://github.com/bioimage-io/core-bioimage-io-python#installation).

For more examples, see [this example notebook](https://github.com/bioimage-io/core-bioimage-io-python/blob/main/example/bioimageio-core-usage.ipynb) for `bioimageio.core`.

You can also access the weight files directly by searching the model folder (e.g. extract the model folder path via `os.path.dirname(model_description[""rdf_source""])`), this will be useful if you prefer to use your own model inference logic.
### `show_model_uploader()`
Display a dialog to instruct the user to upload a model package to the BioImage Model Zoo.
Currently, it only shows a message, in the future, we will try to support direct uploading with user's credentials obtained from Zenodo (a public data repository used by the BioImage Model Zoo to store models).

To create a BioImageIO-compatible model package, you can use the `build_model` function as demonstrated in [this notebook]((https://github.com/bioimage-io/core-bioimage-io-python/blob/main/example/bioimageio-core-usage.ipynb)).

## Development

- Install and set up development environment.

  ```sh
  pip install -r requirements_dev.txt
  ```

  This will install all requirements.
It will also install this package in development mode, so that code changes are applied immediately without reinstall necessary.

- Here's a list of development tools we use.
  - [black](https://pypi.org/project/black/)
  - [flake8](https://pypi.org/project/flake8/)
  - [mypy](https://pypi.org/project/mypy/)
  - [pydocstyle](https://pypi.org/project/pydocstyle/)
  - [pylint](https://pypi.org/project/pylint/)
  - [pytest](https://pypi.org/project/pytest/)
  - [tox](https://pypi.org/project/tox/)
- It's recommended to use the corresponding code formatter and linters also in your code editor to get instant feedback. A popular editor that can do this is [`vscode`](https://code.visualstudio.com/).
- Run all tests, check formatting and linting.

  ```sh
  tox
  ```

- Run a single tox environment.

  ```sh
  tox -e lint
  ```

- Reinstall all tox environments.

  ```sh
  tox -r
  ```

- Run pytest and all tests.

  ```sh
  pytest
  ```

- Run pytest and calculate coverage for the package.

  ```sh
  pytest --cov-report term-missing --cov=napari-bioimageio
  ```

- Continuous integration is by default supported via [GitHub actions](https://help.github.com/en/actions). GitHub actions is free for public repositories and comes with 2000 free Ubuntu build minutes per month for private repositories.
","['Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.7']",,,,napari-bioimageio.QtBioImageIOModelManager,,,,
125,napari-biopb,napari-biopb,single-cell segmentation,0.1.4,2025-02-02,2025-03-07,Ji Yu,jyu@uchc.edu,MIT,https://github.com/jiyuuchc/napari-biopb/issues,https://pypi.org/project/napari-biopb/,,,Performing image analysis by visiting biopb endpoints,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'biopb', 'opencv-python-headless', 'grpcio_tools', 'vedo', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-biopb

[![License MIT](https://img.shields.io/pypi/l/napari-biopb.svg?color=green)](https://github.com/jiyuuchc/napari-biopb/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-biopb.svg?color=green)](https://pypi.org/project/napari-biopb)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-biopb.svg?color=green)](https://python.org)
[![tests](https://github.com/jiyuuchc/napari-biopb/workflows/tests/badge.svg)](https://github.com/jiyuuchc/napari-biopb/actions)
[![codecov](https://codecov.io/gh/jiyuuchc/napari-biopb/branch/main/graph/badge.svg)](https://codecov.io/gh/jiyuuchc/napari-biopb)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-biopb)](https://napari-hub.org/plugins/napari-biopb)

Performing single-cell segmentation by visiting [biopb](https://github.com/jiyuuchc/biopb) endpoints

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-biopb` via [pip]:

    pip install napari-biopb



To install latest development version :

    pip install git+https://github.com/jiyuuchc/napari-biopb.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-biopb"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/jiyuuchc/napari-biopb/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/jiyuuchc/napari-biopb/issues', 'Documentation, https://github.com/jiyuuchc/napari-biopb#README.md', 'Source Code, https://github.com/jiyuuchc/napari-biopb', 'User Support, https://github.com/jiyuuchc/napari-biopb/issues']",,,napari-biopb.make_biopb_image_widget,,,,
126,napari-bio-sample-data,napari-bio-sample-data,napari bio sample data,0.0.4,2022-07-12,2022-07-13,Chi-Li Chiu,cchiu@chanzuckerberg.com,BSD-3-Clause,https://github.com/chili-chiu/napari-bio-sample-data/issues,https://pypi.org/project/napari-bio-sample-data/,,https://github.com/chili-chiu/napari-bio-sample-data,a sample data plugin for bio-related demos,>=3.8,"['numpy', 'fsspec', 'zarr (>=2.12.0)', 'dask', 's3fs', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-bio-sample-data

[![License](https://img.shields.io/pypi/l/napari-bio-sample-data.svg?color=green)](https://github.com/chili-chiu/napari-bio-sample-data/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bio-sample-data.svg?color=green)](https://pypi.org/project/napari-bio-sample-data)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bio-sample-data.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bio-sample-data)](https://napari-hub.org/plugins/napari-bio-sample-data)

a sample data plugin for bio-related demos

----------------------------------
This plugin contains 5 sample datasets with additional napari layer types:

(1) 3D EM dataset (image + points + vectors)  
Image credit: Alister Burt  
The [original data](https://github.com/alisterburt/napari-cryo-et-demo) is down-sampled to have smaller file size.  
<img width=""300"" alt=""image"" src=""https://user-images.githubusercontent.com/89602983/178569428-7daa2eb8-a3ff-4c0e-8e5f-4f615a55684f.png"">

(2) 2D skin RGB dataset (image + shape)  
Image credit: skimage.data.skin  
<img width=""300"" alt=""image"" src=""https://user-images.githubusercontent.com/89602983/178569580-bf77e55c-71cc-4883-9fe5-ed94e05f2a29.png"">
  
(3) 3D nuclei dataset (image + label + surface)  
Image credit: skimage.data.cells3d  
<img width=""300"" alt=""image"" src=""https://user-images.githubusercontent.com/89602983/178569701-7c9b1cc3-c1c3-4e54-8ca0-fb2b530f858e.png"">

(4) 2D timelapse dataset (image + points + tracks)  
Image credit: [Cell Tracking Challenge](http://celltrackingchallenge.net/2d-datasets/)  
The original data is cropped to have smaller file size.  
<img width=""300"" alt=""image"" src=""https://user-images.githubusercontent.com/89602983/178569846-b995d1cb-c1ec-4363-ba1a-71243ffea4e0.png"">

(5) large multi-resolution 3D EM dataset  
Image credit: [Janelia Open Organelle](https://openorganelle.janelia.org/datasets/jrc_hela-1)   
This plugin only accesses 2 lower resolution levels.  
<img width=""300"" alt=""image"" src=""https://user-images.githubusercontent.com/89602983/178570136-6f59ba3c-d687-446c-9f5e-1df567a62948.png"">

Datasets (1)-(4) are stored locally.   
Dataset (5) is downloaded and temporarily stored on RAM when accessed.    

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-bio-sample-data` via [pip]:

    pip install napari-bio-sample-data

To install latest development version :

    pip install git+https://github.com/chili-chiu/napari-bio-sample-data.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-bio-sample-data"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/chili-chiu/napari-bio-sample-data/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/chili-chiu/napari-bio-sample-data/issues', 'Documentation, https://github.com/chili-chiu/napari-bio-sample-data#README.md', 'Source Code, https://github.com/chili-chiu/napari-bio-sample-data', 'User Support, https://github.com/chili-chiu/napari-bio-sample-data/issues']",,,,napari-bio-sample-data.tomo_data,,,
127,napari-blosc2,napari-blosc2,Blosc2 Reader & Writer,0.0.2,2024-07-11,2024-07-11,Karol Gotkowski,karol.gotkowski@dkfz.de,"Apache License
               ...",,https://pypi.org/project/napari-blosc2/,None,,An image reader & writer for blosc2 images.,>=3.9,"['blosc2', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-blosc2

[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-blosc2.svg?color=green)](https://github.com/Karol-G/napari-blosc2/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-blosc2.svg?color=green)](https://pypi.org/project/napari-blosc2)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-blosc2.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-blosc2)](https://napari-hub.org/plugins/napari-blosc2)

An image reader & writer for blosc2 images.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-blosc2` via [pip]:

    pip install napari-blosc2




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-blosc2"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-blosc2.get_reader,napari-blosc2.write_multiple,,,['*.b2nd'],,['.b2nd']
128,napari-bleach-correct,napari-bleach-correct,Bleaching Correction,0.0.1,2022-09-22,2022-09-22,Alexander Marx,a.marx95@gmx.de,MIT,https://github.com/marx-alex/napari-bleach-correct/issues,https://pypi.org/project/napari-bleach-correct/,,https://github.com/marx-alex/napari-bleach-correct,A napari plugin to correct time-lapse images for photobleaching.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'scipy', 'pyqtgraph', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-bleach-correct

[![License](https://img.shields.io/github/license/marx-alex/napari-bleach-correct)](https://github.com/marx-alex/napari-bleach-correct)
[![PyPI](https://img.shields.io/pypi/v/napari-bleach-correct.svg?color=green)](https://pypi.org/project/napari-bleach-correct)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bleach-correct.svg?color=green)](https://python.org)
[![tests](https://github.com/marx-alex/napari-bleach-correct/workflows/tests/badge.svg)](https://github.com/marx-alex/napari-bleach-correct/actions)
[![codecov](https://codecov.io/gh/marx-alex/napari-bleach-correct/branch/main/graph/badge.svg)](https://codecov.io/gh/marx-alex/napari-bleach-correct)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bleach-correct)](https://napari-hub.org/plugins/napari-bleach-correct)

## Bleach correction for napari

This plugin is a python implementation of three different algorithms for bleach correction and can be used 
to correct time-lapse images that lose intensity due to photobleaching. The implementation is based on the ImageJ 
plugin Bleach Corrector by Miura et al. All methods work with 2D and 3D time series.

Napari Bleach correction is easy to use:

![Demo](./data/demo.gif)

### Ratio Method

This is the simplest method. Every pixel in a frame is multiplied by the ratio from the mean intensity of the 
first frame to that of the *i-th* frame.

Assumptions:
* the mean intensity is constant through the time-lapse
* the background fluorescence is the same for every pixel and frame

Parameters:
* Background Intensity: Must be estimated

### Exponential Curve Fitting

Drift estimation of fluorescence signal by fitting the mean intensity to an exponential curve.
The image is corrected by the decay in the normalized exponential function.

Assumptions:
* time intervals between frames are equal

Parameters:
* Exponential Curve: Bleaching can be modelled as a mono- or bi-exponential curve

### Histogram Matching

Bleaching correction by matching histograms to a reference image.
The correct pixel values can be calculated by the cumulative distribution function
of a frame and its reference frame. This method introduced by Miura et al.

Parameters:
* Reference Frame: Match the frame's histogram with the first our neighbor frame 

**The Histogram Matching method using the neighbor frame as reference is a good start to correct bleaching.**
All methods are described in detail in Miura et al.

## References

* Miura K. [Bleach correction ImageJ plugin for compensating the photobleaching of time-lapse sequences.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7871415/) F1000Res. 2020 Dec 21;9:1494. doi: 10.12688/f1000research.27171.1
* [Documentation of the ImageJ plugin](https://wiki.cmci.info/downloads/bleach_corrector)
----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-bleach-correct` via [pip]:

    pip install napari-bleach-correct



To install latest development version :

    pip install git+https://github.com/marx-alex/napari-bleach-correct.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-bleach-correct"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/marx-alex/napari-bleach-correct/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/marx-alex/napari-bleach-correct/issues', 'Documentation, https://github.com/marx-alex/napari-bleach-correct#README.md', 'Source Code, https://github.com/marx-alex/napari-bleach-correct', 'User Support, https://github.com/marx-alex/napari-bleach-correct/issues']",,,napari-bleach-correct.main_widget,napari-bleach-correct.make_sample_data,,,
129,napari-bluesky,napari-bluesky,Bluesky,0.0.2,2024-11-29,2024-11-29,Kyle Harrington,bluesky@kyleharrington.com,MIT,https://github.com/kephale/napari-bluesky/issues,https://pypi.org/project/napari-bluesky/,,,A plugin for posting to Bluesky from napari,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'atproto', 'appdirs', 'python-dotenv', 'pillow', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-bluesky

[![License MIT](https://img.shields.io/pypi/l/napari-bluesky.svg?color=green)](https://github.com/kephale/napari-bluesky/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bluesky.svg?color=green)](https://pypi.org/project/napari-bluesky)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bluesky.svg?color=green)](https://python.org)
[![tests](https://github.com/kephale/napari-bluesky/workflows/tests/badge.svg)](https://github.com/kephale/napari-bluesky/actions)
[![codecov](https://codecov.io/gh/kephale/napari-bluesky/branch/main/graph/badge.svg)](https://codecov.io/gh/kephale/napari-bluesky)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bluesky)](https://napari-hub.org/plugins/napari-bluesky)

A plugin for posting to Bluesky from napari

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-bluesky` via [pip]:

    pip install napari-bluesky



To install latest development version :

    pip install git+https://github.com/kephale/napari-bluesky.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-bluesky"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/kephale/napari-bluesky/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kephale/napari-bluesky/issues', 'Documentation, https://github.com/kephale/napari-bluesky#README.md', 'Source Code, https://github.com/kephale/napari-bluesky', 'User Support, https://github.com/kephale/napari-bluesky/issues']",,,napari-bluesky.make_qwidget,,,,
130,napari-blender-bridge,napari-blender-bridge,napari-blender-bridge,0.2.0,2023-04-07,2023-04-10,Robert Haase,robert.haase@tu-dresden.de,GNU GPL v3.0,https://github.com/haesleinhuepf/napari-blender-bridge,https://pypi.org/project/napari-blender-bridge/,,https://github.com/haesleinhuepf/napari-blender-bridge,Transfer surface layers between Napari and Blender,>=3.8,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari-tools-menu', 'napari-process-points-and-surfaces (>=0.4.2)', 'vedo']","# napari-blender-bridge



[![License](https://img.shields.io/pypi/l/napari-blender-bridge.svg?color=green)](https://github.com/haesleinhuepf/napari-blender-bridge/raw/master/LICENSE)

[![PyPI](https://img.shields.io/pypi/v/napari-blender-bridge.svg?color=green)](https://pypi.org/project/napari-blender-bridge)

[![Python Version](https://img.shields.io/pypi/pyversions/napari-blender-bridge.svg?color=green)](https://python.org)

[![tests](https://github.com/haesleinhuepf/napari-blender-bridge/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-blender-bridge/actions)

[![codecov](https://codecov.io/gh/haesleinhuepf/napari-blender-bridge/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-blender-bridge)

[![Development Status](https://img.shields.io/pypi/status/napari-blender-bridge.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)

[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-blender-bridge)](https://napari-hub.org/plugins/napari-blender-bridge)



Transfer surface layers between Napari and Blender. This plugin is young and has just limited functionality. Contributions are welcome.





![img.png](https://github.com/haesleinhuepf/napari-blender-bridge/raw/main/docs/easter.gif)



## Usage



This plugin has its own submenu with all functionality under `Tools > Blender`. You can start up Blender, send a surface layer to Blender, retrieve all meshes back as one surface layer and shut down Blender.



## Installation instructions



* Download and install [Blender 3.5](https://www.blender.org/download/). 

* Start Blender and click the menu `Edit > Preferences`. Activate `Developer extras`.



![img.png](https://github.com/haesleinhuepf/napari-blender-bridge/raw/main/docs/blender_preferences.png)



* It is recommended to run this plugin in a conda environment together with [devbio-napari](https://github.com/haesleinhuepf/devbio-napari), 

[vedo](https://vedo.embl.es/) and [napari-process-points-and-surfaces](https://github.com/haesleinhuepf/napari-process-points-and-surfaces).

To install these, please run these commands line-by-line:

```

mamba create --name napari-blender-env python=3.9 devbio-napari vedo -c conda-forge

mamba activate napari-blender-env

pip install napari-process-points-and-surfaces napari-blender-bridge

```



## Similar and related plugins



There are other plugins for working with surface meshes:

* [napari-stress](https://github.com/campaslab/napari-stress)

* [napari-pymeshlab](https://github.com/zacsimile/napari-pymeshlab)

* [napari-process-points-and-surfaces](https://github.com/haesleinhuepf/napari-process-points-and-surfaces)



## Contributing



Contributions are very welcome. Tests can be run with [tox], please ensure

the coverage at least stays the same before you submit a pull request.



## License



Distributed under the terms of the [GNU GPL v3.0] license,

""napari-blender-bridge"" is free and open source software



## Issues



If you encounter any problems, please [file an issue] along with a detailed description.



[napari]: https://github.com/napari/napari

[Cookiecutter]: https://github.com/audreyr/cookiecutter

[@napari]: https://github.com/napari

[MIT]: http://opensource.org/licenses/MIT

[BSD-3]: http://opensource.org/licenses/BSD-3-Clause

[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt

[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt

[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0

[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt

[cookiecutter-napari-plugin]: https://github.com/haesleinhuepf/cookiecutter-napari-assistant-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-blender-bridge/issues

[napari]: https://github.com/napari/napari

[tox]: https://tox.readthedocs.io/en/latest/

[pip]: https://pypi.org/project/pip/

[PyPI]: https://pypi.org/

","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']",,,,,,,,
131,napari-blob-detection,napari-blob-detection,napari blob detection,0.0.2,2022-04-22,2022-04-22,"Andy Sweet, Chi-Li Chiu","andrewdsweet@gmail.com, cchiu@chanzuckerberg.com",BSD-3-Clause,https://github.com/andy-sweet/napari-blob-detection/issues,https://pypi.org/project/napari-blob-detection/,,https://github.com/andy-sweet/napari-blob-detection,Detects blobs in images,>=3.8,"['napari (>=0.4.13)', 'numpy', 'scikit-image', 'magicgui', ""pytest ; extra == 'test'""]","# napari-blob-detection

[![License](https://img.shields.io/pypi/l/napari-blob-detection.svg?color=green)](https://github.com/andy-sweet/napari-blob-detection/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-blob-detection.svg?color=green)](https://pypi.org/project/napari-blob-detection)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-blob-detection.svg?color=green)](https://python.org)
[![tests](https://github.com/andy-sweet/napari-blob-detection/workflows/tests/badge.svg)](https://github.com/andy-sweet/napari-blob-detection/actions)
[![codecov](https://codecov.io/gh/andy-sweet/napari-blob-detection/branch/main/graph/badge.svg)](https://codecov.io/gh/andy-sweet/napari-blob-detection)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-blob-detection)](https://napari-hub.org/plugins/napari-blob-detection)

Detects blobs in images

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

This plugin consists of two widgets:

1. Detects blobs on images
2. Convert points layer to labels layer

----------------------------------

### Detects blobs on images

This widget uses [scikit-image's blob detection algorithms](https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_blob.html) to detect bright blobs on dark backgrounds.

Parameters

- method: Laplacian of Gaussian (most accurate) or Difference of Gaussian (faster approximation) 
- image: Image layer for blob detection. Can be a 2D, 3D, or higher dimensionality image.
- dimensionality: users can specify if the image is 2D(+t) or 3D(+t).
- min sigma: the smallest blob size to detect
- max sigma: the largest blob size to detect
- threshold: the lower the threshold, the more low intensity blobs are detected. 

Output

Blobs are represented by the Points layer.
The size of each blob is proportional to `Points.feature['sigma']`,
which signifies the scale at which the feature point was found.

### Convert points layer to labels layer

This widget takes a points layer and converts it into a labels layer, with the image dimension matching the selected image layer.
By converting points to labels, users can leverage feature extraction functions that are available to labels to the detected points.

----------------------------------

## Installation

You can install `napari-blob-detection` via [pip]:

    pip install napari-blob-detection



To install latest development version :

    pip install git+https://github.com/andy-sweet/napari-blob-detection.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-blob-detection"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/andy-sweet/napari-blob-detection/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/andy-sweet/napari-blob-detection/issues', 'Documentation, https://github.com/andy-sweet/napari-blob-detection#README.md', 'Source Code, https://github.com/andy-sweet/napari-blob-detection', 'User Support, https://github.com/andy-sweet/napari-blob-detection/issues']",,,napari-blob-detection.detect_blobs_widget,,,,
132,napari-blossom,napari-blossom,Blossom,0.1.6,2022-06-20,2024-04-24,Herearii Metuarea,herearii.metuarea@gmail.com,BSD-3-Clause,https://github.com/hereariim/napari-blossom/issues,https://pypi.org/project/napari-blossom/,,https://github.com/hereariim/napari-blossom,Segmentation of blossom apple tree images,>=3.8,"['numpy >=1.23.0', 'magicgui >=0.6.1', 'qtpy', 'opencv-python-headless >=4.7.0.68', 'tensorflow >=2.11.0', 'scikit-image >=0.19.3', 'napari', 'focal-loss >=0.0.7', 'pillow >=9.3.0', 'tqdm >=4.64.1', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-blossom

[![License BSD-3](https://img.shields.io/pypi/l/napari-blossom.svg?color=green)](https://github.com/hereariim/napari-blossom/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-blossom.svg?color=green)](https://pypi.org/project/napari-blossom)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-blossom.svg?color=green)](https://python.org)
[![tests](https://github.com/hereariim/napari-blossom/workflows/tests/badge.svg)](https://github.com/hereariim/napari-blossom/actions)
[![codecov](https://codecov.io/gh/hereariim/napari-blossom/branch/main/graph/badge.svg)](https://codecov.io/gh/hereariim/napari-blossom)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-blossom)](https://napari-hub.org/plugins/napari-blossom)

Segmentation of blossom apple tree images

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

This plugin was written by Herearii Metuarea, student intern at LARIS (French laboratory located in Angers, France) in Imhorphen, french scientific team lead by David Rousseau (Full professor). This plugin was designed as part of the european project INVITE.

<img width=""86"" alt=""Logo-IRHS-h_2022_png_large"" src=""https://github.com/hereariim/napari-blossom/assets/93375163/750bbd60-ef3e-4148-9cbd-8a32e11252a4""> ![Logo-INRAE](https://github.com/hereariim/napari-blossom/assets/93375163/d7cc95a1-f09c-4430-8ac8-8962c1046767) ![logo2](https://github.com/hereariim/napari-blossom/assets/93375163/3b41c838-acc8-49a3-81f8-46d1305f43d3) ![logolaris1](https://github.com/hereariim/napari-blossom/assets/93375163/bf92a903-5810-4c43-aa28-573f96f64ff9) ![logo1](https://github.com/hereariim/napari-blossom/assets/93375163/f9361560-dd4f-49f4-955d-ffe41b5c014d)

## Installation

You can install `napari-blossom` via [pip]:

    pip install napari-blossom

To install latest development version :

    pip install git+https://github.com/hereariim/napari-blossom.git

## How does it works

This module offers a plugin that allows you to segment the images of the apple tree flowers. As input, you can enter a **single image** with the image selection widget. Once the image is entered in the napari window, you can segment the apple blossoms with the image segmentation widget by running the run button. The segmented image will appear in the napari window.

![Capture d'Ã©cran 2024-04-24 120758](https://github.com/hereariim/napari-blossom/assets/93375163/4f0c6ac7-b3a8-4849-9c5c-0ff5f35c8362)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-blossom"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hereariim/napari-blossom/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/hereariim/napari-blossom/issues', 'Documentation, https://github.com/hereariim/napari-blossom#README.md', 'Source Code, https://github.com/hereariim/napari-blossom', 'User Support, https://github.com/hereariim/napari-blossom/issues']",napari-blossom.get_reader,napari-blossom.write_multiple,napari-blossom.model_segmentation,napari-blossom.make_sample_data,['*.npy'],,['.npy']
133,napari-boardgame-maker,napari-boardgame-maker,FooBar Segmentation,0.0.2,2023-08-13,2023-08-13,Johannes Soltwedel,johannes_richard.soltwedel@tu-dresden.de,BSD-3-Clause,,https://pypi.org/project/napari-boardgame-maker/,None,,Make boardgame tiles,>=3.8,"['numpy', 'magicgui', 'qtpy', 'napari-stl-exporter', 'vedo', 'napari-tools-menu', 'imagecodecs', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-boardgame-maker

[![License BSD-3](https://img.shields.io/pypi/l/napari-boardgame-maker.svg?color=green)](https://github.com/jo-mueller/napari-boardgame-maker/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-boardgame-maker.svg?color=green)](https://pypi.org/project/napari-boardgame-maker)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-boardgame-maker.svg?color=green)](https://python.org)
[![tests](https://github.com/jo-mueller/napari-boardgame-maker/workflows/tests/badge.svg)](https://github.com/jo-mueller/napari-boardgame-maker/actions)
[![codecov](https://codecov.io/gh/jo-mueller/napari-boardgame-maker/branch/main/graph/badge.svg)](https://codecov.io/gh/jo-mueller/napari-boardgame-maker)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-boardgame-maker)](https://napari-hub.org/plugins/napari-boardgame-maker)

This plugin turns 2D grayscale images into 3D-printable landscape tiles for a certain all-time tabletop boardgame which revolves around building settlements, obtaining ressources expanding and collecting more points than your opponents.

In short, images (for instance, [digital elevation models](https://en.wikipedia.org/wiki/Digital_elevation_model)) can be turned into surfaces like this:

| Image | Created tile|
| --- | --- |
| <img src=""https://github.com/jo-mueller/napari-boardgame-maker/raw/main/docs/imgs/sample.png""> | <img src=""https://github.com/jo-mueller/napari-boardgame-maker/raw/main/docs/imgs/sample_as_tile.png""> |

## Data

In principle, all 2D grayscale image data can be used to create a tile. However, using digital elevation models is particularly cool. Such data is publicly available at [OpenTopography.org](https://portal.opentopography.org/raster?opentopoID=OTSDEM.032021.4326.2). Acknowledgement:

```text
 NASA JPL. NASADEM Merged DEM Global 1 arc second V001. 2020, distributed by NASA EOSDIS Land Processes DAAC, https://doi.org/10.5067/MEaSUREs/NASADEM/NASADEM_HGT.001.
```
## Usage

To use the boardgame tile maker, open it from the plugins menu (`Plugins > napari-boardgame-maker: Boardgame Tile Maker`) or from the tools menu (`Tools > Boardgame tile maker (npbgm)`). There are a few steps and parameters to set before the tile can be created.

[](https://github.com/jo-mueller/napari-boardgame-maker/raw/main/docs/imgs/GUI_screenshot.jpg)

Clicking on `Make hexagon` and `Make number field` will create a hexagonal shape in the viewer (which will be the outline of the tile) and a circular field (which can later be used to put some markers, figures, chips, etc. On the center of the board).

![](https://github.com/jo-mueller/napari-boardgame-maker/raw/main/docs/imgs/sample_with_shapes.png)

The next step is to set the parameters for the tile. The following parameters can be set:

### Radii and sizes

The following sketch shows the different radii and sizes that can be set:

![](https://github.com/jo-mueller/napari-boardgame-maker/raw/main/docs/imgs/stride_and_town.png)

- `hexagon radius`: The radius of the hexagon (in pixels). Upon export, this will be rescaled to a desired physical size in mm.
- `number field radius`: The radius of the number field (in pixels). Can also be set in mm units. The pixels are changed accordingly if the size of the whole hexagon is changed.
- `stride`: The region next to the edge of the tile that should remain flat.
- `town radius`: A circular region around the edges of the hexagonal tiles that should remain flat.

### Topography

The following parameters can be set to create the topography of the tile:

![](https://github.com/jo-mueller/napari-boardgame-maker/raw/main/docs/imgs/slope_and_heights.png)

- `slope`: Adds a smooth transition of a given width between the edge of the cropped topography and the level of the base platte. Setting this to zero will result in a sharp edge.
- `z-multiplier`: The height of the topography is multiplied by this factor. This can be used to scale the topography to the desired height.
- `Plate thickness`: The thickness of the base plate (in mm).

### Export

- CLicking on `produce tile` will run the workflow to create the tile
- Clicking `Export` will open a dialog to save the tile as an `.stl` file. *Note*: The tile will be exported in the size of the hexagon radius. If the hexagon radius is set to 100 mm, the tile will be exported as a 100 mm hexagon.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-boardgame-maker` via [pip]:

    pip install napari-boardgame-maker


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-boardgame-maker"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,,napari-boardgame-maker.write_single_image,napari-boardgame-maker.boardgame_maker,napari-boardgame-maker.rhone_glacier,,['.npy'],
134,napari-bootstrapper,napari-bootstrapper,Bootstrapper,0.2.0,2025-05-23,2025-06-02,Vijay Venu Thiyagarajan,vvenu@utexas.edu,"Copyright (c) 2025, Vijay Venu...",,https://pypi.org/project/napari-bootstrapper/,None,,A plugin to quickly generate dense ground truth with sparse labels,>=3.11,"['numpy', 'scipy', 'scikit-image', 'torch', 'numba', 'gunpowder', 'magicgui', 'qtpy', 'pyqtgraph', 'matplotlib', 'napari', 'tqdm', 'lsds', 'mwatershed', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-bootstrapper

[![License BSD-3](https://img.shields.io/pypi/l/napari-bootstrapper.svg?color=green)](https://github.com/ucsdmanorlab/napari-bootstrapper/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bootstrapper.svg?color=green)](https://pypi.org/project/napari-bootstrapper)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bootstrapper.svg?color=green)](https://python.org)
[![tests](https://github.com/ucsdmanorlab/napari-bootstrapper/workflows/tests/badge.svg)](https://github.com/ucsdmanorlab/napari-bootstrapper/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bootstrapper)](https://napari-hub.org/plugins/napari-bootstrapper)

- [Introduction](#introduction)
- [Installation](#installation)
- [Getting Started](#getting-started)
- [Citation](#citation)
- [Issues](#issues)
- [Funding](#funding)

## Introduction

`napari-bootstrapper` is a tool to quickly generate dense 3D labels using sparse 2D labels within napari.

Dense 3D segmentations are generated using the 2D->3D method described in the preprint titled [_Sparse Annotation is Sufficient for Bootstrapping Dense Segmentation_](https://www.biorxiv.org/content/10.1101/2024.06.14.599135v2). In the preprint, we show sparse 2D annotations made in ~10 minutes on a single section can generate dense 3D segmentations that are reasonably good starting points for refining or bootstrapping.

This plugin is limited to the 2D->3D method and is intended for small volumes that can fit in memory. For more complex bootstrapping workflows, dedicated 3D models, and block-wise processing of large volumes, we recommend using the [_Bootstrapper_](https://github.com/ucsdmanorlab/bootstrapper) CLI tool.

## Installation

We recommend installing `napari-bootstrapper` via conda and [pip]:

1. Create a new environment called `napari-bootstrapper`:

```bash
conda create -n napari-bootstrapper -c conda-forge python==3.11 napari pyqt
```

2. Activate the newly-created environment:

```
conda activate napari-bootstrapper
```

3. You can install `napari-bootstrapper` via [pip]:

```bash
pip install napari-bootstrapper
```
   - Or you can install the latest development version from github:

```bash
pip install git+https://github.com/ucsdmanorlab/napari-bootstrapper.git
```


## Getting Started
Run the following in your terminal:
```bash
conda activate napari-bootstrapper
napari
```

## Citation

If you find Bootstrapper useful in your research, please consider citing our **[preprint](https://www.biorxiv.org/content/10.1101/2024.06.14.599135v1)**:
```
@article {Thiyagarajan2024.06.14.599135,
	author = {Thiyagarajan, Vijay Venu and Sheridan, Arlo and Harris, Kristen M. and Manor, Uri},
	title = {Sparse Annotation is Sufficient for Bootstrapping Dense Segmentation},
	year = {2024},
	doi = {10.1101/2024.06.14.599135},
	URL = {https://www.biorxiv.org/content/10.1101/2024.06.14.599135v2},
}
```


## Issues

If you encounter any problems, please [file an issue](https://github.com/ucsdmanorlab/napari-bootstrapper/issues) along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


## Funding
Chan-Zuckerberg Imaging Scientist Award DOI https://doi.org/10.37921/694870itnyzk from the Chan Zuckerberg Initiative DAF, an advised fund of Silicon Valley Community Foundation (funder DOI 10.13039/100014989).

NSF NeuroNex Technology Hub Award (1707356), NSF NeuroNex2 Award (2014862)

![image](https://github.com/ucsdmanorlab/bootstrapper/assets/64760651/4b4a6029-e1ba-42bb-ab8b-d9357cc46239)
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-bootstrapper.Widget,napari-bootstrapper.make_cremi_sample_data,,,
135,napari-boids,napari-boids,Boids,0.0.1,2022-08-08,2022-08-08,LÃ©o Guignard,leo.guignard@univ-amu.fr,BSD-3-Clause,https://github.com/leoguignard/napari-boids/issues,https://pypi.org/project/napari-boids/,,https://github.com/leoguignard/napari-boids,A plugin to look at boids,>=3.8,"['numpy', 'scipy', 'magicgui', 'qtpy', 'napari', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-boids

[![License BSD-3](https://img.shields.io/pypi/l/napari-boids.svg?color=green)](https://github.com/leoguignard/napari-boids/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-boids.svg?color=green)](https://pypi.org/project/napari-boids)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-boids.svg?color=green)](https://python.org)
[![tests](https://github.com/leoguignard/napari-boids/workflows/tests/badge.svg)](https://github.com/leoguignard/napari-boids/actions)
[![codecov](https://codecov.io/gh/leoguignard/napari-boids/branch/main/graph/badge.svg)](https://codecov.io/gh/leoguignard/napari-boids)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-boids)](https://napari-hub.org/plugins/napari-boids)

A plugin to look at boids

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-boids` via [pip]:

    pip install napari-boids



To install latest development version :

    pip install git+https://github.com/leoguignard/napari-boids.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-boids"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/leoguignard/napari-boids/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/leoguignard/napari-boids/issues', 'Documentation, https://github.com/leoguignard/napari-boids#README.md', 'Source Code, https://github.com/leoguignard/napari-boids', 'User Support, https://github.com/leoguignard/napari-boids/issues']",,,napari-boids.boid_viewer,,,,
136,napari-blender,napari-blender,Blender Visualization,1.0.1,2024-07-03,2024-07-03,Krijn H. van der Steen,"""Krijn H. van der Steen"" <k.h.vandersteen@gmail.com>",Mozilla Public License Version 2.0,https://github.com/Living-Technologies/napari-blender/issues,https://pypi.org/project/napari-blender/,,,A plug-in to help visualize and analyze organoid segmentation using Blender,>=3.10,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'napari-video', 'tifffile', 'bpy >=4.0.0', 'trimesh', 'opencv-python', 'scipy', 'pathlib', 'mathutils', 'pandas']","# napari-blender

napari-blender is a plugin for napari that allows you to render 3D scenes using Blender.

This is a system that combines optical validation of model predictions by having different 3D visualizations and quantitative evaluation. Utilizing Blenderâs rendering capabilities for deepening the understanding of nuclei segmentation for users with different levels of expertise. Examples are time-lapse animations (aimed to be generated from label data), opaque ground truth visualizations with solid prediction objects to compare prediction quality optically and 3D images where nuclei are coloured according to their prediction quality. To facilitate meaningful quantitative evaluation, different metrics are calculated for these predictions and displayed within the animation, such as the Jaccard index, Intersection over Union and the F1-score. The emphasis in this system is on operating it with limited technical knowledge, allowing for bridging between researchers and developers; but includes metrics that allow for a deeper understanding of performance for expert users.

Documentation can be found at https://living-technologies.github.io/napari-blender/
----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

The installation of `napari-blender` is made easier by the inclusion of a virtual environment containing specified versions of each library. These versions should be followed, since dependencies could otherwise break the build. 

Download the [environment.yml], and navigate to the directory of the file. Install by:

    conda env create -f environment.yml
    conda activate napari-blender-env

Now you can install the plug-in using:

    pip install napari-blender

Note:

In Windows, an error might occur in the installation of the `mathutils` package, stating 'Microsoft Visual C++ 14.0 or greater is required'. A fix can be found on[StackOverflow].


To install latest development version :

    pip install git+https://github.com/Living-Technologies/napari-blender.git

## License

Distributed under the terms of the [Mozilla Public License 2.0] license,
""napari-blender"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[environment.yml]: https://github.com/Living-Technologies/napari-blender/blob/main/environment.yml
[StackOverflow]: https://stackoverflow.com/questions/64261546/how-to-solve-error-microsoft-visual-c-14-0-or-greater-is-required-when-inst
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/Living-Technologies/napari-blender/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/Living-Technologies/napari-blender/issues', 'Documentation, https://living-technologies.github.io/napari-blender/index.html', 'Source Code, https://github.com/Living-Technologies/napari-blender', 'User Support, https://github.com/Living-Technologies/napari-blender/issues']",napari-blender.get_reader,napari-blender.write_multiple,napari-blender.make_transparant_widget,napari-blender.make_sample_data,['*.npy'],,['.npy']
137,napari-brainbow-diagnose,napari-brainbow-diagnose,Napari Brainbow Diagnose,0.2.0,2023-01-25,2025-02-04,Clement Caporal,clement.caporal@polytechnique.edu,BSD-3-Clause,https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/issues,https://pypi.org/project/napari-brainbow-diagnose/,,https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose,Visualize and Diagnose brainbow dataset in color space.,>=3.8,"['numpy', 'magicgui', 'pooch', 'matplotlib', 'scikit-image', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'pre-commit; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-brainbow-diagnose

[![License BSD-3](https://img.shields.io/pypi/l/napari-brainbow-diagnose.svg?color=green)](https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-brainbow-diagnose.svg?color=green)](https://pypi.org/project/napari-brainbow-diagnose)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-brainbow-diagnose.svg?color=green)](https://python.org)
[![tests](https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/workflows/tests/badge.svg)](https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/actions)
[![codecov](https://codecov.io/gh/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/branch/main/graph/badge.svg)](https://codecov.io/gh/LaboratoryOpticsBiosciences/napari-brainbow-diagnose)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-brainbow-diagnose)](https://napari-hub.org/plugins/napari-brainbow-diagnose)

Explore image in channel coordinate spaces.


**Original motivation**: Brainbow dataset have unique features that need to be addressed by specialized tools.
This plugin allows you to visualize the distribution of the channel ratio interactively in the image space and channel spaces.

You can also use this plugin along with the [`napari-cluster-plotter` plugin](https://github.com/BiAPoL/napari-clusters-plotter?tab=readme-ov-file#installation) to interact with individual objects.

![demo_gif](https://raw.githubusercontent.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/main/docs/demo_napari-brainbow-diagnose.gif)

## Available Channel space transformation

The following channel spaces are available:

![image|width=10](https://github.com/user-attachments/assets/0dae9090-da16-4653-b466-a08289e061ea)


From Cartesian RGB:
- (a) Maxwell triangle (ternary plot) [illustration](https://en.wikipedia.org/wiki/Ternary_plot)
- (c) Hue-Saturation wheel [illustration (g)](https://en.wikipedia.org/wiki/File:Hsl-hsv_models.svg)
- (e) Spherical coordinates (Theta, Phi and Radius) [illustration](https://en.wikipedia.org/wiki/Spherical_coordinate_system)
- (g,i) Hue-Saturation-Value planes [illustration (b)(f)](https://en.wikipedia.org/wiki/File:Hsl-hsv_models.svg)

## Example Notebooks

You can use this plugin to visualize channel space of:
- interactively every voxel in the image (see [demo notebook](docs/demo.ipynb))
- interactively every object (aka center point) in the image (see [demo notebook](docs/cluster_plotter_compatibility.ipynb)). To use this notebook you need to install [`napari-cluster-plotter` plugin](https://github.com/BiAPoL/napari-clusters-plotter?tab=readme-ov-file#installation).
- Not interactive in matplotlib to export figures: (see [demo notebook](docs/plot_color_space_matplotlib.ipynb))

## Example Datasets

If you want to use your dataset, you have to format it such as each channel is in one distinct `napari.Layers`
You can open test dataset to try this plugin in `File > Open Sample > napari-brainbow-diagnose`.

- The RGB Cube is an array with shape (3x256x256x256) cube : Great to check how the plugin work when all color are represented
- ChroMS Cortex Sample is an array with shape (3x256x256x256) #Hugo : Real life brainbow image (Cortex E18 Emx1Cre) !

Once you have your layers you can use the dropdown and select the corresponding layer. It is advised to match the `red, green, blue` order so the ratio you see on the napari viewer corresponds to the Hue-Saturation Wheel of the plugin.

## Installation

You can install `napari-brainbow-diagnose` via [pip]:

    pip install napari-brainbow-diagnose

If you want to use [`napari-cluster-plotter` plugin](https://github.com/BiAPoL/napari-clusters-plotter?tab=readme-ov-file#installation)  you also need to install it manually

To install latest development version :

    pip install git+https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-brainbow-diagnose"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/issues', 'Documentation, https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose#README.md', 'Source Code, https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose', 'User Support, https://github.com/LaboratoryOpticsBiosciences/napari-brainbow-diagnose/issues']",,,napari-brainbow-diagnose.read_csv_widget,napari-brainbow-diagnose.make_rgb_cube_data,,,
138,napari-brightness-contrast,napari-brightness-contrast,napari-brightness-contrast,0.1.8,2021-08-07,2022-09-25,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-brightness-contrast/issues,https://pypi.org/project/napari-brightness-contrast/,,https://github.com/haesleinhuepf/napari-brightness-contrast,Advanced layer visualization options,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'napari', 'numpy', 'pyqtgraph', 'superqt', 'napari-tools-menu', ""pytest ; extra == 'tests'"", ""pytest-qt ; extra == 'tests'""]","# napari-brightness-contrast

[![License](https://img.shields.io/pypi/l/napari-brightness-contrast.svg?color=green)](https://github.com/haesleinhuepf/napari-brightness-contrast/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-brightness-contrast.svg?color=green)](https://pypi.org/project/napari-brightness-contrast)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-brightness-contrast.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-brightness-contrast/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-brightness-contrast/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-brightness-contrast/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-brightness-contrast)
[![Development Status](https://img.shields.io/pypi/status/napari-brightness-contrast.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-brightness-contrast)](https://napari-hub.org/plugins/napari-brightness-contrast)

Advanced layer histogram visualization options, e.g. for brightness / contrast
![](https://github.com/haesleinhuepf/napari-brightness-contrast/blob/main/docs/images/napari-brightness-contrast3.gif?raw=true)

Note: This will not work for big image data at the moment. 
If the user interface feels slow, consider installing [pyclesperanto](https://github.com/clEsperanto/pyclesperanto_prototype) to speed it up.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-brightness-contrast` via [pip]:

    pip install napari-brightness-contrast

## Contributing

Contributions are very welcome.  
After cloning the repo, install using `pip install -e .[tests]` to enable testing via `pytest`.

## License

Distributed under the terms of the [BSD-3] license,
""napari-brightness-contrast"" is free and open source software

## Issues

If you encounter any problems, please [open a thread on image.sc](https://image.sc) along with a detailed description and tag [@haesleinhuepf](https://github.com/haesleinhuepf).

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/haesleinhuepf/napari-brightness-contrast/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-brightness-contrast/issues', 'Documentation, https://github.com/haesleinhuepf/napari-brightness-contrast#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-brightness-contrast', 'User Support, https://github.com/haesleinhuepf/napari-brightness-contrast/issues']",,,napari-brightness-contrast.BrightnessContrast,,,,
139,napari-boxmanager,napari-boxmanager,Box Manager,0.4.14,2022-09-26,2024-10-30,Markus Stabrin,markus.stabrin@mpi-dortmund.mpg.de,MPL-2.0,https://github.com/MPI-Dortmund/napari-boxmanager,https://pypi.org/project/napari-boxmanager/,,https://github.com/MPI-Dortmund/napari-boxmanager,Particle selection tool for cryo-em,>=3.10,"['matplotlib', 'mrcfile', 'numpy<=1.23.5', 'pystardb>=0.4.2', 'napari>=0.4.17', 'pandas', 'scipy', 'tifffile', 'tqdm', 'mrcfile; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'tox; extra == ""testing""']","# napari-boxmanager

[![License Mozilla Public License 2.0](https://img.shields.io/pypi/l/napari-boxmanager.svg?color=green)](https://github.com/mstabrin/napari-boxmanager/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-boxmanager.svg?color=green)](https://pypi.org/project/napari-boxmanager)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-boxmanager.svg?color=green)](https://python.org)
[![tests](https://github.com/mstabrin/napari-boxmanager/workflows/tests/badge.svg)](https://github.com/mstabrin/napari-boxmanager/actions)
[![codecov](https://codecov.io/gh/mstabrin/napari-boxmanager/branch/main/graph/badge.svg)](https://codecov.io/gh/mstabrin/napari-boxmanager)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-boxmanager)](https://napari-hub.org/plugins/napari-boxmanager)

Particle selection tool for cryo-em

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

Here is how to install napari together with the boxmanager plugin:

    mamba env create -n napari -f https://raw.githubusercontent.com/MPI-Dortmund/napari-boxmanager/main/conda_env.yml
    conda activate napari

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Mozilla Public License 2.0] license,
""napari-boxmanager"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']",,napari-boxmanager.get_reader,napari-boxmanager.get_writer,napari-boxmanager.select_metric,,"['*.tloc', '*.temb', '*.tmap', '*.cbox', '*.box', '*.star', '*.mrc', '*.mrcs', '*.st', '*.coords', '*.rec', '*.cs', '*.tif', '*.tiff', '*.mrci']","['.tloc', '.temb', '.tmap', '.cbox', '.box', '.star', '.mrc', '.mrcs', '.st', '.coords', '.rec', '.mrci']",
140,napari-brushsettings,napari-brushsettings,napari-brushsettings,0.0.2,2021-08-30,2021-08-30,Philipp Schoennenbeck,p.schoennenbeck@fz-juelich.de,BSD-3-Clause,https://github.com/Croxa/napari-brushsettings/issues,https://pypi.org/project/napari-brushsettings/,,https://github.com/Croxa/napari-brushsettings,A simple plugin to set the brush settings for segmentation in napari,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy']","# napari-brushsettings

[![License](https://img.shields.io/pypi/l/napari-brushsettings.svg?color=green)](https://github.com/Croxa/napari-brushsettings/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-brushsettings.svg?color=green)](https://pypi.org/project/napari-brushsettings)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-brushsettings.svg?color=green)](https://python.org)
[![tests](https://github.com/Croxa/napari-brushsettings/workflows/tests/badge.svg)](https://github.com/Croxa/napari-brushsettings/actions)
[![codecov](https://codecov.io/gh/Croxa/napari-brushsettings/branch/master/graph/badge.svg)](https://codecov.io/gh/Croxa/napari-brushsettings)

A simple plugin to set the brush settings for segmentation in napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-brushsettings` via [pip]:

    pip install napari-brushsettings

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-brushsettings"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/Croxa/napari-brushsettings/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/Croxa/napari-brushsettings/issues', 'Documentation, https://github.com/Croxa/napari-brushsettings#README.md', 'Source Code, https://github.com/Croxa/napari-brushsettings', 'User Support, https://github.com/Croxa/napari-brushsettings/issues']",,,napari-brushsettings.Brushsize,,,,
141,napari-calibration,napari-calibration,napari Calibration,0.0.14,2022-08-23,2022-08-29,Tristan Cotte,tristan.cotte@sgs.com,BSD-3-Clause,https://github.com/tcotte/napari-calibration/issues,https://pypi.org/project/napari-calibration/,,https://github.com/tcotte/napari-calibration,Plug in which enables to make camera calibration,>=3.7,"['napari', 'numpy', 'qt-material', 'opencv-python']","# napari-calibration

[![License](https://img.shields.io/pypi/l/napari-calibration.svg?color=green)](https://github.com/tcotte/napari-calibration/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-calibration.svg?color=green)](https://pypi.org/project/napari-calibration)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-calibration.svg?color=green)](https://python.org)
[![tests](https://github.com/tcotte/napari-calibration/workflows/tests/badge.svg)](https://github.com/tcotte/napari-calibration/actions)
[![codecov](https://codecov.io/gh/tcotte/napari-calibration/branch/main/graph/badge.svg)](https://codecov.io/gh/tcotte/napari-calibration)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-calibration)](https://napari-hub.org/plugins/napari-calibration)

Plug in which enables to make camera calibration

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-calibration` via [pip]:

    pip install napari-calibration



To install latest development version :

    pip install git+https://github.com/tcotte/napari-calibration.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-calibration"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/tcotte/napari-calibration/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/tcotte/napari-calibration/issues', 'Documentation, https://github.com/tcotte/napari-calibration#README.md', 'Source Code, https://github.com/tcotte/napari-calibration', 'User Support, https://github.com/tcotte/napari-calibration/issues']",,,napari-calibration.ImageForm,,,,
142,napari-camera,napari-camera,Camera Control,0.0.3,2025-03-26,2025-03-27,Lars KrÃ¤mer,lars.kraemer@dkfz-heidelberg.de,"Apache License
               ...",https://github.com/MIC-DKFZ/napari-camera,https://pypi.org/project/napari-camera/,,,Provides control over camera settings and allows saving and loading full viewer configurations to easily recreate and share consistent visual perspectives.,>=3.9,"['napari_toolkit', 'qtpy', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-camera

A Napari plugin that provides control over camera settings and allows saving and loading full
viewer configurations to easily recreate and share consistent visual perspectives.

## Installation

You can install `napari-camera` via [pip]:

```
pip install napari-camera
```

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-camera"" is free and open source software

# Acknowledgments

<p align=""left"">
  <img src=""https://github.com/MIC-DKFZ/napari-camera/raw/main/imgs/Logos/HI_Logo.png"" width=""150""> &nbsp;&nbsp;&nbsp;&nbsp;
  <img src=""https://github.com/MIC-DKFZ/napari-camera/raw/main/imgs/Logos/DKFZ_Logo.png"" width=""500"">
</p>

This repository is developed and maintained by the Applied Computer Vision Lab (ACVL)
of [Helmholtz Imaging](https://www.helmholtz-imaging.de/) and the
[Division of Medical Image Computing](https://www.dkfz.de/en/medical-image-computing) at DKFZ.

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

[apache software license 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[copier]: https://copier.readthedocs.io/en/stable/
[napari]: https://github.com/napari/napari
[napari-plugin-template]: https://github.com/napari/napari-plugin-template
[pip]: https://pypi.org/project/pip/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Homepage, https://github.com/MIC-DKFZ/napari-camera', 'Code, https://github.com/MIC-DKFZ/napari-camera']",,,napari-camera.CameraControlWidget,,,,
143,napari-bud-cell-segmenter,napari-bud-cell-segmenter,Bud Cell Segmenter,0.1.4,2022-11-14,2022-12-16,Aurelien Maillot,aurelien.maillot@protonmail.com,BSD-3-Clause,https://github.com/AurelienMaillot/napari-bud-cell-segmenter/issues,https://pypi.org/project/napari-bud-cell-segmenter/,,https://github.com/AurelienMaillot/napari-bud-cell-segmenter,A plugin to segment embryonic mammary bud cells and detect 2 RNA probes,>=3.8,"['numpy', 'magicgui', 'qtpy', 'pandas', 'scikit-image', 'napari', 'tifffile', 'matplotlib', 'scipy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-bud-cell-segmenter

[![License BSD-3](https://img.shields.io/pypi/l/napari-bud-cell-segmenter.svg?color=green)](https://github.com/AurelienMaillot/napari-bud-cell-segmenter/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-bud-cell-segmenter.svg?color=green)](https://pypi.org/project/napari-bud-cell-segmenter)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-bud-cell-segmenter.svg?color=green)](https://python.org)
[![tests](https://github.com/AurelienMaillot/napari-bud-cell-segmenter/workflows/tests/badge.svg)](https://github.com/AurelienMaillot/napari-bud-cell-segmenter/actions)
[![codecov](https://codecov.io/gh/AurelienMaillot/napari-bud-cell-segmenter/branch/main/graph/badge.svg)](https://codecov.io/gh/AurelienMaillot/napari-bud-cell-segmenter)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-bud-cell-segmenter)](https://napari-hub.org/plugins/napari-bud-cell-segmenter)

A plugin to segment embryonic mammary bud cells and detect 2 RNA probes

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-bud-cell-segmenter` via [pip]:

    pip install napari-bud-cell-segmenter



To install latest development version :

    pip install git+https://github.com/AurelienMaillot/napari-bud-cell-segmenter.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-bud-cell-segmenter"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/AurelienMaillot/napari-bud-cell-segmenter/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/AurelienMaillot/napari-bud-cell-segmenter/issues', 'Documentation, https://github.com/AurelienMaillot/napari-bud-cell-segmenter#README.md', 'Source Code, https://github.com/AurelienMaillot/napari-bud-cell-segmenter', 'User Support, https://github.com/AurelienMaillot/napari-bud-cell-segmenter/issues']",napari-bud-cell-segmenter.get_reader,napari-bud-cell-segmenter.write_multiple,napari-bud-cell-segmenter.load_data,napari-bud-cell-segmenter.make_sample_data,['*.npy'],,['.npy']
144,napari-cci-annotator,napari-cci-annotator,CCI Annotator,0.6.0,2025-04-28,2025-06-16,Anders Folkesson,anders.folkesson@gu.se,Unavailable,,https://pypi.org/project/napari-cci-annotator/,None,,Plugin to simplify annotations of datasets,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'ultralytics', 'shapely', 'dask', 'xlsxwriter', 'openvino', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-cci-annotator

[![License MIT](https://img.shields.io/pypi/l/napari-cci-annotator.svg?color=green)](https://github.com/xfolka/napari-cci-annotator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-cci-annotator.svg?color=green)](https://pypi.org/project/napari-cci-annotator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-cci-annotator.svg?color=green)](https://python.org)
[![tests](https://github.com/xfolka/napari-cci-annotator/workflows/tests/badge.svg)](https://github.com/xfolka/napari-cci-annotator/actions)
[![codecov](https://codecov.io/gh/xfolka/napari-cci-annotator/branch/main/graph/badge.svg)](https://codecov.io/gh/xfolka/napari-cci-annotator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-cci-annotator)](https://napari-hub.org/plugins/napari-cci-annotator)

Plugin to simplify annotations of datasets

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-cci-annotator` via [pip]:

    pip install napari-cci-annotator




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-cci-annotator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-cci-annotator.make_qwidget,,,,
145,napari-cardio-bio-eval,napari-cardio-bio-eval,Cardio Biosensor Evaluation,0.1.5,2024-08-15,2024-09-24,Nanobiosensorics,horvath.robert@energia.mta.hu,"Copyright (c) 2024, Nanobiosen...",,https://pypi.org/project/napari-cardio-bio-eval/,None,,The evaluation of the epic cardio biosensor integrated into napari,>=3.10,"['matplotlib', 'opencv-python-headless', 'openpyxl', 'napari[pyqt5]', 'torch', 'numpy==1.26', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# Cardio biosensor evaluaton in Napari

[![License BSD-3](https://img.shields.io/pypi/l/napari-cardio-bio-eval.svg?color=green)](https://github.com/Nanobiosensorics/napari-cardio-bio-eval/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-cardio-bio-eval.svg?color=green)](https://pypi.org/project/napari-cardio-bio-eval)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-cardio-bio-eval.svg?color=green)](https://python.org)
[![tests](https://github.com/Nanobiosensorics/napari-cardio-bio-eval/workflows/tests/badge.svg)](https://github.com//Nanobiosensorics/napari-cardio-bio-eval/actions)
<!--[![codecov](https://codecov.io/gh/Nanobiosensorics/napari-cardio-bio-eval/branch/main/graph/badge.svg)](https://codecov.io/gh/Nanobiosensorics/napari-cardio-bio-eval)-->
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-cardio-bio-eval)](https://napari-hub.org/plugins/napari-cardio-bio-eval)

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

----------------------------------

The plugin provides a widget which can load, preprocess, annotate and export cardio biosensor data.  

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-cardio-bio-eval` via [pip]:

    pip install napari-cardio-bio-eval

Or use the Napari plugin manager and search for `napari-cardio-bio-eval`.

<!--
First install a fresh conda enviroment (or other python enviroment) and activate it:

    conda create -y -n napari-env -c conda-forge python=3.10
    conda activate napari-env

Then you can pip install the plugin from the github repository and it will also downloads the necessary packages:

    pip install git+https://github.com/Nanobiosensorics/napari-cardio-bio-eval

Then you can start napari with a simple command:

    napari
-->
# Usage

You can open the plugin's widgets from the **Plugins** menu after the installation of the plugin.

![image](https://github.com/Nanobiosensorics/napari-cardio-bio-eval/assets/78443646/5d209fb5-c921-45d6-bb63-c5e3ff1fb1f8)

## Data loading and preprocessing

At the top of the widget, you need to select the directory, which contains the data you want to examine and process. To successfully load the data the directory have to contain the following files:
- *_wl_power.file: which contains the starting values of the measurement
- DRM directory: which contains the difference from the previous measurement point 
- *_avg.file: which contains additional biosensor data

#### Import parameters:  
- Flipping: horizontal and vertical mirroring of the biosensor recording
- Signal range type: with this you can choose how do you want to select a smaller range of the measurement in the next field *Ranges*
    - measurement phase: you can give the index of the phases you want to see, for example with 0-1 you can view the measurement from the start to the first pause
    - individual point: you can select any given frames in an interval, for example with selecting 34 and 275 you can view the measurement from frame 34 to frame 275
- Ranges: if you choose measurement phase then give the range of the phases you want to see and if you choose individual point then select the starting and end frames. The label above helps as it shows the phrases (except the last one) and the full time of the measurement. The minimum frame or phase must be smaller than the maximum.
- Drift correction threshold: Ranges between 25 and 500.
- Filter method: mean or median

![image](https://github.com/Nanobiosensorics/napari-cardio-bio-eval/assets/78443646/28b5f563-1c5e-4591-bdf6-2ece936becac)

![image](https://github.com/Nanobiosensorics/napari-cardio-bio-eval/assets/78443646/a6004667-deac-4ff8-8729-0fcb8bc35f7f)

After selecting the source directory and the optional fliping you can load in the data with the ***Load Data*** button. After the raw data is loaded you can select the slice of the measurement you want to work with and some other parameters. Then by clicking the ***Preprocess Data*** button you start the processing and after a few seconds the well images will appear on the viewer.  

![image](https://github.com/Nanobiosensorics/napari-cardio-bio-eval/assets/78443646/23e38c70-d058-41cc-9e9e-f2d34ea553e0)

Each well has its own layer. You can turn the layers visible or invisible by clicking the small eye icon on each layer.

If the selected range is not what you wanted then you can change the parameters and preprocess again. But if you moved on to the next step (manual background selection or peak detection) then you need to restart Napari to load other data or preprocess with different parameters.

After you see the wells you can proceed to the next step or if the automatic background correction is not good enough you can click the ***Select Background Points Manually*** button and it will show the automatically selected background points for each well, which you can move to better background coordinates and in the next peak detection step these points will be used by the background correction algorithm. After the first export these points will be saved so if the same directory is loaded a second time the preprocessing will use these points.

During the background selection do NOT delete any layers.

![image](https://github.com/Nanobiosensorics/napari-cardio-bio-eval/assets/78443646/133fd74a-b53b-4540-bdf9-209c325e2b4b)

## Selecting the cells

In this step you can also set some parameters for the peak detection algorithm and then click the ***Detect Signal Peaks*** button to start the process. After a few seconds the wells with the potential cells will show on the window.

#### Detection parameters:  
- Threshold range: 25-5000
- Neighbourhood size: 1-10
- Error mask filtering:

![image](https://github.com/Nanobiosensorics/napari-cardio-bio-eval/assets/78443646/842ad2e3-32dd-4d6c-8e98-47c137a7029b)

Here you can delete, add or move the points on each points layer. There are keyboard shortcuts for easier use! 
Additionally by double clicking on any point of the image you can examine the time-signal diagram of the selected point under the widget. Be sure to select the correct layer!  

If you do not need any of the wells, then you can delete the layer and it won't be exported. If you either delete an image or peak points layer belonging to a well, the well will not be included in the export!  
After selecting the needed cells and wells (and deleting the unnecessary ones) you can export plots and additional information about them.

## Exporting

You can select what kind of data do you want to export and click the ***Export Data*** button. The data will be exported to the source directory into a *result* sub-directory.

#### Export options:
- Coordinates: the coordinates of the selected cells
- Preprocessed signals: 
- Raw signals:
- Average signal: 
- Breakdown signal: 
- Max well: 
- Plot signals with well:  
- Plot well with coordinates: 
- Plot cells individually: 
- Signal parts by phases: 
- Max centered signals: 

## Segmentation widget

The data loading and preprocessing is the same but it uses a deep learning model to segment the cells.

## License

Distributed under the terms of the [BSD-3] license,
""napari-cardio-bio-eval"" is free and open source software

## Issues

If you encounter any problems, please file an issue along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-cardio-bio-eval.cardio_bio_peak_detection_widget,,,,
146,napari-buds,napari-buds,napari BudAnnotation,0.1.6,2022-08-16,2023-03-17,Sander van Otterdijk,scvanotterdijk@gmail.com,BSD-3-Clause,https://github.com/SanderSMFISH/napari-buds/issues,https://pypi.org/project/napari-buds/,,https://github.com/SanderSMFISH/napari-buds,Random-forest automated bud annotation,>=3.8,"['numpy', 'magicgui', 'qtpy', 'pandas', 'napari', 'magic-class', 'scipy', 'scikit-learn', 'scikit-image', 'matplotlib', 'joblib', 'imageio-ffmpeg', 'stackview', 'jupyterlab', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-buds

[![License BSD-3](https://img.shields.io/pypi/l/napari-buds.svg?color=green)](https://github.com/SanderSMFISH/napari-buds/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-buds.svg?color=green)](https://pypi.org/project/napari-buds)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-buds.svg?color=green)](https://python.org)
[![tests](https://github.com/SanderSMFISH/napari-buds/workflows/tests/badge.svg)](https://github.com/SanderSMFISH/napari-buds/actions)
[![codecov](https://codecov.io/gh/SanderSMFISH/napari-buds/branch/main/graph/badge.svg)](https://codecov.io/gh/SanderSMFISH/napari-buds)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-buds)](https://napari-hub.org/plugins/napari-buds)

Random-forest automated bud annotation

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

make sure you already have installed napari. 

Next, You can install `napari-buds` via [pip]:

    pip install napari-buds



To install latest development version :

    pip install git+https://github.com/SanderSMFISH/napari-buds.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## Documentation
Napari-Buds is a random forest based mother-bud annotation plugin for Napari devevoped by the TutucciLab (https://www.tutuccilab.com/) of the systems biology group at the Vrije Universiteit van Amsterdam. Mother-bud annotation requires single or multichannel 2D images of budding yeast and a fluorescent marker that localizes to the bud. In the example dataset provided smFISH DNA-probes were used as localized bud marker.The GUI layout for random forest based classification was inspired by ImageJ 'plugin Weka Segmentation' [1]. **Before installation make sure you have a working version of napari installed (pip install ""napari[all]"").** Napari-Buds is a random forest based mother-bud annotation plugin for Napari developed by the TutucciLab (https://www.tutuccilab.com/) of the systems biology group at the Vrije Universiteit van Amsterdam. Mother-bud annotation requires single or multichannel 2D images of budding yeast and a fluorescent marker that localizes to the bud. In the example dataset provided smFISH DNA-probes were used as localized bud marker.The GUI layout for random forest based classification was inspired by ImageJ 'plugin Weka Segmentation' [1]. 

Please follow the workflow described underneath to perform mother-bud annotation:

1. Open images in napari and create empty label layer.
For multichannel images each channel should be provided seperately to napari.
An example (jupyter) notebook (Open Test Images Napari.ipynb) for loading test data in napari is provided in the notebooks folder. 
Example dataset can be downloaded from https://zenodo.org/record/7004556#.YwM1_HZBztU. 
    
2. If multichannel images are unaligned the  translate widget under Plugins>napari-buds>Translate can be used. 
Select which layer should be translated to align to the layers in widget menu. Then use the aswd keys to translate (move) the selected layer. 
To register changes and update coordinates of the translated image in napari press t. 
    
### Random forest classification
3. To open the mother-bud annotation plugin go to Plugins>napari-buds>bud annotation.
    
4. To train a random forest classifier, in the created label layer draw examples of cells, buds and background (see tutorial gif below). 
In the Define Label segment of the widget you define which label value (class #label_value) corresponds to cells, buds and background. 
Currently, cells and backgrounds and buds **have to be defined in the Define Label segment**  if you want to be able to segment the classification as well.
In the segment **Layers to extract Features from** we can select which layers will be used in training the random forest classifier. 
Next press **Train classifier**. After training is completed a result layer is added to layer list. 
Inspect the results carefully to asses classifier performance. The trained classifier can be saved using the **save classifier** button.
Previously trained classifier can be loaded by pressing **Load classifier**. Loaded classifier can applied to new images by pressing **Classify**, resulting again in a results layer.
It is possible to change the random forest parameters with **the Set random forest parameters** button and changing the values in the pop up menu.
Press **Run** to register changed settings. For an example of the parameters used see: 
https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html and 
https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_trainable_segmentation.html. 
    
5. Next, we want to perfom watershed segmentation using the result layer. However, for watershed segmentation seeds (also called markers) are required
(for an explanation of watershed segmenation see: https://en.wikipedia.org/wiki/Watershed_(image_processing)). 
To define the seeds we can either simply threshold on one of the supplied image layers or we can use distance tranform (https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_watershed.html#sphx-glr-auto   examples-segmentation-plot-watershed-py).The resulting seeds layer can be adjusted manually by editing in napari.
A good seeds layers correspond to each cell having a single seed (buds are not single cells). To perform watershed segmentation press the **Segment** button.
    
6. Carefully inspect the resulting cell mask and bud layer. Correct the mistakes in both layers. 
Bud label values should correspond to the label value of the cell mask of mother cell. To verify mother bud relations were drawn correctly
press **Draw Mother-Bud relations**. If Mother-Bud relations are correct, you can save both label layers. Mother and buds simply share the same label number.
Thus, either the mother or bud layer can be manually corrected for mistakes. Corrections can be checked by clicking **Draw Mother-Bud relations** again. 
mother and buds layer can be saved manually in napari. When using Jupyter notebook mother and bud layers can be saved as shown in Open Test Images Napari.ipynb.

7. An example notebook for dataextraction of the created cell and bud masks can be found in the example notebooks folder (Extract_Mother_Buds_relations_from_Masks_and_intergrate_FQ_spot_data.ipynb).This notebooks relates RNA spots (smFISH data found on zenodo) to the mother or bud compartment. 


See video for clarification:

![Watch the video](https://github.com/SanderSMFISH/napari-buds/blob/main/videos/Napari_bud_gif.gif)

## Similar Napari plugins 

1-napari-accelerated-pixel-and-object-classification (APOC) by Robert Haase.

2-napari-feature-classifier.

## License

Distributed under the terms of the [BSD-3] license,
""napari-buds"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

### Known Issues

If window geometry of the window is unable to be set, this might lead to issues in the display of the widget. For example, part of the widget might fall of the screen.
In these cases, it might help to adjust in your display setting the display scaling to a lower setting. 

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/SanderSMFISH/napari-buds/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

## References
1. Arganda-Carreras, I., Kaynig, V., Rueden, C., Eliceiri, K. W., Schindelin, J., Cardona, A., & Sebastian Seung, H. (2017). Trainable Weka Segmentation: a machine learning tool for microscopy pixel classification. Bioinformatics, 33(15), 2424â2426. doi:10.1093/bioinformatics/btx180
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/SanderSMFISH/napari-buds/issues', 'Documentation, https://github.com/SanderSMFISH/napari-buds#README.md', 'Source Code, https://github.com/SanderSMFISH/napari-buds', 'User Support, https://github.com/SanderSMFISH/napari-buds/issues']",napari-buds.get_reader,napari-buds.write_multiple,napari-buds.translate,napari-buds.make_sample_data,['*.npy'],,['.npy']
147,napari-checkerboard,napari-checkerboard,napari-checkerboard,0.0.3,2021-05-11,2021-05-31,Viktor van der Valk,v.o.van_der_valk@lumc.nl,Apache Software License 2.0,https://github.com/ViktorvdValk/napari-checkerboard,https://pypi.org/project/napari-checkerboard/,,https://github.com/ViktorvdValk/napari-checkerboard,Compare two images with the itk checkerboard filter,>=3.6,"['napari-plugin-engine (>=0.1.4)', 'numpy (>=1.19.0)', 'napari (>=0.4.6)', 'magicgui (>=0.2.6)', 'itk-elastix (>=0.11.1)', 'itk-napari-conversion (>=0.3.1)', 'napari-itk-io (>=0.1.0)']","# napari-checkerboard

[![License](https://img.shields.io/pypi/l/napari-checkerboard.svg?color=green)](https://github.com/ViktorvdValk/napari-checkerboard/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-checkerboard.svg?color=green)](https://pypi.org/project/napari-checkerboard)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-checkerboard.svg?color=green)](https://python.org)
[![tests](https://github.com/ViktorvdValk/napari-checkerboard/workflows/tests/badge.svg)](https://github.com/ViktorvdValk/napari-checkerboard/actions)
[![codecov](https://codecov.io/gh/ViktorvdValk/napari-checkerboard/branch/master/graph/badge.svg)](https://codecov.io/gh/ViktorvdValk/napari-checkerboard)

Compare two images with the itk checkerboard filter


<img width=""1430"" alt=""Screenshot 2021-05-12 at 15 03 17"" src=""https://user-images.githubusercontent.com/33719474/117979519-48bd4680-b333-11eb-874c-d9ec09681d93.png"">


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-checkerboard` via [pip]:

    pip install napari-checkerboard

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-checkerboard"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/ViktorvdValk/napari-checkerboard/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: Apache Software License']",,,,napari-checkerboard.checkerboard,,,,
148,napari-clemreg,napari-clemreg,napari-clemreg,0.2.1,2021-06-01,2024-12-26,Daniel Krentzel,dkrentzel@pm.me,MIT,https://github.com/krentzd/napari-clemreg/issues,https://pypi.org/project/napari-clemreg/,,https://github.com/krentzd/napari-clemreg,A plugin for registering multimodal image volumes based on common segmented structures of interest with point-clouds.,>=3.7,"['typing_extensions', 'setuptools', 'packaging', 'numpy==1.22.0', 'magicgui==0.7.3', 'scipy==1.10.1', 'napari', 'scikit-image==0.21.0', 'h5py==3.9.0', 'matplotlib==3.7.3', 'imageio==2.31.5', 'tifffile==2023.7.10', 'probreg==0.3.6', 'open3d==0.17.0', 'transforms3d==0.4.1', 'tqdm==4.66.1', 'empanada-dl==0.1.7', 'torch==2.0.1', 'magicgui==0.7.3', 'connected-components-3d==3.12.3']","# napari-clemreg
### An automated point cloud based registration algorithm for correlative light and volume electron microscopy

[![License](https://img.shields.io/pypi/l/napari-clemreg.svg?color=green)](https://github.com/krentzd/napari-clemreg/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-clemreg.svg?color=green)](https://pypi.org/project/napari-clemreg)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-clemreg.svg?color=green)](https://python.org)

[//]: # ([![codecov]&#40;https://codecov.io/gh/krentzd/napari-clemreg/branch/master/graph/badge.svg&#41;]&#40;https://codecov.io/gh/krentzd/napari-clemreg&#41;)
[//]: # ([![tests]&#40;https://github.com/krentzd/napari-clemreg/workflows/tests/badge.svg&#41;]&#40;https://github.com/krentzd/napari-clemreg/actions&#41;)

## Installation
### Local Installation

To install `napari-clemreg` it is recommended to create a fresh [conda] environment with Python 3.9:

```
conda create -n clemreg_env python=3.9
```
Next, install `napari` with the following command via [pip]: 

```
pip install ""napari[all]""
```

Finally, `napari-clemreg` can be installed with:
```
pip install napari-clemreg
```
When installing `napari-clemreg` on a Windows machine, the following error might appear:
```
error Microsoft Visual C++ 14.0 is required
```
Ensure that [Visual Studios C++ 14.00](https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=BuildTools&rel=16) is installed

### Docker Container
If you would like to run `napari-clemreg` in a docker container instead of installing it as above, please follow the instructions in our [Docker guide](docker_guide.md)

## Usage
CLEM-reg is the combination of 5 main steps, MitoNet segmentation, LoG segmentation,
point cloud sampling, point cloud registration and lastly image warping. These 5 steps 
can be run all at once using the run registration widget shown below with the tick next to it.
Alternatively, they can be run individually with the numbered widgets.

![clemreg_widget_options.png](docs%2Fimages%2Fclemreg_widget_options.png)

### Run Registration



![registration_labels.png](docs%2Fimages%2FCLEMreg-fig.png)

1. **Moving Image** - Here you select your light microscopy (LM) data which will
be warped to align with the fixed electron microscopy (EM) image.
2. **Fixed Image** - Here you select your EM data which will
act as the reference point for the LM to be aligned to.
3. **Registration Algorithm** - Here you can decide which type of registration algorith
will be used for the registration of inputted LM and EM. In terms of speed of each algorithm
the following is the generally true, Rigid CPD > Affine CPD > BCPD.
4. **MitoNet Segmentation Parameters** - Here are the advanced options for the segmentation
of the mitochondria in the EM data.
   1. Prediction Across Three Axis - By selecting this option MitoNet will run segmentation
across all three axis of the EM volume and then these three predictions will be aggregate.
5. **LoG Segmentation Parameters** - Here are the advanced options for the segmentation of 
the mitochondria in the LM data.
   1. Sigma - Sigma value for the Laplacian of Gaussian filter.
   2. Threshold - Threshold value for the segmenting the LM data.
6. **Point Cloud Sampling** - Here are the advanced options for the point cloud sampling of the 
segmentations of the LM and EM data.
   1. Sampling Frequency - Frequency of point sampling from the fixed and moving segmentation. The greater the value the more points in the point cloud.
   2. Sigma - Sigma value for the canny edge filter.
7. **Point Cloud Registration** - Here are the advanced options for the registration of the point clouds
of both the LM and EM data.
   1. Voxel Size - The size voxel size of each point. Smaller the size the less memory consumption.
   2. Subsampling - Downsampling of the point clouds to reduce memory consumption. Greater the number the fewer points in the point cloud.
   3. Maximum Iterations - The number of round of point cloud registration. If too small it won't converge on an opitmal registration.
8. **Image Warping** - Here are the advanced options for the image warping of the moving LM images.
   1. Interpolation Order - The order of the spline interpolation.
   2. Aproximate Grid - Controls the ""resolution"" of the grid onto which you're warping. A higher value reduces the step size between coordinates.
   3. Sub-division Factor - Controls the size of the chunk when applying the warping.
9. **Save Parameters** - Here you can select the option to save the advanced options you've selected
to a JSON file which can be kept for reproducibility as well as running the registration again.
10. **Visualise Intermediate Results** - Here you can select to view the outputs of each step as they
are completed.

### Split Registration
As well as being able to run all the steps of CLEM-reg in one widget (the `Run registration` widget),
you are also able to do all these steps independently using the `Split Registration` functionality. 

There are four separate widgets that encapsulate the 5 steps of CLEM-reg each of which have
their own unique input and output:
1. `MitoNet Segmentation` 
   - **Input**: EM Image
   - **Output**: EM Segmentation
2. `LoG Segmentation`
   - **Input**: LM Image
   - **Output**: LM Segmentation
3. `Point Cloud Sampling`
   - **Input**: LM Segmentation & EM Segmentation
   - **Output**: LM Point Cloud & LM Point Cloud
4. `Point Cloud Registration & Image Warping`
   - **Input**: EM Image, LM Image, LM Point Cloud & EM Point Cloud
   - **Output**: Registered LM Image, Registered LM Point Cloud

### Registering Multiple LM Channels
One can register multiple LM channels at once by doing the following.

1. Start by splitting the LM channels into the separate layers by right-clicking on
the layer and then selecting `Split Stack`.
![merged-channel-split-options.png](docs%2Fimages%2Fmerged-channel-split-options.png)
This will result in each of the channels having their own individual layer. 

2. Once this is done we must link all the LM layers together, this is done 
by selecting all the layers which will highlight them in blue, once again right-clicking
on the layer and then selecting `Link Layers.`
![split-channels-link-layers.png](docs%2Fimages%2Fsplit-channels-link-layers.png)

3. When you finally go to run CLEM-reg ensure that for the `Moving Image`
you select the LM layer that contains mitochondria.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-clemreg"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/krentzd/napari-clemreg/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[conda]: https://docs.conda.io/en/latest/

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/krentzd/napari-clemreg/issues', 'Documentation, https://github.com/krentzd/napari-clemreg#README.md', 'Source Code, https://github.com/krentzd/napari-clemreg', 'User Support, https://github.com/krentzd/napari-clemreg/issues']",napari-clemreg.get_reader,,napari-clemreg.make_run_registration,napari-clemreg.sample_data,"['*.tif', '*.tiff']",,
149,napari-caphid,napari-caphid,CAphid,0.0.1,2023-07-30,2023-07-30,Herearii Metuarea,herearii.metuarea@gmail.com,BSD-3-Clause,https://github.com/hereariim/napari-caphid/issues,https://pypi.org/project/napari-caphid/,,https://github.com/hereariim/napari-caphid,Annotation of aphid and update table,>=3.8,"['numpy', 'magicgui', 'qtpy', 'opencv-python', 'tqdm', 'pandas', 'Pillow', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-caphid

[![License BSD-3](https://img.shields.io/pypi/l/napari-caphid.svg?color=green)](https://github.com/hereariim/napari-caphid/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-caphid.svg?color=green)](https://pypi.org/project/napari-caphid)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-caphid.svg?color=green)](https://python.org)
[![tests](https://github.com/hereariim/napari-caphid/workflows/tests/badge.svg)](https://github.com/hereariim/napari-caphid/actions)
[![codecov](https://codecov.io/gh/hereariim/napari-caphid/branch/main/graph/badge.svg)](https://codecov.io/gh/hereariim/napari-caphid)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-caphid)](https://napari-hub.org/plugins/napari-caphid)

Annotation of aphid and update table

----------------------------------

Napari-caphid was developed for updating table of quantitative data from images. Napari-caphid was developed by Imhorphen Team (french team of University of Angers and INRAe Angers) for ECLECTIC Team (french team of University of Paris-Saclay and CNRS).

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-caphid` via [pip]:

    pip install napari-caphid



To install latest development version :

    pip install git+https://github.com/hereariim/napari-caphid.git

## Getting started

### Foreword

Before using the plugin, the directory must be structured as follows:

```
âââ Directory
    âââ France
    â   âââ image
    â   â   âââ img_1.tif
    â   â   âââ img_2.tif
    â   â   ...
    â   â   âââ img_n.tif
    â   âââ mask
    â   â   âââ msk_1.tif
    â   â   âââ msk_2.tif
    â   â   ...
    â   â   âââ msk_n.tif
    â   âââ img_1.tif
    â   âââ msk_1.tif
    â   âââ img_2.tif
    â   âââ msk_2.tif
    â   ...
    â   âââ img_n.tif
    â   âââ msk_n.tif
    â 
    âââ Belgium
    â   âââ image
    â   â   âââ ...
    â   âââ mask
    â   â   âââ ...
    â   âââ ...
    âââ Spain
    â   âââ image
    â   â   âââ ...
    â   âââ mask
    â   â   âââ ...
    â   âââ ...
    âââ Aphid.csv
```

Some explanation about structure. The directory contained three folders (France, Spain, Belgium) and one file (Aphid.csv).
- Each folders (France, Spain, Belgium) contains a set of images and masks and two folders (image, mask). The folder image contains images from the set of images. The folder mask contains masks from the set of masks.
- The file Aphid.csv is a table with quantitative data of aphids from inital process of aphid image processing.

Important:
- The structure of directory is very important because it will be useful to get image name.

### Getting started

The widget get three input:
- Mask : Mask stack
- Pick a table : Path/to/Directory/Aphid.csv
- Country : The country where images were taken

The widget gives one output:
- A new table .csv which is the Aphid.csv updated.

### What's it for ?

This widget gives quantitative data from Mask stack. These quantitative data will be contained into dataframe. Quantitative data linked to current masks contained in the Aphid.csv file will be deleted. Then, the new quantitative data contained in the dataframe will be integrated into the Aphid.csv file. In this way, the Aphid.csv file is updated.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-caphid"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hereariim/napari-caphid/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hereariim/napari-caphid/issues', 'Documentation, https://github.com/hereariim/napari-caphid#README.md', 'Source Code, https://github.com/hereariim/napari-caphid', 'User Support, https://github.com/hereariim/napari-caphid/issues']",napari-caphid.get_reader,napari-caphid.write_multiple,napari-caphid.make_process_func,,['*.npy'],,['.npy']
150,napari-ccp4map,napari-ccp4map,napari-ccp4map,1.0,2021-10-04,2021-10-04,Simon Biberger,dev@biberger.xyz,BSD-3-Clause,https://github.com/biberger/napari-ccp4map/issues,https://pypi.org/project/napari-ccp4map/,,https://github.com/biberger/napari-ccp4map,Enables napari to read .map files in the ccp4 format. Drag&Drop or press Ctrl+O to read files.,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'gemmi']","# napari-ccp4map

[![License](https://img.shields.io/pypi/l/napari-ccp4map.svg?color=green)](https://github.com/biberger/napari-ccp4map/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-ccp4map.svg?color=green)](https://pypi.org/project/napari-ccp4map)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-ccp4map.svg?color=green)](https://python.org)
[![tests](https://github.com/biberger/napari-ccp4map/workflows/tests/badge.svg)](https://github.com/biberger/napari-ccp4map/actions)
[![codecov](https://codecov.io/gh/biberger/napari-ccp4map/branch/master/graph/badge.svg)](https://codecov.io/gh/biberger/napari-ccp4map)

Enables napari to read .map files in the ccp4 format.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-ccp4map` via [pip]:

    pip install napari-ccp4map

## Usage
If the plugin was installed correctly, it will pop up in a napari window under Plugins->Install/Uninstall Plugins.
You can either drag&drop filed into the window to read them, or search for a folder/file using Ctrl+O.

## How it works
This plugin simply reads a file and allows [gemmi](https://github.com/project-gemmi/gemmi) to interact with it. Then, numpy turns the file into an array.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-ccp4map"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/biberger/napari-ccp4map/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/biberger/napari-ccp4map/issues', 'Documentation, https://github.com/biberger/napari-ccp4map#README.md', 'Source Code, https://github.com/biberger/napari-ccp4map', 'User Support, https://github.com/biberger/napari-ccp4map/issues']",napari-ccp4map.napari_get_reader,,,,['*'],,
151,napari-cell-centroid-annotator,napari-cell-centroid-annotator,3D cell centroid annotator,0.0.1,2023-03-23,2023-03-23,Tim Van De Looverbosch,tim.vandelooverbosch@gmail.com,MIT,https://github.com/tim-vdl/napari-cell-centroid-annotator/issues,https://pypi.org/project/napari-cell-centroid-annotator/,,https://github.com/tim-vdl/napari-cell-centroid-annotator,A simple plugin to annotate cell centroids in 3D images,>=3.8,"['numpy', 'pandas', 'tifffile', 'pathlib', 'napari', 'napari-plugin-engine', 'napari-layer-table', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-cell-centroid-annotator

[![License MIT](https://img.shields.io/pypi/l/napari-cell-centroid-annotator.svg?color=green)](https://github.com/tim-vdl/napari-cell-centroid-annotator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-cell-centroid-annotator.svg?color=green)](https://pypi.org/project/napari-cell-centroid-annotator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-cell-centroid-annotator.svg?color=green)](https://python.org)
[![tests](https://github.com/tim-vdl/napari-cell-centroid-annotator/workflows/tests/badge.svg)](https://github.com/tim-vdl/napari-cell-centroid-annotator/actions)
[![codecov](https://codecov.io/gh/tim-vdl/napari-cell-centroid-annotator/branch/main/graph/badge.svg)](https://codecov.io/gh/tim-vdl/napari-cell-centroid-annotator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-cell-centroid-annotator)](https://napari-hub.org/plugins/napari-cell-centroid-annotator)

A simple plugin to annotate cell centroids in 3D images

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-cell-centroid-annotator` via [pip]:

    pip install napari-cell-centroid-annotator



To install latest development version :

    pip install git+https://github.com/tim-vdl/napari-cell-centroid-annotator.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-cell-centroid-annotator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/tim-vdl/napari-cell-centroid-annotator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/tim-vdl/napari-cell-centroid-annotator/issues', 'Documentation, https://github.com/tim-vdl/napari-cell-centroid-annotator#README.md', 'Source Code, https://github.com/tim-vdl/napari-cell-centroid-annotator', 'User Support, https://github.com/tim-vdl/napari-cell-centroid-annotator/issues']",napari-cell-centroid-annotator.get_reader,,napari-cell-centroid-annotator.make_annotate_centroids_widget,,"['*.tif', '*.tiff', '*.csv', '*.npy']",,
152,napari-cellseg3d,napari-cellseg3d,CellSeg3D,0.2.2,2022-06-25,2024-12-23,"Cyril Achard, Maxime Vidal, Mackenzie Mathis","Cyril Achard <cyril.achard@epfl.ch>, Maxime Vidal <maxime.vidal@epfl.ch>, Mackenzie Mathis <mackenzie@post.harvard.edu>",MIT,https://github.com/AdaptiveMotorControlLab/CellSeg3D/issues,https://pypi.org/project/napari-cellseg3d/,,,Plugin for cell segmentation in 3D,>=3.8,"['numpy', 'napari[all]>=0.4.14', 'QtPy', 'scikit-image>=0.19.2', 'matplotlib>=3.4.1', 'tifffile>=2022.2.9', 'imagecodecs>=2023.3.16', 'torch>=1.11', 'monai[einops,nibabel]>=0.9.0', 'itk', 'tqdm', 'pyclesperanto-prototype', 'tqdm', 'matplotlib', 'pydensecrf2', 'pyqt5; extra == ""pyqt5""', 'pyside2; extra == ""pyside2""', 'pyside6; extra == ""pyside6""', 'onnx; extra == ""onnx-cpu""', 'onnxruntime; extra == ""onnx-cpu""', 'onnx; extra == ""onnx-gpu""', 'onnxruntime-gpu; extra == ""onnx-gpu""', 'wandb; extra == ""wandb""', 'isort; extra == ""dev""', 'black; extra == ""dev""', 'ruff; extra == ""dev""', 'pre-commit; extra == ""dev""', 'tuna; extra == ""dev""', 'twine; extra == ""dev""', 'jupyter-book; extra == ""docs""', 'pytest; extra == ""test""', 'pytest_qt; extra == ""test""', 'pytest-cov; extra == ""test""', 'coverage; extra == ""test""', 'tox; extra == ""test""', 'twine; extra == ""test""', 'onnx; extra == ""test""', 'onnxruntime; extra == ""test""']","# CellSeg3D: self-supervised (and supervised) 3D cell segmentation, primarily for mesoSPIM data!
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-cellseg3d)](https://www.napari-hub.org/plugins/napari-cellseg3d)
[![PyPI](https://img.shields.io/pypi/v/napari-cellseg3d.svg?color=green)](https://pypi.org/project/napari-cellseg3d)
[![Downloads](https://static.pepy.tech/badge/napari-cellseg3d)](https://pepy.tech/project/napari-cellseg3d)
[![Downloads](https://static.pepy.tech/badge/napari-cellseg3d/month)](https://pepy.tech/project/napari-cellseg3d)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://github.com/AdaptiveMotorControlLab/CellSeg3D/raw/main/LICENSE)
[![codecov](https://codecov.io/gh/AdaptiveMotorControlLab/CellSeg3D/branch/main/graph/badge.svg?token=hzUcn3XN8F)](https://codecov.io/gh/AdaptiveMotorControlLab/CellSeg3D)
<a href=""https://github.com/psf/black""><img alt=""Code style: black"" src=""https://img.shields.io/badge/code%20style-black-000000.svg""></a>

<img src=""https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/838605d0-9723-4e43-83cd-6dbfe4adf36b/cellseg-logo.png?format=1500w"" title=""cellseg3d"" alt=""cellseg3d logo"" width=""350"" align=""right"" vspace = ""80""/>


**A package for 3D cell segmentation with deep learning, including a napari plugin**: training, inference, and data review. In particular, this project was developed for analysis of confocal and mesoSPIM-acquired (cleared tissue + lightsheet) tissue datasets, but is not limited to this type of data. [Check out our preprint for more information!](https://www.biorxiv.org/content/10.1101/2024.05.17.594691v1)


![demo](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/0d16a71b-3ff2-477a-9d83-18d96cb1ce28/full_demo.gif?format=500w)


## Installation

 ð» See the [Installation page](https://adaptivemotorcontrollab.github.io/CellSeg3D/welcome.html) in the documentation for detailed instructions.

## Documentation

ð Documentation is available at [https://AdaptiveMotorControlLab.github.io/CellSeg3D
](https://adaptivemotorcontrollab.github.io/CellSeg3D/welcome.html)


ð For additional examples and how to reproduce our paper figures, see: [https://github.com/C-Achard/cellseg3d-figures](https://github.com/C-Achard/cellseg3d-figures)

## Quick Start

```
pip install napari_cellseg3d
```

To use the plugin, please run:
```
napari
```
Then go into `Plugins > napari-cellseg3d`, and choose which tool to use.

- **Review (label)**: This module allows you to review your labels, from predictions or manual labeling, and correct them if needed. It then saves the status of each file in a csv, for easier monitoring.
- **Inference**: This module allows you to use pre-trained segmentation algorithms on volumes to automatically label cells and compute statistics.
- **Train**:  This module allows you to train segmentation algorithms from labeled volumes.
- **Utilities**: This module allows you to perform several actions like cropping your volumes and labels dynamically, by selecting a fixed size volume and moving it around the image; fragment images into smaller cubes for training; or converting labels from instance to segmentation and the opposite.

## Why use CellSeg3D?

The strength of our approach is we can match supervised model performance with purely self-supervised learning, meaning users don't need to spend (hundreds) of hours on annotation. Here is a quick look of our key results. TL;DR see panel **f**, which shows that with minmal input data we can outperform supervised models:


![FIG1 (1)](https://github.com/user-attachments/assets/0d970b45-79ff-4c58-861f-e1e7dc9abc65)

**Figure 1. Performance of 3D Semantic and Instance Segmentation Models.**
**a:** Raw mesoSPIM whole-brain sample, volumes and corresponding ground truth labels from somatosensory (S1) and visual (V1) cortical regions.
**b:** Evaluation of instance segmentation performance for baseline
thresholding-only, supervised models: Cellpose, StartDist, SwinUNetR, SegResNet, and our self-supervised model WNet3D over three data subsets.
F1-score is computed from the Intersection over Union (IoU) with ground truth labels, then averaged. Error bars represent 50% Confidence Intervals
(CIs).
**c:** View of 3D instance labels from supervised models, as noted, for visual cortex volume in b evaluation.
**d:** Illustration of our WNet3D architecture showcasing the dual 3D U-Net structure with our modifications.


## News

**New version: v0.2.2**

- v0.2.2:
  - Updated the Colab Notebooks for training and inference
  - New models available in the inference demo notebook
  - CRF optional post-processing adjustments (and pip install directly)
- v0.2.1:
  - Updated plugin default behaviors across the board to be more readily applicable to demo data
  - Threshold value in inference is now automatically set by default according to performance on demo data on a per-model basis
  - Added a grid search utility to find best thresholds for supervised models

- v0.2.0:
  - Changed project name to ""napari_cellseg3d"" to avoid setuptools deprecation
  - Small API changes for training/inference from a script
  - Some fixes to WandB integration and csv saving after training

Previous additions:

- v0.1.2: Fixed manifest issue for PyPi
- Improved training interface
- Unsupervised model : WNet3D
  - Generate labels directly from raw data!
  - Can be trained in napari directly or in Google Colab
  - Pretrained weights for mesoSPIM whole-brain cell segmentation
- WandB support (install wandb and login to use automatically when training)
- Remade and improved documentation
  - Moved to Jupyter Book
  - Dedicated installation page, and working ARM64 install for macOS Silicon users
- New utilities
- Many small improvements and many bug fixes




## Requirements

**Compatible with Python 3.8 to 3.10.**
Requires **[napari]**, **[PyTorch]** and **[MONAI]**.
Compatible with Windows, MacOS and Linux.
Installation should not take more than 30 minutes, depending on your internet connection.

For PyTorch, please see [the PyTorch website for installation instructions].

A CUDA-capable GPU is not needed but very strongly recommended, especially for training.

If you get errors from MONAI regarding missing readers, please see [MONAI's optional dependencies] page for instructions on getting the readers required by your images.

### Install note for ARM64 (Silicon) Mac users

To avoid issues when installing on the ARM64 architecture, please follow these steps.

1) Create a new conda env using the provided conda/napari_CellSeg3D_ARM64.yml file :

        git clone https://github.com/AdaptiveMotorControlLab/CellSeg3d.git
        cd CellSeg3d
        conda env create -f conda/napari_CellSeg3D_ARM64.yml
        conda activate napari_CellSeg3D_ARM64


2) Install a Qt backend (PySide or PyQt5)
3) Launch napari, the plugin should be available in the plugins menu.



## Issues

**Help us make the code better by reporting issues and adding your feature requests!**


If you encounter any problems, please [file an issue] along with a detailed description.

## Testing

You can generate docs locally by running ``make html`` in the docs/ folder.

Before testing, install all requirements using ``pip install napari-cellseg3d[test]``.

``pydensecrf`` is also required for testing.

To run tests locally:

- Locally : run ``pytest napari_cellseg3d\_tests`` in the plugin folder.
- Locally with coverage : In the plugin folder, run ``coverage run --source=napari_cellseg3d -m pytest`` then ``coverage xml`` to generate a .xml coverage file.
- With tox : run ``tox`` in the plugin folder (will simulate tests with several python and OS configs, requires substantial storage space)

## Contributing

Contributions are very welcome.

Please ensure the coverage at least stays the same before you submit a pull request.

For local installation from Github cloning, please run:

```
pip install -e .
```

## License

Distributed under the terms of the [MIT] license.

""napari-cellseg3d"" is free and open source software.

[napari-hub]: https://www.napari-hub.org/plugins/napari-cellseg3d

[file an issue]: https://github.com/AdaptiveMotorControlLab/CellSeg3D/issues
[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[Installation page]: https://adaptivemotorcontrollab.github.io/CellSeg3D/source/guides/installation_guide.html
[the PyTorch website for installation instructions]: https://pytorch.org/get-started/locally/
[PyTorch]: https://pytorch.org/get-started/locally/
[MONAI's optional dependencies]: https://docs.monai.io/en/stable/installation.html#installing-the-recommended-dependencies
[MONAI]: https://docs.monai.io/en/stable/installation.html#installing-the-recommended-dependencies

## Citation

```
@article {Achard2024,
	author = {Achard, Cyril and Kousi, Timokleia and Frey, Markus and Vidal, Maxime and Paychere, Yves and Hofmann, Colin and Iqbal, Asim and Hausmann, Sebastien B. and Pages, Stephane and Mathis, Mackenzie W.},
	title = {CellSeg3D: self-supervised 3D cell segmentation for microscopy},
	elocation-id = {2024.05.17.594691},
	year = {2024},
	doi = {10.1101/2024.05.17.594691},
	publisher = {Cold Spring Harbor Laboratory},
	URL = {https://www.biorxiv.org/content/early/2024/05/17/2024.05.17.594691},
	eprint = {https://www.biorxiv.org/content/early/2024/05/17/2024.05.17.594691.full.pdf},
	journal = {bioRxiv}
}
```
## Acknowledgements

This plugin was developed by originally Cyril Achard, Maxime Vidal, Mackenzie Mathis.
This work was funded, in part, from the Wyss Center to the [Mathis Laboratory of Adaptive Intelligence](https://www.mackenziemathislab.org/).
Please refer to the documentation for full acknowledgements.

## Plugin base

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.
","['Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License', 'Topic :: Scientific/Engineering :: Artificial Intelligence', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Visualization']","['Homepage, https://github.com/AdaptiveMotorControlLab/CellSeg3D', 'Documentation, https://adaptivemotorcontrollab.github.io/cellseg3d-docs/res/welcome.html', 'Issues, https://github.com/AdaptiveMotorControlLab/CellSeg3D/issues']",,,napari_cellseg3d.load,,,,
153,napari-clipboard,napari-clipboard,napari clipboard,0.0.1,2023-08-28,2023-08-28,Kyle Harrington,czi@kyleharrington.com,BSD-3-Clause,https://github.com/kephale/napari-clipboard/issues,https://pypi.org/project/napari-clipboard/,,https://github.com/kephale/napari-clipboard,A plugin for creating napari layers from the System clipboard,>=3.8,"['numpy', 'magicgui', 'qtpy', 'napari', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-clipboard

[![License BSD-3](https://img.shields.io/pypi/l/napari-clipboard.svg?color=green)](https://github.com/kephale/napari-clipboard/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-clipboard.svg?color=green)](https://pypi.org/project/napari-clipboard)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-clipboard.svg?color=green)](https://python.org)
[![tests](https://github.com/kephale/napari-clipboard/workflows/tests/badge.svg)](https://github.com/kephale/napari-clipboard/actions)
[![codecov](https://codecov.io/gh/kephale/napari-clipboard/branch/main/graph/badge.svg)](https://codecov.io/gh/kephale/napari-clipboard)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-clipboard)](https://napari-hub.org/plugins/napari-clipboard)

A plugin for creating napari layers from the System clipboard

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-clipboard` via [pip]:

    pip install napari-clipboard



To install latest development version :

    pip install git+https://github.com/kephale/napari-clipboard.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-clipboard"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kephale/napari-clipboard/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kephale/napari-clipboard/issues', 'Documentation, https://github.com/kephale/napari-clipboard#README.md', 'Source Code, https://github.com/kephale/napari-clipboard', 'User Support, https://github.com/kephale/napari-clipboard/issues']",,,napari-clipboard.image_from_clipboard,,,,
154,napari-clusters-plotter,napari-clusters-plotter,napari clusters plotter,0.10.0,2021-11-15,2025-07-16,"Laura Zigutyte, Ryan Savill, Marcelo Zoccoler, Thorsten Wagner, Robert Haase",Johannes Soltwedel <johannes_richard.soltwedel@tu-dresden.de>,"Copyright (c) 2022, DFG Cluste...",https://github.com/BiAPoL/napari-clusters-plotter/issues,https://pypi.org/project/napari-clusters-plotter/,,,A plugin to use with napari for clustering objects according to their properties,>=3.9,"['numpy', 'magicgui', 'qtpy', 'napari', 'npe2', 'scikit-learn', 'pandas', 'umap-learn', 'scikit-image', 'scipy', 'biaplotter>=0.3.1', 'imagecodecs', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-clusters-plotter

[![License](https://img.shields.io/pypi/l/napari-clusters-plotter.svg?color=green)](https://github.com/lazigu/napari-clusters-plotter/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-clusters-plotter.svg?color=green)](https://pypi.org/project/napari-clusters-plotter)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-clusters-plotter.svg?color=green)](https://python.org)
[![Anaconda-Server Badge](https://anaconda.org/conda-forge/napari-clusters-plotter/badges/version.svg)](https://anaconda.org/conda-forge/napari-clusters-plotter)
[![tests](https://github.com/BiAPoL/napari-clusters-plotter/actions/workflows/test_and_deploy.yml/badge.svg)](https://github.com/BiAPoL/napari-clusters-plotter/actions/workflows/test_and_deploy.yml)
[![codecov](https://codecov.io/gh/BiAPoL/napari-clusters-plotter/branch/main/graph/badge.svg?token=R6W2KO1NJ8)](https://codecov.io/gh/BiAPoL/napari-clusters-plotter)
[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)
[![Anaconda-Server Badge](https://anaconda.org/conda-forge/napari-clusters-plotter/badges/downloads.svg)](https://anaconda.org/conda-forge/napari-clusters-plotter)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-clusters-plotter)](https://www.napari-hub.org/plugins/napari-clusters-plotter)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15670497.svg)](https://doi.org/10.5281/zenodo.15670497)

A napari-plugin for clustering objects according to their properties.

## [Documentation](https://biapol.github.io/napari-clusters-plotter/)

The documentation for the napari-clusters-plotter is available under the above link.

## License

Distributed under the terms of the [BSD-3] license,
""napari-clusters-plotter"" is free and open source software

## Acknowledgements
This project was supported by the Deutsche Forschungsgemeinschaft under Germanyâs Excellence Strategy â EXC2068 - Cluster of Excellence ""Physics of Life"" of TU Dresden.
This project has been made possible in part by grant number [2021-240341 (Napari plugin accelerator grant)](https://chanzuckerberg.com/science/programs-resources/imaging/napari/improving-image-processing/) from the Chan Zuckerberg Initiative DAF, an advised fund of the Silicon Valley Community Foundation.

## Issues

If you encounter any problems, please [file an issue](https://github.com/BiAPoL/napari-clusters-plotter/issues) along
with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[pytest]: https://docs.pytest.org/en/7.0.x/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[conda]: https://docs.conda.io/projects/conda/en/latest/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/BiAPoL/napari-clusters-plotter/issues', 'Documentation, https://github.com/BiAPoL/napari-clusters-plotter', 'Source Code, https://github.com/BiAPoL/napari-clusters-plotter', 'User Support, https://github.com/BiAPoL/napari-clusters-plotter/issues']",,,napari-clusters-plotter.plotter,napari-clusters-plotter.bbbc_sample_data,,,
155,napari-conference,napari-conference,Napari Conference,0.1.0,2023-09-28,2023-09-28,Kyle Harrington,czi@kyleharrington.com,BSD-3-Clause,https://github.com/kephale/napari-conference/issues,https://pypi.org/project/napari-conference/,,https://github.com/kephale/napari-conference,A simple plugin that allows you to use napari + your webcam in video calls,>=3.8,"['numpy', 'magicgui', 'qtpy', 'opencv-python', 'pyvirtualcam', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-conference

[![License BSD-3](https://img.shields.io/pypi/l/napari-conference.svg?color=green)](https://github.com/kephale/napari-conference/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-conference.svg?color=green)](https://pypi.org/project/napari-conference)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-conference.svg?color=green)](https://python.org)
[![tests](https://github.com/kephale/napari-conference/workflows/tests/badge.svg)](https://github.com/kephale/napari-conference/actions)
[![codecov](https://codecov.io/gh/kephale/napari-conference/branch/main/graph/badge.svg)](https://codecov.io/gh/kephale/napari-conference)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-conference)](https://napari-hub.org/plugins/napari-conference)

A simple plugin that allows you to use napari + your webcam in video
calls

![Example screenshot of a person using napari conference with the
napari viewer and napari conference widget shown](napari_conference_example.png)

## Usage

1. `Plugins>start conference`
2. Check `running` checkbox
3. Press `Update` button to update any setting (and start/stop)

If things work in zoom but you don't show up, then make sure `blur
background` is disabled.

## Installation

### Prerequisites

You will need to:

- follow `pyvirtualcam`'s installation instructions:
https://github.com/letmaik/pyvirtualcam#installation
- install `napari` from source to get the new async slicing updates 

Note: I needed to install `pyvirtualcam` from source on my MacOS M1
with python=3.10.



[Not available on pypi yet] You can install `napari-conference` via [pip]:

    pip install napari-conference



To install latest development version :

    pip install git+https://github.com/kephale/napari-conference.git


## Known Issues

- resizing the napari window while streaming causes a crash
- cannot be restarted after stopping the widget

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-conference"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kephale/napari-conference/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kephale/napari-conference/issues', 'Documentation, https://github.com/kephale/napari-conference#README.md', 'Source Code, https://github.com/kephale/napari-conference', 'User Support, https://github.com/kephale/napari-conference/issues']",,,napari-conference.make_widget,,,,
156,napari-cookiecut,napari-cookiecut,Cookiecut,0.1.1,2022-10-21,2022-10-24,Sean Martin,martins7@tcd.ie,BSD-3-Clause,https://github.com/seankmartin/napari-cookiecut/issues,https://pypi.org/project/napari-cookiecut/,,https://github.com/seankmartin/napari-cookiecut,Fixed cut,>=3.8,"['numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-cookiecut

[![License BSD-3](https://img.shields.io/pypi/l/napari-cookiecut.svg?color=green)](https://github.com/seankmartin/napari-cookiecut/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-cookiecut.svg?color=green)](https://pypi.org/project/napari-cookiecut)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-cookiecut.svg?color=green)](https://python.org)
[![tests](https://github.com/seankmartin/napari-cookiecut/workflows/tests/badge.svg)](https://github.com/seankmartin/napari-cookiecut/actions)
[![codecov](https://codecov.io/gh/seankmartin/napari-cookiecut/branch/main/graph/badge.svg)](https://codecov.io/gh/seankmartin/napari-cookiecut)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-cookiecut)](https://napari-hub.org/plugins/napari-cookiecut)

A fixed version of a cookiecut napari plugin template that has been set up with all the basic functionality following the README for reference.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-cookiecut` via [pip]:

    pip install napari-cookiecut



To install latest development version :

    pip install git+https://github.com/seankmartin/napari-cookiecut.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-cookiecut"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/seankmartin/napari-cookiecut/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/seankmartin/napari-cookiecut/issues', 'Documentation, https://github.com/seankmartin/napari-cookiecut#README.md', 'Source Code, https://github.com/seankmartin/napari-cookiecut', 'User Support, https://github.com/seankmartin/napari-cookiecut/issues']",napari-cookiecut.get_reader,napari-cookiecut.write_multiple,napari-cookiecut.make_qwidget,napari-cookiecut.make_sample_data,['*.npy'],,['.npy']
157,napari-conidie,napari-conidie,Conidie,1.0.2,2022-12-15,2024-04-29,Herearii Metuarea,herearii.metuarea@gmail.com,BSD-3-Clause,https://github.com/hereariim/napari-conidie/issues,https://pypi.org/project/napari-conidie/,,https://github.com/hereariim/napari-conidie,A segmentation tool to get conidie and hyphe,>=3.8,"['numpy', 'magicgui', 'qtpy', 'pandas', 'h5py', 'scikit-image', 'napari', 'matplotlib', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-conidie

[![License BSD-3](https://img.shields.io/pypi/l/napari-conidie.svg?color=green)](https://github.com/hereariim/napari-conidie/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-conidie.svg?color=green)](https://pypi.org/project/napari-conidie)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-conidie.svg?color=green)](https://python.org)
[![tests](https://github.com/hereariim/napari-conidie/workflows/tests/badge.svg)](https://github.com/hereariim/napari-conidie/actions)
[![codecov](https://codecov.io/gh/hereariim/napari-conidie/branch/main/graph/badge.svg)](https://codecov.io/gh/hereariim/napari-conidie)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-conidie)](https://napari-hub.org/plugins/napari-conidie)

A segmentation tool to get conidie and hyphe

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

This plugin is a use case for obtaining conidia and hyphae surface from images. This plugin is a private tool dedicated exclusively to the work of the QUASAV team.

## Installation

This private tool cannot be found in the built-in napari. The installation therefore follows two steps:

1 - Install latest development version :

    git clone https://github.com/hereariim/napari-conidie.git

## Getting started

As prerequisite, user must have installed ilastik in its computer.

Before using the plugin, you must have two data:

- The ilastik model
- The compressed file contained your images structured as followed :

```
âââ Compressed file
    âââ Folder1
    â   âââ img0_1.jpg
    â   âââ img0_2.jpg
    â   ...
    â   âââ img0_n.jpg
    â 
    âââ Folder2
    â   âââ img1_1.jpg
    â   âââ img1_2.jpg
    â   ...
    â   âââ img1_n.jpg
    ...
    â
    âââ  Foldern
        âââ imgn_1.jpg
        âââ imgn_2.jpg
        ...
        âââ imgn_n.jpg
```

## Plugin

![here](https://github.com/hereariim/napari-conidie/assets/93375163/07cf6bc3-3d55-4ae1-94ac-8e8b33193963)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-conidie"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hereariim/napari-conidie/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hereariim/napari-conidie/issues', 'Documentation, https://github.com/hereariim/napari-conidie#README.md', 'Source Code, https://github.com/hereariim/napari-conidie', 'User Support, https://github.com/hereariim/napari-conidie/issues']",,,napari-conidie.segmentation,,,,
158,napari-copick,napari-copick,copick,1.0.1,2025-07-27,2025-07-27,"Kyle Harrington, Utz H. Ermel","Kyle Harrington <czi@kyleharrington.com>, ""Utz H. Ermel"" <utz.ermel@czii.org>",MIT,https://github.com/kephale/napari-copick/issues,https://pypi.org/project/napari-copick/,,,A plugin for collaborative annotation in cryoET using copick,>=3.9,"['click', 'copick-shared-ui==0.2.0', 'copick>=1.6.0', 'fsspec', 'magicgui', 'napari', 'napari-ome-zarr', 'numpy', 'pydantic>=2', 'qtpy', 'scikit-image', 'trimesh', 'zarr', ""black>=25.1.0; extra == 'dev'"", ""hatch-vcs>=0.4.0; extra == 'dev'"", ""hatchling>=1.25.0; extra == 'dev'"", ""pre-commit>=4.2.0; extra == 'dev'"", ""ruff>=0.12.0; extra == 'dev'"", ""napari; extra == 'testing'"", ""pyqt6; extra == 'testing'"", ""pytest; extra == 'testing'"", ""pytest-cov; extra == 'testing'"", ""pytest-qt; extra == 'testing'"", ""tox; extra == 'testing'"", ""tox-gh-actions; extra == 'testing'"", ""tox-uv; extra == 'testing'""]","# napari-copick

[![License MIT](https://img.shields.io/pypi/l/napari-copick.svg?color=green)](https://github.com/kephale/napari-copick/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-copick.svg?color=green)](https://pypi.org/project/napari-copick)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-copick.svg?color=green)](https://python.org)
[![tests](https://github.com/kephale/napari-copick/workflows/tests/badge.svg)](https://github.com/kephale/napari-copick/actions)
[![codecov](https://codecov.io/gh/kephale/napari-copick/branch/main/graph/badge.svg)](https://codecov.io/gh/kephale/napari-copick)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-copick)](https://napari-hub.org/plugins/napari-copick)

A plugin for collaborative annotation in cryoET using copick

![interface.png](https://github.com/copick/napari-copick/raw/main/docs/assets/interface.png)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-copick` via [pip]:

    pip install napari-copick

To install latest development version:

    pip install git+https://github.com/copick/napari-copick.git

## Usage

### Using a copick config file

```bash
napari-copick run --config path/to/copick_config.json
```

### Using dataset IDs from CZ cryoET Data Portal

```bash
napari-copick run --dataset-ids 10440 10441 --overlay-root /path/to/overlay_root
```

You can specify multiple dataset IDs separated by spaces.

### GUI Usage

The plugin provides an intuitive interface with two loading options:

1. **Load Config File**: Opens a file dialog to select a copick configuration JSON file
2. **Load from Dataset IDs**: Opens a dialog to enter CZ cryoET Data Portal dataset IDs and overlay root path

After loading, you'll see a hierarchical tree of the project structure that you can navigate to access tomograms, segmentations, and picks.

### Tomogram Handling

napari-copick now handles multiscale zarr arrays directly:

- Automatically detects and loads all available resolution levels
- Creates a proper multiscale image stack using napari's native multiscale API
- Uses dask for efficient lazy loading of large tomogram data
- Applies appropriate scaling factors based on the voxel size metadata

This direct zarr handling provides better performance and more flexibility compared to relying on external plugins.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-copick"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kephale/napari-copick/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

## Code of Conduct

This project adheres to the Contributor Covenant [code of conduct](https://github.com/chanzuckerberg/.github/blob/main/CODE_OF_CONDUCT.md). By participating, you are expected to uphold this code. Please report unacceptable behavior to [opensource@chanzuckerberg.com](mailto:opensource@chanzuckerberg.com).

## Reporting Security Issues

If you believe you have found a security issue, please responsibly disclose by contacting us at [security@chanzuckerberg.com](mailto:security@chanzuckerberg.com).
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Programming Language :: Python :: Implementation :: CPython', 'Programming Language :: Python :: Implementation :: PyPy', 'Topic :: Scientific/Engineering :: Image Processing']","['Repository, https://github.com/kephale/napari-copick', 'Issues, https://github.com/kephale/napari-copick/issues', 'Documentation, https://github.com/kephale/napari-copick#README.md', 'Bug Tracker, https://github.com/kephale/napari-copick/issues', 'Source Code, https://github.com/kephale/napari-copick', 'User Support, https://github.com/kephale/napari-copick/issues']",,,napari-copick.make_qwidget,,,,
159,napari-console,napari-console,napari-console,0.1.3,2021-01-21,2024-12-20,napari team,napari team <napari-steering-council@googlegroups.com>,BSD-3-Clause,https://github.com/napari/napari-console,https://pypi.org/project/napari-console/,,,A plugin that adds a console to napari,>=3.9,"['IPython>=7.7.0', 'ipykernel>=5.2.0', 'qtconsole!=4.7.6,!=5.4.2,>=4.5.1', 'qtpy>=1.7.0', 'PySide2!=5.15.0,>=5.13.2; (python_version < ""3.11"" and platform_machine != ""arm64"") and extra == ""pyside2""', 'PySide6<6.5; python_version < ""3.12"" and extra == ""pyside6-experimental""', 'PyQt6>6.5; extra == ""pyqt6""', 'PyQt6!=6.6.1; platform_system == ""Darwin"" and extra == ""pyqt6""', 'napari-console[pyside2]; extra == ""pyside""', 'PyQt5!=5.15.0,>=5.13.2; extra == ""pyqt5""', 'napari-console[pyqt5]; extra == ""pyqt""', 'napari-console[pyqt]; extra == ""qt""', 'napari[pyqt]; extra == ""testing""']","# napari-console (WIP, under active development)

[![License](https://img.shields.io/pypi/l/napari-console.svg?color=green)](https://github.com/napari/napari-console/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-console.svg?color=green)](https://pypi.org/project/napari-console)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-console.svg?color=green)](https://python.org)
[![tests](https://github.com/napari/napari-console/workflows/tests/badge.svg)](https://github.com/napari/napari-console/actions)
[![codecov](https://codecov.io/gh/napari/napari-console/branch/main/graph/badge.svg)](https://codecov.io/gh/napari/napari-console)

A plugin that adds a console to napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Local variables

In napari-console 0.0.8 and earlier, the console `locals()` namespace only
contained a reference to the napari viewer that enclosed the console.

Since version 0.0.9, it instead contains everything in the enclosing frame that
called napari. That is, if your Python code is:

```python
import napari
import numpy as np
from scipy import ndimage as ndi

image = np.random.random((500, 500))
labels = ndi.label(image > 0.7)[0]

viewer, image_layer = napari.imshow(image)
labels_layer = viewer.add_labels(labels)

napari.run()
```

Then the napari console will have the variables `np`, `napari`, `ndi`, `image`,
`labels`, `viewer`, `image_layer`, and `labels_layer` in its namespace.

This is implemented by inspecting the Python stack when the console is first
instantiated, finding the first frame that is outside of the `napari_console`,
`napari`, and `in_n_out` modules, and passing the variables in the frame's
`f_locals` and `f_globals` to the console namespace.

If you want to disable this behavior (for example, because you are embedding
napari and the console within some larger application), you can add
`NAPARI_EMBED=1` to your environment variables before instantiating the
console.

## Installation

You can install `napari-console` via [pip]:

    pip install napari-console

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-console"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/sofroniewn/napari-console/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Software Development :: Testing']","['Homepage, https://github.com/napari/napari-console', 'Bug Tracker, https://github.com/napari/napari-console/issues', 'Source Code, https://github.com/napari/napari-console']",,,,,,,
160,napari-compressed-labels-io,napari-compressed-labels-io,napari-compressed-labels-io,0.0.2,2021-02-23,2021-03-03,Draga Doncila,ddoncila@gmail.com,MIT,https://github.com/DragaDoncila/napari-compressed-labels-io,https://pypi.org/project/napari-compressed-labels-io/,,https://github.com/DragaDoncila/napari-compressed-labels-io,Plugin exploring different options for reading and writing compressed and portable labels layers in napari.,>=3.6,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'zarr', 'dask[complete]']","# napari-compressed-labels-io

[![License](https://img.shields.io/pypi/l/napari-compressed-labels-io.svg?color=green)](https://github.com/DragaDoncila/napari-compressed-labels-io/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-compressed-labels-io.svg?color=green)](https://pypi.org/project/napari-compressed-labels-io)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-compressed-labels-io.svg?color=green)](https://python.org)
[![tests](https://github.com/DragaDoncila/napari-compressed-labels-io/workflows/tests/badge.svg)](https://github.com/DragaDoncila/napari-compressed-labels-io/actions)
[![codecov](https://codecov.io/gh/DragaDoncila/napari-compressed-labels-io/branch/master/graph/badge.svg)](https://codecov.io/gh/DragaDoncila/napari-compressed-labels-io)


## Description

This napari plugin provides readers and writers for labels and their corresponding image layers into zarr format for compression and portability. Each reader/writer pair supports a round trip of saving and loading image and labels layers.

## Writers
Two writers are provided by this plugin, each with its own reader.

### `labels_to_zarr`
This writer is an alternative to napari's default label writer and will write an entire labels layer, regardless of its dimensions, into a single zarr file. This writer provides the best compression option and its associated reader `get_zarr_labels` will read the layer back into napari.

This writer will be called when the user tries to save a selected labels layer into a path ending with .zarr

### `label_image_pairs_to_zarr`
This writer will save 3-dimensional labels and image layers from the viewer into individual zarrs for portability and convenience. For example, given one labels and one image layer of the shape (10, 200, 200) saved to my_stacks.zarr, 10 subdirectories will be created, each with two zarrs inside of shape (200, 200) corresponding to the labels and image layer.

This writer allows users to load stacks of associated images, label them, and then quickly save these stacks out into individual slices for easy loading, viewing and interaction. Its associated reader supports the loading into napari of the whole stack, all layers at one slice of the stack, and an individual layer of a given slice of the stack.

The writer currently supports only 3D layers, with the exception of RGB images of the form (z, y, x, 3), which are also supported.


## Readers

Two readers are provided by this plugin for loading the formats saved by each writer. These are detailed below.

### `get_zarr_labels`

This reader will open any zarr file with a .zarray at the top level in `path` as a labels layer. This is to be used in conjunction with `labels_to_zarr`.


### `get_label_image_stack`

This reader will open any zarr containing a `.zmeta` file as layers into napari. Depending on what is being opened, the reader will either load a full stack of labels and images, one slice of a stack of images and labels or an individual layer within a slice. This is to be used in conjunction with `label_image_pairs_to_zarr`.

## .zmeta

This metadata file contains information about the layer types in the stack and in each individual slice, as well as the number of image/label slices. This allows the reader plugin to load the correct layer types with appropriate names both at a stack level and at the individual slice level.

### An example .zmeta specification

```json
{
    ""meta"": {
        ""stack"": 7                               # number of slices in the entire stack (1 for an individual slice, 0 for a layer within a slice)
    },
    ""data"": {
        ""image"" : [                              # all image layers must be listed here
            {
                ""name"": ""leaves_example_data"",
                ""shape"": [790, 790, 3],
                ""dtype"": ""uint8"",
                ""rgb"": true                      # where rgb is false the image will be loaded as greyscale (colormap support has not yet been implemented)
            }
        ],
        ""labels"" : [
            {
                ""name"": ""oak"",
                ""shape"": [790, 790],
                ""dtype"": ""int64""
            },
            {
                ""name"": ""bg"",
                ""shape"": [790, 790],
                ""dtype"": ""int64""
            }
        ]
    }
}

```


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-compressed-labels-io` via [pip]:

    pip install napari-compressed-labels-io

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-compressed-labels-io"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/DragaDoncila/napari-compressed-labels-io/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']",,napari-compressed-labels-io.get_zarr_labels,napari-compressed-labels-io.labels_to_zarr,,,['*'],,
161,napari-convpaint,napari-convpaint,napari ConvPaint,0.7.0,2023-11-01,2025-04-07,Guillaume Witz,guillaume.witz@unibe.ch,BSD-3-Clause,https://github.com/guiwitz/napari-convpaint/issues,https://pypi.org/project/napari-convpaint/,,https://github.com/guiwitz/napari-convpaint,A plugin for segmentation by pixel classification using pre-trained neural networks for feature extraction,>=3.9,"['catboost', 'einops', 'joblib', 'magicgui', 'napari', 'napari-annotation-project', 'napari-guitils', 'numpy', 'pandas', 'pyyaml', 'qtpy', 'scikit-learn', 'scikit-image', 'tifffile', 'torch', 'torchvision>=0.13.0', 'zarr', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'pyqt5; extra == ""testing""', 'cellpose; extra == ""cellpose""', 'ilastik-napari; extra == ""ilastik""', 'pyqt5; extra == ""qt""']","
[![License](https://img.shields.io/pypi/l/napari-convpaint.svg?color=green)](https://github.com/guiwitz/napari-convpaint/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-convpaint.svg?color=green)](https://pypi.org/project/napari-convpaint)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-convpaint.svg?color=green)](https://python.org)
[![tests](https://github.com/guiwitz/napari-convpaint/workflows/tests/badge.svg)](https://github.com/guiwitz/napari-convpaint/actions)
[![codecov](https://codecov.io/gh/guiwitz/napari-convpaint/branch/main/graph/badge.svg)](https://codecov.io/gh/guiwitz/napari-convpaint)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-convpaint)](https://napari-hub.org/plugins/napari-convpaint)



![overview conv-paint](/images/overview_github.png)
This napari plugin can be used to segment objects or structures in images based on a few brush strokes providing examples of the classes. Based on the same idea as other tools like ilastik, its main strength is that it can use features from pretrained neural networks like VGG16 or DINOV2, enabling the segmentation of more complex images.

**Find more information and tutorials in the [docs](https://guiwitz.github.io/napari-convpaint/) or read the [preprint](https://doi.org/10.1101/2024.09.12.610926).**


![overview conv-paint](/images/network_github.png)

## Installation

You can install `napari-convpaint` via [pip]

    pip install napari-convpaint

To install latest development version :

    pip install git+https://github.com/guiwitz/napari-convpaint.git


## Example use case: Tracking shark body parts in a movie
These are the scribble annotations provided for training:
![](./images/shark_annot.png)

And this is the resulting Convpaint segmentation:
<video src=""https://github.com/user-attachments/assets/6a2be1fe-25cc-4af1-9f50-aab9bc4123d9""></video>

Check out the documentation or the paper for more usecases!

## API

You can now use the API in a fashion very similar to the napari plugin. The ConvpaintModel class combines a feature extractor and a classifier model, and holds all the parameters defining the model. Initialize a ConvpaintModel object, train its classifier and use it to segment an image:

```Python
cp_model = ConvpaintModel(""dino"") # alternatively use vgg, cellpose or gaussian
cp_model.train(image, annotations)
segmentation = cp_model.segment(image)
```

There are many other options, such as predicting all class probabilities (see below) and we will update the documentation and notebook examples soon. In the meantime feel free to test it yourself.

```Python
probas = cp_model.predict_probas(image)
```

## License

Distributed under the terms of the [BSD-3] license,
""napari-convpaint"" is free and open source software

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/guiwitz/napari-convpaint/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

## Authors

The idea behind this napari plugin was first developed by [Lucien Hinderling](https://hinderling.github.io) in the group of [Olivier Pertz](https://www.pertzlab.net/), at the Institute of Cell Biology, University of Bern. Pertz lab obtained a CZI napari plugin development grant with the title [""Democratizing Image Analysis with an Easy-to-Train Classifier""](https://chanzuckerberg.com/science/programs-resources/imaging/napari/democratizing-image-analysis-with-an-easy-to-train-classifier/) which supported the adaptation of the initial concept as a napari plugin called napari-convpaint. The plugin has been developed by [Guillaume Witz<sup>1</sup>](https://guiwitz.github.io/blog/about/), [Roman Schwob<sup>1,2</sup>](https://github.com/quasar1357) and Lucien Hinderling<sup>2</sup> with much appreciated assistance of [Benjamin GrÃ¤del<sup>2</sup>](https://x.com/benigraedel), [Maciej DobrzyÅski<sup>2</sup>](https://macdobry.net), Mykhailo Vladymyrov<sup>1</sup> and Ana StojiljkoviÄ<sup>1</sup>.

<sup>1</sup>[Data Science Lab](https://www.dsl.unibe.ch/), University of Bern \
<sup>2</sup>[Pertz Lab](https://www.pertzlab.net/), Institute of Cell Biology, University of Bern 

## Cite Convpaint

If you find Convpaint useful in your research, please consider citing our work. Please also cite any Feature Extractor you have used in Convpaint, such as [ilastik](https://github.com/ilastik/ilastik-napari), [cellpose](https://cellpose.readthedocs.io/en/latest/) or [DINOv2](https://github.com/facebookresearch/dinov2).

Convpaint:
```
@article {Hinderling2024,
	author = {Hinderling, Lucien and Witz, Guillaume and Schwob, Roman and StojiljkoviÄ, Ana and DobrzyÅski, Maciej and Vladymyrov, Mykhailo and Frei, JoÃ«l and GrÃ¤del, Benjamin and Frismantiene, Agne and Pertz, Olivier},
	title = {Convpaint - Interactive pixel classification using pretrained neural networks},
	elocation-id = {2024.09.12.610926},
	doi = {10.1101/2024.09.12.610926},
	journal = {bioRxiv},
	publisher = {Cold Spring Harbor Laboratory},
	year = {2024},
}
```
Suggested citations for feature extractors:
```
@article {Berg2019,
	author = {Berg, Stuart and Kutra, Dominik and Kroeger, Thorben and Straehle, Christoph N. and Kausler, Bernhard X. and Haubold, Carsten and Schiegg, Martin and Ales, Janez and Beier, Thorsten and Rudy, Markus and Eren, Kemal and Cervantes, Jaime I. and Xu, Buote and Beuttenmueller, Fynn and Wolny, Adrian and Zhang, Chong and Koethe, Ullrich and Hamprecht, Fred A. and Kreshuk, Anna},
	title = {ilastik: interactive machine learning for (bio)image analysis.},
	issn = {1548-7105},
	url = {https://doi.org/10.1038/s41592-019-0582-9},
	doi = {10.1038/s41592-019-0582-9},
	journal = {Nature Methods},
	publisher = {Springer Nature},
	year = {2019},
	journal = {Nature Methods},
}
```
```
@article {Stringer2021,
	author = {Stringer, Carsen and Wang, Tim and Michaelos, Michalis and Pachitariu Marius},
	title = {Cellpose: a generalist algorithm for cellular segmentation.},
	elocation-id = {s41592-020-01018-x},
	doi = {10.1038/s41592-020-01018-x},
	journal = {Nature Methods},
	publisher = {Springer Nature},
	year = {2021},
}
```
```
@article {oquab2024dinov2learningrobustvisual,
      title={DINOv2: Learning Robust Visual Features without Supervision}, 
      author={Maxime Oquab and TimothÃ©e Darcet and ThÃ©o Moutakanni and Huy Vo and Marc Szafraniec and Vasil Khalidov and Pierre Fernandez and Daniel Haziza and Francisco Massa and Alaaeldin El-Nouby and Mahmoud Assran and Nicolas Ballas and Wojciech Galuba and Russell Howes and Po-Yao Huang and Shang-Wen Li and Ishan Misra and Michael Rabbat and Vasu Sharma and Gabriel Synnaeve and Hu Xu and HervÃ© Jegou and Julien Mairal and Patrick Labatut and Armand Joulin and Piotr Bojanowski},
      year={2024},
      eprint={2304.07193},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2304.07193}
}

```
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Topic :: Scientific/Engineering :: Image Recognition', 'Topic :: Scientific/Engineering :: Artificial Intelligence', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/guiwitz/napari-convpaint/issues', 'Documentation, https://github.com/guiwitz/napari-convpaint#README.md', 'Source Code, https://github.com/guiwitz/napari-convpaint', 'User Support, https://github.com/guiwitz/napari-convpaint/issues']",,,napari-convpaint.make_qwidget,napari-convpaint.labelcell3d,,,
162,napari-cosmos-ts,napari-cosmos-ts,napari-cosmos-ts,0.3.6,2024-04-12,2024-11-13,Marcel Goldschen-Ohm,Marcel Goldschen-Ohm <goldschen-ohm@utexas.edu>,Unavailable,https://github.com/marcel-goldschen-ohm/napari-cosmos-ts,https://pypi.org/project/napari-cosmos-ts/,,,napari plugin for colocalization single-molecule spectroscopy (CoSMoS) time series (TS) analysis,>=3.10,"['numpy<2.1,>=2.0', 'qtpy>=2.4.1', 'pyqtgraph>=0.13.4', 'pystackreg>=0.2.7', 'pycpd>=2.0.0', 'qtawesome>=1.3.1', 'h5py>=3.11.0']","# napari-cosmos-ts
[napari](https://napari.org/stable/) plugin for colocalization single-molecule spectroscopy (CoSMoS) time series (TS) analysis.

![GitHub Tag](https://img.shields.io/github/v/tag/marcel-goldschen-ohm/napari-cosmos-ts?cacheSeconds=1)
![build-test](https://github.com/marcel-goldschen-ohm/napari-cosmos-ts/actions/workflows/build-test.yml/badge.svg)

![GitHub Release](https://img.shields.io/github/v/release/marcel-goldschen-ohm/napari-cosmos-ts?include_prereleases&cacheSeconds=1)
![publish](https://github.com/marcel-goldschen-ohm/napari-cosmos-ts/actions/workflows/publish.yml/badge.svg)

- [Install](#install)
- [Run](#run)
- [Documentation](#documentation)

## Install
If you are unfamiliar with how to create a python environment or pip install a package, see the [detailed installation instructions below](#install-for-beginners).

Requires [napari](https://github.com/napari/napari).
```shell
pip install ""napari[all]""
```
Install latest release version:
```shell
pip install napari-cosmos-ts
```
Or install latest development version:
```shell
pip install napari-cosmos-ts@git+https://github.com/marcel-goldschen-ohm/napari-cosmos-ts
```
To upgrade a previously installed version, simply add the `--upgrade` flag to the above install commands.

## Run
Launch the `napari` viewer. In a command shell or terminal *where you have activated the virtual environment where you installed napari-cosmos-ts* run the following command:
```shell
napari
```
Launch the `napari-cosmos-ts` plugin: From the napari viewer `Plugins menu` select `Colocalization Single-Molecule Time Series (napari-cosmos-ts)`. This should bring up the napari-cosmos-ts docked widget within the viewer.

## Documentation
:construction:

## Install for Beginners
1. Install the `conda` package manager. Simplest is to download [Miniconda](https://docs.conda.io/en/main/miniconda.html) and run the installer.
2. Create a virtual python environment named `napari-env` (or name it whatever you want) in which to install [napari](https://napari.org/stable/) and this plugin. In a command shell or terminal run the following command:
```shell
conda create --name napari-env python
```
3. Activate your virtual environment. *!!! Note you will have to do this every time you open a new command shell or terminal.* In a command shell or terminal run the following command:
```shell
conda activate napari-env
```
4. Install `napari` into your virtual environment. In a command shell or terminal *where you have activated your virtual environment* run the following command:
```shell
pip install ""napari[all]""
```
5. Install `napari-cosmos-ts` into your virtual environment. In a command shell or terminal *where you have activated your virtual environment* run the following command:
```shell
pip install napari-cosmos-ts
```
Or for the latest version of `napari-cosmos-ts`:
```shell
pip install napari-cosmos-ts@git+https://github.com/marcel-goldschen-ohm/napari-cosmos-ts
```
*!!! Remember, every time you open a new command shell or terminal you will need to activate the virtual environment where you installed napari-cosmos-ts before [running the app](#run).*
","['Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: MIT License', 'Framework :: napari', 'Programming Language :: Python :: 3 :: Only']","['homepage, https://github.com/marcel-goldschen-ohm/napari-cosmos-ts', 'repository, https://github.com/marcel-goldschen-ohm/napari-cosmos-ts']",,,napari-cosmos-ts.main_widget,,,,
163,napari-cryoet-data-portal,napari-cryoet-data-portal,CryoET Data Portal,0.5.0,2023-08-14,2024-11-25,Andy Sweet,andrewdsweet@gmail.com,MIT,https://github.com/chanzuckerberg/napari-cryoet-data-portal/issues,https://pypi.org/project/napari-cryoet-data-portal/,,https://github.com/chanzuckerberg/napari-cryoet-data-portal,"List, preview, and open data from the CZII CryoET Data Portal",>=3.8,"['cmap', 'cryoet_data_portal~=4.0', 'fsspec[http,s3]', 'npe2', 'numpy', 'napari>=0.4.19', 'napari_ome_zarr', 'ndjson', 'qtpy', 'superqt', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-mock; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-cryoet-data-portal

[![MIT License](https://img.shields.io/pypi/l/napari-cryoet-data-portal.svg?color=green)](https://github.com/chanzuckerberg/napari-cryoet-data-portal/raw/main/LICENSE)
[![Python package index](https://img.shields.io/pypi/v/napari-cryoet-data-portal.svg?color=green)](https://pypi.org/project/napari-cryoet-data-portal)
[![Supported Python versions](https://img.shields.io/pypi/pyversions/napari-cryoet-data-portal.svg?color=green)](https://python.org)
[![Test status](https://github.com/chanzuckerberg/napari-cryoet-data-portal/workflows/tests/badge.svg)](https://github.com/chanzuckerberg/napari-cryoet-data-portal/actions)
[![Code coverage](https://codecov.io/gh/chanzuckerberg/napari-cryoet-data-portal/branch/main/graph/badge.svg)](https://codecov.io/gh/chanzuckerberg/napari-cryoet-data-portal)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-cryoet-data-portal)](https://napari-hub.org/plugins/napari-cryoet-data-portal)

List and open tomograms from the CZ Imaging Institute's [CryoET Data Portal] in [napari].

![Plugin showing tomogram TS_043](https://github.com/chanzuckerberg/napari-cryoet-data-portal/assets/2608297/61427a1f-df88-4e12-a680-32b8a10b6e6b)

## Installation

You can install the latest stable version using [pip]:

    pip install napari-cryoet-data-portal

You will also need to install napari separately as a Python package in the same environment.
One way to do that with Qt included is to run:

    pip install ""napari[all]""

but more generally you should follow the [latest napari installation instructions].

## Usage

See the following video for a demonstration of basic usage of the plugin.

https://github.com/chanzuckerberg/napari-cryoet-data-portal/assets/2608297/51207e08-68af-446a-87bb-3de9c6756d35

Click the *Connect* button to establish a connection to the data portal.

![Connect button and URL to the portal](https://github.com/chanzuckerberg/napari-cryoet-data-portal/assets/2608297/acefbbe8-855a-490b-be44-45a003069b08)

You can optionally query a subset of datasets, runs, voxel spacings, or tomograms using their corresponding IDs.
This can speed up the listing process as the portal grows.
To do so, select an ID type in the associated drop-down box from this panel, then enter the IDs of interest separated by commas in the text box next to it.
For example, if you only want to list datasets 10000 and 10001, select *Dataset IDs* from the drop-down box and enter the text *10000,10001* in the text box.
By default, all datasets are listed.

After connecting to the portal, datasets are added below as they are found.

![Datasets and tomograms in the portal shown as an interactive tree](https://github.com/chanzuckerberg/napari-cryoet-data-portal/assets/2608297/7af78e00-bbba-4c5b-a286-fb865ca8cff0)

Datasets and tomograms can be filtered by specifying a regular expression pattern.

![Datasets and tomograms filtered by the text 26, so that only two are shown](https://github.com/chanzuckerberg/napari-cryoet-data-portal/assets/2608297/96a57f4c-290e-4932-aa2d-95d13edd2d8c)

Selecting a dataset displays its metadata, which can be similarly explored and filtered.

![Metadata of dataset 10000 shown as an interactive tree of keys and values](https://github.com/chanzuckerberg/napari-cryoet-data-portal/assets/2608297/b230720a-9083-4e35-a9db-44071c979fcc)

Selecting a tomogram displays its metadata and also opens the lowest resolution tomogram and all of its associated point annotations in the napari viewer.

![Metadata of tomogram TS_026 shown as an interactive tree of keys and values](https://github.com/chanzuckerberg/napari-cryoet-data-portal/assets/2608297/386b3116-ba16-4f5d-840d-4eafa3dc62b0)

Higher resolution tomograms can be loaded instead by selecting a different resolution and clicking the *Open* button.

![Open button and resolution selector showing high resolution](https://github.com/chanzuckerberg/napari-cryoet-data-portal/assets/2608297/d84c93b2-e6e7-43ee-aeb9-acd1a314637e)

In this case, napari only loads the data that needs to be displayed in the canvas.
While this can reduce the amount of data loaded, it may also cause performance problems when initially opening and exploring the data.
By default, opening a new tomogram clears all the existing layers in napari.
If instead you want to keep those layers, uncheck the associated check-box in this panel.

In general, finding and fetching data from the portal can take a long time.
All plugin operations that fetch data from the portal try to run concurrently in order to keep interaction with napari and the plugin as responsive as possible.
These operations can also be cancelled by clicking the *Cancel* button.

![Progress bar with loading status and cancel button](https://github.com/chanzuckerberg/napari-cryoet-data-portal/assets/2608297/2dc316ae-5231-4159-bc93-785548dbf6a5)

## Contributing

This is still in early development, but contributions and ideas are welcome!
Don't hesitate to [open an issue] or [open a pull request] to help improve this plugin.

To setup a development environment, fork this repository, clone your fork, change into its top level directory and run:

    pip install -e "".[testing]""

This project adheres to the [Contributor Covenant code of conduct].
By participating, you are expected to uphold this code.
Please report unacceptable behavior to opensource@chanzuckerberg.com.

## Security

If you believe you have found a security issue, please see our [security policy] on how to report it.

## License

Distributed under the terms of the [MIT] license, ""napari-cryoet-data-portal"" is free and open source software. See the [license file] for more details.

## Acknowledgements

This plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


[napari]: https://github.com/napari/napari
[@napari]: https://github.com/napari
[CryoET Data Portal]: https://chanzuckerberg.github.io/cryoet-data-portal
[pip]: https://pypi.org/project/pip/
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[MIT]: http://opensource.org/licenses/MIT
[security policy]: /SECURITY.md
[license file]: /LICENSE
[Contributor Covenant code of conduct]: https://github.com/chanzuckerberg/.github/tree/master/CODE_OF_CONDUCT.md
[open an issue]: https://github.com/chanzuckerberg/napari-cryoet-data-portal/issues
[open a pull request]: https://github.com/chanzuckerberg/napari-cryoet-data-portal/pulls
[latest napari installation instructions]: https://napari.org/stable/tutorials/fundamentals/installation.html#install-as-python-package-recommended
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/chanzuckerberg/napari-cryoet-data-portal/issues', 'Documentation, https://github.com/chanzuckerberg/napari-cryoet-data-portal#README.md', 'Source Code, https://github.com/chanzuckerberg/napari-cryoet-data-portal', 'User Support, https://github.com/chanzuckerberg/napari-cryoet-data-portal/issues']",napari-cryoet-data-portal.tomogram_ome_zarr_reader,,napari-cryoet-data-portal.DataPortalWidget,napari-cryoet-data-portal.tomogram_10000_ts_026,['*.zarr'],,
164,napari-cryofibsem-imgproc,napari-cryofibsem-imgproc,Cryo-FIB/SEM Image Stacks Post-Processing,0.0.3,2024-09-20,2024-11-19,Shaina V. To,shaina.to@radboudumc.nl,"Apache License
               ...",https://github.com/EMCRUMC/napari-cryofibsem-imgproc/issues,https://pypi.org/project/napari-cryofibsem-imgproc/,,,"A napari plugin for artifact removal, noise reduction, contrast enhancement and stack brightness correction of Cryo-FIB/SEM image stacks.",>=3.10,"['numpy==1.26.4', 'magicgui', 'scikit-image==0.24.0', 'PyWavelets==1.6.0', 'opencv-python==4.10.0.84', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-cryofibsem-imgproc

[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-cryofibsem-imgproc.svg?color=green)](https://github.com/EMCRUMC/napari-cryofibsem-imgproc/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-cryofibsem-imgproc.svg?color=green)](https://pypi.org/project/napari-cryofibsem-imgproc)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-cryofibsem-imgproc.svg?color=green)](https://python.org)
[![tests](https://github.com/EMCRUMC/napari-cryofibsem-imgproc/workflows/tests/badge.svg)](https://github.com/EMCRUMC/napari-cryofibsem-imgproc/actions)
[![codecov](https://codecov.io/gh/EMCRUMC/napari-cryofibsem-imgproc/branch/main/graph/badge.svg)](https://codecov.io/gh/EMCRUMC/napari-cryofibsem-imgproc)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-cryofibsem-imgproc)](https://napari-hub.org/plugins/napari-cryofibsem-imgproc)

A napari plugin for artifact removal, noise reduction, contrast enhancement and stack brightness correction of Cryo-FIB/SEM image stacks.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

It is recommended to create a fresh [conda] environment with Python 3.12 and napari:

    conda create -n imgproc-env -c conda-forge python=3.12.0 napari pyqt

You can install `napari-cryofibsem-imgproc` via [pip]:

    pip install napari-cryofibsem-imgproc

To install latest development version :

    pip install git+https://github.com/EMCRUMC/napari-cryofibsem-imgproc.git

## Usage 
Cryo-FIB/SEM Image Processing offers 5 functions: curtaining artifact removal, charging artifact removal, noise reduction, contrast enhancement, and stack brightness correction. Using the widgets, the user can choose the input image or stack, set the function parameters, and call the function. These functions can be used in sequence with each other or individually, depending on the image processing requirements. 

![widget.png](widget.png)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-cryofibsem-imgproc"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/EMCRUMC/napari-cryofibsem-imgproc/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/EMCRUMC/napari-cryofibsem-imgproc/issues', 'Documentation, https://github.com/EMCRUMC/napari-cryofibsem-imgproc#README.md', 'Source Code, https://github.com/EMCRUMC/napari-cryofibsem-imgproc', 'User Support, https://github.com/EMCRUMC/napari-cryofibsem-imgproc/issues']",,,napari-cryofibsem-imgproc.make_decurtain_widget,napari-cryofibsem-imgproc.make_sample_data,,,
165,napari-ctc-io,napari-ctc-io,Read CTC format,0.2.1,2024-06-04,2024-11-13,Benjamin Gallusser,benjamin.gallusser@epfl.ch,BSD-3-Clause,https://github.com/bentaculum/napari-ctc-io/issues,https://pypi.org/project/napari-ctc-io/,,https://github.com/bentaculum/napari-ctc-io,Drag and drop/write tracks from/to the Cell Tracking Challenge (CTC) format.,>=3.9,"['napari', 'numpy', 'scikit-image', 'tifffile', 'pandas', 'imagecodecs', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""']","# napari-ctc-io

[![PyPI](https://img.shields.io/pypi/v/napari-ctc-io.svg?color=green)](https://pypi.org/project/napari-ctc-io)
[![tests](https://github.com/bentaculum/napari-ctc-io/workflows/tests/badge.svg)](https://github.com/bentaculum/napari-ctc-io/actions)
[![codecov](https://codecov.io/gh/bentaculum/napari-ctc-io/branch/main/graph/badge.svg)](https://codecov.io/gh/bentaculum/napari-ctc-io)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-ctc-io)](https://napari-hub.org/plugins/napari-ctc-io)

- Drag and drop annotations/results in the [Cell Tracking Challenge (CTC) format](https://celltrackingchallenge.net) into napari.

  Works for `TRA`, `RES`, etc. folders, which contain a time sequence of segmentations in `tiff` format, and a corresponding tracklet file `*.txt`.
- Write tracked cells (`labels` layer & corresponding `tracks` layer) to CTC format (see usage below).


https://github.com/bentaculum/napari-ctc-io/assets/8866751/197c9ea2-4115-4829-851a-4b77eb843bf2


## Installation

You can install `napari-ctc-io` via [pip]:

    pip install napari-ctc-io



To install latest development version :


    pip install git+https://github.com/bentaculum/napari-ctc-io.git

## Usage of writer in widget

```python
def _save(self, event=None):
    pm = npe2.PluginManager.instance()

    outdir = ""TRA""
    writer_contrib = pm.get_writer(
        outdir,
        [""labels"", ""tracks""],
        ""napari-ctc-io"",
    )[0]

    save_layers(
        path=outdir,
        layers=[
            self._viewer.layers[""masks_tracked""],
            self._viewer.layers[""tracks""],
        ],
        plugin=""napari-ctc-io"",
        _writer=writer_contrib,
    )
```


## Contributing

Contributions are very welcome. Tests can be run with [tox].

## License

Distributed under the terms of the [BSD-3] license,
`napari-ctc-io` is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/bentaculum/napari-ctc-io/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/bentaculum/napari-ctc-io/issues', 'Documentation, https://github.com/bentaculum/napari-ctc-io#README.md', 'Source Code, https://github.com/bentaculum/napari-ctc-io', 'User Support, https://github.com/bentaculum/napari-ctc-io/issues']",napari-ctc-io.read_ctc,napari-ctc-io.write_multiple,,,"['TRA', '*RES']",,
166,napari-correct-drift,napari-correct-drift,Napari Correct Drift,0.4.0,2023-04-26,2023-11-06,Christoph Sommer,christoph.sommer@ist.ac.at,BSD-3-Clause,https://github.com/sommerc/napari-correct-drift/issues,https://pypi.org/project/napari-correct-drift/,,https://github.com/sommerc/napari-correct-drift,Drift correction 2D/3D for Napari similar to Fijis Correct 3D drift macro,>=3.8,"['napari', 'numpy', 'qtpy', 'pandas', 'scikit-image', 'scipy', 'dask', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-correct-drift

[![License BSD-3](https://img.shields.io/pypi/l/napari-correct-drift.svg?color=green)](https://github.com/sommerc/napari-correct-drift/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-correct-drift.svg?color=green)](https://pypi.org/project/napari-correct-drift)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-correct-drift.svg?color=green)](https://python.org)
[![tests](https://github.com/sommerc/napari-correct-drift/workflows/tests/badge.svg)](https://github.com/sommerc/napari-correct-drift/actions)
[![codecov](https://codecov.io/gh/sommerc/napari-correct-drift/branch/main/graph/badge.svg)](https://codecov.io/gh/sommerc/napari-correct-drift)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-correct-drift)](https://napari-hub.org/plugins/napari-correct-drift)
[![Documentation Status](https://readthedocs.org/projects/napari-correct-drift/badge/?version=latest)](https://napari-correct-drift.readthedocs.io/en/latest/?badge=latest)

Napari-correct-drift brings the functionality of Fijiâs popular Correct-3D-drift macro to Napari for flexible and efficient correction of stage and sample drift common in time-lapse microscopy.

Napari-correct-drift supports drift correction for 2D/3D multi-channel data.

----------------------------------
## Example

https://user-images.githubusercontent.com/895863/235100349-83379350-06a5-4fe7-9323-f3e5771cca2e.mp4


## Test data
Napari-correct-drift contains synthetic sample data. To test it on real data download an example Arabidopsis growing [root tip](https://seafile.ist.ac.at/f/b05362d4f358430c8c59/?dl=1) file.

## Installation

You can install `napari-correct-drift` via [pip]:

    pip install napari-correct-drift

To install latest development version :

    pip install git+https://github.com/sommerc/napari-correct-drift.git

## Roadmap

- [x] Basic CorrectDrift interface
- [x] Synthetic test data
- [x] Unit tests
- [x] 2D/3D multi-channel support
- [x] ROI support (rectangles)
- [x] Saving and loading of drift tables
- [x] Outlier handling
- [x] Sphinx documentation
- [x] How-tos
- [x] Tutorials and Guides

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-correct-drift"" is free and open source software

### Acknowledgment
This project has been made possible in part by grant number NP2-0000000051 from the napari Plugin Foundations Grants (Cycle 2).
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/sommerc/napari-correct-drift/issues', 'Documentation, https://github.com/sommerc/napari-correct-drift#README.md', 'Source Code, https://github.com/sommerc/napari-correct-drift', 'User Support, https://github.com/sommerc/napari-correct-drift/issues']",,,napari-correct-drift.make_qwidget,napari-correct-drift.sample_2d,,,
167,napari-cryofibsem-monitor,napari-cryofibsem-monitor,napari-cryofibsem-monitor,0.0.3,2021-11-05,2022-11-12,Johannes Elferich,jojotux123@hotmail.com,MIT,https://github.com/jojoelfe/napari-cryofibsem-monitor/issues,https://pypi.org/project/napari-cryofibsem-monitor/,,https://github.com/jojoelfe/napari-cryofibsem-monitor,A plugin to monitor the creation of lamella using AutoTEM on a TFS Acquilos instrument,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'tifffile', 'imreg-dft', 'matplotlib']","# napari-cryofibsem-monitor

[![License](https://img.shields.io/pypi/l/napari-cryofibsem-monitor.svg?color=green)](https://github.com/jojoelfe/napari-cryofibsem-monitor/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-cryofibsem-monitor.svg?color=green)](https://pypi.org/project/napari-cryofibsem-monitor)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-cryofibsem-monitor.svg?color=green)](https://python.org)
[![tests](https://github.com/jojoelfe/napari-cryofibsem-monitor/workflows/tests/badge.svg)](https://github.com/jojoelfe/napari-cryofibsem-monitor/actions)
[![codecov](https://codecov.io/gh/jojoelfe/napari-cryofibsem-monitor/branch/main/graph/badge.svg)](https://codecov.io/gh/jojoelfe/napari-cryofibsem-monitor)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-cryofibsem-monitor)](https://napari-hub.org/plugins/napari-cryofibsem-monitor)

A plugin to monitor the creation of lamella using AutoTEM on a TFS Acquilos instrument


https://user-images.githubusercontent.com/6081039/201448228-fdd8b429-8ff6-4934-ad58-e80fbfcbaef0.mp4

## Changelog

- **v0.0.3** 
    - Update data during milling
    - Align images to keep lamella in the center
    - Monitor thickness

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-cryofibsem-monitor` via [pip]:

    pip install napari-cryofibsem-monitor



To install latest development version :

    pip install git+https://github.com/jojoelfe/napari-cryofibsem-monitor.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-cryofibsem-monitor"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/jojoelfe/napari-cryofibsem-monitor/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/jojoelfe/napari-cryofibsem-monitor/issues', 'Documentation, https://github.com/jojoelfe/napari-cryofibsem-monitor#README.md', 'Source Code, https://github.com/jojoelfe/napari-cryofibsem-monitor', 'User Support, https://github.com/jojoelfe/napari-cryofibsem-monitor/issues']",,,napari-cryofibsem-monitor.ExampleQWidget,,,,
168,napari-cupy-image-processing,napari-cupy-image-processing,napari-cupy-image-processing,0.4.1,2021-10-22,2023-08-17,Robert Haase,robert.haase@tu-dresden.de,MIT,https://github.com/haesleinhuepf/napari-cupy-image-processing/issues,https://pypi.org/project/napari-cupy-image-processing/,,https://github.com/haesleinhuepf/napari-cupy-image-processing,GPU-accelerated image processing using CUDA,>=3.7,"['napari-plugin-engine >=0.1.4', 'numpy', 'toolz', 'cupy', 'napari-tools-menu', 'scikit-image', 'napari-time-slicer >=0.4.8', 'napari-skimage-regionprops', 'napari-assistant', 'stackview >=0.3.2']","# napari-cupy-image-processing

[![License](https://img.shields.io/pypi/l/napari-cupy-image-processing.svg?color=green)](https://github.com/haesleinhuepf/napari-cupy-image-processing/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-cupy-image-processing.svg?color=green)](https://pypi.org/project/napari-cupy-image-processing)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-cupy-image-processing.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-cupy-image-processing/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-cupy-image-processing/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-cupy-image-processing/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-cupy-image-processing)
[![Development Status](https://img.shields.io/pypi/status/napari-cupy-image-processing.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-cupy-image-processing)](https://napari-hub.org/plugins/napari-cupy-image-processing)


GPU-accelerated image processing using [cupy](https://cupy.dev) and [CUDA](https://en.wikipedia.org/wiki/CUDA)

## Usage

This napari plugin adds some menu entries to the Tools menu. You can recognize them with their suffix `(n-cupy)` in brackets.
Furthermore, it can be used from the [napari-assistant](https://www.napari-hub.org/plugins/napari-assistant) graphical user interface. 
Therefore, just click the menu `Tools > Utilities > Assistant (na)` or run `naparia` from the command line.

![img.png](https://github.com/haesleinhuepf/napari-cupy-image-processing/raw/main/docs/screenshot-with-tools-menu.png)

You can also call operations from python, e.g. as shown in this [demo notebook](https://github.com/haesleinhuepf/napari-cupy-image-processing/raw/main/docs/demo.ipynb).

## Installation

You can install `napari-cupy-image-processing` using conda:

    mamba install -c conda-forge cupy cudatoolkit=11.2 napari-cupy-image-processing

## Troubleshooting installation

In case of issues, follow the [instructions for installing cupy](https://docs.cupy.dev/en/stable/install.html#installing-cupy-from-conda-forge). 

A more detailed example for installation (change 11.2 to your desired CUDA version):
```
mamba create --name cupy_p39 python=3.9 
conda activate cupy_p39
```
And then:
```
mamba install -c conda-forge cupy cudatoolkit=11.2 napari-cupy-image-processing
```

## Contributing

Contributions are very welcome. Adding [cupy ndimage](https://docs.cupy.dev/en/stable/reference/ndimage.html) functions is quite easy as you can see in the 
[implementation of the current operations](https://github.com/haesleinhuepf/napari-cupy-image-processing/blob/main/napari_cupy_image_processing/_cupy_image_processing.py#L48). 
If you need another function in napari, just send a PR. Please make sure the tests pass locally before submitting a PR.

```
pip install pytest-cov pytest-qt
pytest --cov=napari_cupy_image_processing
```

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## License

Distributed under the terms of the [MIT] license,
""napari-cupy-image-processing"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-cupy-image-processing/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-cupy-image-processing/issues', 'Documentation, https://github.com/haesleinhuepf/napari-cupy-image-processing#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-cupy-image-processing', 'User Support, https://github.com/haesleinhuepf/napari-cupy-image-processing/issues']",,,napari-cupy-image-processing.napari_experimental_provide_function,,,,
169,napari-cursor-tracker,napari-cursor-tracker,Cursor tracker,0.1.3,2023-10-05,2023-10-25,Florian Aymanns,florian.aymanns@epfl.ch,BSD-3-Clause,https://github.com/faymanns/napari-cursor-tracker,https://pypi.org/project/napari-cursor-tracker/,,https://github.com/faymanns/napari-cursor-tracker,Plugin for easy manual annotation/tracking of 3D or 2D + t dataset by following the cursor.,>=3.8,"['numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-cursor-tracker

[![License BSD-3](https://img.shields.io/pypi/l/napari-cursor-tracker.svg?color=green)](https://github.com/faymanns/napari-cursor-tracker/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-cursor-tracker.svg?color=green)](https://pypi.org/project/napari-cursor-tracker)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-cursor-tracker.svg?color=green)](https://python.org)
[![tests](https://github.com/faymanns/napari-cursor-tracker/workflows/tests/badge.svg)](https://github.com/faymanns/napari-cursor-tracker/actions)
[![codecov](https://codecov.io/gh/faymanns/napari-cursor-tracker/branch/main/graph/badge.svg)](https://codecov.io/gh/faymanns/napari-cursor-tracker)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-cursor-tracker)](https://napari-hub.org/plugins/napari-cursor-tracker)

Plugin for easy manual annotation/tracking of 3D or 2D + t dataset by following the cursor.

----------------------------------

<!--
This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-cursor-tracker` via [pip]:

    pip install napari-cursor-tracker

## Getting Started with napari-cursor-tracker

Welcome to `napari-cursor-tracker`, a tool that simplifies the annotation of points in stacks of images by tracking your cursor's position. This documentation will guide you through the process of setting up and using this plugin effectively.

### Points Layer Setup

Before you can start tracking, you need to create a points layer, which will store the positions of your cursor for each image in the stack. Here's how to set it up:

1. **Choose a Reference Image:** Start by selecting a ""Reference image"" from your image stack. The number of frames or slices in the reference image determines how many points your new layer will have (one per frame/slice).

2. **Specify Point Name:** Assign a name to the tracked point. This name will also serve as the name for the new layer. This step is particularly useful when tracking multiple points.

3. **Create the Layer:** Click on ""Add new layer"" to create the points layer. Initially, all points will be located at the origin (0, 0, 0), but their positions will be updated as you start tracking.

### Tracking Your Cursor

Now that you have set up the points layer, you can start tracking your cursor's position. Follow these steps:

1. **Select the Active Layer:** Choose the points layer where you want to save the tracking results as the ""Active layer.""

2. **Initiate Tracking:** Begin tracking your cursor's position by pressing the 't' key on your keyboard. To stop tracking, press 't' again. If the ""Auto play when tracking is started"" option is enabled, playback will start automatically when you press 't'. Alternatively, you can manually scroll through the images, and your cursor's position will be saved whenever the slice/frame index changes.

3. **Customize Playback:** To facilitate or expedite tracking, you can adjust playback parameters as needed.

### Tracking Multiple Points

If you need to track multiple points of interest, you can follow these steps:

1. **Create Individual Layers:** Create a separate points layer for each point you want to track.

2. **Select Active Layer:** Use the ""Active layer"" dropdown menu to select the specific points layer you want to work with.

3. **Start Tracking:** Begin tracking the selected point following the previously mentioned tracking process.

### Saving Your Results

The results from your tracking sessions can be saved as CSV files. Any points that were not tracked will be marked at the origin point (0, 0, 0) in the saved file.

With these guidelines, you should be well-prepared to efficiently annotate points in your image stacks using `napari-cursor-tracker`. Happy tracking!


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-cursor-tracker"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-cursor-tracker.make_qwidget,napari-cursor-tracker.make_sample_data,,,
170,napari-curviewer,napari-curviewer,Curviewer,0.1.0,2023-12-25,2023-12-25,Romain Fernandez,romain.fernandez@cirad.fr,LGPL-3.0-only,https://github.com/Rocsg/napari-curviewer/issues,https://pypi.org/project/napari-curviewer/,,https://github.com/Rocsg/napari-curviewer,A plugin to unroll organs along their curved central line,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'vedo', 'vtk', 'scipy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-curviewer

[![License GNU LGPL v3.0](https://img.shields.io/pypi/l/napari-curviewer.svg?color=green)](https://github.com/Rocsg/napari-curviewer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-curviewer.svg?color=green)](https://pypi.org/project/napari-curviewer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-curviewer.svg?color=green)](https://python.org)
[![tests](https://github.com/Rocsg/napari-curviewer/workflows/tests/badge.svg)](https://github.com/Rocsg/napari-curviewer/actions)
[![codecov](https://codecov.io/gh/Rocsg/napari-curviewer/branch/main/graph/badge.svg)](https://codecov.io/gh/Rocsg/napari-curviewer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-curviewer)](https://napari-hub.org/plugins/napari-curviewer)

A plugin to unroll organs along their curved central line

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-curviewer` via [pip]:

    pip install napari-curviewer



To install latest development version :

    pip install git+https://github.com/Rocsg/napari-curviewer.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU LGPL v3.0] license,
""napari-curviewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/Rocsg/napari-curviewer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU Lesser General Public License v3 (LGPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/Rocsg/napari-curviewer/issues', 'Documentation, https://github.com/Rocsg/napari-curviewer#README.md', 'Source Code, https://github.com/Rocsg/napari-curviewer', 'User Support, https://github.com/Rocsg/napari-curviewer/issues']",napari-curviewer.get_reader,napari-curviewer.write_multiple,napari-curviewer.make_container_widget,napari-curviewer.make_sample_data,['*.npy'],,['.npy']
171,napari-curtain,napari-curtain,napari-curtain,0.1.1,2021-11-07,2022-01-01,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-curtain/issues,https://pypi.org/project/napari-curtain/,,https://github.com/haesleinhuepf/napari-curtain,View one image over another as curtain,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari-tools-menu']","# napari-curtain

[![License](https://img.shields.io/pypi/l/napari-curtain.svg?color=green)](https://github.com/haesleinhuepf/napari-curtain/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-curtain.svg?color=green)](https://pypi.org/project/napari-curtain)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-curtain.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-curtain/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-curtain/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-curtain/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-curtain)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-curtain)](https://napari-hub.org/plugins/napari-curtain)

View one image over another as curtain

![](https://github.com/haesleinhuepf/napari-curtain/raw/main/docs/curtain_screencast.gif)

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Usage

You find the `Curtain` plugin in the menu `Tools > Visualization > Curtain`. Move the position of the slider left/right 
as shown in the video above. In case one image is much bright than the other, you can modify the `factors` above the 
slider until visualization pleases.

## Installation

You can install `napari-curtain` via [pip]:

    pip install napari-curtain


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-curtain"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-curtain/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-curtain/issues', 'Documentation, https://github.com/haesleinhuepf/napari-curtain#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-curtain', 'User Support, https://github.com/haesleinhuepf/napari-curtain/issues']",,,napari-curtain.curtain,,,,
172,napari-czi-reader,napari-czi-reader,napari-czi-reader,1.2.0,2025-05-27,2025-05-30,Markus L. Bille,github+markus@bille.dk,BSD-3-Clause,https://github.com/MaxusTheOne/napari-czi-reader,https://pypi.org/project/napari-czi-reader/,,https://github.com/MaxusTheOne/napari-czi-reader,A Czi reader plugin for napari,>=3.9,"['aicsimageio', 'aicspylibczi', 'pint', 'xmltodict', 'pytest; extra == ""test""', 'pytest-cov; extra == ""test""', 'pytest-qt; extra == ""test""', 'codecov; extra == ""test""', 'napari[all]; extra == ""dev""', 'build; extra == ""dev""', 'twine; extra == ""dev""', 'pytest; extra == ""dev""', 'pytest-cov; extra == ""dev""', 'pytest-qt; extra == ""dev""', 'codecov; extra == ""dev""']","
Package for reading .czi into napari.

Split from https://github.com/MaxusTheOne/napari-pitcount-cfim

Tasks:
- [ ] Add config
- [ ] Fix bioformats crashing this reader, even though it is not used
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python']",,napari-czi-reader.napari_czi_reader.read_czi_to_napari,,,,['*.czi'],,
173,napari-czann-segment,napari-czann-segment,CZANN Segmentation,0.0.18,2022-07-11,2023-09-22,Sebastian Rhode,sebrhode@gmail.com,BSD-3-Clause,https://github.com/sebi06/napari-czann-segment/issues,https://pypi.org/project/napari-czann-segment/,,https://github.com/sebi06/napari-czann-segment,Semantic Segmentation using Deep Learning ONNX models packaged as *.czann files,>=3.9,"['numpy', 'magicgui', 'qtpy', 'napari', 'cztile', 'czmodel[pytorch] >=5', 'onnxruntime-gpu', 'aicsimageio', 'pytest', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-czann-segment

[![License](https://img.shields.io/pypi/l/napari-czann-segment.svg?color=green)](https://github.com/sebi06/napari-czann-segment/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-czann-segment.svg?color=green)](https://pypi.org/project/napari-czann-segment)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-czann-segment.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-czann-segment)](https://napari-hub.org/plugins/napari-czann-segment)

Semantic Segmentation of multidimensional images using Deep Learning ONNX models packaged as *.czann files.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

![Train on APEER and use model in Napari](https://github.com/sebi06/napari-czann-segment/raw/main/readme_images/Train_APEER_run_Napari_CZANN_no_highlights_small.gif)

## Installation

Before installing, please setup a conda environment. If you have never worked with conda environments, go through [this tutorial](https://biapol.github.io/blog/johannes_mueller/anaconda_getting_started/) first.

You can then install `napari-czann-segment` via [pip]:

    pip install napari-czann-segment

## What does the plugin do

The plugin allows you to:

- Use a *.czann file containing the Deep Neural Network (ONNX) for semantic segmentation and metadata
- Segmentation will be applied per 2D plane for all dimensions
- Processing larger multidimensional images it uses the [cztile] package to chunk the individual 2d arrays using a specific overlap.
- multidimensional images will be processed plane-by-plane

## What does the plugin NOT do

**Before one can actually use a model it needs to be trained, which is NOT done by this plugin**.

There are two main ways hwo such a model can be created:

- Train the segmentation model fully automated on [APEER] and download the *.czann file
- Train your model in a Jupyter notebook etc. and package it using the [czmodel] python package as an *.czann

## Using this plugin

### Sample Data

A test image and a *.czann model file can be downloaded [here](https://github.com/sebi06/napari-czann-segment/tree/main/src/napari_czann_segment/_data).

- `PGC_20X.ome.tiff` --> use `PGC_20X_nucleus_detector.czann` to segment

In order to use this plugin the user has to do the following things:

- Open the image using ""File - Open Files(s)"" (requires [napari-aicsimageio] plugin).
- Click **napari-czann-segment: Segment with CZANN model** in the ""Plugins"" menu.
- **Select a czann file** to use the model for segmentation.
- metadata of the model will be shown (see example below)

| Parameter    | Value                                        | Explanation                                             |
| :----------- | :------------------------------------------- | ------------------------------------------------------- |
| model_type   | ModelType.SINGLE_CLASS_SEMANTIC_SEGMENTATION | see: [czmodel] for details                              |
| input_shape  | [1024, 1024, 1]                              | tile dimensions of model input                          |
| output_shape | [1024, 1024, 3]                              | tile dimensions of model output                         |
| model_id     | ba32bc6d-6bc9-4774-8b47-20646c7cb838         | unique GUID for that model                              |
| min_overlap  | [128, 128]                                   | tile overlap used during training (for this model)      |
| classes      | ['background', 'grains', 'inclusions']       | available classes                                       |
| model_name   | APEER-trained model                          | name of the model                                       |

![Napari - Image loaded and czann selected](https://github.com/sebi06/napari-czann-segment/raw/main/readme_images/napari_czann1.png)

- Adjust the **minimum overlap** for the tiling (optional, see [cztile] for details).
- Select the **layer** to be segmented.
- Toggle **Use GPU for inference** checkbox to enable / disable using a GPU (Nvidia) for the segmentation (experimental feature).
- Press **Segment Selected Image Layer** to run the segmentation.

![Napari - Image successfully segmented](https://github.com/sebi06/napari-czann-segment/raw/main/readme_images/napari_czann3.png)

A successful is obviously only the starting point for further image analysis steps to extract the desired numbers from the segmented image.
Another example is shown below demonstrating a simple ""Grain Size Analysis"" using a deep-learning model trained on [APEER] used in [napari]

![Napari - Simple Grain Size Analysis](https://github.com/sebi06/napari-czann-segment/raw/main/readme_images/grainsize_czann_napari.png)

### Remarks

> **IMPORTANT**: Currently the plugin only supports using models trained on a **single channel** image. Therefore, make sure that during the training on [APEER] or somewhere else the correct inputs images are used.
> It is quite simple to train a single RGB image, which actually has three channels, load this image in [napari] and notice only then that the model will not work, because the image will 3 channels inside [napari].

- Only the CPU will be used for the inference using the ONNX runtime for the [ONNX-CPU] runtime
- GPUs are supported but require the [ONNX-GPU] runtime and the respective CUDA libraries.
- Please check the [YAML](env_napari_czann_segment.yml) for an example environment with GPU support.
- See also [pytorch] for instruction on how to install pytorch

## For developers

- **Please clone this repository first using your favorite tool.**

- **Ideally one creates a new [conda] environment or use an existing environment that already contains [Napari].**

Feel free to create a new environment using the [YAML](env_napari_czann_segment.yml) file at your own risk:

    cd the-github-repo-with-YAML-file
    conda env create --file conda_env_napari_czann_segment.yml
    conda activate napari_czmodel

- **Install the plugin locally**

Please run the following command:

    pip install -e .

To install latest development version:

    pip install git+https://github.com/sebi06/napari_czann_segment.git

## Contributing

Contributions and Feedback are very welcome.

## License

Distributed under the terms of the [BSD-3] license,
""napari-czann-segment"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/sebi06/napari-czann-segment/issues
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[czmodel]: https://pypi.org/project/czmodel/
[cztile]: https://pypi.org/project/cztile/
[APEER]: https://www.apeer.com
[napari-aicsimageio]: https://github.com/AllenCellModeling/napari-aicsimageio
[ONNX-GPU]: https://pypi.org/project/onnxruntime-gpu/
[ONNX-CPU]: https://pypi.org/project/onnxruntime/
[conda]: https://docs.conda.io/projects/conda/en/latest/user-guide/getting-started.html
[pytorch]: https://pytorch.org/get-started/locally
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: BSD License', 'Operating System :: Unix', 'Operating System :: Microsoft :: Windows', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/sebi06/napari-czann-segment/issues', 'Documentation, https://github.com/sebi06/napari-czann-segment#README.md', 'Source Code, https://github.com/sebi06/napari-czann-segment', 'User Support, https://github.com/sebi06/napari-czann-segment/issues']",,,napari-czann-segment.get_czann_widget,,,,
174,napari-czifile2,napari-czifile2,napari-czifile2,0.2.7,2021-02-02,2022-06-01,Jonas Windhager,jonas.windhager@uzh.ch,MIT,https://github.com/BodenmillerGroup/napari-czifile2/issues,https://pypi.org/project/napari-czifile2/,,https://github.com/BodenmillerGroup/napari-czifile2,Carl Zeiss Image (.czi) file support for napari,>=3.8,"['czifile', 'imagecodecs', 'numpy', 'tifffile']","# napari-czifile2

<a href=""https://pypi.org/project/napari-czifile2/"">
    <img src=""https://img.shields.io/pypi/v/napari-czifile2"" alt=""PyPI"" />
</a>
<a href=""https://github.com/BodenmillerGroup/napari-czifile2/blob/main/LICENSE.md"">
    <img src=""https://img.shields.io/pypi/l/napari-czifile2"" alt=""License"" />
</a>
<a href=""https://www.python.org/"">
    <img src=""https://img.shields.io/pypi/pyversions/napari-czifile2"" alt=""Python"" />
</a>
<a href=""https://github.com/BodenmillerGroup/napari-czifile2/issues"">
    <img src=""https://img.shields.io/github/issues/BodenmillerGroup/napari-czifile2"" alt=""Issues"" />
</a>
<a href=""https://github.com/BodenmillerGroup/napari-czifile2/pulls"">
    <img src=""https://img.shields.io/github/issues-pr/BodenmillerGroup/napari-czifile2"" alt=""Pull requests"" />
</a>

Carl Zeiss Image (.czi) file type support for napari

Open .czi files and interactively view scenes co-registered in the machine's coordinate system using napari

## Installation

You can install napari-czifile2 via [pip](https://pypi.org/project/pip/):

    pip install napari-czifile2

Alternatively, you can install napari-czifile2 via [conda](https://conda.io/):

    conda install -c conda-forge napari-czifile2

## Authors

Created and maintained by Jonas Windhager [jonas.windhager@uzh.ch](mailto:jonas.windhager@uzh.ch)

## Contributing

[Contributing](https://github.com/BodenmillerGroup/napari-czifile2/blob/main/CONTRIBUTING.md)

## Changelog

[Changelog](https://github.com/BodenmillerGroup/napari-czifile2/blob/main/CHANGELOG.md)

## License

[MIT](https://github.com/BodenmillerGroup/napari-czifile2/blob/main/LICENSE.md)
","['Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/BodenmillerGroup/napari-czifile2/issues', 'Documentation, https://github.com/BodenmillerGroup/napari-czifile2#README.md', 'Source Code, https://github.com/BodenmillerGroup/napari-czifile2', 'User Support, https://github.com/BodenmillerGroup/napari-czifile2/issues']",napari-czifile2.get_reader,,,,['*.czi'],,
175,napari-data-inspection,napari-data-inspection,Data Inspection,0.0.4,2025-06-16,2025-07-16,Lars KrÃ¤mer,lars.kraemer@dkfz-heidelberg.de,"Apache License
               ...",https://github.com/MIC-DKFZ/napari-data-inspection,https://pypi.org/project/napari-data-inspection/,,,"Data Inspection Plugin, designed to streamline file navigation and enhance the efficiency of data inspection.",>=3.10,"['numpy', 'qtpy', 'napari_toolkit', 'blosc2', 'SimpleITK', 'tifffile', 'scikit-image', 'natsort', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-data-inspection

A data inspection plugin for loading image tiles from multiple folders.
With data loading and prefetching handled automatically, file navigation is streamlined to enable fast and efficient data inspection.
Any number of folders for images and labels can be specified, and files are automatically paired based on their order â manual file selection is eliminated.
Perfect for high-throughput inspection workflows and rapid dataset review, especially in semantic segmentation tasks.

## Installation

```bash
# 1. Install napari if necessary
pip install napari[all]
# 2. Install the plugin
pip install napari-data-inspection
```

## Prerequisites

### Supported File Types
The following file types are supported: `.nii.gz`, `.png`, `.b2nd`, `.nrrd`, `.mha`, `.tif`, `.tiff`.
If you want to add custom ones add a loader to `src/napari_data_inspection/utils/data_loading.py`.

### Data Organization Requirements
Your data should be organized so that different images and different labels can be clearly distinguishedâeither by placing them in separate folders or by using consistent filename patterns (e.g., *_img for images and *_seg for labels).
**The number of files must match across all folders, as they are paired by order.**

## How to

```
napari -w napari-data-inspection
```

<img src=""https://github.com/MIC-DKFZ/napari-data-inspection/raw/main/imgs/GUI.png"">

# Acknowledgments

<p align=""left"">
  <img src=""https://github.com/MIC-DKFZ/napari-data-inspection/raw/main/imgs/Logos/HI_Logo.png"" width=""150""> &nbsp;&nbsp;&nbsp;&nbsp;
  <img src=""https://github.com/MIC-DKFZ/napari-data-inspection/raw/main/imgs/Logos/DKFZ_Logo.png"" width=""500"">
</p>

This repository is developed and maintained by the Applied Computer Vision Lab (ACVL)
of [Helmholtz Imaging](https://www.helmholtz-imaging.de/) and the
[Division of Medical Image Computing](https://www.dkfz.de/en/medical-image-computing) at DKFZ.

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

[copier]: https://copier.readthedocs.io/en/stable/
[napari]: https://github.com/napari/napari
[napari-plugin-template]: https://github.com/napari/napari-plugin-template
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Homepage, https://github.com/MIC-DKFZ/napari-data-inspection', 'Code, https://github.com/MIC-DKFZ/napari-data-inspection']",,,napari-data-inspection.DataInspectionWidget,,,,
176,napari-data-preview,napari-data-preview,napari-data-preview,0.0.3a0,2023-02-17,2023-06-07,"Vivien Gaillet, Jules Scholler",jules.scholler@wysscenter.ch,MPL-2.0,https://github.com/WyssCenter/napari-data-preview,https://pypi.org/project/napari-data-preview/,,https://github.com/WyssCenter/napari-data-preview,"Preview lightsheet microscopes acquisition, and allow the creation of an XML for importing the data into TeraStitcher.",>=3.7,"['numpy', 'napari[all]', 'lxml', 'napari-tools-menu', 'magic-class', 'napari-plugin-engine (>=0.1.4)', 'dask', 'tifffile', 'dask-image', 'elementpath', 'tk (>=0.1.0)', 'zarr', 'scikit-image', 'PySimpleGUI', 'pytest-shutil']","# napari-data-preview

Preview lightsheet microscopes acquisition, and allow the creation of an XML for importing the data into TeraStitcher.

This package is very experimental, and you should expect bug/errors.

## Installation

You can install `napari-data-preview` via [pip]:

    pip install napari-data-preview

To install latest development version :

    pip install git+https://github.com/WyssCenter/napari-data-preview.git
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)']",,napari-data-preview.napari_get_reader,,napari-data-preview.DataPreview,,['*'],,
177,napari-deepfinder,napari-deepfinder,Napari DeepFinder,0.0.2,2022-07-25,2025-04-04,Constantin Aronssohn,cnstt@tutanota.com,GPL-3.0-only,https://github.com/deep-finder/napari-deepfinder/issues,https://pypi.org/project/napari-deepfinder/,,https://github.com/deep-finder/napari-deepfinder,"A napari plugin for the DeepFinder library which includes display, annotation, target generation, segmentation and clustering functionalities. An orthoslice view has been added for an easier visualisation and annotation process.",>=3.9,"['cryoet-deepfinder', 'numpy', 'magicgui', 'qtpy', 'napari', 'scikit-image', 'typing', 'pandas', 'lxml[html_clean]', 'pillow', 'h5py', 'mrcfile', 'scipy', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""']","# napari-deepfinder

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-deepfinder.svg?color=green)](https://github.com/deep-finder/napari-deepfinder/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-deepfinder.svg?color=green)](https://pypi.org/project/napari-deepfinder)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-deepfinder.svg?color=green)](https://python.org)
[![tests](https://github.com/deep-finder/napari-deepfinder/workflows/tests/badge.svg)](https://github.com/deep-finder/napari-deepfinder/actions)
[![codecov](https://codecov.io/gh/deep-finder/napari-deepfinder/branch/main/graph/badge.svg)](https://codecov.io/gh/deep-finder/napari-deepfinder)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-deepfinder)](https://napari-hub.org/plugins/napari-deepfinder)

A napari plugin for the DeepFinder library which includes display, annotation, target generation, segmentation and clustering functionalities.
An orthoslice view has been added for an easier visualisation and annotation process.

**The documentation for users is available [here](https://deep-finder.github.io/napari-deepfinder/).**

> [!WARNING]
>
> An upstream bug in `napari` versions **â¥ 0.5.0** causes the menu bar to break when closing the *Orthoslice view*.
> 
> See this issue for more details: https://github.com/napari/napari/issues/7588.
> 
> As a temporary workaround, you can use [napari v0.4.19](https://github.com/napari/napari/releases/tag/v0.4.19), which is not affected by this bug.


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-deepfinder` via [pip]:

    pip install napari-deepfinder



To install latest development version :

    pip install git+https://github.com/deep-finder/napari-deepfinder.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-deepfinder"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/deep-finder/napari-deepfinder/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Education', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Scientific/Engineering :: Information Analysis', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Artificial Intelligence', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']","['Bug Tracker, https://github.com/deep-finder/napari-deepfinder/issues', 'Documentation, https://deep-finder.github.io/napari-deepfinder/', 'Source Code, https://github.com/deep-finder/napari-deepfinder', 'User Support, https://github.com/deep-finder/napari-deepfinder/issues']",napari-deepfinder.get_reader,napari-deepfinder.write_annotations,napari-deepfinder.make_reorder_widget,,"['*.mrc', '*.map', '*.rec', '*.h5', '*.tif', '*.TIF', '*.xml', '*.ods', '*.xls', '*.xlsx']",['.xml'],['.mrc']
178,napari-deeplabcut,napari-deeplabcut,napari DeepLabCut,0.2.1.7,2022-06-03,2024-06-12,"Team DeepLabCut, Lead by Jessy Lauer",admin@deeplabcut.org,BSD-3-Clause,https://github.com/DeepLabCut/napari-deeplabcut/issues,https://pypi.org/project/napari-deeplabcut/,,https://github.com/DeepLabCut/napari-deeplabcut,napari + DeepLabCut annotation tool,>=3.9,"['dask-image', 'matplotlib >=3.3', 'napari ==0.4.18', 'natsort', 'numpy', 'opencv-python-headless', 'pandas', 'pyyaml', 'qtpy >=2.4', 'scikit-image', 'scipy', 'tables', ""pyside6 ==6.4.2 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-deeplabcut: keypoint annotation for pose estimation



<img src=""https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1d409ffe-c9f4-47e1-bde2-3010c1c40455/naparidlc.png?format=750w"" width=""450"" title=""napari-deeplabcut"" alt=""napari+deeplabcut"" align=""right"" vspace = ""80"">

[ðDocumentation](https://deeplabcut.github.io/DeepLabCut/README.html) |
[ð ï¸ DeepLabCut Installation](https://deeplabcut.github.io/DeepLabCut/docs/installation.html) |
[ð Home Page](https://www.deeplabcut.org) |

[![License: BSD-3](https://img.shields.io/badge/License-BSD3-blue.svg)](https://www.gnu.org/licenses/bsd3)
[![PyPI](https://img.shields.io/pypi/v/napari-deeplabcut.svg?color=green)](https://pypi.org/project/napari-deeplabcut)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-deeplabcut.svg?color=green)](https://python.org)
[![tests](https://github.com/DeepLabCut/napari-deeplabcut/workflows/tests/badge.svg)](https://github.com/DeepLabCut/napari-deeplabcut/actions)
[![codecov](https://codecov.io/gh/DeepLabCut/napari-deeplabcut/branch/main/graph/badge.svg)](https://codecov.io/gh/DeepLabCut/napari-deeplabcut)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-deeplabcut)](https://napari-hub.org/plugins/napari-deeplabcut)

A napari plugin for keypoint annotation, also used within DeepLabCut!


## Installation

If you installed DeepLabCut[gui], this plugin is already installed. However, you can also use this as a stand-alone keypoint annotator without using DeepLabCut. Instructions below!

Start by installing PySide6 with `pip install ""pyside6==6.4.2""`; this is the library we now use to build GUIs.

You can then install `napari-deeplabcut` via [pip]:

    pip install napari-deeplabcut



Alternatively, to install the latest development version, run:

    pip install git+https://github.com/DeepLabCut/napari-deeplabcut.git


## Usage

To use the plugin, please run:

    napari

Then, activate the plugin in Plugins > napari-deeplabcut: Keypoint controls.

All accepted files (config.yaml, images, h5 data files) can be loaded
either by dropping them directly onto the canvas or via the File menu.

The easiest way to get started is to drop a folder (typically a folder from within a DeepLabCut's `labeled-data` directory), and, if labeling from scratch, drop the corresponding `config.yaml` to automatically add a `Points layer` and populate the dropdown menus.

[ð¥ DEMO
](https://youtu.be/hsA9IB5r73E)

**Tools & shortcuts are:**

- `2` and `3`, to easily switch between labeling and selection mode
- `4`, to enable pan & zoom (which is achieved using the mouse wheel or finger scrolling on the Trackpad)
- `M`, to cycle through regular (sequential), quick, and cycle annotation mode (see the description [here](https://github.com/DeepLabCut/napari-deeplabcut/blob/5a5709dd38868341568d66eab548ae8abf37cd63/src/napari_deeplabcut/keypoints.py#L25-L34))
- `E`, to enable edge coloring (by default, if using this in refinement GUI mode, points with a confidence lower than 0.6 are marked
in red)
- `F`, to toggle between animal and body part color scheme.
- `V`, to toggle visibility of the selected layer.
- `backspace` to delete a point.
- Check the box ""display text"" to show the label names on the canvas.
- To move to another folder, be sure to save (`Ctrl+S`), then delete the layers, and re-drag/drop the next folder.
- One can jump to a specific image by double-clicking and editing the current frame number (located to the right of the slider).
- Selected points can be copied with `Ctrl+C`, and pasted onto other images with `Ctrl+V`.


### Save Layers

Annotations and segmentations are saved with `File > Save Selected Layer(s)...` (or its shortcut `Ctrl+S`).
Only when saving segmentation masks does a save file dialog pop up to name the destination folder;
keypoint annotations are otherwise automatically saved in the corresponding folder as `CollectedData_<ScorerName>.h5`.
- As a reminder, DLC will only use the H5 file; so be sure if you open already labeled images you save/overwrite the H5.
- Note, before saving a layer, make sure the points layer is selected. If the user clicked on the image(s) layer first, does `Save As`, then closes the window, any labeling work during that session will be lost!
- Modifying and then saving points in a `machinelabels...` layer will add to or overwrite the existing `CollectedData` layer and will **not** save to the `machinelabels` file.


### Video frame extraction and prediction refinement

Since v0.0.4, videos can be viewed in the GUI.

Since v0.0.5, trailing points can be visualized; e.g., helping in the identification
of swaps or outlier, jittery predictions.

Loading a video (and its corresponding output h5 file) will enable the video actions
at the top of the dock widget: they offer the option to manually extract video
frames from the GUI, or to define cropping coordinates.
Note that keypoints can be displaced and saved, as when annotating individual frames.


## Workflow

Suggested workflows, depending on the image folder contents:

1. **Labeling from scratch** â the image folder does not contain `CollectedData_<ScorerName>.h5` file.

    Open *napari* as described in [Usage](#usage) and open an image folder together with the DeepLabCut project's `config.yaml`.
    The image folder creates an *image layer* with the images to label.
    Supported image formats are: `jpg`, `jpeg`, `png`.
    The `config.yaml` file creates a *Points layer*, which holds metadata (such as keypoints read from the config file) necessary for labeling.
    Select the *Points layer* in the layer list (lower left pane on the GUI) and click on the *+*-symbol in the layer controls menu (upper left pane) to start labeling.
    The current keypoint can be viewed/selected in the keypoints dropdown menu (right pane).
    The slider below the displayed image (or the left/right arrow keys) allows selecting the image to label.

    To save the labeling progress refer to [Save Layers](#save-layers).
    `Data successfully saved` should be shown in the status bar, and the image folder should now contain a `CollectedData_<ScorerName>.h5` file.
    (Note: For convenience, a CSV file with the same name is also saved.)

2. **Resuming labeling** â the image folder contains a `CollectedData_<ScorerName>.h5` file.

    Open *napari* and open an image folder (which needs to contain a `CollectedData_<ScorerName>.h5` file).
    In this case, it is not necessary to open the DLC project's `config.yaml` file, as all necessary metadata is read from the `h5` data file.

    Saving works as described in *1*.

    ***Note that if a new body part has been added to the `config.yaml` file after having started to label, loading the config in the GUI is necessary to update the dropdown menus and other metadata.***

    ***As `viridis` is `napari-deeplabcut` default colormap, loading the config in the GUI is also needed to update the color scheme.***

3. **Refining labels** â the image folder contains a `machinelabels-iter<#>.h5` file.

    The process is analog to *2*.
    Open *napari* and open an image folder.
    If the video was originally labeled, *and* had outliers extracted it will contain a `CollectedData_<ScorerName>.h5` file and a `machinelabels-iter<#>.h5` file. In this case, select the `machinelabels` layer in the GUI, and type `e` to show edges. Red indicates likelihood < 0.6. As you navigate through frames, images with labels with edges will need to be refined (moved, deleted, etc). Images with labels without edges will be on the `CollectedData` (previous manual annotations) layer and shouldn't need refining. However, you can switch to that layer and fix errors. You can also right-click on the `CollectedData` layer and select `toggle visibility` to hide that layer. Select the `machinelabels` layer before saving which will append your refined annotations to `CollectedData`.

    If the folder only had outliers extracted and wasn't originally labeled, it will not have a `CollectedData` layer. Work with the `machinelabels` layer selected to refine annotation positions, then save.

    In this case, it is not necessary to open the DLC project's `config.yaml` file, as all necessary metadata is read from the `h5` data file.

    Saving works as described in *1*.

4. **Drawing segmentation masks**

    Drop an image folder as in *1*, manually add a *shapes layer*. Then select the *rectangle* in the layer controls (top left pane),
    and start drawing rectangles over the images. Masks and rectangle vertices are saved as described in [Save Layers](#save-layers).
    Note that masks can be reloaded and edited at a later stage by dropping the `vertices.csv` file onto the canvas.

### Workflow flowchart

```mermaid
%%{init: {""flowchart"": {""htmlLabels"": false}} }%%
graph TD
  id1[What stage of labeling?]
  id2[deeplabcut.label_frames]
  id3[deeplabcut.refine_labels]
  id4[Add labels to, or modify in, \n `CollectedData...` layer and save that layer]
  id5[Modify labels in `machinelabels` layer and save \n which will create a `CollectedData...` file]
  id6[Have you refined some labels from the most recent iteration and saved already?]
  id7[""All extracted frames are already saved in `CollectedData...`.
1. Hide or trash all `machinelabels` layers.
2. Then modify in and save `CollectedData`""]
  id8[""
1. hide or trash all `machinelabels` layers except for the most recent.
2. Select most recent `machinelabels` and hit `e` to show edges.
3. Modify only in `machinelabels` and skip frames with labels without edges shown.
4. Save `machinelabels` layer, which will add data to `CollectedData`.
	- If you need to revisit this video later, ignore `machinelabels` and work only in `CollectedData`""]

  id1 -->|I need to manually label new frames \n or fix my labels|id2
  id1 ---->|I need to refine outlier frames \nfrom analyzed videos|id3
  id2 -->id4
  id3 -->|I only have a `machinelabels...` file|id5
  id3 ---->|I have both `machinelabels` and `CollectedData` files|id6
  id6 -->|yes|id7
  id6 ---->|no, I just extracted outliers|id8
```

### Labeling multiple image folders

Labeling multiple image folders has to be done in sequence; i.e., only one image folder can be opened at a time.
After labeling the images of a particular folder is done and the associated *Points layer* has been saved, *all* layers should be removed from the layers list (lower left pane on the GUI) by selecting them and clicking on the trashcan icon.
Now, another image folder can be labeled, following the process described in *1*, *2*, or *3*, depending on the particular image folder.


### Defining cropping coordinates

Prior to defining cropping coordinates, two elements should be loaded in the GUI:
a video and the DLC project's `config.yaml` file (into which the crop dimensions will be stored).
Then it suffices to add a `Shapes layer`, draw a `rectangle` in it with the desired area,
and hit the button `Store crop coordinates`; coordinates are automatically written to the configuration file.


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

To locally install the code, please git clone the repo and then run `pip install -e .`

## License

Distributed under the terms of the [BSD-3] license,
""napari-deeplabcut"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[file an issue]: https://github.com/DeepLabCut/napari-deeplabcut/issues


## Acknowledgements


This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template. We thank the Chan Zuckerberg Initiative (CZI) for funding the initial development of this work!

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->


[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Artificial Intelligence', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Visualization']","['Bug Tracker, https://github.com/DeepLabCut/napari-deeplabcut/issues', 'Documentation, https://github.com/DeepLabCut/napari-deeplabcut#README.md', 'Source Code, https://github.com/DeepLabCut/napari-deeplabcut', 'User Support, https://github.com/DeepLabCut/napari-deeplabcut/issues']",napari-deeplabcut.get_hdf_reader,napari-deeplabcut.write_hdf,napari-deeplabcut.make_keypoint_controls,,['*.h5'],['.h5'],['.csv']
179,napari-deepspot,napari-DeepSpot,napari-DeepSpot,0.0.7,2021-11-29,2021-11-30,Emmanuel Bouilhol,emmanuel.bouilhol@u-bordeaux.fr,MIT,https://github.com/ebouilhol/napari-DeepSpot/issues,https://pypi.org/project/napari-DeepSpot/,,https://github.com/ebouilhol/napari-DeepSpot,RNA spot enhancement for fluorescent microscopy images,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'pytest', 'pytest-cov', 'pytest-xvfb', 'pytest-qt', 'napari', 'qtpy (==1.9.0)', 'pyqt5', 'tensorflow', 'scikit-image', 'opencv-python']","# napari-DeepSpot

[![License](https://img.shields.io/pypi/l/napari-DeepSpot.svg?color=green)](https://github.com/ebouilhol/napari-DeepSpot/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-DeepSpot.svg?color=green)](https://pypi.org/project/napari-DeepSpot)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-DeepSpot.svg?color=green)](https://python.org)
[![tests](https://github.com/ebouilhol/napari-DeepSpot/workflows/tests/badge.svg)](https://github.com/ebouilhol/napari-DeepSpot/actions)
[![codecov](https://codecov.io/gh/ebouilhol/napari-DeepSpot/branch/main/graph/badge.svg)](https://codecov.io/gh/ebouilhol/napari-DeepSpot)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-DeepSpot)](https://napari-hub.org/plugins/napari-DeepSpot)

RNA spot enhancement for fluorescent microscopy images.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-DeepSpot` via [pip]:

    pip install napari-DeepSpot

## Build from source

This plugin is using Tensorflow, make sure your Python environment has Tensorflow, on create a new environment using the following commands:
* Conda:  
`conda env create -f environment.yml`  
`conda activate deepspot-napari`
* Or pip:   
`pip install -r requirements.txt`

## Usage

Open one or multiple images using Napari GUI : 
File > Open > Select your image

The images are then displayed on Napari

Load the Plugin:
Plugins > Napari-DeepSpot:Enhance Spot

![Usage](./image/napari.png)

Click on the right panel Button ""Enhance""

Wait a few seconds for the magic to happen :

![Usage](./image/napari_enhance.png)

You can see the original images and the enhanced version in the left panel in the layer section.

To save the images : File > Save all layers or File > Save selected layers.


![Usage](./image/napari_video.gif)



## Citation
If you use this plugin please cite the [paper](https://www.biorxiv.org/content/10.1101/2021.11.25.469984v1):

>@article {Bouilhol2021DeepSpot,  
>	 author = {Bouilhol, Emmanuel and Lefevre, Edgar and Dartigues, Benjamin and Brackin, Robyn and Savulescu, Anca Flavia and Nikolski, Macha},  
>	 title = {DeepSpot: a deep neural network for RNA spot enhancement in smFISH microscopy images},  
>	 elocation-id = {2021.11.25.469984},  
>	 year = {2021},  
>	 doi = {10.1101/2021.11.25.469984},  
>	 publisher = {Cold Spring Harbor Laboratory},  
>	 URL = {https://www.biorxiv.org/content/early/2021/11/25/2021.11.25.469984},  
>	 eprint = {https://www.biorxiv.org/content/early/2021/11/25/2021.11.25.469984.full.pdf},  
>	 journal = {bioRxiv}  
>}  

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-DeepSpot"" is free and open source software

## Known Issues

If you have troubles with the Python packages `typing extensions`, use the command :  
`pip install typing-extensions --upgrade`  

When using ""Enhance"" on multiple images, Napari may freeze. Just wait until it comes to life again, the images will still be enhanced. This is due to Napari memory usage and will be fix one day.


## Other Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/ebouilhol/napari-DeepSpot/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/ebouilhol/napari-DeepSpot/issues', 'Documentation, https://github.com/ebouilhol/napari-DeepSpot#README.md', 'Source Code, https://github.com/ebouilhol/napari-DeepSpot', 'User Support, https://github.com/ebouilhol/napari-DeepSpot/issues']",,,napari-DeepSpot.EnhanceSpot,,,,
180,napari-demo,napari-demo,Demo plugin ported from npe2 example,0.2.5,2021-01-27,2023-09-21,napari hub team,team@napari-hub.org,BSD-3,https://github.com/chanzuckerberg/napari-demo,https://pypi.org/project/napari-demo/,,https://github.com/chanzuckerberg/napari-demo,example plugin for napari plugin developers,>=3.7,"['pydantic', 'npe2', 'numpy']","# napari-demo

[![License](https://img.shields.io/pypi/l/napari-demo.svg?color=green)](https://github.com/chanzuckerberg/napari-demo/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-demo.svg?color=green)](https://pypi.org/project/napari-demo)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-demo.svg?color=green)](https://python.org)
[![tests](https://github.com/chanzuckerberg/napari-demo/workflows/tests/badge.svg)](https://github.com/chanzuckerberg/napari-demo/actions)
[![codecov](https://codecov.io/gh/chanzuckerberg/napari-demo/branch/master/graph/badge.svg)](https://codecov.io/gh/chanzuckerberg/napari-demo)

This is a demo plugin implementation of https://github.com/napari/napari/blob/master/examples/magic_image_arithmetic.py

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-demo` via [pip]:

    pip install napari-demo

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-demo"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.
To report security issues, see [security](SECURITY.md)

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/chanzuckerberg/napari-demo/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


## Code of Conduct

This project adheres to the Contributor Covenant [code of conduct](https://github.com/chanzuckerberg/.github/blob/master/CODE_OF_CONDUCT.md). By participating, you are expected to uphold this code. Please report unacceptable behavior to [opensource@chanzuckerberg.com](mailto:opensource@chanzuckerberg.com).

","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Programming Language :: Python', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing', 'Operating System :: OS Independent', 'Framework :: napari']","['Source Code, https://github.com/chanzuckerberg/napari-demo']",napari-demo.some_reader,napari-demo.my_writer,napari-demo.image_arithmetic,napari-demo.generate_random_data,"['*.fzy', '*.fzzy']","['.tif', '.tiff']","['.pcd', '.e57']"
181,napari-denoiseg,napari-denoiseg,DenoiSeg,0.0.1rc2,2022-10-31,2022-11-01,"Tom Burke, Joran Deschamps",joran.deschamps@fht.org,BSD-3-Clause,https://github.com/juglab/napari_denoiseg/issues,https://pypi.org/project/napari-denoiseg/,,https://github.com/juglab/napari_denoiseg,A napari plugin performing joint denoising and segmentation of microscopy images using DenoiSeg.,>=3.7,"['numpy', 'pyqtgraph', 'denoiseg (>=0.3.0)', 'bioimageio.core', 'magicgui', 'qtpy', 'napari-time-slicer (>=0.4.9)', 'napari (<=0.4.15)', 'vispy (<=0.9.6)', 'imageio (!=2.11.0,!=2.22.1,>=2.5.0)', 'tensorflow ; platform_system != ""Darwin"" or platform_machine != ""arm64""', 'tensorflow-macos ; platform_system == ""Darwin"" and platform_machine == ""arm64""', 'tensorflow-metal ; platform_system == ""Darwin"" and platform_machine == ""arm64""', ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-denoiseg

[![License](https://img.shields.io/pypi/l/napari-denoiseg.svg?color=green)](https://github.com/juglab/napari-denoiseg/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-denoiseg.svg?color=green)](https://pypi.org/project/napari-denoiseg)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-denoiseg.svg?color=green)](https://python.org)
[![tests](https://github.com/juglab/napari-denoiseg/workflows/build/badge.svg)](https://github.com/juglab/napari-denoiseg/actions)
[![codecov](https://codecov.io/gh/juglab/napari-denoiseg/branch/main/graph/badge.svg)](https://codecov.io/gh/juglab/napari-denoiseg)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-denoiseg)](https://napari-hub.org/plugins/napari-denoiseg)

A napari plugin performing joint denoising and segmentation of microscopy images using [DenoiSeg](https://github.com/juglab/DenoiSeg).

<img src=""https://raw.githubusercontent.com/juglab/napari-denoiseg/master/docs/images/example.png"" width=""800"" />
----------------------------------

## Installation

Check out the [documentation](https://juglab.github.io/napari-denoiseg/installation.html) for more detailed installation 
instructions. 


## Quick demo

You can try out a demo by loading the `DenoiSeg Demo prediction` plugin and directly clicking on `Predict`.


<img src=""https://raw.githubusercontent.com/juglab/napari-denoiseg/master/docs/images/prediction.gif"" width=""800"" />


## Documentation

Documentation is available on the [project website](https://juglab.github.io/napari-denoiseg/).


## Contributing and feedback

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request. You can also 
help us improve by [filing an issue] along with a detailed description or contact us
through the [image.sc](https://forum.image.sc/) forum (tag @jdeschamps).


## Cite us


Tim-Oliver Buchholz, Mangal Prakash, Alexander Krull and Florian Jug, ""[DenoiSeg: Joint Denoising and Segmentation](https://arxiv.org/abs/2005.02987)"" _arxiv_ (2020)


## Acknowledgements

This plugin was developed thanks to the support of the Silicon Valley Community Foundation (SCVF) and the 
Chan-Zuckerberg Initiative (CZI) with the napari Plugin Accelerator grant _2021-239867_.


Distributed under the terms of the [BSD-3] license,
""napari-denoiseg"" is a free and open source software.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[filing an issue]: https://github.com/juglab/napari-denoiseg/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Framework :: napari', 'Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/juglab/napari_denoiseg/issues', 'Documentation, https://juglab.github.io/napari-denoiseg/', 'Source Code, https://github.com/juglab/napari_denoiseg', 'User Support, https://github.com/juglab/napari_denoiseg/issues']",,,napari-denoiseg.make_train_widget,napari-denoiseg.denoiseg_data_2D_n0,,,
182,napari-dinosim,napari-dinosim,DINOSim Segmentation,0.1.3,2025-03-09,2025-07-15,Aitor Gonzalez-Marfil,aitorgacad@gmail.com,MIT,https://github.com/AAitorG/napari-DINOSim/issues,https://pypi.org/project/napari-dinosim/,,,A simple plugin to use DINOSim in napari,"<3.13,>=3.9","['numpy', 'magicgui', 'qtpy', 'torch', 'torchvision', 'tqdm', 'pillow', 'matplotlib', 'opencv-python', 'tifffile', 'napari[all]', 'tox; extra == ""testing""', 'pytest>=8.3.5; extra == ""testing""', 'pytest-qt>=4.4.0; extra == ""testing""', 'pytest-xvfb>=3.0.0; extra == ""testing""', 'pytest-cov>=6.0; extra == ""testing""', 'pyqt5>=5.15.11; extra == ""testing""', 'napari>=0.5.6; extra == ""testing""', 'magicgui>=0.10.0; extra == ""testing""']","# DINOSim

[![License: MIT](https://img.shields.io/pypi/l/napari-dinosim.svg?color=blue)](https://github.com/AAitorG/napari-DINOSim/raw/main/LICENSE)
[![biorxiv](https://img.shields.io/badge/bioRxiv-Paper-bd2635.svg)](https://doi.org/10.1101/2025.03.09.642092)
[![PyPI](https://img.shields.io/pypi/v/napari-DINOSim.svg?color=green)](https://pypi.org/project/napari-DINOSim)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-DINOSim.svg?color=green)](https://python.org)
[![tests](https://github.com/AAitorG/napari-DINOSim/workflows/tests/badge.svg)](https://github.com/AAitorG/napari-DINOSim/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-dinosim)](https://napari-hub.org/plugins/napari-dinosim)

![DINOSim-simple](docs/DINOSim-simplest.png)

A [napari] plugin for zero-shot image segmentation using DINOv2 vision transformers.

----------------------------------

## Overview

`napari-DINOSim` enables zero-shot image segmentation by selecting reference points on an image. The plugin leverages DINOv2's powerful feature extraction capabilities to compute similarity maps and generate segmentation masks.

For detailed information about the widget's functionality, UI elements, and usage instructions, please refer to the [Plugin Documentation](./docs/plugin_documentation.md). A simple [example notebook](./src/DINOSim_example.ipynb) demonstrating how to use DINOSim programmatically is also available.

## Installation

You can install `napari-DINOSim` via [pip]:

```sh
pip install napari-dinosim
```

or from source using [conda]:

```bash
# Clone the repository
git clone https://github.com/AAitorG/napari-DINOSim.git
cd napari-DINOSim

# Create and activate the conda environment
conda env create -f environment.yml
conda activate napari-dinosim
```

## Usage

To launch napari, run the following command in your terminal:

```sh
napari
```

Within the napari interface, locate and click the `DINOSim segmentation` plugin in the Plugins section of the top bar. You can then:
1. Drag and drop your image into the napari viewer
2. Select points on the objects you want to segment
3. The plugin will automatically generate segmentation masks based on your selections

For more detailed instructions and examples, please refer to our [Plugin Documentation](./docs/plugin_documentation.md).

## License

Distributed under the terms of the [MIT] license,
""napari-DINOSim"" is free and open source software.

## Citation

Please note that DINOSim is based on a [publication](https://doi.org/10.1101/2025.03.09.642092). If you use DINOSim in your research, please be so kind to cite our work:

```bibtex
@article {Gonzalez-Marfil2025dinosim,
    title = {DINOSim: Zero-Shot Object Detection and Semantic Segmentation on Electron Microscopy Images},
    author = {Gonz{\'a}lez-Marfil, Aitor and G{\'o}mez-de-Mariscal, Estibaliz and Arganda-Carreras, Ignacio},
    journal = {bioRxiv},
    publisher = {Cold Spring Harbor Laboratory},
    url = {https://www.biorxiv.org/content/early/2025/03/13/2025.03.09.642092},
    doi = {10.1101/2025.03.09.642092},
    year = {2025}
}
```

## Contributing

Contributions are very welcome! Tests can be run with [tox]. Please ensure the test coverage at least stays the same before submitting a pull request.

## Issues

If you encounter any problems, please [file an issue](https://github.com/AAitorG/napari-DINOSim/issues) along with a detailed description.

[napari]: https://github.com/napari/napari
[MIT]: http://opensource.org/licenses/MIT
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[conda]: https://docs.conda.io/en/latest/miniconda.html
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Artificial Intelligence']","['Documentation, https://github.com/AAitorG/napari-DINOSim#readme', 'Repository, https://github.com/AAitorG/napari-DINOSim', 'Issues, https://github.com/AAitorG/napari-DINOSim/issues']",,,napari-dinosim.make_container_widget,,,,
183,napari-deepmeta,napari-deepmeta,napari DeepMeta,2.1,2021-06-02,2022-07-07,Edgar Lefevre,lefevreedg@gmail.com,MIT,https://github.com/EdgarLefevre/napari-deepmeta/issues,https://pypi.org/project/napari-deepmeta/,,https://github.com/EdgarLefevre/napari-deepmeta,Mice lungs and metastases segmentation tool.,>=3.8,"['connected-components-3d', 'magicgui', 'napari', 'numpy', 'opencv-python', 'qtpy', 'scikit-image', 'torch', ""connected-components-3d ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""opencv-python ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-deepmeta

[![License MIT](https://img.shields.io/pypi/l/napari-deepmeta.svg?color=green)](https://github.com/EdgarLefevre/napari-deepmeta/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-deepmeta.svg?color=green)](https://pypi.org/project/napari-deepmeta)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-deepmeta.svg?color=green)](https://python.org)
[![tests](https://github.com/EdgarLefevre/napari-deepmeta/workflows/tests/badge.svg)](https://github.com/EdgarLefevre/napari-deepmeta/actions)
[![codecov](https://codecov.io/gh/EdgarLefevre/napari-deepmeta/branch/main/graph/badge.svg)](https://codecov.io/gh/EdgarLefevre/napari-deepmeta)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-deepmeta)](https://napari-hub.org/plugins/napari-deepmeta)

Mice lungs and metastases segmentation tool.
This tool is a demo tool for DeepMeta network.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-deepmeta` via [pip]:

    pip install napari-deepmeta



To install latest development version :

    pip install git+https://github.com/EdgarLefevre/napari-deepmeta.git


## Usage

This plugin is designed to process your mouse MRI images with our dataset. It comes with a demo, including one of our
test images.

By opening the deepmeta demo plugin, you will see an interface with one unique button, by clicking on it, it will load an image,
run prediction and then draw the masks contours on each slice.

If you open the deepmeta plugin, you will see an interface with one button and 3 checkboxes.
By checking the checkboxes, you add steps to the pipeline (enhance contrast, do postprocessing, segment metastases).
Once everything is setup, just click on the button and wait (the waiting time depends on your computer performance.)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-deepmeta"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/EdgarLefevre/napari-deepmeta/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/EdgarLefevre/napari-deepmeta/issues', 'Documentation, https://github.com/EdgarLefevre/napari-deepmeta#README.md', 'Source Code, https://github.com/EdgarLefevre/napari-deepmeta', 'User Support, https://github.com/EdgarLefevre/napari-deepmeta/issues']",,,napari-deepmeta.make_qwidget,,,,
184,napari-dmc-brainmap,napari-dmc-brainmap,dmc_brainmap,0.1.7b4,2025-02-18,2025-05-18,Felix Jung,jung.neurosc@gmail.com,BSD-3-Clause,,https://pypi.org/project/napari-dmc-brainmap/,None,,DMC-BrainMap is an end-to-end tool for multi-feature brain mapping across species,==3.10.*,"['numpy==1.26.4', 'pandas==2.0.1', 'matplotlib==3.8.3', 'seaborn==0.12.2', 'scikit-learn==1.4.1.post1', 'scikit-image==0.22.0', 'scikit-spatial==7.2.0', 'tifffile==2023.2.28', 'magicgui==0.8.1', 'qtpy==2.4.1', 'opencv-python==4.9.0.80', 'natsort==8.4.0', 'imagecodecs==2024.1.1', 'mergedeep==1.3.4', 'aicsimageio==4.14.0', 'aicspylibczi==3.1.2', 'aicssegmentation==0.5.3', 'distinctipy==1.3.4', 'bg_atlasapi==1.0.2', 'shapely==2.0.1']","
# napari-dmc-brainmap
*DMC-BrainMap is an end-to-end tool for multi-feature brain mapping across species.*  
This [napari](https://napari.org/stable/) plugin was generated with [Cookiecutter](https://github.com/cookiecutter/cookiecutter) using napari's [cookiecutter-napari-plugin](https://github.com/napari/cookiecutter-napari-plugin) template.

[![License BSD-3](https://img.shields.io/pypi/l/napari-dmc-brainmap.svg?color=green)](https://github.com/hejDMC/napari-dmc-brainmap/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-dmc-brainmap.svg?color=green)](https://pypi.org/project/napari-dmc-brainmap)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-dmc-brainmap.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-dmc-brainmap)](https://napari-hub.org/plugins/napari-dmc-brainmap)


## Quick start
A detailed guide and tutorial can be found on the [Wiki pages of this repo](https://github.com/hejDMC/napari-dmc-brainmap/wiki).

### Installation

DMC-BrainMap is a plugin for [napari](https://napari.org/stable/). Hence, you first need to install napari and subsequently the DMC-BrainMap plugin via the plugin manager. To install napari, we recommend to install napari into a clean virtual environment using *conda* or *venv*. Please refer to the [napari installation guide](https://napari.org/stable/tutorials/fundamentals/installation.html#napari-installation) for more information and [for information on installing napari as a bundled app](https://napari.org/stable/tutorials/fundamentals/installation.html#napari-installation).  

#### Step 1: Setup the virtual environment (Python 3.10)

```
conda create -y -n napari-env -c conda-forge python=3.10
conda activate napari-env
```

#### Step 2: Install napari

```
python -m pip install ""napari[all]""
```

#### Step 3: Install napari-dmc-brainmap

You can install `napari-dmc-brainmap` via the napari plugin manager or via [pip](https://pypi.org/project/napari-dmc-brainmap/):

    pip install napari-dmc-brainmap

### Usage

Please refer to the Wiki pages for detailed instructions and a short tutorial on how to use DMC-BrainMap. When working with DMC-BrainMap on your own data, please keep the following points in mind:
- DMC-BrainMap requires single-channel 16-bit .tif/.tiff images to work (in principle 8-bit also work)
- DMC-BrainMap requires that your data is organized by animals in separate folders (you can pool data later down the lane)
- DMC-BrainMap uses 5 channel labels (`dapi`, `green`, `n3`, `cy3`, `cy5`) corresponding to blue, green, orange, red and far red channels. *However, these are only labels, you can assign them as you please. Hence, you can use DMC-BrainMap also for non-fluorescence data given you converted your images to single-channel 16-bit .tif/.tiff images*. Please contact us if you need to use more than 5 channels.
- It is essential that you structure your data in the following way (hierarchical organization, same name for images in different channels, channel labels are selected by you), **otherwise DMC-BrainMap won't work**:
```
animal_id-001
â
ââââstitched
â   â
â   ââââdapi
â   |    â   animal_id-001_001.tiff
â   |    â   animal_id-001_002.tiff
|   â    |   animal_id-001_003.tiff
â   |    â   animal_id-001_004.tiff
â   |    â   ...
â   â   
â   ââââgreen
â       â   animal_id-001_001.tiff
â       â   animal_id-001_002.tiff
â       â   animal_id-001_003.tiff
â       â   animal_id-001_004.tiff
â       â   ...
â   
animal_id-2
â   ...
```

## Documentation
Documentation on DMC-BrainMap's source code can be found on the project's [Read the Docs page](https://napari-dmc-brainmap.readthedocs.io/en/latest/#).

## Seeking help or contributing

DMC-BrainMap is an open-source project, and we welcome contributions of all kinds. If you have any questions, feedback, or suggestions, please feel free to open an issue on this repository. 

## License

Distributed under the terms of the [BSD-3](https://github.com/teamdigitale/licenses/blob/master/BSD-3-Clause) license,
""napari-dmc-brainmap"" is free and open source software

## Citing DMC-BrainMap

If you use DMC-BrainMap in your scientific work, please cite:
```
Jung, F., Cao, X., Heymans, L., CarlÃ©n, M. (2025) ""DMC-BrainMap - an open-source, end-to-end tool for multi-feature brain mapping across species"", bioRxiv, https://doi.org/10.1101/2025.02.19.639009
```

BibTeX:

``` bibtex
@article{Jung2025x,
   author = {Felix Jung and Xiao Cao and Loran Heymans and Marie Carlen},
   doi = {10.1101/2025.02.19.639009},
   journal = {bioRxiv},
   month = {2},
   title = {DMC-BrainMap - an open-source, end-to-end tool for multi-feature brain mapping across species},
   url = {http://biorxiv.org/lookup/doi/10.1101/2025.02.19.639009},
   year = {2025},
}
```

","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-dmc-brainmap.ParamsWidget,,,,
185,napari-dexp,napari-dexp,DEXP,0.0.7,2021-07-01,2022-06-23,Jordao Bragantini,jordao.bragantini@czbiohub.org,BSD-3,https://github.com/royerlab/napari-dexp,https://pypi.org/project/napari-dexp/,,https://github.com/royerlab/napari-dexp,A simple plugin to use with napari,>=3.7,"['napari', 'napari-plugin-engine (>=0.1.4)', 'dexp', 'numpy']","# napari-DEXP

[![License](https://img.shields.io/pypi/l/napari-dexp.svg?color=green)](https://github.com/royerlab/napari-dexp/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-dexp.svg?color=green)](https://pypi.org/project/napari-dexp)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-dexp.svg?color=green)](https://python.org)
[![tests](https://github.com/royerlab/napari-dexp/workflows/tests/badge.svg)](https://github.com/royerlab/napari-dexp/actions)
[![codecov](https://codecov.io/gh/royerlab/napari-dexp/branch/master/graph/badge.svg)](https://codecov.io/gh/royerlab/napari-dexp)

A plugin to interface [DEXP](https://github.com/royerlab/dexp) with [napari](https://github.com/napari/napari).

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-dexp` via [pip]:

    pip install napari-dexp

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-dexp"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/royerlab/napari-dexp/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,napari-dexp.get_reader,napari-dexp.write_image,,,"['*.zarr', '*.zarr.zip']",['.zarr'],['.zarr']
186,napari-easy-augment-batch-dl,napari-easy-augment-batch-dl,Easy Augment Batch DL,0.0.6,2025-02-13,2025-04-11,Brian Northan,bnorthan@gmail.com,"Copyright (c) 2024, Brian Nort...",https://github.com/bnorthan/napari-easy-augment-batch-dl/issues,https://pypi.org/project/napari-easy-augment-batch-dl/,,,A plugin to perform unet based deep learning with a small number of labels and augmentation,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'tnia-python', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-easy-augment-batch-dl

[![License BSD-3](https://img.shields.io/pypi/l/napari-easy-augment-batch-dl.svg?color=green)](https://github.com/bnorthan/napari-easy-augment-batch-dl/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-easy-augment-batch-dl.svg?color=green)](https://pypi.org/project/napari-easy-augment-batch-dl)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-easy-augment-batch-dl.svg?color=green)](https://python.org)
[![tests](https://github.com/bnorthan/napari-easy-augment-batch-dl/workflows/tests/badge.svg)](https://github.com/bnorthan/napari-easy-augment-batch-dl/actions)
[![codecov](https://codecov.io/gh/bnorthan/napari-easy-augment-batch-dl/branch/main/graph/badge.svg)](https://codecov.io/gh/bnorthan/napari-easy-augment-batch-dl)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-easy-augment-batch-dl)](https://napari-hub.org/plugins/napari-easy-augment-batch-dl)  


See [full documentation](https://true-north-intelligent-algorithms.github.io/napari-easy-augment-batch-dl/)

A plugin to perform deep learning on small to medium sized image sets with UNETs, Cellpose, Stardist, SAM and friends.  In particular this plugin is useful for performing deep learning with a small number of labels and augmentation, and experimenting with different deep learning frameworks.  

Important note on dependencies:  This plugin is designed to work with different permutations of dependencies.  For example it should work if one of Pytorch, Cellpose, SAM and/or Stardist is installed but does not require all.   Thus we don't specify all the dependencies and leave it up to the user to install the permutation of DL related dependencies they would like to use.  More detailed instructions are below. 

If you have any questions about dependencies splease post on the [Image.sc](Image.sc) forum. 

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

To install latest development version :

    pip install git+https://github.com/bnorthan/napari-easy-augment-batch-dl.git

You will also need to install the latest development version of tnia-python:

    pip install git+https://github.com/True-North-Intelligent-Algorithms/tnia-python.git

You will need to install napari and for augmentation you will need albumentations library.  Also explicitly install numpy 1.26.  (We have not tested with numpy 2.0 so it is a good idea to explicitly install numpy 1.26 to avoid another dependency installing numpy 2.x)

```
    pip install numpy==1.26
    pip install napari[all]
    pip install albumentations
    pip install matplotlib
```

You will also need one or more of stardist, cellpose, segment-everything or Yolo

### Stardist

#### Windows

```
    conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0
    pip install ""tensorflow<2.11""
    pip install stardist==0.8.5
    pip install gputools
    pip install edt
```

#### Linux

```
    pip install tensorflow[and-cuda]
    pip install stardist
    pip install gputools
    pip install edt
```

### Pytorch (for unet segmentation)

```
    pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
    pip install pytorch-lightning
    pip install monai
    pip install scipy
    pip install tifffile
```

### Cellpose

```
    pip install cellpose
```

### SAM (Segment Anything)

```
    pip install segment-everything
```

###

You can install `napari-easy-augment-batch-dl` via [pip]:

    pip install napari-easy-augment-batch-dl


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-easy-augment-batch-dl"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/bnorthan/napari-easy-augment-batch-dl/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/bnorthan/napari-easy-augment-batch-dl/issues', 'Documentation, https://github.com/bnorthan/napari-easy-augment-batch-dl#README.md', 'Source Code, https://github.com/bnorthan/napari-easy-augment-batch-dl', 'User Support, https://github.com/bnorthan/napari-easy-augment-batch-dl/issues']",,,napari-easy-augment-batch-dl.napari_easy_augment_batch_dl,,,,
187,napari-dv,napari-dv,napari-dv,0.3.0,2021-01-27,2022-03-19,Talley Lambert,talley.lambert@gmail.com,MIT,https://github.com/tlambert03/napari-dv/issues,https://pypi.org/project/napari-dv/,,https://github.com/tlambert03/napari-dv,Deltavision/MRC file reader for napari,>=3.7,"['mrc (>=0.2.0)', 'napari-plugin-engine (>=0.1.4)', ""numpy ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-dv

[![License](https://img.shields.io/pypi/l/napari-dv.svg?color=green)](https://github.com/tlambert03/napari-dv/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-dv.svg?color=green)](https://pypi.org/project/napari-dv)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-dv.svg?color=green)](https://python.org)
[![tests](https://github.com/tlambert03/napari-dv/workflows/tests/badge.svg)](https://github.com/tlambert03/napari-dv/actions)
[![codecov](https://codecov.io/gh/tlambert03/napari-dv/branch/master/graph/badge.svg)](https://codecov.io/gh/tlambert03/napari-dv)

Deltavision/MRC file reader for napari.

This wraps the [mrc](https://github.com/tlambert03/mrc) library.

See also [napari-aicsimageio](https://github.com/AllenCellModeling/napari-aicsimageio), which also uses the [mrc](https://github.com/tlambert03/mrc) to provide dv file support,
along with many other common file formats.

## Installation

You can install `napari-dv` via [pip]:

    pip install napari-dv

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-dv"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[file an issue]: https://github.com/tlambert03/napari-dv/issues
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/


","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10']","['Bug Tracker, https://github.com/tlambert03/napari-dv/issues', 'Documentation, https://github.com/tlambert03/napari-dv#README.md', 'Source Code, https://github.com/tlambert03/napari-dv', 'User Support, https://github.com/tlambert03/napari-dv/issues']",napari-dv.get_reader,napari-dv.write_image,,,"['*.dv', '*.mrc']","['.dv', '.mrc']",
188,napari-ehooke,napari-ehooke,eHooke,0.0.17,2023-03-02,2025-01-29,AntÃ³nio Brito,antmsbrito95@gmail.com,BSD-3-Clause,https://github.com/antmsbrito/napari-ehooke/issues,https://pypi.org/project/napari-ehooke/,,https://github.com/antmsbrito/napari-ehooke,eHooke implementation within napari,>=3.8,"['numpy<2.0', 'magicgui==0.6.1', 'napari[all]', 'tensorflow<=2.15.0', 'napari-skimage-regionprops', 'stardist-napari==2022.12.6', 'scikit-learn', 'scikit-image==0.20.0', 'pandas', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-ehooke

[![License BSD-3](https://img.shields.io/pypi/l/napari-ehooke.svg?color=green)](https://github.com/antmsbrito/napari-ehooke/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-ehooke.svg?color=green)](https://pypi.org/project/napari-ehooke)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-ehooke.svg?color=green)](https://python.org)
[![tests](https://github.com/antmsbrito/napari-ehooke/workflows/tests/badge.svg)](https://github.com/antmsbrito/napari-ehooke/actions)
[![codecov](https://codecov.io/gh/antmsbrito/napari-ehooke/branch/main/graph/badge.svg)](https://codecov.io/gh/antmsbrito/napari-ehooke)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-ehooke)](https://napari-hub.org/plugins/napari-ehooke)

eHooke implementation within napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-ehooke` via [pip]:

    pip install napari-ehooke



To install latest development version :

    pip install git+https://github.com/antmsbrito/napari-ehooke.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-ehooke"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/antmsbrito/napari-ehooke/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/antmsbrito/napari-ehooke/issues', 'Documentation, https://github.com/antmsbrito/napari-ehooke#README.md', 'Source Code, https://github.com/antmsbrito/napari-ehooke', 'User Support, https://github.com/antmsbrito/napari-ehooke/issues']",,,napari-ehooke.compute_mask,napari-ehooke.phase_example,,,
189,napari-dvid,napari-dvid,napari-dvid,0.2.0,2021-06-09,2021-06-09,Emma Zhou,emma@emmazhou.com,MIT,https://github.com/emmazhou/napari-dvid/issues,https://pypi.org/project/napari-dvid/,,https://github.com/emmazhou/napari-dvid,"DVID loader for napari, from a url",>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'requests']","# napari-dvid

[![License](https://img.shields.io/pypi/l/napari-dvid.svg?color=green)](https://github.com/emmazhou/napari-dvid/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-dvid.svg?color=green)](https://pypi.org/project/napari-dvid)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-dvid.svg?color=green)](https://python.org)
[![tests](https://github.com/emmazhou/napari-dvid/workflows/tests/badge.svg)](https://github.com/emmazhou/napari-dvid/actions)
[![codecov](https://codecov.io/gh/emmazhou/napari-dvid/branch/master/graph/badge.svg)](https://codecov.io/gh/emmazhou/napari-dvid)

DVID loader for napari, from a url

---

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-dvid` via [pip]:

    pip install napari-dvid

## Examples

Once installed, run `napari --with napari-dvid` to get the plugin sidebar:

![Screenshot](screenshot.png)

Paste in a URL to a DVID volume and hit ""Load"" to load the volume! As an example, try:

`https://emdata.janelia.org/api/node/ab6e610d4/grayscale/raw/0_1_2/256_256_256/7500_7000_4400`

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-dvid"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[mit]: http://opensource.org/licenses/MIT
[bsd-3]: http://opensource.org/licenses/BSD-3-Clause
[gnu gpl v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[gnu lgpl v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[apache software license 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[mozilla public license 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/emmazhou/napari-dvid/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[pypi]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/emmazhou/napari-dvid/issues', 'Documentation, https://github.com/emmazhou/napari-dvid#README.md', 'Source Code, https://github.com/emmazhou/napari-dvid', 'User Support, https://github.com/emmazhou/napari-dvid/issues']",napari-dvid.napari_get_reader,,napari-dvid.UrlWidget,,['*'],,
190,napari-elementary-numpy-operations,napari-elementary-numpy-operations,napari-elementary-numpy-operations,0.0.5,2022-01-12,2022-01-21,"Marc Boucsein, Robin Koch",,BSD-3,https://github.com/MBPhys/napari-elementary-numpy-operations,https://pypi.org/project/napari-elementary-numpy-operations/,,https://github.com/MBPhys/napari-elementary-numpy-operations,"A napari plugin covers elementary numpy operations like swap axes, flip, sqeeze an array or rotate an arrays by 90Â° steps",>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'qtpy', 'superqt']","# napari-elementary-numpy-operations

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/napari-elementary-numpy-operations/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-elementary-numpy-operations.svg?color=green)](https://pypi.org/project/napari-elementary-numpy-operations)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-elementary-numpy-operations.svg?color=green)](https://python.org)


A napari plugin covers elementary numpy operations like swap axes, flip, sqeeze an array or rotate an arrays by 90Â° steps.

----------------------------------

## Installation

You can install `napari-elementary-numpy-operations` via [pip]:

    napari-elementary-numpy-operations

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-elementary-numpy-operations"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/napari-elementary-numpy-operations/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,napari-elementary-numpy-operations.elementary_numpy,,,,
191,napari-dzi-zarr,napari-dzi-zarr,napari-dzi-zarr,0.1.2,2020-10-26,2021-04-06,Trevor Manz,trevor.j.manz@gmail.com,BSD-3,https://github.com/manzt/napari-dzi-zarr,https://pypi.org/project/napari-dzi-zarr/,,https://github.com/manzt/napari-dzi-zarr,An experimental plugin for viewing Deep Zoom Images (DZI) with napari and zarr.,>=3.6,"['napari-plugin-engine (>=0.1.4)', 'numpy (>=0.1.19)', 'zarr (>=0.2.4)', 'dask[array] (>=2.23.0)', 'fsspec (>=0.8.0)', 'requests (>=2.24.0)', 'aiohttp (>=3.6.2)', 'imageio (>=2.9.0)']","# napari-dzi-zarr

[![License](https://img.shields.io/pypi/l/napari-dzi-zarr.svg?color=green)](https://github.com/napari/napari-dzi-zarr/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-dzi-zarr.svg?color=green)](https://pypi.org/project/napari-dzi-zarr)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-dzi-zarr.svg?color=green)](https://python.org)
[![tests](https://github.com/manzt/napari-dzi-zarr/workflows/tests/badge.svg)](https://github.com/manzt/napari-dzi-zarr/actions)

An experimental plugin for viewing Deep Zoom Images (DZI) with napari + zarr + dask.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## Description 

The [DZI File Format](https://github.com/openseadragon/openseadragon/wiki/The-DZI-File-Format) 
is a pyramidal tile source specification where individual tiles are RGB/RGBA JPEG/PNG images. 
DZI is a very popular tile source for zoomable web-viewers like 
[OpenSeadragon](https://openseadragon.github.io/), and as a result many tile sources are available over 
HTTP. This plugin wraps a DZI tile source (local or remote) as a multiscale Zarr, where each pyramidal level is a `zarr.Array` of shape `(level_height, level_width, 3/4)`, allowing the same images to be viewed 
in `napari` + `dask`.

## Installation

You can install `napari-dzi-zarr` via [pip]:

    pip install napari-dzi-zarr


## Usage

This high-resolution scan of Rembrandt's Night Watch is available thanks to [R.G Erdmann](https://twitter.com/erdmann). More examples can be found on [boschproject.org](http://boschproject.org).

    $ napari http://hyper-resolution.org/dzi/Rijksmuseum/SK-C-5/SK-C-5_VIS_20-um_2019-12-21.dzi

![Rembrandt's Night Watch in napari](./night_watch_napari.png)

## Contributing

Contributions are very welcome. Tests can be run with [tox].

## License

Distributed under the terms of the [BSD-3] license,
""napari-dzi-zarr"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/manzt/napari-dzi-zarr/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.6', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: Implementation :: CPython', 'Programming Language :: Python :: Implementation :: PyPy', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License', 'Framework :: napari']",,napari-dzi-zarr.napari_get_reader,,,,['*'],,
192,napari-emd,napari-EMD,EMD File Viewer,0.1.1,2023-08-01,2023-08-08,Nicolette Shaw,shaw.nicki@gmail.com,BSD-3-Clause,https://github.com/NickiShaw/napari-EMD.git,https://pypi.org/project/napari-EMD/,,https://github.com/NickiShaw/napari-EMD.git,A simple plugin to view .emd files in napari (Velox files),>=3.8,"['numpy', 'h5py', 'magicgui', 'ujson', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-EMD

[![License BSD-3](https://img.shields.io/pypi/l/napari-EMD.svg?color=green)](https://github.com/NickiShaw/napari-EMD/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-EMD.svg?color=green)](https://pypi.org/project/napari-EMD)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-EMD.svg?color=green)](https://python.org)
[![tests](https://github.com/NickiShaw/napari-EMD/workflows/tests/badge.svg)](https://github.com/NickiShaw/napari-EMD/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-EMD)](https://napari-hub.org/plugins/napari-EMD)

A simple plugin to view .emd files in napari (i.e. Velox files). Allows users to track metadata as it changes over the course of a video/stack, developed for analysis of in-situ microscopy data, where users may be changing magnification, focus, etc. during aquisition.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-EMD` via [pip]:

    `pip install napari-EMD`

You can install napari and access the plugin through the GUI. [Reccomended install command for napari](https://napari.org/stable/tutorials/fundamentals/installation.html):

    `python -m pip install ""napari[all]""`

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-EMD"" is free and open source software

## Issues and Requests

> **Warning: The metadata viewer does not work in the current [Napari bundle](https://napari.org/stable/tutorials/fundamentals/installation.html#install-as-a-bundled-app) version (August 2023). Use the [python package version](https://napari.org/stable/tutorials/fundamentals/installation.html#install-as-python-package-recommended) of Napari for this feature.**

If you encounter any problems or would like any functionality added, please [file an issue](https://docs.github.com/en/issues/tracking-your-work-with-issues/creating-an-issue) along with a detailed description.

Current maintainer(s): [Nicki Shaw](https://docs.github.com/en/issues/tracking-your-work-with-issues/creating-an-issue)

## Preview

Images A and B show different frames in the same image stack, the metadata plugin on the right shows the changing focus value.
![NapariEMD screenshots](Images/napariEMD_screenshots.jpg)

## To Do

- Attatch last-opened information, so the widget does not reset when frames are changed and open toggle options are open remain.
- Add a search bar for navigating metadata.
- Output metadata as file option.
- Add note to change order of open files to replacee active metadata view.
- Make Singleframe note update automatically on change of file order.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-EMD.get_reader,,napari-EMD.load_widget,,['*.emd'],,
193,napari-em-reader,napari-em-reader,napari-em-reader,0.1.0,2021-02-23,2021-02-23,Lorenzo Gaifas,brisvag@gmail.com,BSD-3,https://github.com/brisvag/napari-em-reader,https://pypi.org/project/napari-em-reader/,,https://github.com/brisvag/napari-em-reader,A napari plugin to read .em files,>=3.6,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'emfile (>=0.2)']","# napari-em-reader

[![License](https://img.shields.io/pypi/l/napari-em-reader.svg?color=green)](https://github.com/brisvag/napari-em-reader/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-em-reader.svg?color=green)](https://pypi.org/project/napari-em-reader)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-em-reader.svg?color=green)](https://python.org)
[![tests](https://github.com/brisvag/napari-em-reader/workflows/tests/badge.svg)](https://github.com/brisvag/napari-em-reader/actions)
[![codecov](https://codecov.io/gh/brisvag/napari-em-reader/branch/master/graph/badge.svg)](https://codecov.io/gh/brisvag/napari-em-reader)

A napari plugin to read .em files

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-em-reader` via [pip]:

    pip install napari-em-reader

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-em-reader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/brisvag/napari-em-reader/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,napari-em-reader.napari_get_reader,,,,['*'],,
194,napari-epyseg,napari-epyseg,Napari-EpySeg,0.0.4,2025-02-12,2025-02-13,GaÃ«lle Letort,,BSD-3-Clause,https://github.com/gletort/napari-epyseg/issues,https://pypi.org/project/napari-epyseg/,,https://github.com/gletort/napari-epyseg,Napari plugin to segment epithelia with EpySeg,>=3.8,"['epyseg', 'napari<=0.4.19', 'numpy', 'magicgui', 'tifffile<=2021.11.2', 'pillow', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-epyseg

Plugin to run [EpySeg](https://github.com/baigouy/EPySeg) directly in [Napari](https://napari.org/stable/).
Can handle temporal data (movie) or single time point (image).

## Installation

To install it from Napari, go into the `Plugins` menu, select `Install/Uninstall Plugins..` and look for napari-epyseg in the plugins list.

To install it directly outside of napari, create/reuse and activate a python environement, e.g `epyseg_env` and install it with `pip`:
```
pip install napari-epyseg
```

## Usage

In Napari, go to `Plugins>napari-epyseg` to start it.
It will open an interface in the left part of the main window.

![interface_image](./imgs/napepy-interface.png)

You must select the layer (image or movie, single color channel) on which to run `EpySeg`.
For this, in the `Pick an Image` parameter, select the corresponding layer (you should open the image/movie independantly of the plugin).

To run `EpySeg` with default parameters, press directly `Segment` once you have selected the image.
When processing is finished, a new layer called `Segmentation` will be added in the right panel of the interface.
You can save the result with the `Save segmentation` button that appears on the left part of the interface. 
Choose where to save the file and the file name with the `Segmentation filename` parameter, and click the button to save it.

![results_image](./imgs/result.png)

## Remark

This plugin was tested on python 3.10, with epyseg version 0.1.52, napari version 0.4.19


## License

This plugin is distributed under the BDS-3 license
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/gletort/napari-epyseg/issues', 'Documentation, https://github.com/gletort/napari-epyseg#README.md', 'Source Code, https://github.com/gletort/napari-epyseg', 'User Support, https://github.com/gletort/napari-epyseg/issues']",,,napari-epyseg.start,,,,
195,napari-event-monitor,napari-event-monitor,Napari Event Monitor,0.1.3,2025-07-16,2025-07-16,Ian Coccimiglio,Ian Coccimiglio <icoccimi@gmail.com>,Unavailable,https://github.com/ian-coccimiglio/napari-event-monitor/issues/,https://pypi.org/project/napari-event-monitor/,,,Dynamic event monitoring and diagnostics in napari,>3.10,,"# napari-event-monitor
Testing and Documenting the napari Event Loop
","['Programming Language :: Python :: 3', 'Operating System :: OS Independent', 'Framework :: napari']","['Homepage, https://github.com/ian-coccimiglio/napari-event-monitor', 'Issues, https://github.com/ian-coccimiglio/napari-event-monitor/issues/']",,,napari-event-monitor.make_monitor,,,,
196,napari-exodeepfinder,napari-exodeepfinder,Napari ExoDeepFinder,0.0.11,2024-06-28,2024-10-23,"Constantin Aronssohn, Arthur Masson",cnstt@tutanota.com,GPL-3.0-only,https://github.com/deep-finder/napari-exodeepfinder/issues,https://pypi.org/project/napari-exodeepfinder/,,https://github.com/deep-finder/napari-exodeepfinder,"A napari plugin for the ExpDeepFinder library which includes display, annotation, target generation, segmentation and clustering functionalities. An orthoslice view has been added for an easier visualisation and annotation process.",>=3.9,"['exodeepfinder>=0.3.11', 'typing>=3.7.4.3', 'pandas>=2.2.2', 'pillow>=10.3.0', 'napari[all]>=0.4.19; extra == ""all""', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari[all]>=0.4.19; extra == ""testing""']","# napari-exodeepfinder

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-exodeepfinder.svg?color=green)](https://github.com/deep-finder/napari-exodeepfinder/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-exodeepfinder.svg?color=green)](https://pypi.org/project/napari-exodeepfinder)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-exodeepfinder.svg?color=green)](https://python.org)
[![tests](https://github.com/deep-finder/napari-exodeepfinder/workflows/tests/badge.svg)](https://github.com/deep-finder/napari-exodeepfinder/actions)
[![codecov](https://codecov.io/gh/deep-finder/napari-exodeepfinder/branch/main/graph/badge.svg)](https://codecov.io/gh/deep-finder/napari-exodeepfinder)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-exodeepfinder)](https://napari-hub.org/plugins/napari-exodeepfinder)

A napari plugin for the ExoDeepFinder library which includes display, annotation, target generation, segmentation and clustering functionalities.
An orthoslice view has been added for an easier visualisation and annotation process.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

1. Create a conda environment with python 3.10: `conda create -n napari-exodeepfinder python=3.10`
1. Activate the environment: `conda activate napari-exodeepfinder`
1. Install napari: `pip install napari-exodeepfinder`

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-exodeepfinder"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/deep-finder/napari-exodeepfinder/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Education', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Scientific/Engineering :: Information Analysis', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Artificial Intelligence', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']","['Bug Tracker, https://github.com/deep-finder/napari-exodeepfinder/issues', 'Documentation, https://deep-finder.github.io/napari-exodeepfinder/', 'Source Code, https://github.com/deep-finder/napari-exodeepfinder', 'User Support, https://github.com/deep-finder/napari-exodeepfinder/issues']",napari-exodeepfinder.get_reader,napari-exodeepfinder.write_annotations,napari-exodeepfinder.make_reorder_widget,,"['*.mrc', '*.map', '*.rec', '*.h5', '*.tif', '*.TIF', '*.xml', '*.ods', '*.xls', '*.xlsx']",['.xml'],['.mrc']
197,napari-explorer,napari-explorer,Explorer,0.0.2,2023-01-31,2023-01-31,Tim Monko,timmonko@gmail.com,BSD-3-Clause,https://github.com/TimMonko/napari-explorer,https://pypi.org/project/napari-explorer/,,https://github.com/TimMonko/napari-explorer,"Browse files in a folder, filter, and open within napari",>=3.8,"['numpy', 'magicgui', 'qtpy', 'napari', 'napari-aicsimageio', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-explorer

[![License BSD-3](https://img.shields.io/pypi/l/napari-explorer.svg?color=green)](https://github.com/TimMonko/napari-explorer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-explorer.svg?color=green)](https://pypi.org/project/napari-explorer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-explorer.svg?color=green)](https://python.org)
[![tests](https://github.com/TimMonko/napari-explorer/workflows/tests/badge.svg)](https://github.com/TimMonko/napari-explorer/actions)
[![codecov](https://codecov.io/gh/TimMonko/napari-explorer/branch/main/graph/badge.svg)](https://codecov.io/gh/TimMonko/napari-explorer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-explorer)](https://napari-hub.org/plugins/napari-explorer)

Browse files in a folder, filter, and open within napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-explorer` via [pip]:

    pip install napari-explorer




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-explorer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-explorer.folder_explorer,,,,
198,napari-fast4dreg,napari-fast4dreg,Fast4DReg,0.0.1,2024-07-03,2024-07-03,Marcel Issler,"marcel.issler@kuleuven.be, marcel.issler@vib.be",BSD-3-Clause,,https://pypi.org/project/napari-fast4dreg/,None,,"Dask empowered multidim, rigid registration for volumetric measurements",>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'matplotlib', 'zarr', 'tqdm', 'scipy', 'pandas', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-fast4dreg

[![License BSD-3](https://img.shields.io/pypi/l/napari-fast4dreg.svg?color=green)](https://github.com/Macl-I/napari-fast4dreg/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-fast4dreg.svg?color=green)](https://pypi.org/project/napari-fast4dreg)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-fast4dreg.svg?color=green)](https://python.org)
[![tests](https://github.com/Macl-I/napari-fast4dreg/workflows/tests/badge.svg)](https://github.com/Macl-I/napari-fast4dreg/actions)
[![codecov](https://codecov.io/gh/Macl-I/napari-fast4dreg/branch/main/graph/badge.svg)](https://codecov.io/gh/Macl-I/napari-fast4dreg)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-fast4dreg)](https://napari-hub.org/plugins/napari-fast4dreg)

Dask empowered multi-dimensional, registration for volumetric measurements.
This is a python port of the original Fast4DReg Fiji Plugin, with added rotation correction in lateral direction and support for out of memory processing.
The original paper can be found here:
https://journals.biologists.com/jcs/article/136/4/jcs260728/287682/Fast4DReg-fast-registration-of-4D-microscopy

----------------------------------


<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-fast4dreg` via [pip]:

    pip install napari-fast4dreg

## Usage 

It's easy! 
1) Just drag and drop your image, or the test image from this repository, into napari and open it normally. 
Don't worry if your file is big, napari already internally uses dask to open even the biggest images (although it might hurt the performance).
2) Open the napari-fast4dreg plugin from the plugin menu.
3) In the image row, make sure your image is selected in the image drop down menu.
4) In the axes row, choose the structure of your input image. If your axis orientation is correct in ImageJ choose the standard TZCYX (ImageJ) orientation. If you are using python to process the image you probabbly are using the alternatively availabe CTZYX orientation. In this case just select CTZYX in the drop down menu instead.
5) Select the reference channel used for the registration. The drift will be determined for this reference channel and applied to all other channels. Counting begins by 0. In case for the test image we select the nuclear signal in channel 1.
6) Select the corrections that you want to apply on your image. Note that the crop function reduces only in xy, according to the previously determined drift. (e.g. drift = -5 in x --> drop 5 pixels from the left hand side of the registered stack.)
7) Wait for output (this may take a while, so go and get a coffe or tea).
8) Enjoy your registered image.


## Example Outcome
The output will consist of the following (if chosen): 
- registered.tif: The registered file, output of this image registration pipeline.
- tmp_data: This folder was used for temporary data saving and stores at the end the registered image in a chunked manner (can be deleted or dragged into napari for a greater data versatility)
- drifts.csv: csv table, home to the drift of all corrected variables, if you prefer your own plotting style, here is where you find the pure drift table.
- XY-Drift.svg: Vector based graphic, visualising the drift in lateral direction. The svg format can be opened by your web browser or directly imported to powerpoint. Key advantage of .svg instead of .png: You can resize any way you like without loss of image quality.
- Z-Drift.svg: Vector based graphic, visualising the drift in axial direction.
- Rotation-Drift.svg: Showing rotation correction of the image in lateral direction.
  
![3D_MIP_registration](./media/3D_registration.gif)
![3D_plane](./media/3D_plane_registration.gif)
![XY-Drift](./media/XY-Drift.svg)
![Z-Drift](./media/Z-Drift.svg)
![Rotation-Drift](./media/Rotation-Drift.svg)

## Contributing

Contributions are very welcome. Just send me an E-mail: marcel.issler@kuleuven.be or directly submit a pull request.

## Credit 
This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## License

Distributed under the terms of the [BSD-3] license,
""napari-fast4dreg"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-fast4dreg.get_reader,napari-fast4dreg.write_multiple,napari-fast4dreg.make_function_widget,napari-fast4dreg.make_sample_data,['*.npy'],,['.npy']
199,napari-error-reporter,napari-error-reporter,Napari Error Reporter,0.3.1,2022-02-13,2022-06-21,Talley Lambert,talley.lambert@gmail.com,BSD-3-Clause,https://github.com/tlambert03/napari-error-reporter,https://pypi.org/project/napari-error-reporter/,,https://github.com/tlambert03/napari-error-reporter,Opt-in automated bug/error reporting for napari,>=3.8,"['appdirs', 'qtpy', 'sentry-sdk', ""black ; extra == 'dev'"", ""flake8 ; extra == 'dev'"", ""flake8-docstrings ; extra == 'dev'"", ""ipython ; extra == 'dev'"", ""isort ; extra == 'dev'"", ""jedi (<0.18.0) ; extra == 'dev'"", ""mypy ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""pydocstyle ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'"", ""tox-conda ; extra == 'testing'""]","# ð napari-error-reporter

[![License](https://img.shields.io/pypi/l/napari-error-reporter.svg?color=green)](https://github.com/tlambert03/napari-error-reporter/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-error-reporter.svg?color=green)](https://pypi.org/project/napari-error-reporter)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-error-reporter.svg?color=green)](https://python.org)
[![CI](https://github.com/tlambert03/napari-error-reporter/actions/workflows/ci.yml/badge.svg)](https://github.com/tlambert03/napari-error-reporter/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/tlambert03/napari-error-reporter/branch/main/graph/badge.svg)](https://codecov.io/gh/tlambert03/napari-error-reporter)

Want to help out napari?  Install this plugin!

This plugin will automatically send error reports to napari (via
[sentry.io](https://sentry.io)) whenever an exception occurs while you are using
napari.

The first time you run napari after installing this plugin an opt-in
notification will appear (Be sure to click ""yes"", otherwise no reports will be
collected or sent).  You may opt back out at any time in napari's help menu.

Every effort is made to strip these reports of personally identifiable
information.  Here is an example exception event:

<details>

<summary>Example bug report</summary>

```python
{
    'breadcrumbs': {
        'values': [
            {
                'category': 'subprocess',
                'data': {},
                'message': 'sw_vers -productVersion',
                'timestamp': '2022-02-02T01:30:00.216738Z',
                'type': 'subprocess'
            }
        ]
    },
    'contexts': {
        'runtime': {
            'build': '3.9.9 | packaged by conda-forge | (main, Dec 20 2021, 02:41:37) \n[Clang 11.1.0 ]',
            'name': 'CPython',
            'version': '3.9.9'
        }
    },
    'environment': 'macOS-10.15.7-x86_64-i386-64bit',
    'event_id': '02dd8ddd3a4b4743af3d7d7a09949df4',
    'exception': {
        'values': [
            {
                'mechanism': None,
                'module': None,
                'stacktrace': {
                    'frames': [
                        {
                            'context_line': '                x = 1 / 0',
                            'filename': 'napari_error_reporter/_util.py',
                            'function': 'get_sample_event',
                            'in_app': True,
                            'lineno': 130,
                            'module': 'napari_error_reporter._util',
                            'post_context': [
                                '            except Exception:',
                                '                with sentry_sdk.push_scope() as scope:',
                                '                    for k, v in _get_tags().items():',
                                '                        scope.set_tag(k, v)',
                                '                    del v, k, scope'
                            ],
                            'pre_context': [
                                ""            # remove locals that wouldn't really be there"",
                                '            del settings, _trans, kwargs, client, EVENT',
                                '            try:',
                                '                some_variable = 1',
                                '                another_variable = ""my_string""'
                            ]
                        }
                    ]
                },
                'type': 'ZeroDivisionError',
                'value': 'division by zero'
            }
        ]
    },
    'extra': {'sys.argv': ['napari']},
    'level': 'error',
    'modules': {
        'aicsimageio': '4.5.2',
        'aicspylibczi': '3.0.4',
        'aiohttp': '3.8.1',
        'aiosignal': '1.2.0',
        'alabaster': '0.7.12',
        'anyio': '3.5.0',
        'appdirs': '1.4.4',
        'appnope': '0.1.2',
        'argon2-cffi': '21.3.0',
        'argon2-cffi-bindings': '21.2.0',
        'arrow': '1.2.1',
        'asciitree': '0.3.3',
        'asttokens': '2.0.5',
        'async-timeout': '4.0.2',
        'atomium': '1.0.11',
        'attrs': '21.4.0',
        'autopep8': '1.6.0',
        'babel': '2.9.1',
        'backcall': '0.2.0',
        'bcrypt': '3.2.0',
        'beautifulsoup4': '4.10.0',
        'binaryornot': '0.4.4',
        'black': '20.8b1',
        'bleach': '4.1.0',
        'bracex': '2.2.1',
        'build': '0.7.0',
        'cachey': '0.2.1',
        'cellpose': '0.6.5',
        'certifi': '2021.10.8',
        'cffi': '1.15.0',
        'cfgv': '3.3.1',
        'chardet': '4.0.0',
        'charset-normalizer': '2.0.10',
        'check-manifest': '0.47',
        'click': '7.1.2',
        'click-option-group': '0.5.3',
        'cloudpickle': '2.0.0',
        'colorama': '0.4.4',
        'commonmark': '0.9.1',
        'cookiecutter': '1.7.3',
        'coverage': '6.2',
        'cryptography': '36.0.1',
        'cycler': '0.11.0',
        'dask': '2022.1.0',
        'debugpy': '1.5.1',
        'decorator': '5.1.1',
        'defusedxml': '0.7.1',
        'distlib': '0.3.4',
        'dnspython': '2.2.0',
        'docstring-parser': '0.13',
        'docutils': '0.16',
        'elementpath': '2.4.0',
        'email-validator': '1.1.3',
        'entrypoints': '0.3',
        'executing': '0.8.2',
        'fancycompleter': '0.9.1',
        'fasteners': '0.17.2',
        'fastremap': '1.12.2',
        'filelock': '3.4.2',
        'flake8': '3.8.4',
        'fonttools': '4.28.5',
        'freetype-py': '2.2.0',
        'frozenlist': '1.3.0',
        'fsspec': '2022.1.0',
        'furo': '2022.1.2',
        'gitdb': '4.0.9',
        'gitpython': '3.1.26',
        'greenlet': '1.1.2',
        'heapdict': '1.0.1',
        'hsluv': '5.0.2',
        'hypothesis': '6.35.1',
        'identify': '2.4.4',
        'idna': '3.3',
        'imagecodecs': '2021.11.20',
        'imageio': '2.10.5',
        'imageio-ffmpeg': '0.4.5',
        'imagesize': '1.3.0',
        'importlib-metadata': '4.10.1',
        'iniconfig': '1.1.1',
        'install': '1.3.5',
        'intervaltree': '3.1.0',
        'ipykernel': '6.7.0',
        'ipython': '8.0.0',
        'ipython-genutils': '0.2.0',
        'ipywidgets': '7.6.5',
        'jedi': '0.18.1',
        'jinja2': '3.0.3',
        'jinja2-time': '0.2.0',
        'jsonschema': '3.2.0',
        'jupyter': '1.0.0',
        'jupyter-book': '0.12.1',
        'jupyter-cache': '0.4.3',
        'jupyter-client': '7.1.1',
        'jupyter-console': '6.4.0',
        'jupyter-core': '4.9.1',
        'jupyter-server': '1.13.3',
        'jupyter-server-mathjax': '0.2.3',
        'jupyter-sphinx': '0.3.2',
        'jupyterlab-pygments': '0.1.2',
        'jupyterlab-widgets': '1.0.2',
        'jupytext': '1.11.5',
        'kiwisolver': '1.3.2',
        'latexcodec': '2.0.1',
        'linkify-it-py': '1.0.3',
        'llvmlite': '0.38.0',
        'locket': '0.2.1',
        'loguru': '0.5.3',
        'lxml': '4.7.1',
        'magicgui': '0.3.5.dev18+g78d1687',
        'markdown-it-py': '1.1.0',
        'markupsafe': '2.0.1',
        'matplotlib': '3.5.1',
        'matplotlib-inline': '0.1.3',
        'mccabe': '0.6.1',
        'mdit-py-plugins': '0.2.8',
        'meshzoo': '0.9.2',
        'mistune': '0.8.4',
        'mrc': '0.2.0',
        'msgpack': '1.0.3',
        'multidict': '5.2.0',
        'mypy': '0.931',
        'mypy-extensions': '0.4.3',
        'myst-nb': '0.13.1',
        'myst-parser': '0.15.2',
        'napari': '0.4.14rc1.dev4+gcdf58d44b',
        'napari-aicsimageio': '0.4.1',
        'napari-console': '0.0.4',
        'napari-dv': '0.2.7.dev0+g54e1691.d20220128',
        'napari-error-reporter': '0.1.dev1+g1b388f2.d20220201',
        'napari-hello': '0.0.1',
        'napari-math': '0.0.1a0',
        'napari-micromanager': '0.0.1rc6.dev14+g5149788.d20220128',
        'napari-molecule-reader': '0.1.2.dev1+gc2ec2de',
        'napari-plugin-engine': '0.2.0',
        'napari-pyclesperanto-assistant': '0.12.0',
        'napari-skimage-regionprops': '0.2.9',
        'napari-svg': '0.1.6',
        'napari-time-slicer': '0.4.2',
        'napari-workflows': '0.1.2',
        'natsort': '8.0.2',
        'nbclient': '0.5.10',
        'nbconvert': '6.4.0',
        'nbdime': '3.1.1',
        'nbformat': '5.1.3',
        'nd2': '0.1.4',
        'nest-asyncio': '1.5.4',
        'networkx': '2.6.3',
        'nodeenv': '1.6.0',
        'notebook': '6.4.7',
        'npe2': '0.1.1',
        'numba': '0.55.0',
        'numcodecs': '0.9.1',
        'numpy': '1.20.3',
        'numpydoc': '1.1.0',
        'ome-types': '0.2.10',
        'opencv-python-headless': '4.5.5.62',
        'packaging': '21.3',
        'pandas': '1.3.5',
        'pandocfilters': '1.5.0',
        'paramiko': '2.9.2',
        'parso': '0.8.3',
        'partd': '1.2.0',
        'pathspec': '0.9.0',
        'pdbpp': '0.10.3',
        'peewee': '3.14.8',
        'pep517': '0.12.0',
        'pexpect': '4.8.0',
        'pickleshare': '0.7.5',
        'pillow': '8.4.0',
        'pint': '0.18',
        'pip': '21.3.1',
        'platformdirs': '2.4.1',
        'pluggy': '1.0.0',
        'pooch': '1.5.2',
        'poyo': '0.5.0',
        'pre-commit': '2.16.0',
        'prometheus-client': '0.12.0',
        'prompt-toolkit': '3.0.24',
        'psutil': '5.9.0',
        'psygnal': '0.2.0',
        'ptyprocess': '0.7.0',
        'pure-eval': '0.2.1',
        'py': '1.11.0',
        'pybtex': '0.24.0',
        'pybtex-docutils': '1.0.1',
        'pyclesperanto-prototype': '0.12.0',
        'pycodestyle': '2.8.0',
        'pycparser': '2.21',
        'pydantic': '1.9.0',
        'pydata-sphinx-theme': '0.7.2',
        'pyflakes': '2.2.0',
        'pygments': '2.11.2',
        'pymmcore': '10.1.1.70.5',
        'pymmcore-plus': '0.1.8',
        'pynacl': '1.5.0',
        'pyopencl': '2021.2.13',
        'pyopengl': '3.1.5',
        'pyparsing': '3.0.6',
        'pyperclip': '1.8.2',
        'pyrepl': '0.9.0',
        'pyro5': '5.13.1',
        'pyrsistent': '0.18.1',
        'pyside2': '5.15.2.1',
        'pytest': '6.2.5',
        'pytest-cookies': '0.6.1',
        'pytest-cov': '3.0.0',
        'pytest-faulthandler': '2.0.1',
        'pytest-order': '1.0.1',
        'pytest-qt': '4.0.2',
        'python-dateutil': '2.8.2',
        'python-dotenv': '0.19.2',
        'python-slugify': '5.0.2',
        'pytomlpp': '1.0.10',
        'pytools': '2021.2.9',
        'pytz': '2021.3',
        'pywavelets': '1.2.0',
        'pyyaml': '6.0',
        'pyzmq': '22.3.0',
        'qtconsole': '5.2.2',
        'qtpy': '2.0.0',
        'regex': '2021.11.10',
        'requests': '2.27.1',
        'rich': '11.0.0',
        'rmsd': '1.4',
        'ruamel.yaml': '0.17.20',
        'ruamel.yaml.clib': '0.2.6',
        'scikit-image': '0.19.1',
        'scipy': '1.7.3',
        'semgrep': '0.78.0',
        'send2trash': '1.8.0',
        'sentry-sdk': '1.5.4',
        'serpent': '1.40',
        'setuptools': '60.5.0',
        'shiboken2': '5.15.2.1',
        'six': '1.16.0',
        'smmap': '5.0.0',
        'sniffio': '1.2.0',
        'snowballstemmer': '2.2.0',
        'sortedcontainers': '2.4.0',
        'soupsieve': '2.3.1',
        'sourcery-cli': '0.10.0',
        'sphinx': '4.4.0',
        'sphinx-autodoc-typehints': '1.12.0',
        'sphinx-book-theme': '0.1.10',
        'sphinx-comments': '0.0.3',
        'sphinx-copybutton': '0.4.0',
        'sphinx-external-toc': '0.2.3',
        'sphinx-jupyterbook-latex': '0.4.6',
        'sphinx-multitoc-numbering': '0.1.3',
        'sphinx-panels': '0.6.0',
        'sphinx-tabs': '3.2.0',
        'sphinx-thebe': '0.0.10',
        'sphinx-togglebutton': '0.2.3',
        'sphinxcontrib-applehelp': '1.0.2',
        'sphinxcontrib-bibtex': '2.2.1',
        'sphinxcontrib-devhelp': '1.0.2',
        'sphinxcontrib-htmlhelp': '2.0.0',
        'sphinxcontrib-jsmath': '1.0.1',
        'sphinxcontrib-qthelp': '1.0.3',
        'sphinxcontrib-serializinghtml': '1.1.5',
        'sqlalchemy': '1.4.29',
        'stack-data': '0.1.4',
        'superqt': '0.2.5.post2.dev7+ga49bcd7',
        'tensorstore': '0.1.16',
        'terminado': '0.12.1',
        'testpath': '0.5.0',
        'text-unidecode': '1.3',
        'tifffile': '2021.11.2',
        'toml': '0.10.2',
        'tomli': '2.0.0',
        'toolz': '0.11.2',
        'torch': '1.10.1',
        'tornado': '6.1',
        'tox': '3.24.5',
        'tox-conda': '0.9.1',
        'tqdm': '4.62.3',
        'traitlets': '5.1.1',
        'transforms3d': '0.3.1',
        'transitions': '0.8.10',
        'typed-ast': '1.5.1',
        'typer': '0.4.0',
        'typing-extensions': '4.0.1',
        'uc-micro-py': '1.0.1',
        'urllib3': '1.26.8',
        'useq-schema': '0.1.1.dev13+g01d1b46.d20220120',
        'valerius': '0.2.0',
        'virtualenv': '20.13.0',
        'vispy': '0.9.4',
        'watchdog': '2.1.6',
        'wcmatch': '8.3',
        'wcwidth': '0.2.5',
        'webencodings': '0.5.1',
        'websocket-client': '1.2.3',
        'wheel': '0.37.1',
        'widgetsnbextension': '3.5.2',
        'wmctrl': '0.4',
        'wrapt': '1.13.3',
        'wurlitzer': '3.0.2',
        'xarray': '0.20.2',
        'xmlschema': '1.9.2',
        'yarl': '1.7.2',
        'zarr': '2.10.3',
        'zipp': '3.7.0'
    },
    'platform': 'python',
    'release': '0.4.14rc1.dev4+gcdf58d44b',
    'sdk': {
        'integrations': [
            'aiohttp',
            'argv',
            'atexit',
            'dedupe',
            'excepthook',
            'logging',
            'modules',
            'sqlalchemy',
            'stdlib',
            'threading',
            'tornado'
        ],
        'name': 'sentry.python',
        'packages': [{'name': 'pypi:sentry-sdk', 'version': '1.5.4'}],
        'version': '1.5.4'
    },
    'server_name': '',
    'tags': {
        'platform.name': 'MacOS 10.15.7',
        'platform.system': 'Darwin',
        'qtpy.API_NAME': 'PySide2',
        'qtpy.QT_VERSION': '5.15.2'
    },
    'timestamp': '2022-02-02T01:30:00.229122Z'
}
```

</details>

> ***NOTE**: in the opt-in dialog, there is a checkbox labeled ""include local variables"",
checking this will include the value of variables in the local scope when an exception
occurs.  While these can be very useful when interpreting a bug report, they may
occasionally include local file path strings.  If that concerns you, please leave this
box unchecked*

## Install

This plugin requires napari version 0.4.15 or greater, or the `main` branch with PR
[napari/napari#4055](https://github.com/napari/napari/pull/4055).

Install via pip with:

```sh
pip install napari-error-reporter
```

or in the built-in plugin installer (a restart will be required):

<img width=""503"" alt=""Untitled"" src=""https://user-images.githubusercontent.com/1609449/153915128-09a5e3d7-8561-4c17-b543-5ea172e3e860.png"">


Thank you!!

## Privacy FAQ

Even with the multiple layers of opt-ins, and the attempts to wipe all personal info
prior to sending reports, we understand that privacy is always a concern.

### Do you collect personal info?

We make every attempt to collect ***no*** personally identifiable information.  No
name, location, IP address, etc...  We do collect your
([`uuid.getnode()`](https://docs.python.org/3.10/library/uuid.html#uuid.getnode)) to
be able to track bug resolution over time. As mentioned above, allowing local
variables to be collected may occasionally include a file path in the log.
If that concerns you, please leave that unchecked.

### Is this shipped with napari?

`napari-error-reporter` is **not** bundled with napari or listed as a napari dependency.
In order for reports to be sent, you must first install this plugin yourself, and then
opt in on the next launch.  If you uninstall the plugin, no more reports can be sent.

### Who can access these reports?

Only the following napari core developers have access to these reports.
If [this](https://raw.githubusercontent.com/tlambert03/napari-error-reporter/main/ADMINS)
list changes in the future, you will be asked to opt-in again in napari:

- Juan Nunez-Iglesias ([@jni](https://github.com/jni))
- Talley Lambert ([@tlambert03](https://github.com/tlambert03))

*This plugin is **not** associated with the Chan Zuckerberg Initiative*.

### How will these reports be used?

Commonly occuring errors will be will be manually purged of file paths and
local variables and posted to https://github.com/napari/napari/issues

### How long is data retained

Sentry retains event data for 90 days by default.  For complete details,
see Sentry's page on [Security & Compliance](https://sentry.io/security/)
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'License :: OSI Approved :: BSD License', 'Natural Language :: English', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10']","['Source Code, https://github.com/tlambert03/napari-error-reporter']",,,,,,,
200,napari-feature-visualization,napari-feature-visualization,Napari Feature Visualization,0.0.2,2024-07-25,2025-06-27,"Joel Luethi, Adrian Tschan",joel.luethi@uzh.ch,"Copyright (c) 2024, Joel Lueth...",https://github.com/fractal-napari-plugins-collection/napari-feature-visualization/issues,https://pypi.org/project/napari-feature-visualization/,,,Visualizing feature measurements on label images in napari,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'matplotlib', 'pandas', 'packaging', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-feature-visualization

[![License BSD-3](https://img.shields.io/pypi/l/napari-feature-visualization.svg?color=green)](https://github.com/fractal-napari-plugins-collection/napari-feature-visualization/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-feature-visualization.svg?color=green)](https://pypi.org/project/napari-feature-visualization)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-feature-visualization.svg?color=green)](https://python.org)
[![tests](https://github.com/fractal-napari-plugins-collection/napari-feature-visualization/workflows/tests/badge.svg)](https://github.com/fractal-napari-plugins-collection/napari-feature-visualization/actions)
[![codecov](https://codecov.io/gh/fractal-napari-plugins-collection/napari-feature-visualization/branch/main/graph/badge.svg)](https://codecov.io/gh/fractal-napari-plugins-collection/napari-feature-visualization)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-feature-visualization)](https://napari-hub.org/plugins/napari-feature-visualization)

Visualizing feature measurements on label images in napari

<img src=""https://github.com/user-attachments/assets/d2c83d70-d122-4e08-812f-12c5e6006488"" alt=""feature_vis_demo"" style=""width: 100%;""/>

Supports both loading features from a CSV file or visualizing features saved in the label_layer.features dataframe. Through plugins like the [napari OME-Zarr navigator](https://github.com/fractal-napari-plugins-collection/napari-ome-zarr-navigator), this enables visualizing feature measurements stored in OME-Zarrs.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-feature-visualization` via [pip]:

    pip install napari-feature-visualization



To install latest development version :

    pip install git+https://github.com/fractal-napari-plugins-collection/napari-feature-visualization.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-feature-visualization"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/fractal-napari-plugins-collection/napari-feature-visualization/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/fractal-napari-plugins-collection/napari-feature-visualization/issues', 'Documentation, https://github.com/fractal-napari-plugins-collection/napari-feature-visualization#README.md', 'Source Code, https://github.com/fractal-napari-plugins-collection/napari-feature-visualization', 'User Support, https://github.com/fractal-napari-plugins-collection/napari-feature-visualization/issues']",,,napari-feature-visualization.feature_vis,napari-feature-visualization.make_sample_data,,,
201,napari-feature-classifier,napari-feature-classifier,napari feature classifier,0.3.2,2022-02-12,2025-06-27,Joel Luethi and Max Hess,joel.luethi@uzh.ch,BSD-3-Clause,https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/issues,https://pypi.org/project/napari-feature-classifier/,,https://github.com/fractal-napari-plugins-collection/napari-feature-classifier,An interactive classifier plugin to use with label images and feature measurements,>=3.9,"['numpy', 'napari', 'matplotlib', 'magicgui', 'pandas>=2.2.0', 'scikit-learn>=1.2.2', 'pandera', 'xxhash', 'hypothesis']","# napari-feature-classifier

[![License](https://img.shields.io/pypi/l/napari-feature-classifier.svg?color=green)](https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-feature-classifier.svg?color=green)](https://pypi.org/project/napari-feature-classifier)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-feature-classifier.svg?color=green)](https://python.org)
[![tests](https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/workflows/tests/badge.svg)](https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/actions)
[![codecov](https://codecov.io/gh/fractal-napari-plugins-collection/napari-feature-classifier/branch/main/graph/badge.svg)](https://codecov.io/gh/fractal-napari-plugins-collection/napari-feature-classifier)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-feature-classifier)](https://napari-hub.org/plugins/napari-feature-classifier)

An interactive classifier plugin that allows the user to assign objects in a label image to multiple classes and train a classifier to learn those classes based on a feature dataframe.

## Usage
<p align=""center""><img src=""https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/assets/18033446/1ebf0890-1a7b-4e4b-a21c-88ca8f1dd800"" /></p>

To use the napari-feature-classifier, you need to have a label image and corresponding measurements: as a csv file, loaded to layer.features or in an [OME-Zarr Anndata table loaded with another plugin](https://github.com/fractal-napari-plugins-collection/napari-ome-zarr-navigator). Your feature measurements need to contain a `label` column that matches the label objects in the label image.
These interactive classification workflows are well suited to visually define cell types, find mitotic cells in images, do quality control by automatically detecting missegmented cells and other tasks where a user can easily assign objects to groups.

#### Prepare the label layer:
- Load your label layer into napari and add the features measurements to layer.features of the corresponding label layer. You can have multiple label layers with their features open at the same time
    - To load features from a CSV file: `Plugins -> napari-feature-classifier -> CSV Feature Loader`, then load the features for the correct label image.
    - To load features from an OME-Zarr file: Get both the label layer into memory as a normal label layer (not a pyramidal label layer, currently untested) and the corresponding features. If your OME-Zarr file is created by [Fractal](https://fractal-analytics-platform.github.io/), you can use [this ROI loader plugin](https://github.com/jluethi/napari-ome-zarr-roi-loader).
    - To load features from anywhere else, load them manually to your label_layer.features
- Your feature table should have 2 columns used for indexing (but stored as normal columns in layer.features):
    - The `label` column to match the object in the label image
    - The `roi_id` column to identify the image you're currently classifying (used when a classifier is trained on multiple label images)


#### Initialize a classifier:
- Start the classifier in napari by going to `Plugins -> napari-feature-classifier -> Initialize a Classifier`  
- Select the features you want to use for the classifier (you need to do the feature selection before initializing. The feature selection can't be changed after initialization anymore). Hold the command key to select multiple features. Feature options are always shown for the features available in the last selected label layer, based on layer.features available features.
- (Optional) Give your classes recognizable names (e.g. Mitotic & Interphase, Cell Type a, b and c etc.)
<img width=""1606"" alt=""Screenshot 2023-05-09 at 11 46 35"" src=""https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/assets/18033446/452c0d6a-98a3-4e2d-9233-33bfd5bcad19"">




#### Classify objects:
<img width=""1802"" alt=""Classifier_annotation"" src=""https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/assets/18033446/556739b8-972b-4570-9da4-637738fc6a75"">

- Make sure you have the label layer selected on which you want to classify
- Select the current class with the radio buttons or by pressing 0, 1, 2, etc.
- Click on label objects in the viewer to assign them to the currently selected class
- Once you have trained enough examples, click ""Run Classifier"" to run the classifier and have it make a prediction for all objects. Aim for at least a dozen annotations per class, as the classifier divides your annotations 80/20 in training and test sets. 
- Once you get predictions, correct mistakes the classifier made and retrain it to improve its performance.
- You can save the classifier under a different name or in a different location. Define the new output location and then click `Save Classifier` (you need to click the Save Classifier button. Just defining the new output path does not save it yet. But every run of the classifier triggers an autosave)
<img width=""1802"" alt=""Classifier_prediction"" src=""https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/assets/18033446/69cff600-4585-4a66-9274-d2e7caeb335f"">



#### Apply the classifier to additional images:
- You can apply a classifier trained on one image to additional label images. Use `Plugins -> napari-feature-classifier -> Load Classifier`  
- Select the classifier (.clf file with the name you gave above) while already having the label images ready (see `Prepare the label layer` above).
- Click Load Classifier, proceed as above.
<img width=""1606"" alt=""Screenshot 2023-05-09 at 12 01 00"" src=""https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/assets/18033446/e1143f9f-9729-4f8e-979c-2ab195e0aaca"">



#### Export classifier results
- To export the training data and the results of the classifier, define an Export Name (full path to an output file or just a filename ending in .csv) where the results of the classifier shall be saved. It defaults to the layer name for the selected layer in the last directory you chose (or the current working directory if none was chosen so far)
- Click `Export Classifier Result` (Just selecting a filename is not enough, you need to click the export button). This will export the predictions for the currently selected layer.
- The results of the classifier are save in a csv file. The label is an integer of the label object within that image. The prediction column contains predictions of the classifier for all objects (except those that contained NaNs in their feature data) and the annotation column contains the annotations you made (NaN for unclassified objects, -1 for objects you deselected, 1 - 9 for the classes)
<img width=""1802"" alt=""Classifier_prediction"" src=""https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/assets/18033446/e8f6f7b7-d88b-44f8-b43e-8a2fa81e18d4"">


#### Batch mode result export
(To be updated: Create a new notebook to run batch processing, this is for the older version of the classifier)
There is a simple workflow for the classifier in the examples folder:
- Install jupyter-lab (`pip install jupyterlab`)
- Open the notebook in jupyter lab (Type `jupyter-lab` in the terminal when you are in the examples folder)
- Follow the instructions to generate an example dataframe and an example label image
- Use the classifier in napari with this simplified data


#### Initializing the Annotator
You can use the annotation functionality also independently from the classifier
Start the annotator widget by going to `Plugins -> napari-feature-classifier -> Annotator`
Select names for your classes. You can name up to 9 classes. Only classes that you give a name will be created upon initialization.
Then click `Initialize`.

<img width=""1411"" alt=""Screenshot 2023-02-16 at 14 49 38"" src=""https://user-images.githubusercontent.com/18033446/219384524-9873bd66-270b-4cdd-b913-60d390f6c77a.png"">

A annotator widget opens. Use the Radio-Buttons to select what class you're annotating (or keybindings for 1-9 for classes, 0 for deselect).
The annotator will always work on the currently selected label layer. While the annotator is open, you can't edit the labels. Restart napari to allow editing of labels again.

<img width=""1411"" alt=""Screenshot 2023-02-16 at 14 50 00"" src=""https://user-images.githubusercontent.com/18033446/219384925-b20e4c1a-2eca-4070-8269-902493c5d5ef.png"">

The annotations are saved in the `layer.features` table of the corresponding label layer as an `annotations` column.
<img width=""1411"" alt=""Screenshot 2023-02-16 at 15 01 01"" src=""https://user-images.githubusercontent.com/18033446/219385788-f61bd0a5-fbb6-42d7-81e5-f77ee4d1b4ff.png"">


## Installation

This plugin is written for the new napari npe2 plugin engine. Thus, it requires napari >= 0.4.13.
Activate your environment where you have napari installed (or install napari using `pip install ""napari[all]""`), then install the classifier plugin:

    pip install napari-feature-classifier

The layer.features dataframes have some issues in napari 0.4.17 (see [here](https://github.com/napari/napari/issues/5617)). They seem to be working again in the nighlty builds. To set up a nightly builds napari env, do the following:

```
conda create -n classifier-dev-napari-main -c ""napari/label/nightly"" -c conda-forge napari python=3.10 -y
```
    
## Similar napari plugins
If you're looking for other classification approaches, [apoc](https://github.com/haesleinhuepf/apoc) by [Robert Haase](https://github.com/haesleinhuepf) has a pixel classifier in napari and an object classification workflow:  
[napari-accelerated-pixel-and-object-classification (APOC)](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification)  
Alternatively, ClÃ©ment Cazorla has built [napari-svetlana, a deep learning based classifier](https://www.napari-hub.org/plugins/napari-svetlana)

## Release process
1. Update the version number in src/napari-feature-classifier/__init__.py
2. Update the version in setup.cfg
3. Add a Github release with a new version tag (matching the version set above)
4. Once tests pass, this should automatically be deployed to pypi
5. Wait for conda automation to make a PR for an updated conda release (see https://github.com/conda-forge/napari-feature-classifier-feedstock). This can take 1-2 days. Make sure that PR gets merged.


## Contributing

Contributions are very welcome.

## License

Distributed under the terms of the [BSD-3] license,
""napari-feature-classifier"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

## Contributors
[Joel LÃ¼thi](https://github.com/jluethi) & [Max Hess](https://github.com/MaksHess)

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/issues', 'Documentation, https://github.com/fractal-napari-plugins-collection/napari-feature-classifier#napari-feature-classifier', 'Source Code, https://github.com/fractal-napari-plugins-collection/napari-feature-classifier', 'User Support, https://github.com/fractal-napari-plugins-collection/napari-feature-classifier/issues']",,,napari-feature-classifier.annotator_init_widget,,,,
202,napari-figure,napari-figure,Figure,0.1.1,2023-06-02,2023-06-02,romainGuiet,romain.guiet@epfl.ch,BSD-3-Clause,https://github.com/BIOP/napari-figure/issues,https://pypi.org/project/napari-figure/,,https://github.com/BIOP/napari-figure,Making Figure with napari more easily,>=3.8,"['numpy', 'magicgui', 'qtpy', 'microfilm', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-figure

[![License BSD-3](https://img.shields.io/pypi/l/napari-figure.svg?color=green)](https://github.com/romainGuiet/napari-figure/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-figure.svg?color=green)](https://pypi.org/project/napari-figure)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-figure.svg?color=green)](https://python.org)
[![tests](https://github.com/romainGuiet/napari-figure/workflows/tests/badge.svg)](https://github.com/romainGuiet/napari-figure/actions)
[![codecov](https://codecov.io/gh/romainGuiet/napari-figure/branch/main/graph/badge.svg)](https://codecov.io/gh/romainGuiet/napari-figure)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-figure)](https://napari-hub.org/plugins/napari-figure)

Making Figure with napari more easily

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-figure` via [pip]:

    pip install napari-figure



To install latest development version :

    pip install git+https://github.com/romainGuiet/napari-figure.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-figure"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/romainGuiet/napari-figure/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/BIOP/napari-figure/issues', 'Documentation, https://github.com/BIOP/napari-figure#README.md', 'Source Code, https://github.com/BIOP/napari-figure', 'User Support, https://github.com/BIOP/napari-figure/issues']",,,napari-figure.make_qwidget,,,,
203,napari-features,napari-features,napari-features,0.1.4,2021-06-17,2021-08-24,Allen Goodman,allen.goodman@icloud.com,MIT,https://github.com/0x00b1/napari-features/issues,https://pypi.org/project/napari-features/,,https://github.com/0x00b1/napari-features,extracts image and object features,>=3.7,"['magicgui (>=0.2.9)', 'napari (>=0.4.10)', 'napari-plugin-engine (>=0.1.4)', 'numpy (>=1.19.5)', 'pandas (>=1.2.4)', 'qtpy (>=1.9.0)', 'scikit-image (>=0.18.1)', 'scipy (>=1.4.1)']","# napari-features

[![License](https://img.shields.io/pypi/l/napari-features.svg?color=green)](https://github.com/0x00b1/napari-features/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-features.svg?color=green)](https://pypi.org/project/napari-features)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-features.svg?color=green)](https://python.org)
[![tests](https://github.com/0x00b1/napari-features/workflows/tests/badge.svg)](https://github.com/0x00b1/napari-features/actions)
[![codecov](https://codecov.io/gh/0x00b1/napari-features/branch/master/graph/badge.svg)](https://codecov.io/gh/0x00b1/napari-features)

An extensible, general-purpose feature extraction plug-in for the [Napari](https://napari.org) image viewer.

## Features

### Color

#### Image

    color_image_integrated_intensity
    color_image_maximum_intensity
    color_image_mean_intensity
    color_image_median_absolute_deviation_intensity
    color_image_median_intensity
    color_image_minimum_intensity
    color_image_quantile_1_intensity
    color_image_quantile_3_intensity
    color_image_standard_deviation_intensity

#### Object

    color_object_center_mass_intensity_x
    color_object_center_mass_intensity_y
    color_object_integrated_intensity
    color_object_integrated_intensity_edge
    color_object_mass_displacement
    color_object_maximum_intensity
    color_object_maximum_intensity_edge
    color_object_maximum_intensity_x
    color_object_maximum_intensity_y
    color_object_mean_intensity
    color_object_mean_intensity_edge
    color_object_median_absolute_deviation_intensity
    color_object_median_intensity
    color_object_median_intensity_edge
    color_object_minimum_intensity
    color_object_minimum_intensity_edge
    color_object_quantile_1_intensity
    color_object_quantile_1_intensity_edge   
    color_object_quantile_3_intensity
    color_object_quantile_3_intensity_edge
    color_object_standard_deviation_intensity
    color_object_standard_deviation_intensity_edge
    Object distribution
    color_object_distribution_coefficient_of_variation_intensity
    color_object_distribution_integrated_intensity
    Color_object_distribution_mean_intensity

### Location

#### Object neighborhood

    location_object_neighborhood_angle
    location_object_neighborhood_closest_0_distance
    location_object_neighborhood_closest_0_object_index
    location_object_neighborhood_closest_1_distance
    location_object_neighborhood_closest_1_object_index
    location_object_neighborhood_closest_2_distance
    location_object_neighborhood_closest_2_object_index
    location_object_neighborhood_neighbors
    location_object_neighborhood_touching

### Metadata

#### Image

    metadata_image_checksum
    metadata_image_filename

#### Layer

    metadata_layer_name
    metadata_layer_type

#### Object

    metadata_object_index

### Shape

#### Image

    shape_image_area

#### Image skeleton

    shape_image_skeleton_branches
    shape_image_skeleton_endpoints
    shape_image_skeleton_length
    shape_image_skeleton_trunks

#### Object

    shape_object_area
    shape_object_bounding_box_area
    shape_object_bounding_box_maximum_x
    shape_object_bounding_box_maximum_y
    shape_object_bounding_box_maximum_z
    shape_object_bounding_box_minimum_x
    shape_object_bounding_box_minimum_y
    shape_object_bounding_box_minimum_z
    shape_object_bounding_box_volume
    shape_object_central_moment_0_0_0
    shape_object_central_moment_0_0_1
    shape_object_central_moment_0_1_2
    shape_object_central_moment_0_1_3
    shape_object_central_moment_1_2_0
    shape_object_central_moment_1_2_1
    shape_object_central_moment_1_3_2
    shape_object_central_moment_1_3_3
    shape_object_central_moment_2_0_0
    shape_object_central_moment_2_0_1
    shape_object_central_moment_2_1_2
    shape_object_central_moment_2_1_3
    shape_object_central_moment_3_2_0
    shape_object_central_moment_3_2_1
    shape_object_central_moment_3_3_2
    shape_object_central_moment_3_3_3
    shape_object_centroid_x
    shape_object_centroid_y
    shape_object_centroid_z
    shape_object_compactness
    shape_object_eccentricity
    shape_object_equivalent_diameter
    shape_object_euler_number
    shape_object_extent
    shape_object_form_factor
    shape_object_hu_moment_0
    shape_object_hu_moment_1
    shape_object_hu_moment_2
    shape_object_hu_moment_3
    shape_object_hu_moment_4
    shape_object_hu_moment_5
    shape_object_hu_moment_6
    shape_object_inertia_tensor_eigenvalues_x
    shape_object_inertia_tensor_eigenvalues_y
    shape_object_inertia_tensor_eigenvalues_z
    shape_object_inertia_tensor_x_x
    shape_object_inertia_tensor_x_y
    Shape_object_inertia_tensor_x_z
    shape_object_inertia_tensor_y_x
    shape_object_inertia_tensor_y_y
    shape_object_inertia_tensor_y_z
    shape_object_inertia_tensor_z_x
    shape_object_inertia_tensor_z_y
    shape_object_inertia_tensor_z_z
    shape_object_major_axis_length
    shape_object_maximum_feret_diameter
    shape_object_maximum_radius
    shape_object_mean_radius
    shape_object_median_radius
    shape_object_minimum_feret_diameter
    shape_object_minor_axis_length
    shape_object_normalized_moment_x_y
    shape_object_orientation
    shape_object_perimeter
    shape_object_solidity
    shape_object_spatial_moment_0_0_0
    shape_object_spatial_moment_0_0_1
    shape_object_spatial_moment_0_1_2
    shape_object_spatial_moment_0_1_3
    shape_object_spatial_moment_1_2_0
    shape_object_spatial_moment_1_2_1
    shape_object_spatial_moment_1_3_2
    shape_object_spatial_moment_1_3_3
    shape_object_spatial_moment_2_0_0
    shape_object_spatial_moment_2_0_1
    shape_object_spatial_moment_2_1_2
    shape_object_spatial_moment_2_1_3
    shape_object_spatial_moment_3_2_0
    shape_object_spatial_moment_3_2_1
    shape_object_spatial_moment_3_3_2
    shape_object_spatial_moment_3_3_3
    shape_object_surface_area
    shape_object_volume
    shape_object_zernike shape features
    Object skeleton
    shape_object_skeleton_endpoints
    shape_object_skeleton_branches
    shape_object_skeleton_length
    shape_object_skeleton_trunks

### Texture

#### Object

    texture_object_haralick_angular_second_moment
    texture_object_haralick_contrast
    texture_object_haralick_coorelation
    texture_object_haralick_sum_of_squares_variance
    texture_object_haralick_inverse_difference_moment
    texture_object_haralick_sum_average
    texture_object_haralick_sum_variance
    texture_object_haralick_sum_entropy
    texture_object_haralick_entropy
    texture_object_haralick_difference_variance
    texture_object_haralick_measure_of_correlation_0
    texture_object_haralick_measure_of_correlation_1
    texture_object_haralick_maximum_correlation_coefficient


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/0x00b1/napari-features/issues', 'Documentation, https://github.com/0x00b1/napari-features#README.md', 'Source Code, https://github.com/0x00b1/napari-features', 'User Support, https://github.com/0x00b1/napari-features/issues']",,,,,,,
204,napari-features-selector,napari-features-selector,Features Selection GA,0.0.4,2023-03-28,2023-03-29,Sanjeev Kumar,kumar.san96@gmail.com,BSD-3-Clause,https://github.com/kumar-sanjeeev/napari-features-selector/issues,https://pypi.org/project/napari-features-selector/,,https://github.com/kumar-sanjeeev/napari-features-selector,A lightweight widget for features selection.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'pandas', 'scikit-learn', 'sklearn-genetic-opt', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-features-selector

[![License BSD-3](https://img.shields.io/pypi/l/napari-features-selector.svg?color=green)](https://github.com/kumar-sanjeeev/napari-features-selector/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-features-selector.svg?color=green)](https://pypi.org/project/napari-features-selector)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-features-selector.svg?color=green)](https://python.org)
[![tests](https://github.com/kumar-sanjeeev/napari-features-selector/workflows/tests/badge.svg)](https://github.com/kumar-sanjeeev/napari-features-selector/actions)
[![codecov](https://codecov.io/gh/kumar-sanjeeev/napari-features-selector/branch/main/graph/badge.svg)](https://codecov.io/gh/kumar-sanjeeev/napari-features-selector)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-features-selector)](https://napari-hub.org/plugins/napari-features-selector)


An interactive plugin that enables users to choose the important/relevant features from a set of multiple features. These selected features can then be applied to various tasks like object detection, segmentation, classification, among others.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-features-selector` via [pip]:

    pip install napari-features-selector





## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-features-selector"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kumar-sanjeeev/napari-features-selector/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kumar-sanjeeev/napari-features-selector/issues', 'Documentation, https://github.com/kumar-sanjeeev/napari-features-selector#README.md', 'Source Code, https://github.com/kumar-sanjeeev/napari-features-selector', 'User Support, https://github.com/kumar-sanjeeev/napari-features-selector/issues']",,,napari-features-selector.gui_GA,,,,
205,napari-file2folder,napari-file2folder,Save multidimensional file as folder of tifs,0.0.4,2024-10-28,2025-06-12,Jules Vanaret,jules.vanaret@univ-amu.fr,MIT,,https://pypi.org/project/napari-file2folder/,None,,Save multidimensional file as folder of tifs,>=3.9,"['numpy', 'qtpy', 'magicgui', 'tifffile', 'bioio', 'bioio-ome-tiff', 'bioio-ome-zarr', 'bioio-nd2', 'bioio-czi', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-file2folder

[![License MIT](https://img.shields.io/pypi/l/napari-file2folder.svg?color=green)](https://github.com/GuignardLab/napari-file2folder/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-file2folder.svg?color=green)](https://pypi.org/project/napari-file2folder)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-file2folder.svg?color=green)](https://python.org)
[![tests](https://github.com/jules-vanaret/napari-file2folder/workflows/tests/badge.svg)](https://github.com/jules-vanaret/napari-file2folder/actions)
[![codecov](https://codecov.io/gh/jules-vanaret/napari-file2folder/branch/main/graph/badge.svg)](https://codecov.io/gh/jules-vanaret/napari-file2folder)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-file2folder)](https://napari-hub.org/plugins/napari-file2folder)

<img src=""https://github.com/GuignardLab/tapenade/blob/main/imgs/tapenade3.png"" width=""100"">

A plugin to inspect bioimages (e.g. .tif, .czi, .nd2, .lsm...) and save them as individual .tif files in a folder.

`napari-file2folder` is a [napari] plugin that is part of the [Tapenade](https://github.com/GuignardLab/tapenade) project. Tapenade is a tool for the analysis of dense 3D tissues acquired with deep imaging microscopy. It is designed to be user-friendly and to provide a comprehensive analysis of the data.

If you use this plugin for your research, please [cite us](https://github.com/GuignardLab/tapenade/blob/main/README.md#how-to-cite).

## Overview

<img src=""imgs/napari-file2folder-demo.gif""/>

This plugin allows you to inspect (possibly large) bioimages by displaying their shape (number of elements in each dimension), and allowing you to save each element along a chosen dimension as a separate .tif file in a folder. This is useful when you have a large movie or stack of images and you want to save each frame or slice as a separate file. Optionally, the plugin allows the user to visualize the middle element of a given dimension to help the user decide which dimension to save as separate files.

The plugin currently supports the following file formats:
- .tif
- .ome.tiff
- .zarr
- .ome.zarr
- .nd2
- .lsm
- .czi

This plugin leverages [tifffile], [bioio], and [zarr] to circumvent loading the entire images in memory, which allows inspection of very large images.

> [!CAUTION]
> When inspecting the middle element of a dimension, or when saving one element of a dimension as a separate file, the plugin loads the element in memory, which means that at least this lone element must fit in memory.

## Installation

The plugin obviously requires [napari] to run. If you don't have it yet, follow the instructions [here](https://napari.org/stable/tutorials/fundamentals/installation.html).

The simplest way to install `napari-file2folder` is via the [napari] plugin manager. Open Napari, go to `Plugins > Install/Uninstall Packages...` and search for `napari-file2folder`. Click on the install button and you are ready to go!

You can install `napari-file2folder` via [pip]:

    pip install napari-file2folder




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-file2folder"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[tifffile]: https://github.com/cgohlke/tifffile
[bioio]: https://github.com/bioio-devs/bioio
[zarr]: https://github.com/zarr-developers/zarr-python
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-file2folder.make_qwidget,,,,
206,napari-filaments,napari-filaments,napari filaments,0.3.0,2022-07-01,2023-06-04,Hanjin Liu,liuhanjin-sc@g.ecc.u-tokyo.ac.jp,BSD-3-Clause,https://github.com/hanjinliu/napari-filaments/issues,https://pypi.org/project/napari-filaments/,,https://github.com/hanjinliu/napari-filaments,A napari plugin for filament analysis,>=3.9,"['magic-class (>=0.7.3)', 'magicgui', 'matplotlib', 'numpy', 'qtpy', 'scipy', ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""roifile ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-filaments

[![License BSD-3](https://img.shields.io/pypi/l/napari-filaments.svg?color=green)](https://github.com/hanjinliu/napari-filaments/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-filaments.svg?color=green)](https://pypi.org/project/napari-filaments)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-filaments.svg?color=green)](https://python.org)
[![tests](https://github.com/hanjinliu/napari-filaments/workflows/tests/badge.svg)](https://github.com/hanjinliu/napari-filaments/actions)
[![codecov](https://codecov.io/gh/hanjinliu/napari-filaments/branch/main/graph/badge.svg)](https://codecov.io/gh/hanjinliu/napari-filaments)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-filaments)](https://napari-hub.org/plugins/napari-filaments)

A napari plugin for filament analysis.

This plugin helps you to manually track filaments using path shapes of `Shapes` layer.

![](https://github.com/hanjinliu/napari-filaments/raw/main/resources/fit.gif)

Currently implemented functions

- Fit paths to filaments in an image as a 2-D spline curve.
- Clip/extend paths.
- Measurement of filament length at sub-pixel precision.
- Basic quantification (mean, std, etc.) along paths.
- Import paths from ImageJ ROI file.

Basic Usage
-----------

Click `Layers > open image` to open a tif file. You'll find the image you chose and a shapes layer are added to the layer list.

![](https://github.com/hanjinliu/napari-filaments/raw/main/resources/fig-1.png)

- The ""target filaments"" box shows the working shapes layer.
- The ""target image"" box shows the image layer on which fitting and quantification will be conducted.
- The ""filament"" box shows currently selected shape (initially this box is empty).

Add path shapes and push key `F1` to fit the shape to the filament in the target image layer.

- In the ""Spline"" tab, you can cut/extend or re-fit splines.
- In the ""Measure"" tab, click ""measure property"" to measure mean instensity etc along each spline.

How it works
------------

Spline fitting is done as following.

![](https://github.com/hanjinliu/napari-filaments/raw/main/resources/fig-2.png)


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


## Installation

You can install `napari-filaments` via [pip]:

    pip install napari-filaments



To install latest development version :

    pip install git+https://github.com/hanjinliu/napari-filaments.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-filaments"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hanjinliu/napari-filaments/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/hanjinliu/napari-filaments/issues', 'Documentation, https://github.com/hanjinliu/napari-filaments#README.md', 'Source Code, https://github.com/hanjinliu/napari-filaments', 'User Support, https://github.com/hanjinliu/napari-filaments/issues']",,,napari-filaments.make_qwidget,,,,
207,napari-filter-labels-by-prop,napari-filter-labels-by-prop,Filter labels by properties,0.1.0,2025-01-24,2025-03-04,LoÃ¯c Sauteur,loic.sauteur@unibas.ch,"Copyright (c) 2025, LoÃ¯c Saute...",https://github.com/loicsauteur/napari-filter-labels-by-prop/issues,https://pypi.org/project/napari-filter-labels-by-prop/,,,A simple plugin to filter labels by properites.,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'matplotlib', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-filter-labels-by-prop

[![License BSD-3](https://img.shields.io/pypi/l/napari-filter-labels-by-prop.svg?color=green)](https://github.com/loicsauteur/napari-filter-labels-by-prop/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-filter-labels-by-prop.svg?color=green)](https://pypi.org/project/napari-filter-labels-by-prop)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-filter-labels-by-prop.svg?color=green)](https://python.org)
[![tests](https://github.com/loicsauteur/napari-filter-labels-by-prop/workflows/tests/badge.svg)](https://github.com/loicsauteur/napari-filter-labels-by-prop/actions)
[![codecov](https://codecov.io/gh/loicsauteur/napari-filter-labels-by-prop/branch/main/graph/badge.svg)](https://codecov.io/gh/loicsauteur/napari-filter-labels-by-prop)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-filter-labels-by-prop)](https://napari-hub.org/plugins/napari-filter-labels-by-prop)

A simple plugin to filter labels by properties.

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->
## Description

This plugin provides the possibility to filter segmentation objects by measurements
(shape and intensity). E.g. you segmented your cells, and you want to exclude segmentation objects
that have a mean intensity below a certain value.

It is intended for 2D and 3D images.

You can interactively set minimum and maximum thresholds on measurement properties, and
napari will show a preview of the selection.

Measurements are based on `scikit-image regionprops`. However, not all properties are
implemented, and they are more restricted for 3D images.

## Usage: Quick start

![](https://github.com/loicsauteur/napari-filter-labels-by-prop/raw/main/resources/preview_filter_labels.gif)

1. Start napari
2. Start the plugin from the menu: `Plugins > Filter labels by properties`
3. Add a label image
4. (optionally) Add a corresponding intensity image with the same (Z)YX shape
5. In the widget, select the property you want to filter on
6. Adjust the min/max sliders
7. When you are ready to create a new label layer click the `Create labels` button in the widget

### Usage notes:

When dealing with more than 100 label objects in an image, the filtering view update is
triggered only once you release the sliders.

Another similar plugin you could consider checking out:
[napari-skimage-regionprops](https://www.napari-hub.org/plugins/napari-skimage-regionprops).

Pixel/Voxel size are read from the napari layer scale attribute (defaults to 1 if not specified when adding the layer).
You can manually enter the size and press the `Set` button, which will set the layer scale,
and measure the shape properties with calibrated units

The ""Measure projected shape properties"" option is only available for 3D images.
It measures additional properties of Z-projected labels (including: ""area"", ""convex_area"", ""circularity"" and ""perimeter"").

The ""Measure cytoplasm and cell compartments"" is intended for label images that represent nuclei.
With this option selected, cytoplasm and cell masks will be created by a dilation of 5 units (pixels or calibrated).
Measurement in those compartments will be made and be used to filter on.
`Create labels` will also add the respective cytoplasm and cell mask layers to the napari viewer.

<!--
         ## TODO: add feature measurement also to layer.features?
-->
## Installation

You can install `napari-filter-labels-by-prop` via [pip]:

    pip install napari-filter-labels-by-prop


To install latest development version :

    pip install git+https://github.com/loicsauteur/napari-filter-labels-by-prop.git

<!--
Install Test dependencies
    `pip install -e "".[testing]""`
-->

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-filter-labels-by-prop"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/loicsauteur/napari-filter-labels-by-prop/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/loicsauteur/napari-filter-labels-by-prop/issues', 'Documentation, https://github.com/loicsauteur/napari-filter-labels-by-prop#README.md', 'Source Code, https://github.com/loicsauteur/napari-filter-labels-by-prop', 'User Support, https://github.com/loicsauteur/napari-filter-labels-by-prop/issues']",,,napari-filter-labels-by-prop._filter_by_widget,,,,
208,napari-filament-annotator,napari-filament-annotator,napari 3D filament annotator,0.1.2,2022-10-04,2022-10-06,Anna Medyukhina,anna.medyukhina@gmail.com,Apache-2.0,https://github.com/amedyukhina/napari-filament-annotator/issues,https://pypi.org/project/napari-filament-annotator/,,https://github.com/amedyukhina/napari-filament-annotator,Annotation of filaments / curvilinear structures in 3D,>=3.8,"['Geometry3D', 'networkx', 'numpy', 'magicgui', 'pandas', 'qtpy', 'scipy', 'sklearn', 'imageio (!=2.22.1)', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# 3D Filament Annotator

[![DOI](https://zenodo.org/badge/513980347.svg)](https://zenodo.org/badge/latestdoi/513980347)
[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-filament-annotator.svg?color=green)](https://github.com/amedyukhina/napari-filament-annotator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-filament-annotator.svg?color=green)](https://pypi.org/project/napari-filament-annotator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-filament-annotator.svg?color=green)](https://python.org)
[![tests](https://github.com/amedyukhina/napari-filament-annotator/workflows/tests/badge.svg)](https://github.com/amedyukhina/napari-filament-annotator/actions)
[![codecov](https://codecov.io/gh/amedyukhina/napari-filament-annotator/branch/main/graph/badge.svg)](https://codecov.io/gh/amedyukhina/napari-filament-annotator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-filament-annotator)](https://napari-hub.org/plugins/napari-filament-annotator)

3D Filament Annotator is a tool for annotating filaments and other curvilinear structures in 3D. 
The 3D annotation is done by annotating the filament in two different projections, 
calculating intersection, and refining the filament position with active contours.

![demo](https://raw.githubusercontent.com/amedyukhina/napari-filament-annotator/main/docs/demo_09.gif)


## Installation

### Install napari

    pip install napari[all]

### Install the filament annotator

<!--
You can install `napari-filament-annotator` via [pip]:

    pip install napari-filament-annotator


To install latest development version :
-->
    pip install git+https://github.com/amedyukhina/napari-filament-annotator.git

## Usage

For detailed usage instructions, please refer to the [usage tutorial](docs/tutorial.md).

## Contributing

Contributions are very welcome both with regard to plugin functionality, and
tips on using it and setting parameters. 

Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-filament-annotator"" is free and open source software

## Dependencies

- [napari](https://github.com/napari/napari)
- [scikit-image](https://scikit-image.org/)
- [scikit-learn](https://github.com/scikit-learn/scikit-learn)
- [NetworkX](https://networkx.org/documentation/stable/index.html)
- [Geometry3D](https://github.com/GouMinghao/Geometry3D)


## Issues

If you encounter any problems, please [file an issue] along with a detailed description.


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->


[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/amedyukhina/napari-filament-annotator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/amedyukhina/napari-filament-annotator/issues', 'Documentation, https://github.com/amedyukhina/napari-filament-annotator#README.md', 'Source Code, https://github.com/amedyukhina/napari-filament-annotator', 'User Support, https://github.com/amedyukhina/napari-filament-annotator/issues']",,,napari-filament-annotator.make_annotator_widget,napari-filament-annotator.load_sample_image,,,
209,napari-flim-phasor-plotter,napari-flim-phasor-plotter,FLIM phasor plotter,0.2.0,2023-08-17,2025-06-23,"Marcelo L. Zoccoler, Cornelia Wetzker",marzoccoler@gmail.com,BSD-3-Clause,https://github.com/zoccoler/napari-flim-phasor-plotter/issues,https://pypi.org/project/napari-flim-phasor-plotter/,,https://github.com/zoccoler/napari-flim-phasor-plotter,A plugin that performs phasor plot from TCSPC FLIM data.,>=3.9,"['numpy', 'magicgui', 'qtpy', 'napari>=0.4.19', 'napari-clusters-plotter<0.9.0,>=0.8.1', 'ptufile', 'sdtfile', 'natsort', 'rocket-fft', 'dask', 'zarr', 'napari-segment-blobs-and-things-with-membranes', 'napari-skimage-regionprops', 'scikit-image>=0.20.0', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-flim-phasor-plotter

[![License BSD-3](https://img.shields.io/pypi/l/napari-flim-phasor-plotter.svg?color=green)](https://github.com/zoccoler/napari-flim-phasor-plotter/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-flim-phasor-plotter.svg?color=green)](https://pypi.org/project/napari-flim-phasor-plotter)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-flim-phasor-plotter.svg?color=green)](https://python.org)
[![tests](https://github.com/zoccoler/napari-flim-phasor-plotter/workflows/tests/badge.svg)](https://github.com/zoccoler/napari-flim-phasor-plotter/actions)
[![codecov](https://codecov.io/gh/zoccoler/napari-flim-phasor-plotter/branch/main/graph/badge.svg)](https://codecov.io/gh/zoccoler/napari-flim-phasor-plotter)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-flim-phasor-plotter)](https://napari-hub.org/plugins/napari-flim-phasor-plotter)
[![DOI](https://zenodo.org/badge/578127094.svg)](https://zenodo.org/doi/10.5281/zenodo.12620955)

Napari-flim-phasor-plotter is a [napari](https://napari.org/stable/) plugin to interactively load and show raw fluorescence lifetime imaging microscopy (FLIM) single images and series and generate phasor plots. These are Fourier transforms of the decay data being visualized using the [napari-clusters-plotter](https://github.com/BiAPoL/napari-clusters-plotter) plotter, adapted to suit the FLIM context. This allows qualitative and quantitative downstream analysis of FLIM images.  

----------------------------------

## Quick demo

![](https://github.com/zoccoler/napari-flim-phasor-plotter/raw/main/images/napari_FLIM_phasor_calculator_Demo.gif)

## Documentation

Please check our [documentation](https://napari-flim-phasor-plotter.readthedocs.io/en/latest/) for more details on how to install and use this plugin.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-flim-phasor-plotter"" is free and open source software. 

If you use this plugin in a publication, please cite us: https://doi.org/10.5281/zenodo.12620956

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/zoccoler/napari-flim-phasor-plotter/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/zoccoler/napari-flim-phasor-plotter/issues', 'Documentation, https://github.com/zoccoler/napari-flim-phasor-plotter#README.md', 'Source Code, https://github.com/zoccoler/napari-flim-phasor-plotter', 'User Support, https://github.com/zoccoler/napari-flim-phasor-plotter/issues']",napari-flim-phasor-plotter.get_reader,,napari-flim-phasor-plotter.calculate_phasors,napari-flim-phasor-plotter.load_seminal_receptacle_image,"['*.ptu', '*.PTU', '*.sdt', '*.SDT', '*.tif', '*.zarr']",,
210,napari-findaureus,napari-findaureus,napari-findaureus,0.0.4,2024-04-20,2024-04-20,Shibarjun Mandal,shibarjunmandal@gmail.com,MIT,,https://pypi.org/project/napari-findaureus/,None,,Locate bacteria in CLSM obtained infected bone tissue images,>=3.8,"['magicgui', 'qtpy', 'napari[all]', 'aicsimageio ==4.11.0', 'nd2 ==0.5.3', 'aicspylibczi ==3.1.2', 'fsspec ==2023.5.0', 'readlif ==0.6.5', 'czifile ==2019.7.2', 'tifffile ==2023.7.10', 'webcolors ==1.13', 'opencv-python ==4.7.0.72', 'numpy ==1.24.3', 'scikit-image ==0.20.0', 'xmltodict', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-findaureus

""Findaureus"" is now available to use in napari.
<p align=""center"">
<img src=""https://raw.githubusercontent.com/shibarjun/napari-findaureus/main/docs/napari-findaureus.png"" />
</p>

Findaureus is a tool designed to identify bacteria in infected bone tissue images obtained via Confocal Laser Scanning Microscopy (CLSM). This tool can be accessed independently [here](https://github.com/shibarjun/Findaureus). Findaureus has been integrated as a plugin for napari. In addition to its bacteria-locating algorithm, the napari viewer provides improved visualization features, in 2D and 3D perspectives.

----------------------------------
## Installation
### Windows/Linux
If you donât have conda installed, you can get miniconda or Anaconda from their websites.
1. Open your command line tool and run these commands to create and activate a conda environment:
```
conda create -n napari-findaureus python=3.9
conda activate napari-findaureus
```
2. Install napari and napari-findaureus with this command:
```
pip install ""napari[all]"" napari-findaureus
```
### macOS
1. Create an environment with napari and pyqt5
```
conda create -n napari-findaureus -c conda-forge python=3.9 pyqt imagecodecs napari
```
2. Install the napari-findaureus plugin
```
pip install napari-findaureus
```

## Start napari-findaureus
Launch napari from the terminal while the napari-findaureus environment is running.
```
napari
```
To launch the napari plugin, go to âPluginsâ and select ânapari-findaureusâ.
## Quick demo
To use the `napari-findaureus` plugin, please follow the steps below:

1. First, download some relevant fluorescence-labeled images of infected mouse bone tissues from [Zenodo](https://zenodo.org/doi/10.5281/zenodo.8411791).
2. Next, load the image file through the `napari-findaureus` plugin.
3. Navigate to the âPluginsâ menu and select the `napari-findaureus` option to activate the widget.
4. In the viewer, identify the bacteria channel from the ""layer list,"" which is specified in the image file name, and select it.
5. Once the bacteria channel is selected, click on the `Find bacteria!` button.
6. The widget will display the image-related data and bacteria count. If you need additional help, click on the `Instruction` button in the widget.
7. Before you proceed to another image, reset the viewer by clicking on the `Reset` button provided in the widget.

<p align=""center"">
<img src=""https://raw.githubusercontent.com/shibarjun/napari-findaureus/main/docs/napari-findaureus.gif"" />
</p>

Enjoy exploring the fascinating world of bacteria in mouse bone tissues!

----------------------------------
## Contributing
We welcome and appreciate all contributions to the `napari-findaureus` project! Whether it's reporting bugs, suggesting new features, improving documentation, or writing code, your involvement is greatly valued.
When using our dataset or referring to our work, we kindly ask that you acknowledge the dataset and cite the related articles. This helps support our work and allows us to continue improving this project.

Thank you for your interest and support!
## Citations and Dataset
### Findaureus
 Mandal S, Tannert A, LÃ¶ffler B, Neugebauer U, Silva LB (2024) [Findaureus: An open-source application for locating Staphylococcus aureus in fluorescence-labelled infected bone tissue slices.](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0296854) PLoS ONE 19(1): e0296854.
### Infected mouse bone tissue
Mandal S, Tannert A, Ebert C, Guliev RR, Ozegowski Y, Carvalho L, Wildemann B, Eiserloh S, Coldewey SM, LÃ¶ffler B, BastiÃ£o Silva L, Hoerr V, Tuchscherr L, Neugebauer U. (2023) [Insights into S. aureus-Induced Bone Deformation in a Mouse Model of Chronic Osteomyelitis Using Fluorescence and Raman Imaging.](https://www.mdpi.com/1422-0067/24/11/9762) International Journal of Molecular Sciences 24(11):9762.

### [Dataset](https://zenodo.org/doi/10.5281/zenodo.8411791)
## Acknowledgements

This project is a part of the European Union's Horizon 2020 research and innovation program under grant agreement No 861122 (ITN IMAGE-IN). We acknowledge support from the Jena Biophotonics and Imaging Laboratory (JBIL), from the European Union via EFRE funds within the ThÃ¼ringer Innovationszentrum fÃ¼r Medizintechnik-LÃ¶sungen (ThIMEDOP, FKZ IZN 2018 0002), the BMBF via the funding program Photonics Research Germany (LPI, FKZ: 13N15713) and via the CSCC (FKZ 01EO1502) and the Institute of Anatomical and Molecular Pathology, University Coimbra, Portugal.
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-findaureus.get_reader,,napari-findaureus.make_magic_widget,,"['*.czi', '*.nd2', '*.lif', '*.tiff']",,
211,napari-fluoresfm,napari-fluoresfm,FluoResFM,0.2.3,2025-07-22,2025-07-29,Qiqi Lu,136303971@qq.com,MIT,https://github.com/qiqi-lu/napari-fluoresfm/issues,https://pypi.org/project/napari-fluoresfm/,,,A plugin to use FluoResFM model in napari.,>=3.10,"['numpy', 'magicgui', 'qtpy', 'napari', 'scikit-image', 'torch', 'torchvision', 'torchaudio', 'tqdm', 'scipy', 'open_clip_torch', 'pandas', 'pytorch_msssim', 'pydicom', 'torchinfo', 'tensorboard', 'transformers', 'openpyxl', 'napari[all]; extra == ""all""', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari[qt]; extra == ""testing""']","# napari-fluoresfm

[![License MIT](https://img.shields.io/pypi/l/napari-fluoresfm.svg?color=green)](https://github.com/qiqi-lu/napari-fluoresfm/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-fluoresfm.svg?color=green)](https://pypi.org/project/napari-fluoresfm)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-fluoresfm.svg?color=green)](https://python.org)
[![tests](https://github.com/qiqi-lu/napari-fluoresfm/workflows/tests/badge.svg)](https://github.com/qiqi-lu/napari-fluoresfm/actions)
[![codecov](https://codecov.io/gh/qiqi-lu/napari-fluoresfm/branch/main/graph/badge.svg)](https://codecov.io/gh/qiqi-lu/napari-fluoresfm)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-fluoresfm)](https://napari-hub.org/plugins/napari-fluoresfm)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

This is a `napari` plugin developed for using FluoResFM model in napari.
FluoresFM is a deep learning-based foundation model for multi-task cross-distribution restoration of fluorescence microscopic images.

FluoResFM's `napari` plugin is in early satge, therefore I highly encourage any feedback and suggestions.

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Before Installation
As FluoResFM is a deep learning-based model, it is recommended to use a GPU for inference and training on Linux system. So no choice to use CPU is provided in the plugin. Besides, as the code is depended on PyTorch and `triton` packages, you should install the plugin through command lines.

I recommand you to install the plugin in a new envoroment created by `conda` .

 First, create a new environment with `conda` and activate it.
```
conda create -y --name napari-fluoresfm python=3.12
conda activate napari-fluoresfm
```

Then, install `napari`.
```
pip install -U ""napari[all]""
```

To use GPU for inference and training, you should install the GPU version of PyTorch. You can use `nvcc -V` to check the cuda version. Then install the corresponding version of PyTorch by check the [table](https://pytorch.org/get-started/previous-versions/) provided by PyTorch. For example, if you have `cuda 12.4`, you should install the following version of PyTorch.
```
pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu124
```

We recommend you using Linux for training and inference, as the `triton` support for Windows is not stable. And the with Linux system, the acceleration of `triton` is much better than Windows, which allow larger `batch size` and `patch size` to be used in training and inference.

If you are using Windows, you should install the `triton` package first according the PyTorch version you installed. Please check this [link](https://github.com/woct0rdho/triton-windows?tab=readme-ov-file#3-pytorch) for more details.
```
pip install -U ""triton-windows<3.3""
```

## Installation

You can install `napari-fluoresfm` via [pip]:

```
pip install napari-fluoresfm
```

To install latest development version :

```
pip install git+https://github.com/qiqi-lu/napari-fluoresfm.git
```

## Functions
This plugin can be used for data preprocessing, model training, and model inference.

![interface](src/napari_fluoresfm/images/interface.png)
**Figure 1: The interface of the plugin.** **a** The label page uased for prediction of restored images. **b** The page for data preprocessing, including data patching and text embedding modules. **c** The page for model training.

**Each page can be run independetly. You only need to input the data and model information as described below from top to bottom, and click `run` button to start. To train or fine-tune the mdoel, you need to preprocess the data firstly using the `Preprocess` page. The training and fine-tuning can both be done in `Train` page.**

### Predict
This label page is used for prediction of restored images. You can select the pretrained model and the input image to predict the restored image.
#### PATH box
This box is used to select the folder for data and models.
- **Input Folder**: The folder containing the input images. The input images should be in `.tif` format with a shape of `(1, H, W)` or `(H, W)`. The model will restored the images one by one and save them into the **Output Folder**.
- **Index File**: This should be a `.txt` file containing all the file names of the images to be restored in each line. The file name should be the same as the file name of the input images.
- **Output Folder** (optional): The folder to save the restored images. If not specified, the restored images will be saved into the `#Input Folder#_fluoresfm`.
- **Embedder**: The folder saved the text embedder model. You can download the text model from my [Google Drive](https://drive.google.com/drive/folders/1pfiCHtXrf5ne6fjKJQAvwQhgBO_yVpWy?usp=sharing).
- **Checkpoint**: The pre-trained FluoResFM model checkpoint with a suffix `.pt`.

#### PARAMETERS box
This box is used to set the parameters for prediction.
- **Device**: The device to run the model. Only support `cuda`.
- **Compile model**: Whether to compile the model. If checked, the model will be compiled with `triton` for faster inference and lower BPU memory usage. But the compile process will take a few minutes. if only a few image to be restored, you can uncheck this box.
- **Input interpolation (nearest)**: Do nearest interpolation on the input image to implement super-resolution task, as the input and output image of FluoResFM have the save shape.
- **Batch size**: The batch size used during inference. Larger batch size will use more memory and faster inference. If your GPU memory is not enough, you can reduce this value.
- **Patch size**: The patch size used during inference. Larger patch size will use more memory. If your GPU memory is not enough, you can reduce this value. Different pacth size may lead to slightly different results due to the patch stiching process.
#### TEXT box
This box is used to set the text prompt for the model.
- **Task**: The task to be performed. For example, ""denoising"", ""deconvolution"", or ""super-resolution with a scale factor of 2"". When inputing ""super-resolution with a scale factor of 2"", the **Input interpolation (nearest)** should be also set as 2. Other tasks may result in unexpected results as the model is not trained for these tasks.
- **Sample**: The image sample. For example, ""fixed COS-7 cell line"".
- **Structure**: The imaging structure. For example, ""microtubules"".
- **Fluorescence indicator**: The fluorescence indicator. For example, ""mEmerald (GFP)"".
- **INPUT**: The imaging condition of image image.
    - **Microscope**: The microscope used for imaging. Such as, ""wide-field microscope"".
    - **Mircoscopy params**: The microscope parameters. For example, ""with excitation numrical aperture (NA) of 1.35, detection namerical aperture (NA) of 1.3"".
    - **Pixel size**: The pixel size of the image. For example, ""62.6 x 62.6 nm"".

- **OUTPUT**: The imaging condition of the target image.
    - **Microscope**: The microscope used for imaging. Such as, ""linear structured illumination microscopy"".
    - **Mircoscopy params**: The microscope parameters. For example, ""with excitation numrical aperture (NA) of 1.35, detection namerical aperture (NA) of 1.3"".
    - **Pixel size**: The pixel size of the image. For example, ""62.6 x 62.6 nm"".

#### RUN box
This box is used to start, stop, and watch the prediction process. Press the **run** button to start the prediction. Press the **stop** button to stop the prediction. The prediciton process will be shown in the progress bar.

### Preprocess
This page is used for data preprocessing, including data patching and text embedding modules.
#### IMAGE PATCHING box
- **PATH**
    - **Dataset Folder**: The folder containing the images to be patched. The images should be in `.tif` format with a shape of `(1, H, W)` or `(H, W)`. The model will patch the images one by one and save them into a folder named `#Dataset Folder#_p#patch size#_s#patch stride#_2d`.
    - **Index File**: This should be a `.txt` file containing all the file names of the images to be patched in each line. The file name should be the same as that of images in the **Dataset Folder**.

- **PARAMETERS**
    - **Patch size**: The size of the patch. Deault is `64`, which is same as that used for FluoResFM pretraining.
    - **Patch stride**: The stride of the patch. Deault is `64`, i.e., no overlap between patches, which is same as that used for FluoResFM pretraining.
    - **Normalization (low)**: The lower bound of the percentile-based normalization. Deault is `0.03`.
    - **Normalization (high)**: The upper bound of the percentile-based normalization. Deault is `0.995`.

- **RUN**

    This box is used to start, stop, and watch the preprocessing process. Same function as the **RUN box** in the **Predict** page.

#### EMBEDDING box
- **PATH**
    - **Excel File**: The excel file containing all the information for the datasets used for training or fine-tuning. The excel file should be in `.xlsx` format. The excel file should contain the all the columns as shown in the example data.
    - **Output Folder**: The folder to save the text embeddings. The generated text will be saved into a `.txt` file named as `dataset_text_#Text type#.txt`. The corresponding text embedding will be saved into a folder named `dataset_text_#Text type#_#Context length#`. Each `.npy` file is for each dataset. The id is corresponding to the order of the dataset in the excel file.
    - **Embedder**: The folder saved the text embedder model.

- **PARAMETERS**
    - **Device**: The device to run the model. Only support `cuda`.
    - **Context length**: The context length of the text embedding. Deault is `160`, which is same as that used for FluoResFM pretraining.
    - **Text type**: The type of the text. [""ALL"", ""T"", ""TS""], where ""ALL"" means all the text informatio will be used, ""T"" means only the task informaiton will be used, and ""TS"" means only the task and structure informaiton will be used.

- **RUN**: This box is used to start, stop, and watch the preprocessing process. Same function as the **RUN box** in the **Predict** page.

### Train
This page is used for model training.
#### PATH box
- **Information Folder**: The folder containing the information for the datasets used for training or fine-tuning, includeingt the path of input and reference images and the path of their corresponding index files. Other information should be same as the provided example.
- **Text Embedding**: The folder containing the text embeddings for the datasets used for training or fine-tuning, which should be generated first using the **EMBEDDING box** in the **Preprocess** page.
- **Checkpoint (load from)**: The pre-trained FluoResFM model checkpoint with a suffix `.pt`. If not specified, the model will be trained from scratch.
- **Finetune**: Whether to fine-tune the model. If checked, **Checkpoint (load from)** must be specified and will be fine-tuned (only the first and last convolution layers will be trainable). If not checked, all the parameters in the model wil be setted as trainable.
- **Checkpoint (save to)**: The folder  to save the trained model checkpoint. The checkpoint will be saved into a folder named `unet_sd_c_mae_bs#bactch size#_lr_#learning rate#-160-res1-att0123`. It `finetune` is checked, the folder will be added a suffix of `-ft-in-out`.
#### PARAMETERS box
- **Device**: : The device to run the model. Only support `cuda`.
- **Compile**: Whether to compile the model. The compiling of model will take a few minutes, but will accelerate the training/fine-tuning process and save the GPU memory. On Linux system, the compiling of model will be more efficient than on Windows system.
- **Batch size**: The batch size used during training.
- **Epochs**: The number of epochs used during training.
- **Learning rate**: The start learning rate.
- **Decay (every iter)**: The learning rate will decay every `#Decay (every iter)#` iterations. The decay rate is 0.5.
- **Validation (every iter)**: The validation will be performed every `#Validation (every iter)#` iterations.
- **Validation (fraction)**: The fraction of the dataset used for validation. If it is set as 0, the validation will not be performed. (0,1)*100% dataset will be used for validation.
- **Save Model (every iter)**: The model will be saved every `#Save Model (every iter)#` iterations.

#### RUN box
This box is used to start, stop, and watch the training process. Same function as the **RUN box** in the **Predict** page.

### Log
This page is used to show the working log.
Press the **CLEAR** button to clear the log.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-fluoresfm"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/qiqi-lu/napari-fluoresfm/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/qiqi-lu/napari-fluoresfm/issues', 'Documentation, https://github.com/qiqi-lu/napari-fluoresfm#README.md', 'Source Code, https://github.com/qiqi-lu/napari-fluoresfm', 'User Support, https://github.com/qiqi-lu/napari-fluoresfm/issues']",,,napari-fluoresfm.make_main_widget,,,,
212,napari-file-watcher,napari-file-watcher,napari-file-watcher,0.1.1,2023-01-16,2023-01-16,Xavier Casas Moreno,xaviercm@kth.se,GPL-3.0,https://github.com/kasasxav/napari-file-watcher/issues,https://pypi.org/project/napari-file-watcher/,,https://github.com/kasasxav/napari-file-watcher,A napari plugin for file watching,,"['napari', 'ome-zarr', 'zarr', 'h5py', 'PyQt5', 'qtpy', 'QScintilla']","# File watcher plugin for napari (napari-file-watcher)


This plugin contains two widgets: file watcher and script editor.


## Usage: file watcher

The file watcher monitors a folder and displays its images (tiff, ome-zarr or hdf5) as napari layers, watch the following video for a demo:

[![IMAGE ALT TEXT](http://img.youtube.com/vi/lFRVwlHgJ-Y/0.jpg)](https://www.youtube.com/watch?v=lFRVwlHgJ-Y ""Demo napari-file-watcher"")

Instructions:

1. Select the folder you want to monitor by pressing ""Browse"".
2. Select the extension of the files: ""zarr"", ""hdf5"" or ""tiff"".
3. Click ""Watch and run"" to display the current items & the newly arrived as napari layers.
4. If you click in one of the files of the list, the metadata will show (for hdf5 and zarr)

## Usage: scripting editor

The script editor is for developing scripts and saving them in the filesystem. 
We have used this widget in the context of developing scripts for microscopy control software that implements another file watcher.

Instructions:

1. Select the folder where you want to save your scripts in ""Browse"".
2. Type the name of the script in the edit box below.
3. Click ""Add"" for saving it into the folder after typing, or ""Open"" to display an existing file.

## Installation

You can install `napari-file-watcher` via [pip]:

    pip install napari-file-watcher

Or if you plan to develop it:

    git clone https://github.com/kasasxav/napari-file-watcher
    cd napari-file-watcher
    pip install -e .

If there is an error message suggesting that git is not installed, run `conda install git`.

## Contributing

Contributions are welcome, tests are run with pytest.

## Issues

Issues can be reported at: https://github.com/kasasxav/napari-file-watcher/issues
","['Framework :: napari', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8']","['Bug Tracker, https://github.com/kasasxav/napari-file-watcher', 'Documentation, https://github.com/kasasxav/napari-file-watcher/blob/main/README.md', 'Source Code, https://github.com/kasasxav/napari-file-watcher', 'User Support, https://github.com/kasasxav/napari-file-watcher/issues']",,,napari-file-watcher.watcher_widget,,,,
213,napari-geff,napari-geff,Geff IO,0.0.1,2025-07-23,2025-07-23,Live Image Tracking Tools (LITT) team,,"Copyright (c) 2025, Live Image...",,https://pypi.org/project/napari-geff/,None,,A reader and writer for the graph exchange file format (geff),>=3.10,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'geff==0.4.0', 'pandas', 'napari[all]; extra == ""all""', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari[qt]; extra == ""testing""']","# napari-geff

[![License BSD-3](https://img.shields.io/pypi/l/napari-geff.svg?color=green)](https://github.com/live-image-tracking-tools/napari-geff/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-geff.svg?color=green)](https://pypi.org/project/napari-geff)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-geff.svg?color=green)](https://python.org)
[![tests](https://github.com/live-image-tracking-tools/napari-geff/workflows/tests/badge.svg)](https://github.com/live-image-tracking-tools/napari-geff/actions)
[![codecov](https://codecov.io/gh/live-image-tracking-tools/napari-geff/branch/main/graph/badge.svg)](https://codecov.io/gh/live-image-tracking-tools/napari-geff)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-geff)](https://napari-hub.org/plugins/napari-geff)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

A reader and writer for the graph exchange file format (geff)

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

![geff-read](https://github.com/user-attachments/assets/bd3d510e-a9c8-490a-b499-47093f15105d)


## Installation

You can install `napari-geff` via [pip]:

```
pip install napari-geff
```

If napari is not already installed, you can install `napari-geff` with napari and Qt via:

```
pip install ""napari-geff[all]""
```

## Usage

`napari-geff` supports loading directed graphs stored as [GEFF](https://live-image-tracking-tools.github.io/geff/latest/) files into
`napari` as `Tracks` layers, and saving them back out to GEFF format.

To use `napari-geff` after installation, simply drag a GEFF file into the viewer and select `GEFF IO` from the
plugin selection dialog, if required. The file will be loaded as a `Tracks` layer.

Any node properties defined on your graph will be stored as features on your tracks layer. Edge properties
will be available under `layer.metadata['edge_properties']` as a dictionary, but cannot currently be displayed
or used for visualization in `napari`.

If your file contains `image` or `labels` related objects as per the GEFF
[spec](https://live-image-tracking-tools.github.io/geff/v0.4.0/specification/#geff_related_objects),
these will also be loaded alongside your `Tracks` layer.

If you wish to open your geff file into layers **programmatically**, you can do so using the `viewer.open` method:

```python
import napari
path = 'path/to/top_level_zarr.zarr/my-geff-group/

viewer = napari.Viewer()
layers = viewer.open(path, plugin='napari-geff')
```


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-geff"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-geff.get_reader,napari-geff.write,,napari-geff.sample_data,['*'],,
214,napari-folder-browser,napari-folder-browser,napari-folder-browser,0.1.4,2021-10-03,2024-03-26,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-folder-browser/issues,https://pypi.org/project/napari-folder-browser/,,https://github.com/haesleinhuepf/napari-folder-browser,Browse folders of images and open them using double-click,>=3.7,"['napari-plugin-engine >=0.1.4', 'napari-tools-menu']","# napari-folder-browser

[![License](https://img.shields.io/pypi/l/napari-folder-browser.svg?color=green)](https://github.com/haesleinhuepf/napari-folder-browser/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-folder-browser.svg?color=green)](https://pypi.org/project/napari-folder-browser)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-folder-browser.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-folder-browser/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-folder-browser/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-folder-browser/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-folder-browser)

Browse folders of images and open them using double-click or <ENTER>. You can also navigate through the list using arrow up/down keys.

![](https://github.com/haesleinhuepf/napari-folder-browser/raw/main/docs/napari-folder-browser.gif)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-folder-browser` from within napari by clicking menu `Plugins > Install/uninstall Plugins...` and entering here:
![img.png](https://github.com/haesleinhuepf/napari-folder-browser/raw/main/docs/install.png)

You can install `napari-folder-browser` via [pip]:

    pip install napari-folder-browser

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## Development
### Test the plugin in Napari
Simply use pip install and run napari to test the plugin in the same environment:
```bash
pip install -e .
napari
```

### Conda
If you prefer to use conda, you can create a new environment with the following command:
```bash
conda env create -f environment.yml
conda activate napari-folder-browser
```

## License

Distributed under the terms of the [BSD-3] license,
""napari-folder-browser"" is free and open source software

## Issues

If you encounter any problems, please create a thread on [image.sc] along with a detailed description and tag [@haesleinhuepf].

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-folder-browser/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[image.sc]: https://image.sc
[@haesleinhuepf]: https://twitter.com/haesleinhuepf

","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-folder-browser/issues', 'Documentation, https://github.com/haesleinhuepf/napari-folder-browser#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-folder-browser', 'User Support, https://github.com/haesleinhuepf/napari-folder-browser/issues']",,,napari-folder-browser.FolderBrowser,,,,
215,napari-grid-cropping,napari-grid-cropping,Grid cropping napari plugin,0.0.1,2024-10-08,2024-10-08,Niklas Breitenbach-Netter,niknett@gmail.com,"Copyright (c) 2024, Niklas Bre...",https://github.com/gatoniel/napari-grid-cropping/issues,https://pypi.org/project/napari-grid-cropping/,,,Create multiple crops of an image in a grid like fashion.,>=3.9,"['numpy', 'qtpy', 'tifffile', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'magicgui; extra == ""testing""']","# napari-grid-cropping

[![License BSD-3](https://img.shields.io/pypi/l/napari-grid-cropping.svg?color=green)](https://github.com/gatoniel/napari-grid-cropping/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-grid-cropping.svg?color=green)](https://pypi.org/project/napari-grid-cropping)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-grid-cropping.svg?color=green)](https://python.org)
[![tests](https://github.com/gatoniel/napari-grid-cropping/workflows/tests/badge.svg)](https://github.com/gatoniel/napari-grid-cropping/actions)
[![codecov](https://codecov.io/gh/gatoniel/napari-grid-cropping/branch/main/graph/badge.svg)](https://codecov.io/gh/gatoniel/napari-grid-cropping)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-grid-cropping)](https://napari-hub.org/plugins/napari-grid-cropping)

Create multiple crops of an image in a grid like fashion.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-grid-cropping` via [pip]:

    pip install napari-grid-cropping



To install latest development version :

    pip install git+https://github.com/gatoniel/napari-grid-cropping.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-grid-cropping"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/gatoniel/napari-grid-cropping/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/gatoniel/napari-grid-cropping/issues', 'Documentation, https://github.com/gatoniel/napari-grid-cropping#README.md', 'Source Code, https://github.com/gatoniel/napari-grid-cropping', 'User Support, https://github.com/gatoniel/napari-grid-cropping/issues']",,,napari-grid-cropping.make_grid_widget,,,,
216,napari-gemspa,napari-gemspa,GEMspa,0.0.4,2023-05-29,2023-08-04,Sarah Keegan,sarah.keegan@nyulangone.org,BSD-3-Clause,https://github.com/liamholtlab/napari-gemspa/issues,https://pypi.org/project/napari-gemspa/,,https://github.com/liamholtlab/napari-gemspa,A plugin for analysis of single particle tracking experiments,>=3.8,"['numpy', 'magicgui', 'qtpy', 'pandas', 'napari', 'scikit-image', 'gemspa-spt', 'matplotlib', 'trackpy', 'nd2', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-gemspa

This plugin provides for analysis tools for data from single particle tracking experiments.  It provides an interface for particle localization and tracking using [trackpy](http://soft-matter.github.io/trackpy/dev/index.html).  It also allows for import of tracking data from Mosaic and Trackmate.  These files must be tab/comma delimited text files.  It provides an option to exclude particles/tracks masked with a labels layer.

There are 5 tabs available in the plugin, following the workflow of data analysis:

1) **New/Open**: open nd2/tiff time-lapse movie files and/or import a tracks layer (from Mosaic, Trackmate or napari-gemspa saved tracks layer)
2) **Locate**: locate particles with trackpy
3) **Link**: link particles with trackpy
4) **Filter Links**: filter links with trackpy
5) **Analyze**: Perform analysis on tracks from a tracks layer (can be from imported file from step 1 or layer created in step 3)

**Detailed description of features:**

1) **New/Open**

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/1_1.png)

**Add layer** button will create a blank 2D (no time dimension) layer that is the same height/width as the currently selected image layer.  Alternatively, a labeled mask can be opened from a file.  The labels layer can be used to provide a mask for excluding areas of the image from analysis.

Track files from other software or previously saved by GEMspa can also be imported in this pane.  Only tab/comma (.csv/.txt/.tsv) delimited text files are allowed.

**GEMspa** expects these columns in the header: ['track_id', 'frame', 'z', 'y', 'x']

**Mosaic** expects these columns in the header: ['Trajectory', 'Frame', 'z', 'y', 'x']

**Trackmate** expects these columns in the header: ['TRACK_ID', 'FRAME', 'POSITION_Z', 'POSITION_Y', 'POSITION_X'],
* 3 rows will be skipped for Trackmate files (assumes data begins at the 4th row after the header)

**Trackpy** expects these columns in the header: ['particle', 'frame', 'z', 'y', 'x']

_(All columns are case and order insensitive)_

2) **Locate**
![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/2_1.png)

In this tab, adjust the parameters and perform particle localization with [trackpy.locate](http://soft-matter.github.io/trackpy/dev/generated/trackpy.locate.html#trackpy.locate).  To first test out parameters on a single frame, check the ""Process only current frame"" checkbox.  Please refer to the trackpy documentation for more details on parameters.

After localization is performed, a new points layer will be created and particles will be shown circled in red.  In the example, we have used a labels layer to exclude particles outside an ROI (this is optional):

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/2_2.png)

In addition, the mass histogram and subpixel bias histograms will be shown for help with adjusting the mass and diameter parameters:

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/2_3.png)

3) **Link**

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/3_1.png)

In this tab, adjust parameters and perform linking with [trackpy.link](http://soft-matter.github.io/trackpy/dev/generated/trackpy.link.html).  Once linking is performed a new tracks layer will be added.  Please refer to the trackpy documentation for more details on parameters.

In addition, scatter plots of mass vs. size and mass vs. eccentricity, as well as the track lengths histogram are shown for help with filtering tracks. (next step)

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/3_2.png)

4) **Filter**

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/4_1.png)

In this tab, adjust parameters and filter links from trackpy output.  After filtering, a new layer will be added to napari with the filtered tracks and the same plots as shown in step 4 will be displayed.

5) **Analyze**

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_1.png)

In this tab, adjust parameters and perform analysis.  You may process all tracks or enter a track id and deselect the ""Process all tracks"" check box.  Enter the appropriate parameters for converting pixels to microns and the time lag (in seconds) between frames of the movie.  

GEMspa will calculate the effective diffusion coefficient (D) for each track based on the mean squared displacement values (MSD) for each time-lag using this equation:

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_2.png)

This is the diffusion coefficient with the assumption of Brownian motion.  GEMspa will also calculate the generalized diffusion coefficient and anomalous exponent using this equation:

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_3.png)

The fitting is performed on a log-log scale where the slope corresponds to the anomalous exponent (alpha):

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_4.png)

**Definition of terms:**

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_5.png)

This review: [Manzo et al](https://pubmed.ncbi.nlm.nih.gov/26511974/)  is useful for learning more about these and other analysis methods.

**Min track len for fit**: all tracks less than this length will be excluded from calculations of effective diffusion coefficient and anomalous exponent.

**Max time lag for fit**: GEMspa will fit the MSD up to the max time-lag entered here.  (in frames)

**Fit with error term**: check this box to allow a y-intercept when fitting for effective diffusion coefficient:

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_6.png)

Check these papers by [Martin, et al](https://www.sciencedirect.com/science/article/pii/S0006349502739714) and [Xavier Michalet](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3055791/) for some information on fitting MSD with localization error.

**Rainbow tracks**

GEMspa can output a plot where the tracks are colored by any of the listed quantities.  Check each box that you would like to see.  

For the effective diffusion coefficient and anomalous exponent, set the Min/Max cutoffs for the track color map.  Any tracks at or below the minimum will be colored with the minimum color (blue).  Any tracks at or above the maximum will be colored with the maximum color (red).

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_10.png)

**Plots**

GEMspa will also output summary plots including:
* Ensemble average MSD shown on linear and log-scale with results from fitting the MSD vs time-lag data from the ensemble average MSD.
* Track length histogram, Radius of gyration (for full track lengths) histogram, Scatter plot of track length vs. radius of gyration

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_7.png)

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_8.png)

**Tracks data table**

GEMspa will output a table of data in a new pop-up window with data for each track.  This table will only show one line for each track (not one line for every particle position) and it will output the following data:
* track_id
* frame_start
* frame_end
* radius_gyration: radius of gyration for the full track length (See [Elliot et al](https://doi.org/10.1039/c0cp01805h))
* track_length
* D: effective diffusion coefficient
* E: y-intercept for the fit of MSD for D
* r_sq (lin): R-squared value for goodness-of-fit for the fit of MSD vs time-lag
* K: generalized diffusion coefficient
* a: anomalous exponent (alpha)
* r_sq (log): R-squared value for goodness-of-fit for the fit of log-log MSD vs. time-lag

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_9.png)

**New tracks layer**

GEMspa will add a new tracks layer and save all data for each track in the properties of the tracks layer.  Save the tracks layer to obtain a tab/comma-delimited text file with all analysis results.  The data included for each track is:
* track_id
* frame
* y: y position in pixels
* x: x position in pixels
* frame_start
* frame_end
* y (microns): y position in microns
* x (microns): x position in microns
* tau: time-lag in seconds
* MSD: mean squared displacement 
* t: time in seconds from start of track
* step_size
* radius_gyration: radius of gyration at each time point of track (See [Elliot et al](https://doi.org/10.1039/c0cp01805h))
* track_length
* D: effective diffusion coefficient
* E: y-intercept for the fit of MSD for D
* r_sq (lin): R-squared value for goodness-of-fit for the fit of MSD vs time-lag
* K: generalized diffusion coefficient
* a: anomalous exponent (alpha)
* r_sq (log): R-squared value for goodness-of-fit for the fit of log-log MSD vs. time-lag

To extract this data, save the layer as a tab or comma delimited text file (txt/tsv/csv).  GEMspa will save all track information.

**Analysis for a single track**

GEMspa also provides the option to select a single track and output analysis results.  Detailed information is shown for the selected track, including a plot of the radius of gyration at each time point and a plot of the track itself.  

Here is an example:

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_11.png)

![My Image](https://raw.githubusercontent.com/liamholtlab/napari-gemspa/main/screen_shots/5_12.png)


","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/liamholtlab/napari-gemspa/issues', 'Documentation, https://github.com/liamholtlab/napari-gemspa#README.md', 'Source Code, https://github.com/liamholtlab/napari-gemspa', 'User Support, https://github.com/liamholtlab/napari-gemspa/issues']",napari-gemspa.get_reader,napari-gemspa.write_points,napari-gemspa.make_gemspa_plugin,,"['*.txt', '*.csv', '*.tsv']","['.txt', '.csv', '.tsv']","['.txt', '.csv', '.tsv']"
217,napari-generic-simulator,napari-generic-SIMulator,napari generic SIMulator,0.1.3,2022-06-30,2024-09-23,Meizhu Liang,ml2618@ic.ac.uk,BSD-3-Clause,https://github.com/Meizhu-Liang/napari-generic-SIMulator/issues,https://pypi.org/project/napari-generic-SIMulator/,,https://github.com/Meizhu-Liang/napari-generic-SIMulator,A napari plugin to simulate raw-image stacks of Structured illumination microscopy (SIM).,>=3.8,"['numpy', 'magicgui', 'qtpy', 'tifffile', 'opt-einsum', 'matplotlib', 'pypcd-imp', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'tifffile; extra == ""testing""', 'pypcd-imp; extra == ""testing""', 'opt-einsum; extra == ""testing""', 'matplotlib; extra == ""testing""']","# napari-generic-SIMulator

[![License BSD-3](https://img.shields.io/pypi/l/napari-generic-SIMulator.svg?color=green)](https://github.com/Meizhu-Liang/napari-generic-SIMulator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-generic-SIMulator.svg?color=green)](https://pypi.org/project/napari-generic-SIMulator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-generic-SIMulator.svg?color=green)](https://python.org)
[![tests](https://github.com/Meizhu-Liang/napari-generic-SIMulator/workflows/tests/badge.svg)](https://github.com/Meizhu-Liang/napari-generic-SIMulator/actions)
[![codecov](https://codecov.io/gh/Meizhu-Liang/napari-generic-SIMulator/branch/main/graph/badge.svg)](https://codecov.io/gh/Meizhu-Liang/napari-generic-SIMulator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-generic-SIMulator)](https://napari-hub.org/plugins/napari-generic-SIMulator)

A napari plugin to simulate raw-image stacks of Structured illumination microscopy (SIM). 

The simulation is originally based on the paper <strong>GPU-accelerated real-time reconstruction in Python of three-dimensional datasets from structured illumination microscopy with hexagonal patterns</strong> by
Hai Gong, Wenjun Guo and Mark A. A. Neil (https://doi.org/10.1098/rsta.2020.0162). 

The calculation can be GPU-accelerated if the CUPY (tested with cupy-cuda11x) is installed. In addition, the TORCH package can complete the acceleration both on CPU if TORCH is installed, and on GPU if TORCH is compiled with the CUDA (tested with torch v1.13.1+cu117) enabled.

Currently applies to:
- conventional 2-beam SIM data with 3 angles and 3 phases
- 3-beam hexagonal SIM data with 7 phases, as described in the paper
- 3-beam hexagonal SIM data with 5 phases at right-angles
- conventional 3-beam 3-D data with 3 angles and 5 phases

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-generic-SIMulator` via [pip]:

    pip install napari-generic-SIMulator



To install latest development version :

    pip install git+https://github.com/Meizhu-Liang/napari-generic-SIMulator.git

This plugin is compatible with **napari 0.4.17** or above, older versions of napari would show errors in _interpolation_.

## Usage

1) Open napari and create the viewer.


2) Launch two widgets: **Point cloud generator** and **SIM data generator** in ***Plugin***.

   ![raw](https://github.com/Meizhu-Liang/napari-generic-SIMulator/raw/main/images/lauch.png)

   The two widgets can be tabbed together.
   ![raw](https://github.com/Meizhu-Liang/napari-generic-SIMulator/raw/main/images/2tabs.png)


3) Choose the type and other parameters of point cloud as a sample in **Point cloud generator**.

    ![raw](https://github.com/Meizhu-Liang/napari-generic-SIMulator/raw/main/images/pc.png)

    The point cloud can be displayed in three dimensions, and be saved and loaded as .pcd files.
  
    https://user-images.githubusercontent.com/74197598/227589232-9006842b-6706-48b7-9f2b-fe93c6698503.mp4


4) Adjust parameters in SIM data generator to simulate a raw image stack.

   Apart from basic parameters such as the refractive index, the wavelengths and so on, the z scanning can be either 
   **z drift**: the conventional SIM (imaging a raw stack at the same z-position) or **z step**: the drifting case in 
   the papaer mentioned above (imaging only one raw image at a z-position).


   ![raw](https://github.com/Meizhu-Liang/napari-generic-SIMulator/raw/main/images/raw_stack.png)

   The parameters used in the simulation can be saved with the image stack by clicking **save tif with tags**. Tags (of current or of one stack dragged into napari viewer) can be printed in Python by **print tags**. 


5) Three-dimensional point spread function (**PSF**), optical transfer function (**OTF**) and **illumination** patterns applied in the simulation can be showed by buttons. Note the all of these correspond the generated raw-image stack, so keep the parameters the same before showing the **PSF** (or **OTF** and **illumination**).

    https://user-images.githubusercontent.com/74197598/227588321-ad3c8f17-1c61-4079-9e34-9b1f990714c1.mp4
    
    https://user-images.githubusercontent.com/74197598/227586957-b76ad56e-44d5-4d9b-a1cc-2cfd08ca5400.mp4
    
    https://user-images.githubusercontent.com/74197598/227585827-64531265-b4fb-48a9-9698-7f263f22d718.mp4 
   
6) The raw image stacks can be then processed by napari-sim-processor (https://www.napari-hub.org/plugins/napari-sim-processor).
   
   ![raw](https://github.com/Meizhu-Liang/napari-generic-SIMulator/raw/main/images/processor.png)


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-generic-SIMulator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/Meizhu-Liang/napari-generic-SIMulator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10']","['Bug Tracker, https://github.com/Meizhu-Liang/napari-generic-SIMulator/issues', 'Documentation, https://github.com/Meizhu-Liang/napari-generic-SIMulator#README.md', 'Source Code, https://github.com/Meizhu-Liang/napari-generic-SIMulator', 'User Support, https://github.com/Meizhu-Liang/napari-generic-SIMulator/issues']",,,napari-generic-SIMulator.make_pointcloud_widget,,,,
218,napari-geojson,napari-geojson,napari-geojson,0.1.3,2021-12-27,2022-11-10,Tim Morello,tdmorello@gmail.com,BSD-3-Clause,https://github.com/tdmorello/napari-geojson/issues,https://pypi.org/project/napari-geojson/,,https://github.com/tdmorello/napari-geojson,Read and write geojson files in napari,>=3.8,"['geojson', 'numpy', ""black ; extra == 'dev'"", ""flake8 ; extra == 'dev'"", ""flake8-black ; extra == 'dev'"", ""flake8-docstrings ; extra == 'dev'"", ""flake8-isort ; extra == 'dev'"", ""isort ; extra == 'dev'"", ""mypy ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""pytest-cov ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""tox ; extra == 'dev'"", ""napari[all] ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-geojson

[![License](https://img.shields.io/pypi/l/napari-geojson.svg?color=green)](https://github.com/tdmorello/napari-geojson/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-geojson.svg?color=green)](https://pypi.org/project/napari-geojson)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-geojson.svg?color=green)](https://python.org)
[![tests](https://github.com/tdmorello/napari-geojson/workflows/tests/badge.svg)](https://github.com/tdmorello/napari-geojson/actions)
[![codecov](https://codecov.io/gh/tdmorello/napari-geojson/branch/main/graph/badge.svg)](https://codecov.io/gh/tdmorello/napari-geojson)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-geojson)](https://napari-hub.org/plugins/napari-geojson)

Read and write geojson files in napari.

![](https://github.com/tdmorello/napari-geojson/raw/main/resources/output.gif)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-geojson` via [pip]:

    pip install napari-geojson



To install latest development version :

    pip install git+https://github.com/tdmorello/napari-geojson.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-geojson"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/tdmorello/napari-geojson/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/tdmorello/napari-geojson/issues', 'Documentation, https://github.com/tdmorello/napari-geojson#README.md', 'Source Code, https://github.com/tdmorello/napari-geojson', 'User Support, https://github.com/tdmorello/napari-geojson/issues']",napari-geojson.get_reader,napari-geojson.write_shapes,,,['*.geojson'],['.geojson'],
219,napari-griottes,napari-griottes,Griottes,0.4.1,2023-03-09,2023-04-14,Andrey Aristov,aaristov@pasteur.fr,BSD-3-Clause,https://github.com/aaristov/napari-griottes/issues,https://pypi.org/project/napari-griottes/,,https://github.com/aaristov/napari-griottes,Create graphs,>=3.8,"['griottes', 'networkx', 'numpy', 'pandas (<2)']","# napari-griottes

[![License](https://img.shields.io/pypi/l/napari-griottes.svg?color=green)](https://github.com/BaroudLab/napari-griottes/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-griottes.svg?color=green)](https://pypi.org/project/napari-griottes)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-griottes.svg?color=green)](https://python.org)
[![tests](https://github.com/BaroudLab/napari-griottes/workflows/tests/badge.svg)](https://github.com/BaroudLab/napari-griottes/actions)
[![codecov](https://codecov.io/gh/BaroudLab/napari-griottes/branch/main/graph/badge.svg)](https://codecov.io/gh/BaroudLab/napari-griottes)

[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-griottes)](https://napari-hub.org/plugins/napari-griottes)



Use [ð  `Griottes` ð](https://github.com/BaroudLab/Griottes) in napari!

----------------------------------



https://user-images.githubusercontent.com/11408456/224119160-c381091d-8275-449e-9cf4-679ab474acd2.mp4




## Installation

Install from napari

![image](https://user-images.githubusercontent.com/11408456/224108834-f484ba37-50f4-415e-bdfb-509c6c5b88c4.png)


You can install `napari-griottes` via [pip]:

    pip install napari-griottes



To install latest development version :

    pip install git+https://github.com/BaroudLab/napari-griottes.git



## Usage

### Starting with labels:

1. Open the plugin in Plugins/napari-griottes
2. Make sure the layer with labels is selected
3. Click Run once to get centers
4. Click Run second time to get graph
5. Select the right kind of graph in the drop-down menu
6. Adjust the distance
7. Adjust thickness

![Screenshot from three labels geometric contact mp4](https://user-images.githubusercontent.com/11408456/167371516-05db2ba5-cdfc-47c4-a488-8f46afd0ae5b.png)



https://user-images.githubusercontent.com/11408456/167825581-47c39884-34cf-4b5c-ad84-a4572217559d.mp4



### Starting with Segmented cells

1. Open sample data: File / Open Sample / napari-griottes / Zebrafish 2D with labels
2. Select the top layer and covert it to labels (right click - Convert to labels)
3. Run the plugin once to get the centers of labels
4. Run the plugin twice to get the connections
5. Proceed with graph creation


![Screenshot from cells graphs mp4](https://user-images.githubusercontent.com/11408456/167372895-3c9036b9-af50-4575-bcf3-1805eb261bd7.png)




https://user-images.githubusercontent.com/11408456/168237170-b43afd5a-26a4-4cdc-bc42-d3f46f138536.mp4


### Saving and recovering the graph

Any graph you see in napari can be saved in .json format.
1. Select he layers with connections
2. Click File/Save Selected Layer
3. Choose Griottes in drop-down menu
4. Save

In order to recover a previously saved graph in napari, you can simply drag-n-drop your file into napari, or use file open fialog.



https://user-images.githubusercontent.com/11408456/167845853-e7071199-3f58-4d11-8d7b-c1358a150e6b.mp4


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-griottes"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/BaroudLab/napari-griottes/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/aaristov/napari-griottes/issues', 'Documentation, https://github.com/aaristov/napari-griottes#README.md', 'Source Code, https://github.com/aaristov/napari-griottes', 'User Support, https://github.com/aaristov/napari-griottes/issues']",napari-griottes.get_reader,napari-griottes.save_graph,napari-griottes.make_graph,napari-griottes.make_cell_properties,"['*.json', '*.npy', '*.tif', '*.tiff', '*.csv', '*.griottes']",['.json'],
220,napari-hello,napari-hello,napari_hello,0.1.0,2023-04-16,2023-04-16,Your Name,your.email@example.com,Unavailable,,https://pypi.org/project/napari-hello/,None,,My napari plugin,,['napari'],,['Framework :: napari'],,,,,,,,
221,napari-h5,napari-h5,napari-h5,0.0.8,2023-08-07,2024-02-19,Luis Perdigao,luis.perdigao@rfi.ac.uk,Apache-2.0,https://github.com/rosalindfranklininstitute/napari-h5/issues,https://pypi.org/project/napari-h5/,,https://github.com/rosalindfranklininstitute/napari-h5,A hdf5 file reader plugin for napari,>=3.8,"['numpy', 'h5py', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-h5

[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-h5.svg?color=green)](https://github.com/rosalindfranklininstitute/napari-h5/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-h5.svg?color=green)](https://pypi.org/project/napari-h5)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-h5.svg?color=green)](https://python.org)
[![tests](https://github.com/rosalindfranklininstitute/napari-h5/workflows/tests/badge.svg)](https://github.com/rosalindfranklininstitute/napari-h5/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-h5)](https://napari-hub.org/plugins/napari-h5)

A file reader plugin for napari


It opens simple *.h5 files. Reads all Datasets inside the file and converts to
a napari Image object (np.array).

It can also save ""image"" or ""labels"" data. Note that these will be saved individually.

It does not support data organised internally in ""groups"".
For these more complicated h5 data structures please try other plugins.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-h5` via [pip]:

    pip install napari-h5




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-h5"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/rosalindfranklininstitute/napari-h5/issues', 'Documentation, https://github.com/rosalindfranklininstitute/napari-h5#readme', 'Source Code, https://github.com/rosalindfranklininstitute/napari-h5', 'User Support, https://github.com/rosalindfranklininstitute/napari-h5/issues']",napari-h5.get_reader,napari-h5.multi_layer_writer,,,['*.h5'],['.h5'],['.h5']
222,napari-gruvbox,napari-gruvbox,napari Gruvbox,0.1.1,2022-12-14,2023-03-06,Lorenzo Gaifas,brisvag@gmail.com,GPL-3.0-only,https://github.com/brisvag/napari-gruvbox/issues,https://pypi.org/project/napari-gruvbox/,,https://github.com/brisvag/napari-gruvbox,Gruvbox theme for napari.,>=3.8,['pygments (>=2.9)'],"# napari-gruvbox

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-gruvbox.svg?color=green)](https://github.com/brisvag/napari-gruvbox/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-gruvbox.svg?color=green)](https://pypi.org/project/napari-gruvbox)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-gruvbox.svg?color=green)](https://python.org)
[![tests](https://github.com/brisvag/napari-gruvbox/workflows/tests/badge.svg)](https://github.com/brisvag/napari-gruvbox/actions)
[![codecov](https://codecov.io/gh/brisvag/napari-gruvbox/branch/main/graph/badge.svg)](https://codecov.io/gh/brisvag/napari-gruvbox)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-gruvbox)](https://napari-hub.org/plugins/napari-gruvbox)

Gruvbox theme for napari. Colors are taken from the palette in https://github.com/morhetz/gruvbox.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-gruvbox` via [pip]:

    pip install napari-gruvbox



To install latest development version :

    pip install git+https://github.com/brisvag/napari-gruvbox.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-gruvbox"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/brisvag/napari-gruvbox/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/brisvag/napari-gruvbox/issues', 'Documentation, https://github.com/brisvag/napari-gruvbox#README.md', 'Source Code, https://github.com/brisvag/napari-gruvbox', 'User Support, https://github.com/brisvag/napari-gruvbox/issues']",,,,,,,
223,napari-hdf5-labels-io,napari-hdf5-labels-io,napari-hdf5-labels-io,0.3.dev16,2021-03-04,2021-11-30,"Duway Nicolas Lesmes Leon, Pranjal Dhole","dlesmesleon@hotmail.com, dhole.pranjal@gmail.com",GNU GPL v3.0,https://github.com/yapic/napari-hdf5-labels-io,https://pypi.org/project/napari-hdf5-labels-io/,,https://github.com/yapic/napari-hdf5-labels-io,Napari plugin to store set of layers in a .h5 file. Label layer are stored in a sparse representation.,<3.9,"['napari-plugin-engine (>=0.1.4)', 'typing', 'numpy', 'sparse', 'h5py (==2.10.0)', 'zarr']","# napari-hdf5-labels-io

[![License](https://img.shields.io/pypi/l/napari-hdf5-labels-io.svg?color=green)](https://github.com/yapic/napari-hdf5-labels-io/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-hdf5-labels-io.svg?color=green)](https://pypi.org/project/napari-hdf5-labels-io)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-hdf5-labels-io.svg?color=green)](https://python.org)
[![tests](https://github.com/yapic/napari-hdf5-labels-io/workflows/tests/badge.svg)](https://github.com/yapic/napari-hdf5-labels-io/actions)
[![codecov](https://codecov.io/gh/yapic/napari-hdf5-labels-io/branch/master/graph/badge.svg)](https://codecov.io/gh/yapic/napari-hdf5-labels-io)

napari plugin to store napari projects in a .h5 file. Label layer are stored in a sparse representation (COO list).

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Description

This napari plugin provides a writer and reader to store existing layers in the current napari window, all the metadata is stored as well in a HDF5 file. All the stored preferences are included when a project file is opened.

Label layers are stored in a coordinate list sparse representation with the [Sparse module](https://sparse.pydata.org/) to keep the project file size minimum when possible (aiming to implement this in other layers in the future).

## HDF5 file architecture

The project file is a HDF5 generated with the [h5py module](https://docs.h5py.org). The file groups correspond to the different napari layer types and the layer metadata is stored as attributes of each layer.

In the case of the meta dictionary which is nested in the LayerData meta dictionary (napari IO), new keys are generated in the outer dictionary to use them as h5 dataset attributes. This nested dictionary architecture is reconstructed by the reader to ensure format compatibility.

## Installation

You can install `napari-hdf5-labels-io` via [pip]:

    pip install napari-hdf5-labels-io

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-hdf5-labels-io"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/yapic/napari-hdf5-labels-io/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']",,napari-hdf5-labels-io.h5_to_napari,napari-hdf5-labels-io.napari_write_image,,,['*'],,
224,napari-himena,napari-himena,Himena,0.0.1,2025-04-08,2025-04-08,Hanjin Liu,liuhanjin.sc@gmail.com,"Copyright (c) 2025, Hanjin Liu...",https://github.com/hanjinliu/napari-himena/issues,https://pypi.org/project/napari-himena/,,,Pipeline between napari and himena,>=3.10,"['himena', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt6; extra == ""testing""']","# napari-himena

[![License BSD-3](https://img.shields.io/pypi/l/napari-himena.svg?color=green)](https://github.com/hanjinliu/napari-himena/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-himena.svg?color=green)](https://pypi.org/project/napari-himena)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-himena.svg?color=green)](https://python.org)
[![tests](https://github.com/hanjinliu/napari-himena/workflows/tests/badge.svg)](https://github.com/hanjinliu/napari-himena/actions)
[![codecov](https://codecov.io/gh/hanjinliu/napari-himena/branch/main/graph/badge.svg)](https://codecov.io/gh/hanjinliu/napari-himena)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-himena)](https://napari-hub.org/plugins/napari-himena)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

Pipeline between [`napari`](https://github.com/napari/napari) and [`himena`](https://github.com/hanjinliu/himena).

`napari` is a great tool for visualization, annotation and analysis of multi-dimensional
images. On the other hand, `himena` has a powerful plugin system that allows users to
technically do anything, such as editing table and plotting.

`napari-himena` connects these two ecosystems together, enabling users to send data
back and forth, extending the functionality of the both packages.

## Examples

#### 1. Sending image layers to `himena` for ImageJ-like multi-measurement and Excel-like plotting.

Measuring time-course change in the image intensity with [`himena-image`](https://github.com/hanjinliu/himena-image) plugin, and plot the result using the built-in plot functions using `matplotlib`.

![](https://github.com/hanjinliu/napari-himena/blob/main/assets/image-plot.gif)

#### 2. Sending points and their features to `himena` for seaborn plotting.

Feature dataframe can be directly sent to `himena` for `seaborn` plotting using [`himena-seaborn`](https://github.com/hanjinliu/himena-seaborn) plugin.

![](https://github.com/hanjinliu/napari-himena/blob/main/assets/feature-sns.gif)

## Usage

#### Starting from `napari`

Open the `napari-himena` dock widget from the ""Plugin"" menu, connect to one of the
`himena` profile (only ""default"" is available by default), and that's it!

![](https://github.com/hanjinliu/napari-himena/blob/main/assets/from-napari.png)

#### Starting from `himena`

To use this plugin from `himena`, you need to first register this plugin to the `himena`
profile

```shell
# install to the default profile
himena --install napari-himena

# or install to a specific profile
himena <my-profile> --install napari-himena
```

Then all the commands will be available in `himena` and a napari viewer will be launched
when it is needed. You don't need to do this if you always launch `himena` from `napari`
plugin; it automatically register this package in the beginning.

![](https://github.com/hanjinliu/napari-himena/blob/main/assets/from-himena.png)

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

## Installation

You can install `napari-himena` via [pip]:

    pip install napari-himena



To install latest development version :

    pip install git+https://github.com/hanjinliu/napari-himena.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-himena"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/hanjinliu/napari-himena/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hanjinliu/napari-himena/issues', 'Documentation, https://github.com/hanjinliu/napari-himena#README.md', 'Source Code, https://github.com/hanjinliu/napari-himena', 'User Support, https://github.com/hanjinliu/napari-himena/issues']",,,napari-himena.make_qwidget,,,,
225,napari-hippo,napari-hippo,Hippo,0.2.0,2024-01-31,2024-05-15,Sam Thiele,s.thiele@hzdr.de,MIT,,https://pypi.org/project/napari-hippo/,None,,A fat and clumsy collection of hyperspectral tools,>=3.8,"['natsort', 'hylite', 'numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""hylite ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-hippo


| <a href=""https://github.com/samthiele/napari-hippo/wiki""><img src=""https://github.com/samthiele/napari-hippo/blob/main/logo.png"" height=""32""/></a>| [![License MIT](https://img.shields.io/pypi/l/napari-hippo.svg?color=green)](https://github.com/samthiele/napari-hippo/blob/main/LICENSE) | [![PyPI](https://img.shields.io/pypi/v/napari-hippo.svg?color=green)](https://pypi.org/project/napari-hippo) | [![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-hippo)](https://napari-hub.org/plugins/napari-hippo)
| -------------------------- | ------------------------------- |--------------------|-------------------|

    
A large and slightly clumsy plugin for viewing and analysing hyperspectral data in Napari.

![Funky screenshot of the napari-hippo GUI](screenshot.png)


----------------------------------

## Installation

Follow [these instructions](https://napari.org/stable/tutorials/fundamentals/installation) to first install napari. Then you can install `napari-hippo` via [pip](https://pypi.org/project/napari-hippo):

    pip install napari-hippo

## Documentation

We are in the process of building a documentation wiki for this plugin [here](https://github.com/samthiele/napari-hippo/wiki).

## Contributing

Contributions are very welcome! Please feel free to submit pull requests or tell us about your ideas (or problems) on the [discussions](https://pypi.org/project/napari-hippo) page.

## License

Distributed under the terms of the [MIT](https://github.com/samthiele/napari-hippo/blob/main/LICENSE) license,
`napari-hippo` is free and open source software.

## Issues

If you encounter any problems, please [file an issue](https://github.com/samthiele/napari-hippo/issues/new/choose) along with a detailed description.

## Citation

A citation for `napari-hippo` will be announced shortly.
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-hippo.get_ENVI_reader,napari-hippo.write_multiple,napari-hippo.make_IOTools,napari-hippo.make_sample_data,"['*.hdr', '*.dat', '*.png', '*.jpg', '*.jpeg', '*.bmp']",,"['.dat', '.hdr']"
226,napari-help,napari-help,napari Help,0.1.0,2022-07-28,2022-07-28,Lorenzo Gaifas,brisvag@gmail.com,GPL-3.0,https://github.com/brisvag/napari-help/issues,https://pypi.org/project/napari-help/,,https://github.com/brisvag/napari-help,Helpful tooltips for napari.,>=3.8,"['napari', 'qtpy', ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-help

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-help.svg?color=green)](https://github.com/brisvag/napari-help/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-help.svg?color=green)](https://pypi.org/project/napari-help)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-help.svg?color=green)](https://python.org)
[![tests](https://github.com/brisvag/napari-help/workflows/tests/badge.svg)](https://github.com/brisvag/napari-help/actions)
[![codecov](https://codecov.io/gh/brisvag/napari-help/branch/main/graph/badge.svg)](https://codecov.io/gh/brisvag/napari-help)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-help)](https://napari-hub.org/plugins/napari-help)

Helpful tooltips for napari.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-help` via [pip]:

    pip install napari-help



To install latest development version :

    pip install git+https://github.com/brisvag/napari-help.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-help"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/brisvag/napari-help/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/brisvag/napari-help/issues', 'Documentation, https://github.com/brisvag/napari-help#README.md', 'Source Code, https://github.com/brisvag/napari-help', 'User Support, https://github.com/brisvag/napari-help/issues']",,,napari-help.help_widget,,,,
227,napari-hierarchical,napari-hierarchical,napari-hierarchical,0.1.0,2022-12-21,2022-12-21,Jonas Windhager,jonas.windhager@uzh.ch,MIT,https://github.com/BodenmillerGroup/napari-hierarchical/issues,https://pypi.org/project/napari-hierarchical/,,https://github.com/BodenmillerGroup/napari-hierarchical,Hierarchical file format support for napari,"<3.11,>=3.8","['napari (<0.4.18,>=0.4.17)', 'pluggy', 'qtpy', ""dask ; extra == 'all'"", ""h5py ; extra == 'all'"", ""readimc ; extra == 'all'"", ""s3fs ; extra == 'all'"", ""zarr ; extra == 'all'"", ""dask ; extra == 'hdf5'"", ""h5py ; extra == 'hdf5'"", ""dask ; extra == 'imc'"", ""readimc ; extra == 'imc'"", ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""dask ; extra == 'zarr'"", ""s3fs ; extra == 'zarr'"", ""zarr ; extra == 'zarr'""]","# napari-hierarchical

[![License MIT](https://img.shields.io/pypi/l/napari-hierarchical.svg?color=green)](https://github.com/BodenmillerGroup/napari-hierarchical/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-hierarchical.svg?color=green)](https://pypi.org/project/napari-hierarchical)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-hierarchical.svg?color=green)](https://python.org)
[![tests](https://github.com/BodenmillerGroup/napari-hierarchical/workflows/tests/badge.svg)](https://github.com/BodenmillerGroup/napari-hierarchical/actions)
[![codecov](https://codecov.io/gh/BodenmillerGroup/napari-hierarchical/branch/main/graph/badge.svg)](https://codecov.io/gh/BodenmillerGroup/napari-hierarchical)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-hierarchical)](https://napari-hub.org/plugins/napari-hierarchical)

Hierarchical file format support for napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


## Installation

You can install `napari-hierarchical` via [pip]:

    pip install ""napari-hierarchical[all]""

To install latest development version :

    pip install ""git+https://github.com/BodenmillerGroup/napari-hierarchical.git#egg=napari-hierarchical[all]""

## Usage

The plugin enables the reading, editing and writing of container formats. In the plugin, *groups* represent hierarchically structured collections of *arrays*. Each group can hold zero or more arrays and can have zero or more child groups (hierarchical structure). An array is a logical representation of (image) data on disk and directly corresponds to a napari layer when loaded.

Files can be opened through napari (e.g. `File -> Open File(s)` menu, `Viewer.open(...)` function), as the plugin implements napari's file reader hook. Upon opening a hierarchically structured file, the *Groups* and *Arrays* widgets are displayed. The *Groups* widget allows to browse and restructure the groups tree, while the *Arrays* widget groups arrays from the selected groups by file format-specific metadata (e.g. channel name for MCD files). Selecting arrays also selects the corresponding napari layers, allowing to adjust their properties.

Arrays can be loaded individually by toggling their *loaded* state (circular button), which will add napari layers for the corresponding arrays. Similarly, loaded arrays can be shown or hidden by toggling their *visible* state (eye button), which will toggle the visibility of the associated napari layers. The loaded/visible states of groups (collections of arrays) can be toggled in a similar fashion. Arrays are always loaded into memory (no memory mapping), to allow for editing the tree structure. Loaded root groups can be exported to supported hierarchical file formats.

Currently, reading/writing of HDF5 and Zarr (not: OME-NGFF) files are supported out of the box, as well as reading imaging mass cytometry (IMC) data (i.e., MCD files). For these file formats, sample data is available through the plugin. Additional readers/writers can be implemented using a pluggy-based interface, similar to the first generation `napari-plugin-engine`.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.


## License

Distributed under the terms of the [MIT] license,
""napari-hierarchical"" is free and open source software


## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/BodenmillerGroup/napari-hierarchical/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Framework :: napari', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/BodenmillerGroup/napari-hierarchical/issues', 'Documentation, https://github.com/BodenmillerGroup/napari-hierarchical#README.md', 'Source Code, https://github.com/BodenmillerGroup/napari-hierarchical', 'User Support, https://github.com/BodenmillerGroup/napari-hierarchical/issues']",napari-hierarchical.get_reader,,napari-hierarchical.make_groups_widget,napari-hierarchical.sample_data.imc_mock,['*'],,
228,napari-hsi-analysis,napari-hsi-analysis,Hyperspectral Imaging Analysis Plugin,0.3.1,2025-03-12,2025-06-23,Alessia Di Benedetto,alessiadibenedetto.97@gmail.com,"Copyright (c) 2025, Alessia Di...",https://github.com/alessiadb/napari-hsi-analysis/issues,https://pypi.org/project/napari-hsi-analysis/,,,Napari plugin to perform analysis on Hyperspectral Imaging datasets.,>=3.10,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'scikit-learn', 'h5py', 'bokeh', 'plotly', 'PyWavelets', 'scipy', 'pyqtgraph', 'qtawesome', 'matplotlib', 'umap-learn', 'spectral', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'numpy; extra == ""testing""', 'magicgui; extra == ""testing""', 'qtpy; extra == ""testing""', 'scikit-image; extra == ""testing""', 'scikit-learn; extra == ""testing""', 'h5py; extra == ""testing""', 'bokeh; extra == ""testing""', 'plotly; extra == ""testing""', 'PyWavelets; extra == ""testing""', 'scipy; extra == ""testing""', 'pyqtgraph; extra == ""testing""', 'qtawesome; extra == ""testing""', 'matplotlib; extra == ""testing""', 'umap-learn; extra == ""testing""', 'spectral; extra == ""testing""']","# napari-hsi-analysis

[![License BSD-3](https://img.shields.io/pypi/l/napari-hsi-analysis.svg?color=green)](https://github.com/alessiadb/napari-hsi-analysis/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-hsi-analysis.svg?color=green)](https://pypi.org/project/napari-hsi-analysis)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-hsi-analysis.svg?color=green)](https://python.org)
[![tests](https://github.com/alessiadb/napari-hsi-analysis/workflows/tests/badge.svg)](https://github.com/alessiadb/napari-hsi-analysis/actions)
[![codecov](https://codecov.io/gh/alessiadb/napari-hsi-analysis/branch/main/graph/badge.svg)](https://codecov.io/gh/alessiadb/napari-hsi-analysis)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-hsi-analysis)](https://napari-hub.org/plugins/napari-hsi-analysis)

A Napari plugin to perform analysis on Hyperspectral Imaging datasets.

The 'Data Manager' widget loads, opens and visualize the datasets.
The 'Fusion' widget fused two or three opened datasets.
The 'UMAP' widget perform and visualize the Uniform Manifold Approximation and Projection analysis.

----------------------------------


This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->


## Installation

You can install `napari-hsi-analysis` via [pip]:

    pip install napari-hsi-analysis



To install latest development version :

    pip install git+https://github.com/alessiadb/napari-hsi-analysis.git

## Usage
A detailed guide which shows how to use the plugin and how to properly choose the parameters can be found [here].


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-hsi-analysis"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/alessiadb/napari-hsi-analysis/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

[here]:  https://github.com/alessiadb/napari-hsi-analysis/blob/main/docs/guide.md
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/alessiadb/napari-hsi-analysis/issues', 'Documentation, https://github.com/alessiadb/napari-hsi-analysis#README.md', 'Source Code, https://github.com/alessiadb/napari-hsi-analysis', 'User Support, https://github.com/alessiadb/napari-hsi-analysis/issues']",,,napari-hsi-analysis.run_app,,,,
229,napari-ids,napari-IDS,napari IDS,0.0.8,2022-02-17,2022-02-23,Tristan Cotte,tristan.cotte@sgs.com,BSD-3,https://github.com/tcotte/napari-IDS/issues,https://pypi.org/project/napari-IDS/,,https://github.com/tcotte/napari-IDS,Plug in which enables to take photo with IDS uEye camera,>=3.8,"['opencv-python', 'numpy']","# napari-IDS

[![License](https://img.shields.io/pypi/l/napari-IDS.svg?color=green)](https://github.com/githubuser/napari-IDS/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-IDS.svg?color=green)](https://pypi.org/project/napari-IDS)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-IDS.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-IDS)](https://napari-hub.org/plugins/napari-IDS)

A simple plugin to use with napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-IDS` via [pip]:

    pip install napari-IDS



To install latest development version :

    pip install git+https://github.com/githubuser/napari-IDS.git


## First utilisation

Suggested environment : 
- Python 3.8
- IDS 1.2.0.5 version installed

To use this package for the first time :
1. Install Napari `pip install ""napari[all]""`
2. Install napari-IDS package
3. Install IDS Python api thanks to the command `ids_packages`

If your environment is not the suggested environment, you have to install IDS packages manually. 


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-IDS"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/githubuser/napari-IDS/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/tcotte/napari-IDS/issues', 'Documentation, https://github.com/tcotte/napari-IDS#README.md', 'Source Code, https://github.com/tcotte/napari-IDS', 'User Support, https://github.com/tcotte/napari-IDS/issues']",,,napari-IDS.make_qwidget,,,,
230,napari-imagegrains,napari-imagegrains,ImageGrains,0.1.0,2025-06-26,2025-06-26,"Guillaume Witz, Michael Horn","Guillaume Witz <guillaume.witz@unibe.ch>, Michael Horn <michael.horn@unibe.ch}>","Copyright (c) 2025,  Universit...",https://github.com/guiwitz/napari-imagegrains/issues,https://pypi.org/project/napari-imagegrains/,,,An interactive napari plugin for the ImageGrains software.,>=3.9,"['numpy', 'magicgui', 'qtpy', 'superqt', 'napari_matplotlib', 'scikit-image', 'seaborn', 'pandas', 'imagegrains', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'nbformat; extra == ""testing""', 'nbconvert; extra == ""testing""']","# napari-imagegrains

[![License BSD-3](https://img.shields.io/pypi/l/napari-imagegrains.svg?color=green)](https://github.com/guiwitz/napari-imagegrains/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-imagegrains.svg?color=green)](https://pypi.org/project/napari-imagegrains)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-imagegrains.svg?color=green)](https://python.org)
[![tests](https://github.com/guiwitz/napari-imagegrains/workflows/tests/badge.svg)](https://github.com/guiwitz/napari-imagegrains/actions)
[![codecov](https://codecov.io/gh/guiwitz/napari-imagegrains/branch/main/graph/badge.svg)](https://codecov.io/gh/guiwitz/napari-imagegrains)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-imagegrains)](https://napari-hub.org/plugins/napari-imagegrains)

An interactive napari plugin for the [ImageGrains](https://github.com/dmair1989/imagegrains) software.

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

We recommend to install the plugin in an isolated environment as provided by conda. For conda create an appropriate environment with (do not use Python more recent than 3.11):

    conda create -n napari-imagegrains -c conda-forge python=3.11 napari pyqt
    conda activate napari-imagegrains

> :warning: 
> This is a work in progress and the plugin is available neither on PyPi nor in the napari plugin manager.
>You can install `napari-imagegrains` via [pip]:
>
>    pip install napari-imagegrains


To install latest development version :

    pip install git+https://github.com/guiwitz/napari-imagegrains.git

Or if you want to contribute to the plugin, fork the repository, clone it locally and install it in editable mode:

    pip install -e .


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-imagegrains"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

## Authors

The original software ImageGrain was developed by David Mair, Institute of Geological Sciences, University of Bern. The current plugin, a user-interface for the ImageGrains software, was developed by Guillaume Witz and Michael Horn, Data Science Lab, University of Bern in collaboration with David Mair.

## Citation

If you use this software, please cite the following publication: Mair, D., Witz, G., Do Prado, A.H., Garefalakis, P. & Schlunegger, F. (2023) Automated detecting, segmenting and measuring of grains in images of fluvial sediments: The potential for large and precise data from specialist deep learning models and transfer learning. Earth Surface Processes and Landforms, 1â18. <https://doi.org/10.1002/esp.5755>.


[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/guiwitz/napari-imagegrains/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/guiwitz/napari-imagegrains/issues', 'Documentation, https://github.com/guiwitz/napari-imagegrains#README.md', 'Source Code, https://github.com/guiwitz/napari-imagegrains', 'User Support, https://github.com/guiwitz/napari-imagegrains/issues']",,,napari-imagegrains.make_proc_qwidget,,,,
231,napari-hough-circle-detector,napari-hough-circle-detector,Hough circle detector,0.0.5,2023-04-03,2023-09-06,Florian Aymanns,florian.aymanns@epfl.ch,Unavailable,,https://pypi.org/project/napari-hough-circle-detector/,None,,An interactive Hough transform for napari.,,"['napari[all]', 'opencv-contrib-python-headless', 'numpy', 'pyqt5', 'scikit-image']","# napari-hough-circle-detector

A plugin for napari that detects circles using the Hough transform.
",['Framework :: napari'],,,,napari-hough-circle-detector.CircleDetectorWidget,,,,
232,napari-imodmodel,napari-imodmodel,Napari Imod Model,1.0.2,2024-04-16,2024-04-16,Moritz Wachsmuth-Melm,mail@moritzwm.de,BSD-3-Clause,https://github.com/MoritzWM/napari-imodmodel/issues,https://pypi.org/project/napari-imodmodel/,,https://github.com/MoritzWM/napari-imodmodel,Open IMOD model files in napari,>=3.8,"['numpy', 'imodmodel', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-imodmodel

[![License BSD-3](https://img.shields.io/pypi/l/napari-imodmodel.svg?color=green)](https://github.com/MoritzWM/napari-imodmodel/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-imodmodel.svg?color=green)](https://pypi.org/project/napari-imodmodel)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-imodmodel.svg?color=green)](https://python.org)
[![tests](https://github.com/MoritzWM/napari-imodmodel/workflows/tests/badge.svg)](https://github.com/MoritzWM/napari-imodmodel/actions)
[![codecov](https://codecov.io/gh/MoritzWM/napari-imodmodel/branch/main/graph/badge.svg)](https://codecov.io/gh/MoritzWM/napari-imodmodel)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-imodmodel)](https://napari-hub.org/plugins/napari-imodmodel)

Open IMOD model files in napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-imodmodel` via [pip]:

    pip install napari-imodmodel



To install latest development version :

    pip install git+https://github.com/MoritzWM/napari-imodmodel.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-imodmodel"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/MoritzWM/napari-imodmodel/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/MoritzWM/napari-imodmodel/issues', 'Documentation, https://github.com/MoritzWM/napari-imodmodel#README.md', 'Source Code, https://github.com/MoritzWM/napari-imodmodel', 'User Support, https://github.com/MoritzWM/napari-imodmodel/issues']",napari-imodmodel.get_reader,,,napari-imodmodel.make_sample_data,['*.mod'],,
233,napari-imagej,napari-imagej,napari-imagej,0.2.0,2023-05-24,2024-12-20,ImageJ2 developers,ImageJ2 developers <ctrueden@wisc.edu>,BSD-2-Clause,https://github.com/imagej/napari-imagej/issues,https://pypi.org/project/napari-imagej/,,,ImageJ functionality from napari,"<3.13,>=3.9","['confuse>=2.0.0', 'imglyb>=2.1.0', 'jpype1>=1.4.1', 'labeling>=0.1.12', 'magicgui>=0.5.1', 'napari>=0.4.17', 'numpy', 'pandas', 'pyimagej>=1.4.1', 'scyjava>=1.9.1', 'superqt>=0.7.0', 'xarray<2024.10.0', 'qtconsole!=5.4.2', 'typing_extensions!=4.6.0', 'build; extra == ""dev""', 'myst-parser; extra == ""dev""', 'pre-commit; extra == ""dev""', 'pyqt5; extra == ""dev""', 'pytest; extra == ""dev""', 'pytest-cov; extra == ""dev""', 'pytest-env; extra == ""dev""', 'pytest-qt; extra == ""dev""', 'ruff; extra == ""dev""', 'sphinx; extra == ""dev""', 'sphinx-copybutton; extra == ""dev""', 'sphinx-rtd-theme; extra == ""dev""', 'qtpy; extra == ""dev""', 'validate-pyproject[all]; extra == ""dev""']","# napari-imagej

### A [napari] plugin for access to [ImageJ2]

[![License](https://img.shields.io/pypi/l/napari-imagej.svg?color=green)](https://github.com/imagej/napari-imagej/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-imagej.svg?color=green)](https://pypi.org/project/napari-imagej)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-imagej.svg?color=green)](https://python.org)
[![tests](https://github.com/imagej/napari-imagej/workflows/tests/badge.svg)](https://github.com/imagej/napari-imagej/actions)
[![codecov](https://codecov.io/gh/imagej/napari-imagej/branch/main/graph/badge.svg)](https://codecov.io/gh/imagej/napari-imagej)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-imagej)](https://napari-hub.org/plugins/napari-imagej)

**napari-imagej** aims to provide access to all [ImageJ2] functionality through the [napari] graphical user interface. It builds on the foundation of [PyImageJ], a project allowing ImageJ2 access from Python.

**With napari-imagej, you can access:**

1. The napari-imagej widget, providing *headless access* to:
   * [ImageJ2 Commands] - 100+ image processing algorithms
   * [ImageJ Ops] - 500+ *functional* image processing algorithms
   * [SciJava Scripts] - migrated from Fiji or ImageJ2, or written yourself!
2. The ImageJ user interface, providing access to *the entire ImageJ ecosystem* within napari.

See the [project roadmap](https://github.com/orgs/imagej/projects/2) for future directions.

## Getting Started

Learn more about the project [here](https://napari-imagej.readthedocs.io/en/latest/), or jump straight to [installation](https://napari-imagej.readthedocs.io/en/latest/Install.html)!

## Usage

* [Image Processing with ImageJ Ops](https://napari-imagej.readthedocs.io/en/latest/examples/ops.html)
* [Puncta Segmentation with SciJava Scripts](https://napari-imagej.readthedocs.io/en/latest/examples/scripting.html)

## Troubleshooting

The [FAQ](https://napari-imagej.readthedocs.io/en/latest/Troubleshooting.html) outlines solutions to many common issues.

For more obscure issues, feel free to reach out on [forum.image.sc](https://forum.image.sc).

If you've found a bug, please [file an issue]!

## Contributing

We welcome any and all contributions made onto the napari-imagej repository.

Development discussion occurs on the [Image.sc Zulip chat](https://imagesc.zulipchat.com/#narrow/stream/328100-scyjava).

For technical details involved with contributing, please see [here](https://napari-imagej.readthedocs.io/en/latest/Development.html)

## License

Distributed under the terms of the [BSD-2] license,
""napari-imagej"" is free and open source software.

## Citing

_napari-imagej: ImageJ ecosystem access from napari_, Nature Methods, 2023 Aug 18

DOI: [10.1038/s41592-023-01990-0](https://doi.org/10.1038/s41592-023-01990-0)

[Apache Software License 2.0]: https://www.apache.org/licenses/LICENSE-2.0
[black]: https://github.com/psf/black
[BSD-2]: https://opensource.org/licenses/BSD-2-Clause
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[conda]: https://docs.conda.io/
[conda-forge]: https://conda-forge.org/
[file an issue]: https://github.com/imagej/napari-imagej/issues
[flake8]: https://flake8.pycqa.org/
[GNU GPL v3.0]: https://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: https://www.gnu.org/licenses/lgpl-3.0.txt
[ImageJ2]: https://imagej.net/software/imagej2
[ImageJ2 Commands]: https://github.com/imagej/imagej-plugins-commands
[ImageJ Ops]: https://imagej.net/libs/imagej-ops
[install mamba]: https://mamba.readthedocs.io/en/latest/installation.html
[isort]: https://pycqa.github.io/isort/
[mamba]: https://mamba.readthedocs.io/
[MIT]: https://opensource.org/licenses/MIT
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari]: https://github.com/napari/napari
[napari hub]: https://www.napari-hub.org/
[npe2]: https://github.com/napari/npe2
[pip]: https://pypi.org/project/pip/
[pull request]: https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests
[PyImageJ]: https://github.com/imagej/pyimagej
[PyPI]: https://pypi.org/
[SciJava Scripts]: https://imagej.net/scripting
[tox]: https://tox.readthedocs.io/
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Operating System :: Microsoft :: Windows', 'Operating System :: Unix', 'Operating System :: MacOS', 'License :: OSI Approved :: BSD License', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Software Development :: Libraries :: Java Libraries', 'Topic :: Software Development :: Libraries :: Python Modules']","['homepage, https://github.com/imagej/napari-imagej', 'documentation, https://napari-imagej.readthedocs.io', 'source, https://github.com/imagej/napari-imagej', 'download, https://pypi.org/project/napari-imagej/#files', 'tracker, https://github.com/imagej/napari-imagej/issues']",napari-imagej.get_trackmate_reader,,napari-imagej.func,,['*.xml'],,
234,napari-image-stacker,napari-image-stacker,napari-image-stacker,0.1.10,2022-01-11,2022-02-04,"Robin Koch, Marc Boucsein",robin.koch@dkfz-heidelberg.de,BSD3,https://github.com/RobAnKo/napari-image-stacker/issues,https://pypi.org/project/napari-image-stacker/,,https://github.com/RobAnKo/napari-image-stacker,A plugin designed to convert multiple open layers into a stack or vice versa,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy']","# napari-image-stacker

[![License](https://img.shields.io/pypi/l/napari-image-stacker.svg?color=green)](https://github.com/RobAnKo/napari-image-stacker/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-image-stacker.svg?color=green)](https://pypi.org/project/napari-image-stacker)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-image-stacker.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-image-stacker)](https://napari-hub.org/plugins/napari-image-stacker)

A plugin designed to convert multiple open layers into a stack or vice versa

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


## Installation

You can install `napari-image-stacker` via [pip]:

    pip install napari-image-stacker



To install latest development version :

    pip install git+https://github.com/RobAnKo/napari-image-stacker.git


## Contributing

Contributions are very welcome. Tests can be run with [tox].

## License

Distributed under the terms of the [BSD-3] license,
""napari-image-stacker"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/RobAnKo/napari-image-stacker/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/RobAnKo/napari-image-stacker/issues', 'Documentation, https://github.com/RobAnKo/napari-image-stacker#README.md', 'Source Code, https://github.com/RobAnKo/napari-image-stacker', 'User Support, https://github.com/RobAnKo/napari-image-stacker/issues']",,,napari-image-stacker.image_stacker_widget,,,,
235,napari-imaris-loader,napari-imaris-loader,napari-imaris-loader,0.1.8,2021-10-21,2022-04-13,Alan M Watson,alan.watson@pitt.edu,BSD-3-Clause,https://github.com/AlanMWatson/napari-imaris-loader/issues,https://pypi.org/project/napari-imaris-loader/,,https://github.com/AlanMWatson/napari-imaris-loader,Napari plugin for loading Bitplane imaris files '.ims',>=3.8,"['napari[all]', 'napari-plugin-engine (>=0.1.4)', 'imaris-ims-file-reader (>=0.1.5)', 'numpy', 'h5py', 'dask']","

# Description

This plugin enables viewing of Bitplane Imaris files, including very large datasets.  The GIFs below demonstrate rendering of a ~2TB IMS file containing a 2 color whole mouse brain.  The plugin has been tested on datasets as large as 20TB.

**NOTE: For this plugin to work ""File/Preferences/Experimental/Render Images Asynchronously"" must be selected.**

### Open IMS file:

![Open IMS file GIF](https://i.imgur.com/ByHb0wI.gif ""Open IMS file"")



### Render in 3D:

A plugin is provided to dynamically reload the data after selecting the lowest resolution level to be included in the viewer.  Since napari only renders the lowest resolution, the user can use this plugin to control the quality of 3D rendering.  See features and limitations for tips on suggested usage.

![3D Rendering and Quality Adjustment GIF](https://i.imgur.com/MZNlWtM.gif ""3D Rendering and Quality Adjustment"")

### Features

* Multiscale Rendering
  * Image pyramids which are present in the native IMS format are automatically added to napari during file loading.
* Chunks are implemented by dask and matched to the chunk sizes stored in each dataset.  (Napari appears to only ask for 2D chunks - unclear how helpful this feature is currently)
* Successfully handles multi-terabyte multi-timepoint multi-channel datasets.
* Tested with all sample files provided by Bitplane.
* Higher 3D rendering quality is enabled by a widget that reloads data after specifying the lowest resolution level (higher number = lower resolution) to be included in the multiscale series.

### Known Issues / limitations

* Currently, this is **only an image loader**, and there are no features for loading or viewing objects
* Napari sometimes throws errors indicating that it expected a 3D or 5D array but receives the other.
  * This sometimes *but relatively rarely* causes napari to crash
  * Would like to enable Asynchronous Tiling of Images, but this results in more instability and causes crashes.


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-imaris-loader` via [pip]:

    pip install napari-imaris-loader

## Change Log:

##### <u>v0.1.2:</u>

**Fixed:** Issue where .ims files containing a single color 2D image would not open.

**Fixed:** Issue where using the widget to change resolutions while in 3D rendering would cause a crash.  Now the viewer is automatically forced into 2D rendering mode when the widget is used.

**Dependency change:** The loader is now dependent in a separate package for loading IMS files.  https://pypi.org/project/imaris-ims-file-reader/

**v0.1.3:**

Documentation

**v0.1.4:**

Add napari to install requirements for plugin compatibility

**v0.1.5:**

Changes to napari:

- now requires napari[all] upon install.
- requires >=v0.1.5 of imaris-ims-file-reader

**v0.1.6:**

- Fix issue #7 where contrastLimits possibly unbound in reader

**v0.1.7:**

- For squeeze_output=False when opening .ims file for Napari compatibility

**v0.1.8:**

- Add automatic determination of contrast_limits
- Fix bug in squeeze_output

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-imaris-loader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/AlanMWatson/napari-imaris-loader/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/AlanMWatson/napari-imaris-loader/issues', 'Documentation, https://github.com/AlanMWatson/napari-imaris-loader#README.md', 'Source Code, https://github.com/AlanMWatson/napari-imaris-loader', 'User Support, https://github.com/AlanMWatson/napari-imaris-loader/issues']",napari-imaris-loader.napari_get_reader,,napari-imaris-loader.resolution_change,,['*'],,
236,napari-imc,napari-imc,napari-imc,0.6.5,2021-01-19,2022-06-01,Jonas Windhager,jonas.windhager@uzh.ch,MIT,https://github.com/BodenmillerGroup/napari-imc/issues,https://pypi.org/project/napari-imc/,,https://github.com/BodenmillerGroup/napari-imc,Imaging Mass Cytometry (IMC) file type support for napari,>=3.8,"['numpy', 'qtpy', 'readimc', 'superqt']","# napari-imc

[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-imc)](https://napari-hub.org/plugins/napari-imc)
[![PyPI](https://img.shields.io/pypi/v/napari-imc.svg?color=green)](https://pypi.org/project/napari-imc)
[![License](https://img.shields.io/pypi/l/napari-imc.svg?color=green)](https://github.com/BodenmillerGroup/napari-imc/raw/main/LICENSE)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-imc.svg?color=green)](https://python.org)
[![Issues](https://img.shields.io/github/issues/BodenmillerGroup/napari-imc)](https://github.com/BodenmillerGroup/napari-imc/issues)
[![Pull requests](https://img.shields.io/github/issues-pr/BodenmillerGroup/napari-imc)](https://github.com/BodenmillerGroup/napari-imc/pulls)

Imaging Mass Cytometry (IMC) file type support for napari

Load panoramas and multi-channel acquisitions co-registered within the machine's coordinate system from Fluidigm TXT/MCD files

## Installation

You can install napari-imc via [pip](https://pypi.org/project/pip/):

    pip install napari-imc
    
Alternatively, you can install napari-imc via [conda](https://conda.io/):

    conda install -c conda-forge napari-imc
    
For example, to install napari and napari-imc in a fresh conda environment using pip:

    conda create -n napari-imc python=3.9
    conda activate napari-imc
    pip install ""napari[all]"" napari-imc
    
## Usage

Simply open your Fluidigm TXT/MCD file using napari.

## Authors

Created and maintained by Jonas Windhager [jonas.windhager@uzh.ch](mailto:jonas.windhager@uzh.ch)

## Citation

Please cite the following paper when using napari-imc in your work:

> Windhager J, Bodenmiller B, Eling N (2021). An end-to-end workflow for multiplexed image processing and analysis. bioRxiv. doi: https://doi.org/10.1101/2021.11.12.468357.

    @article{Windhager2021,
      author = {Windhager, Jonas and Bodenmiller, Bernd and Eling, Nils},
      title = {An end-to-end workflow for multiplexed image processing and analysis},
      year = {2021},
      doi = {10.1101/2021.11.12.468357},
      URL = {https://www.biorxiv.org/content/early/2021/11/13/2021.11.12.468357},
      journal = {bioRxiv}
    }

## Contributing

[Contributing](https://github.com/BodenmillerGroup/napari-imc/blob/main/CONTRIBUTING.md)

## Changelog

[Changelog](https://github.com/BodenmillerGroup/napari-imc/blob/main/CHANGELOG.md)

## License

[MIT](https://github.com/BodenmillerGroup/napari-imc/blob/main/LICENSE.md)
","['Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/BodenmillerGroup/napari-imc/issues', 'Documentation, https://github.com/BodenmillerGroup/napari-imc#README.md', 'Source Code, https://github.com/BodenmillerGroup/napari-imc', 'User Support, https://github.com/BodenmillerGroup/napari-imc/issues']",napari-imc.get_reader,,napari-imc.IMCWidget,,"['*.mcd', '*.txt']",,
237,napari-imsmicrolink,napari-imsmicrolink,napari-imsmicrolink,0.1.9,2021-12-14,2023-02-10,Nathan Heath Patterson,heath.patterson@vanderbilt.edu,MIT,https://github.com/nhpatterson/napari-imsmicrolink/issues,https://pypi.org/project/napari-imsmicrolink/,,https://github.com/nhpatterson/napari-imsmicrolink,Plugin to perform IMS to microscopy registration using laser ablation marks.,>=3.8,"['numpy', 'tifffile', 'dask', 'zarr (>=2.10.3)', 'qtpy', 'aicsimageio[bioformats]', 'bioformats-jar', 'SimpleITK', 'pandas', 'h5py', 'opencv-python', 'czifile', 'imagecodecs', 'napari[all]']","# napari-imsmicrolink
![microlink-logo-update](https://user-images.githubusercontent.com/17855764/146078168-dd557089-ff10-46d6-b24d-268f5d21a9ee.png)

[![License](https://img.shields.io/pypi/l/napari-imsmicrolink.svg?color=green)](https://github.com/nhpatterson/napari-imsmicrolink/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-imsmicrolink.svg?color=green)](https://pypi.org/project/napari-imsmicrolink)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-imsmicrolink.svg?color=green)](https://python.org)
[![tests](https://github.com/nhpatterson/napari-imsmicrolink/workflows/tests/badge.svg)](https://github.com/nhpatterson/napari-imsmicrolink/actions)

[napari] plugin to perform MALDI IMS - microscopy registration using laser ablation marks as described in [Anal. Chem. 2018, 90, 21, 12395â12403](https://pubs.acs.org/doi/abs/10.1021/acs.analchem.8b02884). This plugin is a work-in-progress but is mostly functional.

__N.B.__ This tool is __NOT__ a general purpose registration framework to find transforms between IMS (MALDI or otherwise)
and microscopy. It is built to align MALDI IMS pixels to their corresponding laser ablation marks as captured by microscopy AFTER the IMS experiment. 
This approach has the advantage of providing direct evidence of registration performance as IMS pixels are aligned 
to their _explicit spatial origin_ in microscopy space, improving overall accuracy and confidence of microscopy-driven IMS 
data analysis.

## Installation

You can install `napari-imsmicrolink` via [pip]:

    pip install napari-imsmicrolink

### Typical experiment workflow
1. Acquire pre-IMS microscopy (autofluorescence, brightfield) - _optional_
2. Perform normal IMS sample preparation.
3. Acquire post-IMS microscopy (autofluorescence, brightfield) with matrix still on sample
that reveals laser ablation marks.

4. Gather IMS data that contains XY integer coordinates for the IMS experiment
   (.imzML, Bruker spotlist (.txt, .csv), Bruker peaks.sqlite (_FTICR_),
   Bruker .tsf (TIMS qTOF only))

5. Run `napari-imsmicrolink` with data 3 and 4

6. Once registered, use `wsireg` to align other microscopy modalities to IMS-registered post-IMS
microscopy

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-imsmicrolink"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/nhpatterson/napari-imsmicrolink/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/nhpatterson/napari-imsmicrolink/issues', 'Documentation, https://github.com/nhpatterson/napari-imsmicrolink#README.md', 'Source Code, https://github.com/nhpatterson/napari-imsmicrolink', 'User Support, https://github.com/nhpatterson/napari-imsmicrolink/issues']",,,napari-imsmicrolink.IMSMicroLink,,,,
238,napari-input-visualizer,napari-input-visualizer,Input Visualizer,0.0.1,2022-10-10,2022-10-10,David Bauer,dbauer@brc.hu,BSD-3-Clause,https://github.com/bauerdavid/napari-input-visualizer/issues,https://pypi.org/project/napari-input-visualizer/,,https://github.com/bauerdavid/napari-input-visualizer,Visualize keyboard and mouse button presses,>=3.8,"['numpy', 'magicgui', 'qtpy', 'napari', 'imageio-ffmpeg', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-input-visualizer

[![License BSD-3](https://img.shields.io/pypi/l/napari-input-visualizer.svg?color=green)](https://github.com/bauerdavid/napari-input-visualizer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-input-visualizer.svg?color=green)](https://pypi.org/project/napari-input-visualizer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-input-visualizer.svg?color=green)](https://python.org)
[![tests](https://github.com/bauerdavid/napari-input-visualizer/workflows/tests/badge.svg)](https://github.com/bauerdavid/napari-input-visualizer/actions)
[![codecov](https://codecov.io/gh/bauerdavid/napari-input-visualizer/branch/main/graph/badge.svg)](https://codecov.io/gh/bauerdavid/napari-input-visualizer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-input-visualizer)](https://napari-hub.org/plugins/napari-input-visualizer)

Visualize keyboard and mouse button presses

A simple tool to visualize input events like keyboard presses or mouse clicking and scrolling. Use it to create tutorial videos or to demonstrate a bug you encountered!

## Demo:


https://user-images.githubusercontent.com/36735863/194586424-1e6288d3-2c2f-412c-a1cb-91d139f787bd.mp4



----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-input-visualizer` via [pip]:

    pip install napari-input-visualizer



To install latest development version :

    pip install git+https://github.com/bauerdavid/napari-input-visualizer.git


## Contributing

Contributions are very welcome.

## License

Distributed under the terms of the [BSD-3] license,
""napari-input-visualizer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/bauerdavid/napari-input-visualizer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/bauerdavid/napari-input-visualizer/issues', 'Documentation, https://github.com/bauerdavid/napari-input-visualizer#README.md', 'Source Code, https://github.com/bauerdavid/napari-input-visualizer', 'User Support, https://github.com/bauerdavid/napari-input-visualizer/issues']",,,napari-input-visualizer.input_visualizer_widget,,,,
239,napari-indices,napari-indices,indices,0.0.2,2023-05-30,2023-05-31,Emmanuella OKAFOR,eokafor010@gmail.com,BSD-3-Clause,https://github.com/Emmanulla0/napari-indices/issues,https://pypi.org/project/napari-indices/,,https://github.com/Emmanulla0/napari-indices,Calculer les indices de vÃ©gÃ©tation,>=3.8,"['numpy', 'magicgui', 'qtpy', 'spectral', 'matplotlib', 'tifffile', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-indices

[![License BSD-3](https://img.shields.io/pypi/l/napari-indices.svg?color=green)](https://github.com/Emmanulla0/napari-indices/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-indices.svg?color=green)](https://pypi.org/project/napari-indices)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-indices.svg?color=green)](https://python.org)
[![tests](https://github.com/Emmanulla0/napari-indices/workflows/tests/badge.svg)](https://github.com/Emmanulla0/napari-indices/actions)
[![codecov](https://codecov.io/gh/Emmanulla0/napari-indices/branch/main/graph/badge.svg)](https://codecov.io/gh/Emmanulla0/napari-indices)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-indices)](https://napari-hub.org/plugins/napari-indices)

Calculer les indices de vÃ©gÃ©tation

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->
Emmanuella OKAFOR (L3 PA CMI-PSI_UniversitÃ© d'Angers) developed this plugin during her internship with a french team called ImHorPHen (lead by David ROUSSEAU). This plugin realises vegetation indexes computation with hyperspectral images. For the momment, there are five vegetation indexes : NDVI, TCARI, NPCI, SGI, NDGI.
## Installation

You can install `napari-indices` via [pip]:

    pip install napari-indices



To install latest development version :

    pip install git+https://github.com/Emmanulla0/napari-indices.git

## Plugin description


Using this plugin requires importing the bands of a hyperspectral image into a **tif file**, in our case, 160 bands. You must launch it by accessing the **Plugins > napari-indices> Vegetation indices** menu.

![Capture d'Ã©cran 2023-05-29 124720](https://github.com/Emmanuella0/napari-indices/assets/132358490/3b3895df-d0a7-466e-8ada-92bd4b642852)

Then select the vegetation index to be calculated and the different bands to be used, then click the **Run** button to start the calculation. This results in the images corresponding to the calculated indices.

![etape_2](https://github.com/Emmanuella0/napari-indices/assets/132358490/4875f0fc-3435-4875-ba4e-8881cb179b96)


The areas of interest to be analysed must then be defined. To do this, click the **Shapes** button on the Napari interface and choose the **add rectangle** shape from the menu that appears. Using the mouse, it is then possible to draw a rectangle on each of the two areas to be analyzed, for example a tree sheet and a green sheet of paper. 

![etape_3](https://github.com/Emmanuella0/napari-indices/assets/132358490/fc8612fe-5deb-4290-b4c3-9cac20acf1ce)


To perform the Fisher ratio calculation and display the histogram, it is necessary to go back to the **Plugins > napari-indices > ExempleQWidget** menu and click the **Click me! **. This action opens a new window displaying the best vegetation index to use, its corresponding Fisher ratio and the histogram of the two selected regions on the image of the vegetation index concerned. A video explaining the plugin is available at: https://uabox.univ-angers.fr/index.php/s/LqB0qs11n3jxZVJ.

![Histogram](https://github.com/Emmanuella0/napari-indices/assets/132358490/be176176-1972-402c-9a01-8e367347d9d8)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-indices"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/Emmanulla0/napari-indices/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/Emmanulla0/napari-indices/issues', 'Documentation, https://github.com/Emmanulla0/napari-indices#README.md', 'Source Code, https://github.com/Emmanulla0/napari-indices', 'User Support, https://github.com/Emmanulla0/napari-indices/issues']",napari-indices.get_reader,napari-indices.write_multiple,napari-indices.make_qwidget,napari-indices.make_sample_data,['*.npy'],,['.npy']
240,napari-intensity-plotter,napari-intensity-plotter,Intensity Plotter,0.1.6,2024-10-20,2024-11-15,Toranosuke Takagi,toranporin_1224@yahoo.co.jp,"Copyright (c) 2024, Toranosuke...",https://github.com/Tbrn1103/napari-intensity-plotter/issues,https://pypi.org/project/napari-intensity-plotter/,,,A plugin for plotting intensity profiles with control features in napari.,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'pyqtgraph; extra == ""testing""']","# napari-intensity-plotter

[![License BSD-3](https://img.shields.io/pypi/l/napari-intensity-plotter.svg?color=green)](https://github.com/Tbrn1103/napari-intensity-plotter/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-intensity-plotter.svg?color=green)](https://pypi.org/project/napari-intensity-plotter)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-intensity-plotter.svg?color=green)](https://python.org)
[![tests](https://github.com/Tbrn1103/napari-intensity-plotter/workflows/tests/badge.svg)](https://github.com/Tbrn1103/napari-intensity-plotter/actions)
[![codecov](https://codecov.io/gh/Tbrn1103/napari-intensity-plotter/branch/main/graph/badge.svg)](https://codecov.io/gh/Tbrn1103/napari-intensity-plotter)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-intensity-plotter)](https://napari-hub.org/plugins/napari-intensity-plotter)

# napari-intensity-plotter

**napari-intensity-plotter** is a plugin for **[napari](https://napari.org)** that provides tools to measure and plot intensity profiles in 2D time-series images.

![Intensity Plot Widget](images/intensity_plot_widget_example.png)

*Screenshot: Intensity profile of a region of interest in a 2D time-series image.*

## Features

- **Intensity Plot Widget**: Allows you to select a region of interest in a 2D time-series image and plot the intensity profile over time.
- **Intensity Plot Control Widget**: Lets you fine-tune plot parameters and save the results as CSV or PNG files.

## Installation

You can install `napari-intensity-plotter` via pip:

```bash
pip install napari-intensity-plotter
```

Alternatively, you can install it directly from the napari plugin interface.

### Usage

1. **Load a 2D Time-Series Image**  
   Load a 2D time-series image (e.g., fluorescence microscopy data) in napari.

2. **Activate the Widgets**  
   Open the `Intensity Plot Widget` and `Intensity Plot Control Widget` from the `Plugins` menu in napari.

3. **Intensity Plot Widget**  
   - Move your mouse over the image, or click on a specific location to plot the intensity profile of the selected region across slices (e.g., time).
   - The region of interest (ROI) size can be adjusted using the square size setting in the control widget.

4. **Intensity Plot Control Widget**  
   - Configure the square size for the ROI (ensures that the region size remains odd).
   - Set the directory to save plots and intensity data.
   - Save the intensity profile as a `.csv` or `.png` file by clicking the corresponding buttons or using keyboard shortcuts (`Ctrl+S`).

5. **Additional Controls**  
   - Hide all layers using the `Hide All Layers` button or `Ctrl+D`.
   - Use the rectangle to visualize the selected ROI.

### Example Workflow

**Step 1**: Load a 2D time-series image (e.g., `tif` or `nd2`) into napari. Ensure the layer is visible.

**Step 2**: Open the `Intensity Plot Widget` to visualize intensity changes over time or slices for a specific ROI.

**Step 3**: Use the `Intensity Plot Control Widget` to:
- Adjust the square size for the ROI.
- Specify a directory to save intensity data.
- Enable saving in CSV or PNG formats.
  
**Step 4**: Save the plotted intensity data by clicking `Save to CSV/PNG` or pressing `Ctrl+S`.

**Step 5**: Hide all layers if necessary using `Hide All Layers` or `Ctrl+D`.

## Contributing

Contributions are welcome! If you encounter issues or have ideas for new features, please submit them via the [GitHub Issues](https://github.com/Tbrn1103/napari-intensity-plotter/issues).

## Acknowledgements

This plugin was developed using the **napari plugin cookiecutter template**, which greatly streamlined the creation of this tool. See the [cookiecutter-napari-plugin](https://github.com/napari/cookiecutter-napari-plugin) for more details.

Special thanks to the napari community for their continuous support and resources.

## License

This project is licensed under the BSD 3-Clause License. See the [LICENSE](LICENSE) file for details.
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/Tbrn1103/napari-intensity-plotter/issues', 'Documentation, https://github.com/Tbrn1103/napari-intensity-plotter#README.md', 'Source Code, https://github.com/Tbrn1103/napari-intensity-plotter', 'User Support, https://github.com/Tbrn1103/napari-intensity-plotter/issues']",,,napari-intensity-plotter.IntensityPlotWidget,,,,
241,napari-itk-io,napari-itk-io,napari-itk-io,0.4.1,2021-04-28,2024-11-13,Matt McCormick,matt.mccormick@kitware.com,Apache-2.0,https://github.com/InsightSoftwareConsortium/napari-itk-io,https://pypi.org/project/napari-itk-io/,,https://github.com/InsightSoftwareConsortium/napari-itk-io,File IO with itk for napari,>=3.8,"['numpy', 'napari-plugin-engine>=0.2.0', 'itk-io>=5.2.0', 'itk-napari-conversion']","# napari-itk-io

[![License](https://img.shields.io/pypi/l/napari-itk-io.svg?color=green)](https://github.com/InsightSoftwareConsortium/napari-itk-io/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-itk-io.svg?color=green)](https://pypi.org/project/napari-itk-io)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-itk-io.svg?color=green)](https://python.org)
[![tests](https://github.com/InsightSoftwareConsortium/napari-itk-io/workflows/tests/badge.svg)](https://github.com/InsightSoftwareConsortium/napari-itk-io/actions)
[![codecov](https://codecov.io/gh/InsightSoftwareConsortium/napari-itk-io/branch/master/graph/badge.svg)](https://codecov.io/gh/InsightSoftwareConsortium/napari-itk-io)

File IO with [itk](https://itk.org) for [napari](https://napari.org).

Image metadata, e.g. the pixel spacing, origin, and metadata tags, are preserved and passed into napari.

Supported image file formats:

- [BioRad](http://www.bio-rad.com/)
- [BMP](https://en.wikipedia.org/wiki/BMP_file_format)
- [DICOM](http://dicom.nema.org/)
- [DICOM Series](http://dicom.nema.org/)
- [ITK HDF5](https://support.hdfgroup.org/HDF5/)
- [JPEG](https://en.wikipedia.org/wiki/JPEG_File_Interchange_Format)
- [GE4,GE5,GEAdw](http://www3.gehealthcare.com)
- [Gipl (Guys Image Processing Lab)](https://www.ncbi.nlm.nih.gov/pubmed/12956259)
- [LSM](http://www.openwetware.org/wiki/Dissecting_LSM_files)
- [MetaImage](https://itk.org/Wiki/ITK/MetaIO/Documentation)
- [MINC 2.0](https://en.wikibooks.org/wiki/MINC/SoftwareDevelopment/MINC2.0_File_Format_Reference)
- [MGH](https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/MghFormat)
- [MRC](http://www.ccpem.ac.uk/mrc_format/mrc_format.php)
- [NifTi](https://nifti.nimh.nih.gov/nifti-1)
- [NRRD](http://teem.sourceforge.net/nrrd/format.html)
- [Portable Network Graphics (PNG)](https://en.wikipedia.org/wiki/Portable_Network_Graphics)
- [Tagged Image File Format (TIFF)](https://en.wikipedia.org/wiki/TIFF)
- [VTK legacy file format for images](http://www.vtk.org/VTK/img/file-formats.pdf)

For DICOM Series, select the folder containing the series with *File -> Open
Folder...*. The first series will be selected and sorted spatially.

## Installation

You can install `napari-itk-io` via [pip]:

    pip install napari-itk-io

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

Follow the [itk contributing
guidelines](https://github.com/InsightSoftwareConsortium/ITK/blob/master/CONTRIBUTING.md)
and the [itk code of
conduct](https://github.com/InsightSoftwareConsortium/ITK/blob/master/CODE_OF_CONDUCT.md).

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-itk-io"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/InsightSoftwareConsortium/napari-itk-io/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Operating System :: OS Independent', 'License :: OSI Approved :: Apache Software License']",,napari-itk-io.get_reader,napari-itk-io.write_multiple,,,"['*.bmp', '*.dcm', '*.dicom', '*.gipl', '*.gipl.gz', '*.h5', '*.hdf5', '*.hdr', '*.jpg', '*.jpeg', '*.lsm', '*.mnc', '*.mnc.gz', '*.mnc2', '*.mgh', '*.mgz', '*.mgh.gz', '*.mha', '*.mhd', '*.mrc', '*.nia', '*.hdr', '*.nhdr', '*.nii', '*.nii.gz', '*.nrrd', '*.pic', '*.png', '*.tif', '*.tiff', '*.vtk']",,"['.bmp', '.dcm', '.dicom', '.gipl', '.gipl.gz', '.h5', '.hdf5', '.hdr', '.jpg', '.jpeg', '.lsm', '.mnc', '.mnc.gz', '.mnc2', '.mgh', '.mgz', '.mgh.gz', '.mha', '.mhd', '.mrc', '.nia', '.hdr', '.nhdr', '.nii', '.nii.gz', '.nrrd', '.pic', '.png', '.tif', '.tiff', '.vtk']"
242,napari-ism,napari-ISM,Napari-ISM,1.0.7,2022-05-26,2023-08-30,Alessandro Zunino,Alessandro Zunino <alessandro.zunino@iit.it>,Unavailable,https://github.com/VicidominiLab/napari-ism,https://pypi.org/project/napari-ISM/,,https://github.com/VicidominiLab/napari-ISM,A Napari plugin for analysing and simulating ISM images,>=3.7,"['numpy', 'scipy', 'h5py', 'PyQt5', 'brighteyes-ism >=1.2.2', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-ISM

[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-ISM)](https://napari-hub.org/plugins/napari-ISM)
[![License](https://img.shields.io/pypi/l/napari-ISM.svg?color=green)](https://github.com/VicidominiLab/napari-ISM/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-ISM.svg?color=green)](https://pypi.org/project/napari-ISM)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-ISM.svg?color=green)](https://python.org)


This plugin is built upon the python package [BrightEyes-ISM]. Napari-ISM enables the simulation, loading, and analysis of ISM datasets.
More in detail, it performs:

* Loading and compression of .h5 files generated by the [MCS software].
* Simulation of a realistic dataset of tubulin filaments.
* Simulation of realistic ISM Point Spread Functions.
* Summing over the detector array dimension
* Adaptive Pixel Reassignment
* Multi-image deconvolution
* Focus-ISM

----------------------------------

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-ISM` via [PyPI]:

    pip install napari-ISM
    
or by using [napari hub].

It requires the following Python packages

    numpy
    scipy
    h5py
    PyQt5
    brighteyes-ism>=1.2.0

## Documentation

To generate a simulated dataset, go to `File > Open Sample > ISM dataset`. 

![](https://github.com/VicidominiLab/napari-ISM/raw/main/docs/sample.png)

To acces the plugin list, go to `Plugins > Napari-ISM`.

![](https://github.com/VicidominiLab/napari-ISM/raw/main/docs/plugin_list.png)

To open a .h5 file, go to `File > Open `.
You can then sum over the dimensions that are not needed, using the command `integrateDims`.
The default axes are 0 (repetition), 1 (axial position), and 4 (time).

![](https://github.com/VicidominiLab/napari-ISM/raw/main/docs/file.png)

Note that all the analysis commands expect an input with size `X x Y X Ch`.

To see the result of summing over the SPAD dimensions `Ch`, use the plugin command `Sum`. Then, press `Run`.

![](https://github.com/VicidominiLab/napari-ISM/raw/main/docs/sum.png)

To see the result of Adaptive Pixel Reassignment, use the plugin command `APR_stack`.
Select as reference image (`ref`) the central one. Select an upsampling factor (`usf`), 
which corresponds to the sub-pixel precision of the shift-vector estimation. Then, press `Run`.

![](https://github.com/VicidominiLab/napari-ISM/raw/main/docs/apr.png)

To generate the PSFs, use the plugin command `PSFs`. Select an image layer (`img layer`), 
it will be used to determine the number of pixels and the pixel size.
Then, select the detector pixel size (`pxsize`) and pixel pitch (`pxpitch`) in microns.
Select the magnification of the system (`M`). Select the excitation (`exWl`) and emission wavelength (`emWl`) in nanometers.
Then, press `Run`.

![](https://github.com/VicidominiLab/napari-ISM/raw/main/docs/PSF.png)

To see the result of multi-image deconvolution, use the plugin command `Deconvolution`.
Select an image layer (`img layer`) containing the ISM dataset to deconvolve and another image layer (`psf layer`) containing the PSFs, either simulated or experimental.
Then, press `Run`.

![](https://github.com/VicidominiLab/napari-ISM/raw/main/docs/deconv.png)

To use Focus-ISM, first select a region on the input dataset using a `shapes` layer.
Select a rectangle containing mainly in-focus emitters. It will be used as a calibration.
Then, use the plugin command `Focus-ISM`. Select an image layer (`img layer`) containing the ISM dataset and a shape layer (`shape layer`) defining the calibration region.
Select a lower bound for the standard deviation of the out-of-focus curve (`sigma B bound`) in units of standard deviations of the in-focus term. We suggest to never select a value below 2.
Select a threshold (`threshold`) in units of photon counts. Scan coordinates with less photons than the threshold will be skipped in the analysis and classified as background. Then, press `Run`.

![](https://github.com/VicidominiLab/napari-ISM/raw/main/docs/shapes.png)

To use FRC, prepare the dataset to be in the shape `xyt`.
Select the theshodling method (`method`) and smoothing method (`smoothing`) among those available.
Then, press `Calculate`.

![](https://github.com/VicidominiLab/napari-ISM/raw/main/docs/frc.png)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU LGPL v3.0] license,
""napari-ISM"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/VicidominiLab/napari-ISM/issues

[napari hub]: https://www.napari-hub.org/plugins/napari-ISM
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/project/napari-ISM/

[BrightEyes-ISM]: https://github.com/VicidominiLab/BrightEyes-ISM
[MCS software]: https://github.com/VicidominiLab/BrightEyes-MCS
","['Framework :: napari', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)']","['Homepage, https://github.com/VicidominiLab/napari-ism', 'Documentation, https://brighteyes-ism.readthedocs.io']",napari-ISM.get_reader,napari-ISM.write_multiple,napari-ISM.APR_stack,napari-ISM.make_sample_data,"['*.npy', '*.h5']",,"['.npy', '.h5']"
243,napari-k2-wavebreaker,napari-k2-WaveBreaker,K2 Wave Breaker,0.2.5,2024-12-02,2024-12-03,Sam Kris Vanspauwen,sam.vanspauwen.dk@gmail.com,BSD-3-Clause,,https://pypi.org/project/napari-k2-WaveBreaker/,None,,later,>=3.8,"['numpy', 'magicgui', 'qtpy', 'plotly', 'pandas', 'scikit-learn', 'opencv-python', 'matplotlib', 'pathvalidate', 'seaborn', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-k2-WaveBreaker

[![License BSD-3](https://img.shields.io/pypi/l/napari-k2-WaveBreaker.svg?color=green)](https://github.com/SamKVs/napari-k2-WaveBreaker/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-k2-WaveBreaker.svg?color=green)](https://pypi.org/project/napari-k2-WaveBreaker)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-k2-WaveBreaker.svg?color=green)](https://python.org)
[![tests](https://github.com/SamKVs/napari-k2-WaveBreaker/workflows/tests/badge.svg)](https://github.com/SamKVs/napari-k2-WaveBreaker/actions)
[![codecov](https://codecov.io/gh/SamKVs/napari-k2-WaveBreaker/branch/main/graph/badge.svg)](https://codecov.io/gh/SamKVs/napari-k2-WaveBreaker)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-k2-WaveBreaker)](https://napari-hub.org/plugins/napari-k2-WaveBreaker)

<div>
    <img src=""static/Logo.png"">
</div>
<h2>About this plugin</h2>


This Napari plugin was designed for the detection and quantification of periodic biological structures.
As this plugin has not been uploaded to napari-hub as of this moment it **cannot be installed on a pre-compiled, bundled 
version of Napari**. Therefore Napari will need to be installed as a python package 
(<a href=""https://napari.org/stable/tutorials/fundamentals/installation.html"">more info about Napari installation</a>). 
Further information about the installation and licensing of the plugin can be found below. A detailed manual on the usage of the plugin can be found below as well. 

**If you have any questions or need help with the installation, please do hesitate to use the issues tab.**

**In case you need a tutorial on how to use the plugin, please use the ""tutorial request"" label in the issues tab to reach out to me:**


<h3>Guide</h3>

Actin is the most abundant protein in eukaryotic cells. As it is part of the cytoskeleton its function is essential for 
the maintenance of the cell's morphological structure. In neurons, it was only recently that researchers started paying 
attention to the peculiar subcellular organization and localization of actin. First focussing on the dendritic spines, 
later expanding to the axon.  

The axon initial segment (AIS) is defined as the most proximal 30-60 Âµm of the axon and is known for its sturdy 
actin-betaIV cytoskeletal structure which is known to facilitate the densely packed ion channels, regulatory and
scaffolding proteins on the membrane. The recent popularity of superresolution microscopy techniques like STORM and STED
has made the study of the localization of these proteins relatively easy and straightforward.

&nbsp;
<p align=""center"">
    <img src=""static/Figure 1.svg"" width=""100%"">
</p>
&nbsp;

Because of this property of the AIS many ion channels are localized either perpendicular to the actin rings
or attached to a scaffolding protein called Ankyrin G which is localized in between two actin rings. This results in ion 
channels like the Kv 1.1 (displayed below) appearing similar to superresolution images of actin.

&nbsp;
<div align=""center"">
    <img src=""static/AIS.png"" width=""100%"" style=""mix-blend-mode: screen"">
    <i align=""center"" style=""font-size: 9px""> Example image of a rat hippocampal neuron AIS immunostained for Kv1.1.
Image made on a Zeiss AxioImager Z1 equipped with a STEDYCON scanhead detector for confocal and super-resolution imaging,
fitted with 4 APDs. Post-acquisition, image was deconvolved using Huygens Deconvolution Software  </i>
</div>

&nbsp;

This plugin was designed to detect and quantify the distance and the goodness of periodicity between cellular periodic structures. 
Additionally, it can be used to detect and quantify the periodicity shift between two periodic stuctures.

&nbsp;



<a href=""static/WaveBreaker User Manual.pdf"">
    <img src=""static/UM BUT.svg"" width=""50%"">  
</a>

<a href=""static/TEMPLATE AUTOCORRELATION 0.17-0.21 (x10).xlsx"">
    <img src=""static/AC EX BUT.svg"" width=""50%"">  
</a>

<a href=""static/TEMPLATE CROSSCORRELATION (x15).xlsx"">
    <img src=""static/CC EX BUT.svg"" width=""50%"">  
</a>

<a href=""static/Post-processing.py"">
    <img src=""static/EX%20PY.svg"" width=""50%"">
</a>


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-k2-WaveBreaker` via [pip]:

    pip install napari-k2-WaveBreaker

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-k2-autocorrelation"" is free and open source software

## Issues

If you encounter any problems, please file an issue along with a detailed description or reach out to me.

[napari]: https://github.com/napari/napari

[Cookiecutter]: https://github.com/audreyr/cookiecutter

[@napari]: https://github.com/napari

[MIT]: http://opensource.org/licenses/MIT

[BSD-3]: http://opensource.org/licenses/BSD-3-Clause

[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt

[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt

[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0

[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt

[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari

[tox]: https://tox.readthedocs.io/en/latest/

[pip]: https://pypi.org/project/pip/

[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']",,,,napari-k2-WaveBreaker.AutocorrelationTool,,,,
244,napari-j,napari-J,napari-J,0.3,2022-01-07,2023-03-03,Volker Baecker,volker.baecker@mri.cnrs.fr,MIT,https://github.com/MontpellierRessourcesImagerie/napari-J/issues,https://pypi.org/project/napari-J/,,https://github.com/MontpellierRessourcesImagerie/napari-J,A plugin to exchange data with FIJI and to use FIJI image analysis from napari,>=3.7,"['JPype1 (>=1.2.1)', 'matplotlib', 'imageio-ffmpeg', ""matplotlib ; extra == 'testing'"", ""imageio-ffmpeg ; extra == 'testing'"", ""python-matplotlib-qt5 ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'""]","# napari-J

[![License](https://img.shields.io/pypi/l/napari-J.svg?color=green)](https://github.com/MontpellierRessourcesImagerie/napari-J/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-J.svg?color=green)](https://pypi.org/project/napari-J)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-J.svg?color=green)](https://python.org)
[![tests](https://github.com/MontpellierRessourcesImagerie/napari-J/workflows/tests/badge.svg)](https://github.com/MontpellierRessourcesImagerie/napari-J/actions)
[![codecov](https://codecov.io/gh/MontpellierRessourcesImagerie/napari-J/branch/master/graph/badge.svg)](https://codecov.io/gh/MontpellierRessourcesImagerie/napari-J)

A plugin to exchange data with FIJI and to use FIJI image analysis from napari.
Current features are:

 * get the active image from FIJI
 * send a screenshot to FIJI
 * get a set of points from the FIJI results table
 * filter the points in napari
 * send the filtered points back to FIJI
 
Known problems:

* Crashes on linux  when the file-dialog is opened. Workaround: Set the option ``Use JFileChooser to open/save`` from the ``Edit>Options>Input/Output`` menu.
* 03.05.2022 - Currently you need to have the range of the quality values for point between 0 and 255, in the new version they can have any range, but we are waiting for the bug in napari 0.4.15 to be fixed to release this. 

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-J` via [pip]:

    pip install napari-J

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-J"" is free and open source software

## Issues

If you encounter any problems, please [file an issue](https://github.com/MontpellierRessourcesImagerie/napari-J/issues) along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MontpellierRessourcesImagerie/napari-J/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'Topic :: Scientific/Engineering', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Framework :: napari']","['Bug Tracker, https://github.com/MontpellierRessourcesImagerie/napari-J/issues', 'Documentation, https://github.com/MontpellierRessourcesImagerie/napari-J#README.md', 'Source Code, https://github.com/MontpellierRessourcesImagerie/napari-J', 'User Support, https://github.com/MontpellierRessourcesImagerie/napari-J/issues']",,,napari-J.Connection,,,,
245,napari-kld,napari-kld,Kernel Learning Deconvolution,1.1.0,2024-07-31,2024-08-05,Qiqi Lu,136303971@qq.com,"Copyright (c) 2024, Qiqi Lu
Al...",,https://pypi.org/project/napari-kld/,None,,"Kernel learning deconvolution (KLD) is a rapid deconvolution algorithm for fluorescence microscopic image, which learns the forward and backward kernels in Richardson-Lucy Deconvolution (KLD) from paired low-/high-resolution images. ",>=3.9,"['numpy==1.26.4', 'magicgui', 'qtpy', 'scikit-image', 'torch==2.0', 'torchvision', 'fft-conv-pytorch', 'pytorch-msssim', 'tensorboard', 'pydicom', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-kld

[![License](https://img.shields.io/pypi/l/napari-kld.svg?color=green)](https://github.com/qiqi-lu/napari-kld/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-kld.svg?color=green)](https://pypi.org/project/napari-kld)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-kld.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-kld)](https://napari-hub.org/plugins/napari-kld)

`napari-kld` is a `napari` plugin that implements kernel learning deconvolution algrotihm.

## **Kernel Learning Deconvolution (KLD)**

KLD is a rapid deconvolution algorithm for fluorescence microscopic image, which learns the forward and backward kernels in Richardson-Lucy Deconvolution (RLD) from paired low-resolution (LR) and high-resolution (HR) images.

It only requires **one sample** to training the model, and **two iterations** to achieve a superior deconvolution performance compared to RLD and its variants using unmatched backward projection.

**This [napari] plugin was generated with [copier] using the [napari-plugin-template].*

## **Installation**

You must install `napari` firstly and then install `napari-kld`.

### **Install `napari`**

You can download the `napari` bundled app for a simple installation via https://napari.org/stable/tutorials/fundamentals/quick_start.html#installation.

Or, you can install `napari` with Python using pip:

```
conda create -y -n napari-env -c conda-forge python=3.10
conda activate napari-env
python -m pip install 'napari[all]'
```

Refer to https://napari.org/stable/tutorials/fundamentals/quick_start.html#installation.

### **Install `napari-kld`**

You can install `napari-kld` plugin with `napari`:

`Plugins` > `Install/Uninstall Pluginsâ¦` > [search napari-kld] > `install`.


Or you can install `napari-kld` via [pip]:

    pip install napari-kld

## **Instruction**
This plugin includes two part:

- `RL Deconvolution` : Conventional RLD algorithm using different type of backward kernels (including matched backward kernel [`Traditional`] and unmatched backward kernels [`Guassian`, `Butterworth`, `Wiener-Butterworth (WB)`]). The forward kernel, i.e., point spread function (PSF), is required.

- `KL Deconvolution` : KLD using learned forward/backward kernels.

**You can download the `""test""` folder  at https://github.com/qiqi-lu/kernel-learning-deconvolution for testing, which save some 2D/3D images used for training and testing.**

## **RL Deconvolution**

The conventional RLD using different type of backward kernels.

1. Open `napari` and load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `RL Deconvolution`

2. Load input low-resolution (LR) image: `File` > `Open File(s)` > `[choose the image to be deconvolved]` > `[the image will appear in the layer list of napari]`, such as the simulated image `""test/data/simulation/data_128_128_128_gauss_0.0_poiss_0_ratio_1.0/train/raw/0.tif""`.

3. Choose the name of loaded image in `Input RAW data`, such as `""0""`.

4. Press `Choose` to choose a `PSF` correspongding to the loaded image, such as `""test/data/simulation/data_128_128_128_gauss_0.0_poiss_0_ratio_1.0/train/psf.tif""`.

5. Choose the type of backward kernel in `Method` combo box:

    - `Traditional` : the backward kernel is just the flip of forward kernel (i.e., PSF).
    - `Guassian` : Guassian-shaped backward kernel, thw FWHM of which is same as the forward kernel.
    - `Butterworth` : Butterworth-shaped backward kernel, which is constructed using Butterworth filter.
    - `WB` : WB-shaped backward kernel, which is constructed by combining Wiener and Butterworth filter.

6. Set the number of RL iterations `Iterations` and parameters of backward kernel*.

7. Press `run` button to do deconvolution.

8. Wait the `progress bar` to reach 100%.

9. The output deconved image will appear in the layer list named as `{name of input image}_deconv_{Method}_iter_{Iterations}`, such as `""0_deconv_traditional_iter_30""`.

**The adjustment of parameters of backward kernels should refer to the paper : Guo, M. et al. Rapid image deconvolution and multiview fusion for optical microscopy. Nat Biotechnol 38, 1337â1346 (2020).*

## **KL Deconvolution**

### **Training data preparation**

The data used for training must be prepared in a folder consisting of:

- A folder named `""gt""` (optional) , such as `""test/data/real/2D/train/gt""`, which saves all the GT images (only support .tif file).
- A folder named `""raw""`, such as `""test/data/real/2D/train/raw""`, which saves all the LR images (only support .tif file). The file names must be the same as those in `""gt""` folder.
- A file named `""train.txt""`, such as `""test/data/real/2D/train/train.txt""`, which saves the name of each image in `""gt""/""raw""` filder in each line.

### **When yuo have paired LR image and HR image**

When we have paired LR image and HR image, we can treat LR image as **raw input** and HR image as **ground truth** (GT). We can first learn the forward kernel and then learn the backward kernel in a **supervised strategy**.

#### **Training of Forward Projection**

Train the forward projection to learn forward kernel.

1. Open `napari` and load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `KL Deconvolution`

2. Choose `Training` tab.

3. Choose `Data Directory`, such as `""test/data/real/2D/train""`. Then the dimention of training data will show in the `Dimension` box.

4. Choose `Output Directory`, such as `""test/data/real/2D""`.

5. `PSF Directory` is not required as the PSF is unknown.

6. If the raw input and GT image have different intensity, please check the `Preprocess` check box, which will rescale the input and GT images to have the same intensity. Here, do not check.

7. In the `Forward Projection` box, set the parameters of training:
    - `Epoch` : number of epochs of training.
    - `Batch Size` : batch size of training data used during training.
    - `Kernel Size (z, xy)` : the size of forward kernel to learned.
    - `Optimizer` : the optimization algorithm. Default: Adam.
    - `Learning Rate` : learning rate of training.
    - `Decay Step` ï¼ the decay step of learning rate. Note: `0` for no decay.
    - `Decay Rate` : the decay rate of learning rate.

8. Press `run` button. You can press the `stop` button to end the training.

9. Wait the `progress bar` to reach 100% and training finished.

After the training of forward projection, the results will be save in the `/checkpoints` folder in `Output Directory`, the model was named as `forward_bs_{batch size}_lr_{learning rate}_ks_{kernel size (z)}_{kernel size (xy)}`, such as `""test/data/real/2D/checkpoints/forward_bs_1_lr_0.001_ks_1_31""`, which consists of:
- a `log` folder saved the `Tensorboard` log, which can be opened with `Tensorboard`.
- many model checkpoints, named as `epoch_{epoch}.pt`.
- a `parameters.json` file saving the parameters used to training the model.

#### **Training of Backward Projection**

After training of forward projeciton, we can freeze the forward projeciton and then train the backward projeciton.

1. Open `napari` and load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `KL Deconvolution`

2. Choose `Training` tab.

3. Choose `Data Directory`, such as `""test/data/2D/real/train""`. Then the dimention of training data will show in the `Dimension` box.

4. Choose `Output Directory`, such as `""test/data/2D/real""`.

5. `PSF Directory` is no required as the PSF is unknown.

6. If the raw input and GT image have different intensity, please check the `Preprocess` check box, which will rescale the input and GT images to have the same intensity. Here, do not check.

7. In the `Backward Projeciton` box, set parameters for the trianing of backward projeciton.

    - `Training strategy` : `supervised` training or `self-supervised` training. Here, set as `supervised`, as we have the GT images. When choosing the `self-supervised` mode, a PSF is required.
    - `Iterations (RL)` : The number of iterations of RL iterative procedure. Default: 2.
    - `Epoch` : The number fo epochs used to traing the model.
    - `Batch Size` : The batch size used to training the model.
    - `Kernel Size (z, xy)`: The size of backward kernel, `x` and `y` have the same size.
    - `FP directory` : the directory of the pre-trained forward projeciton model, such as `""test/data/real/2D/checkpoints/forward_bs_1_lr_0.001_ks_1_31/epoch_500_final.pt""` (commonly the model labeled with `""_final""` is used).
    - `Optimizer` : Optimization algorithm. Default: Adam.
    - `Learning Rate` : The learning rate used to trianing the model.
    - `Decay Step` : the decay step of learning rate.
    - `Decay Rate` : the decay rate of learning rate.

8. Press `run` button. You can press the `stop` button to end the training.

9. Wait the `progress bar` to reach 100% and then the training finishes.

When the training finishes, the results will be save in the `/checkpoints` folder in `Output Directory`, the model was named as `backward_bs_{batch size}_lr_{learning rate}_iter_{num of RL iterations}_ks_{kernel size (z)}_{kernel size (xy)}`, such as `""test/data/real/2D/checkpoints/backward_bs_1_lr_1e-05_iter_2_ks_1_31""`, which consists of:

- a `log` folder saved the `Tensorboard` log, which can be opened with `Tensorboard`.
- many model checkpoints, named as `epoch_{epoch}.pt`.
- a `parameters.json` file saving the parameters used to training the model.

Now we get the learned forward projection and backward projection.

Next, we can use them to do `Prediction`.

### **When you only have a PSF**

When you only have a PSF to do deconvolution, you can train the model using simulated data following the below steps:

1. Generate simulaiton data.
2. Train the model under supervised mode.
3. Apply the trained model on real data.

#### **Simulation data generation**

1. Open `napari` and load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `KL Deconvolution`

2. Choose `Simulation` tab.

3. Choose the `Output Directory` of the generated simulation data, such as `""test\data\simulation""`.

4. Choose the `PSF Directory` (only support 2D/3D PSF file save as .tif, axes = (y, x) or (z, y, x)), such as `""test\data\simulation\psf.tif""`.

5. Adjust the parameters as needed.
    - `Image Shape` : the shape of simulated image, when `z=1`, 2D image will be generated.
    - `PSF Crop` : when the input PSF is too large, you can crop the PSF to acuqire a smaller PSF. All the PSF will be converted to have an odd shape and normalized.
    - `Num of Simulations` : number of generated images.
    - `Gaussian (std)` : the standard deviation (std) of Gaussian noise added in the generated LR images. The mean of Gaussian noise = 0. Default: 0 (i.e., without gaussian noise).
    - `Poisson` : whether to add Poisson noise, if `True`, make the `Enable` checked.
    - `Ratio` : a ratio factor multiplied on GT image to control the level of Poisson noise, thus the simulated raw input LR image RAW can be expressed as:

    $$ RAW = Possion((GT \cdot Ratio)\times PSF) + Gaussian $$

    - `Scale Factor` : downsampling scale factor. Default: 1.

6. Press `run` button.

7. Wait the `progress bar` to reach 100%.

The generated simulation data will be save in `Output directory`, named as `""data_{shape_z}_{shape_y}_{shape_x}_gauss_{std of Gaussian noise}_poiss_{whether to add Poisson noise}_ratio_{Ratio}""`, such as: `""test\data\simulation\data_128_128_128_gauss_0.0_poiss_0_ratio_1.0\train""`

- `""data\train\gt""` saves the GT images which consist of structures with various shapes*.
- `""data\train\raw""` saves the RAW images with blur and noise.
- `""data\train\parameters.json""` is a dictionary of parameters used to generate the simulation data.
- `""data\train\psf.tif""` is the PSF used in the simulation data generation (as the original PSF may be cropped).
- `""data\train\train.txt` save all the image used to train the model.

After you generate simulation data, you can use them to train the model.

**the code was refered to the paper: Li, Y. et al. Incorporating the image formation process into deep learning improves network performance. Nat Methods 19, 1427â1437 (2022).*

*You may need to adjust the noise level in the image accordding to the real acuqired data.*

#### **Training with known PSF and simulated data**

The simulated data should be those generated using the known PSF.

1. Open `napari` and load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `KL Deconvolution`

2. Choose `Training` tab.

3. Choose `Data Directory`, such as `test/data/simulation/data_128_128_128_gauss_0.0_poiss_0_ratio_1.0/train""`, which saves the data used to train the model in should include:
    - A `gt` folder saves the GT images
    - A `raw` folder save the raw input LR images with the same file name as GT images
    - A `train.txt` file saves all the file names used to train the model (does not need to list all the files in `gt`/`raw` folder but at least one).

4. Choose a `Output Directory` to save the model checkpoints, such as `""test/data/simulation/data_128_128_128_gauss_0.0_poiss_0_ratio_1.0""`.

5. Choose `PSF Directory` of the PSF corresponding to the data, such as `""test/data/simulation/data_128_128_128_gauss_0.0_poiss_0_ratio_1.0/train/psf.tif""`. Then the `Forward Projection` group box will be invisible as we do not need to learn the forward kernel when we know the PSF. Just use the PSF as the forward kernel.

6. If the raw input and GT image have different intensity, please check the `Preprocess` check box, which will rescale the input and GT images to have the same intensity. Here, do not check.

7. Then set parameters to learn the backward kernel.

    - `Training Strategy` : `supervised` training or `self-supervised` training. Here, set as `supervised`, as we have the GT images.
    - `Iterations (RL)` : the number of iterations of RL iteration procedure. Default: 2.
    - `Epoch` : the number fo epochs used to traing the model.
    - `Batch Size` : the batch size used to training the model.
    - `Kernel Size (z, xy)`: the size of backward kernel, `x` and `y` directions have the same size.
    - `FP Directory` : the directory of the forward projeciton model. Here, it is disabled as the PSF is known.
    - `Optimizer` : Optimization algorithm. Default: Adam.
    - `Learning Rate` : the learning rate used to trianing the model.
    - `Decay Step` : the decay step of learning rate.
    - `Decay Rate` : the decay rate of learning rate.

8. Press `run` button. You can press the `stop` button to end the training.

9. Wait the `progress bar` to reach 100% and the training finishes.

When the training finishes, a checkpoints folder will be created in `Output Directory` such as `""test/data/simulation/data_128_128_128_gauss_0.0_poiss_0_ratio_1.0/checkpoints""`.

The models is save in `/checkpoints` folder, which is named as `""backward_bs_{batch size}_lr_{learning rate}_iter_{num of RL iterations}_ks_{kernel size (z)}_{kernel size (xy)}""`, such as `""/checkpoints/backward_bs_1_lr_1e-06_iter_2_ks_1_31""`, consists of:

- A `log` folder saved the `Tensorboard` log, which can be open with `Tensorboard`.
- Many model checkpoints, named as `epoch_{epoch}.pt`.
- A `parameters.json` file saving the parameters used to training the model.

### **When you only have LR image and corresponding PSF**
When we only have LR image and its PSF, we can traing the backward projection through supervised training using simulation data as introduced above. The plugin also provide an alternative self-supervised training stratergy to learn the backward kernel.

1. Open `napari` and load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `KL Deconvolution`

2. Choose `Training` tab.

3. Choose `Data Directory`, such as `""test/data/simulation/data_128_128_128_gauss_0.0_poiss_0_ratio_1.0/train""`.

4. choose `Output Directory`, such as `""test/data/simulation/data_128_128_128_gauss_0.0_poiss_0_ratio_1.0""`.

5. Choose `PSF Directory`, such as `""test/data/simulation/data_128_128_128_gauss_0.0_poiss_0_ratio_1.0/train/psf.tif""` then the `Forward Projection` box will be invisiable.

6. As there is no GT image, preprocessing is not needed. Do not check `Preprocess` check box.

7. In the `Backward Projeciton` box, set parameters for the trianing of backward projeciton.

    - `Training strategy` : `supervised` training or `self-supervised` training. Set as `self-supervised`, as we do not have the GT images.
    - `Iterations (RL)` : the number of iterations of RL iteration procedure. Default: 2.
    - `Epoch` : the number fo epochs used to traing the model.
    - `Batch Size` : the batch size used to training the model.
    - `Kernel Size (z, xy)`: the size of backward kernel, `x` and `y` directions have the same size.
    - `FP Directory` : the directory of the forward projeciton model. Here, it is disabled as the PSF is known.
    - `Optimizer` : Optimization algorithm. Default: Adam.
    - `Learning Rate` : the learning rate used to trianing the model.
    - `Decay Step` : the decay step of learning rate.
    - `Decay Rate` : the decay rate of learning rate.

8. Press `run` button. You can press the `stop` button to end the training.

9. Wait the `progress bar` to reach 100% and training finishes.

When the training finishes, the results will be save in the `/checkpoints` folder in `Output Directory`, the model was named as `backward_bs_{batch size}_lr_{learning rate}_iter_{num of RL iterations}_ks_{kernel size (z)}_{kernel size (xy)}_ss`, such as `""/checkpoints/backward_bs_1_lr_1e-05_iter_2_ks_31_31_ss""`, which consists of:

- a `log` folder saved the `Tensorboard` log, which can be opened with `Tensorboard`.
- many model checkpoints, named as `epoch_{epoch}.pt`.
- a `parameters.json` file saving the parameters used to training the model.

*The performance of self-supervised learning may be inferior to supervised learning according to our experiments.*

### **Prediction**
Use the learned forward/backward kernel to do deconvolution.

1. Open `napari` and load `napari-kld` plugin: `Plugins` > `Kernel Learning Deconvolution` > `KL Deconvolution`

2. Choose `Prediction` tab.

3. Load raw input low-resolution image through `napari`: `File` > `Open File(s)` > `[choose the image to be deconvolved]` > `[the image will appear in the layer list of napari]`, such as `""test/data/real/2D/test/raw/2.tif""`.

4. Choose the loaded image in `Input RAW data` box, e.g., `2`.

5. If the PSF is known, choose the `PSF directory`.

6. If the PSF is unknown, choose the `Forward Projection` directory, such as `""test/data/real/2D/checkpoints/forward_bs_1_lr_0.001_ks_1_31/epoch_500_final.pt""` (commonly the model labeled with `""_final""` is used). If both the directories of PSF and Forward Projeciton is choosen, KLD will directly use the PSF selected.

7. Choose the `Backward Projeciton` directory, such as `""test/data/real/2D/checkpoints/backward_bs_1_lr_1e-05_iter_2_ks_1_31/epoch_1000_final.pt""`  (commonly the model labeled with `""_final""` is used).

8. Set the number of RL iterations at `Iterations (RL)`. Default: 2.

9. Press run to do deconvolution.

10. Wait the progress bar to reach 100%.

The deconvolved image will be directly shown in the `layer list` of `napari`, named as `""{input data name}_deconvo_iter_{number of RL iterations}""`, e.g., `""16_deconv_iter_2""`. You can save it as needed.

### **Others**
The `log` tab print the message during running.
Press `clean` button will clean all the text in the `log` box.

### **Notice**

- *Currently, the plugin is runned on CPU. We have tried to run the training on GPU, but the training time did not decrease (maybe it is because the FFT-based covnlution was not optimized on GPU). We are trying to make improvements.*

- *The training time may be very long if we set the kernel size or the number of epoches too large, especially for 3D images. Besides, it also depends on the  computation capability of your device.*

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

MIT LICENSE

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-kld.get_reader,napari-kld.write_multiple,napari-kld.rldwidget,napari-kld.make_sample_data,['*.npy'],,['.npy']
246,napari-ip-workflow,napari-IP-workflow,Image Processing Workflow,0.0.3,2022-05-17,2022-05-18,Jay Unruh,jru@stowers.org,GPL-3.0-only,https://github.com/jayunruh/napari-IP-workflow/issues,https://pypi.org/project/napari-IP-workflow/,,https://github.com/jayunruh/napari-IP-workflow,"A plugin to do image preprocessing, segmentation, and measurements on other images.",>=3.8,"['numpy', 'magicgui', 'qtpy', 'pandas', 'skimage', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-IP-workflow

[![License](https://img.shields.io/pypi/l/napari-IP-workflow.svg?color=green)](https://github.com/jayunruh/napari-IP-workflow/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-IP-workflow.svg?color=green)](https://pypi.org/project/napari-IP-workflow)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-IP-workflow.svg?color=green)](https://python.org)
[![tests](https://github.com/jayunruh/napari-IP-workflow/workflows/tests/badge.svg)](https://github.com/jayunruh/napari-IP-workflow/actions)
[![codecov](https://codecov.io/gh/jayunruh/napari-IP-workflow/branch/main/graph/badge.svg)](https://codecov.io/gh/jayunruh/napari-IP-workflow)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-IP-workflow)](https://napari-hub.org/plugins/napari-IP-workflow)

A plugin to do image preprocessing, segmentation, and measurements on other images.  The typical workflow is background subtraction followed by smoothing, thresholding, and size filtering.  This is typically done on nuclear stained images.  Segmentation can optionally be followed by circular label expansion to find cytoplasmic signals. The labeled signals are then measured on background subtracted images.

##General organization

The code is separated into non-interactive processing functions (ipfunctions module) and an interactive widget (segwidget module).  Please look at the code on github for examples: [Github](https://github.com/jayunruh/napari-ip-workflow). The expected workflow is from jupyter notebooks with an interactive workflow shown in src/napari-ip-workflow/_tests/standard_segementation_widget.ipynb and a non-interactive workflow shown in src/napari-ip-workflow/_tests/standard_segmentation.ipynb.  The expectation is to find the best parameters in an interactive way (ideally testing on several images) and then use the non-interactive workflow to batch through more data sets.  All image processing algorithms are in the ipfunctions module and the segwidget module has the Napari widget code.  Below I describe the strategies that are utilized in the workflow.

## Background subtraction strategy

Automated background subtraction (e.g. as in Fiji) is often accomplished with a low pass filter-style approach like rolling ball background subtraction.  This approach fails as feature sizes grow larger or measurements approach the background.  Manual selection of the background is more robust but introduces human variability and isn't compatible with high throughput analyses.  Our approach is to attempt to automate regional selection of background as follows.  First the image is smoothed with a Gaussian filter to eliminate background noise.  Next, minimum values are subtracted from each channel and the resulting images are summed.   Next, a uniform 2D boxcar smoothing is applied to the image--background level regions in the resulting image are at least the boxcar size distance away from foreground objects.  The minimum pixel in that resulting image is a good approximation for the background region of the image.  A thick border is specified to avoid lower intensity regions at the border of the image.  This algorithm is implemented in the ipfunctions module as findBackground.  Once the background region is found, it can be measured with measureCirc.

## Segmentation and thresholding strategy

There are many automated thresholding algorithms available via python and, by extension, Napari.  This program uses a very simplistic but powerful method.  Most segmentable images consist of foreground and background components.  In imaging, the foreground is more noisy than the background.  Ideally a smoothed background subtracted image will have a maximum intensity that represents the foreground well and a background intensity of 0.  In that case, the threshold level can be easily defined as a fraction of that smoothed maximum intensity.  A threshold fraction of 0.25 tends to work well but lower values may be more robust if background is fairly smooth and the foreground is noisier.  In some cases the foreground has anomalous high values that will skew the estimation.  In that case it may be better to estimate the foreground as e.g. the 99th percentile of the intensity.  In some cases it may be useful to use the average intensity as a reference point instead or use the raw intensity value (statistic is Identity).  Those last options tend to be less robust and it may be desired in those cases to use some of the more complex autothresholding methods.  After thresholding, objects on the image edge are eliminated and objects are filtered according to size.  The minimum area can easy remove small debris that can contaminate a measurement.  The maximum area can be used for large contaminants or poorly segmented clusters of cells that might not be desired in the analysis.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-IP-workflow` via [pip]:

    pip install napari-IP-workflow



To install latest development version :

    pip install git+https://github.com/jayunruh/napari-IP-workflow.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-IP-workflow"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/jayunruh/napari-IP-workflow/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']","['Bug Tracker, https://github.com/jayunruh/napari-IP-workflow/issues', 'Documentation, https://github.com/jayunruh/napari-IP-workflow#README.md', 'Source Code, https://github.com/jayunruh/napari-IP-workflow', 'User Support, https://github.com/jayunruh/napari-IP-workflow/issues']",,,napari-ip-workflow.segwidget,,,,
247,napari-labelimg4classification,napari-labelimg4classification,napari-labelimg4classification,0.1.1,2021-12-02,2021-12-03,Hiroki Kawai,h.kawai888@gmail.com,MIT,https://github.com/hiroalchem/napari-labelimg4classification/issues,https://pypi.org/project/napari-labelimg4classification/,,https://github.com/hiroalchem/napari-labelimg4classification,Image-Level labeling tool,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'napari', 'numpy', 'napari-tools-menu', 'pandas']","# napari-labelimg4classification

[![License](https://img.shields.io/pypi/l/napari-labelimg4classification.svg?color=green)](https://github.com/hiroalchem/napari-labelimg4classification/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-labelimg4classification.svg?color=green)](https://pypi.org/project/napari-labelimg4classification)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-labelimg4classification.svg?color=green)](https://python.org)
[![tests](https://github.com/hiroalchem/napari-labelimg4classification/workflows/tests/badge.svg)](https://github.com/hiroalchem/napari-labelimg4classification/actions)
[![codecov](https://codecov.io/gh/hiroalchem/napari-labelimg4classification/branch/main/graph/badge.svg)](https://codecov.io/gh/hiroalchem/napari-labelimg4classification)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-labelimg4classification)](https://napari-hub.org/plugins/napari-labelimg4classification)

A simple image-level annotation tool supporting multi-channel images for napari.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Usage
Start the labeling tool from the menu `Utilities > label tool for classification`.   
First, click on the Choose directory button to open the folder selection window, and select the folder that contains the
 images you want to label and annotate.   
It will automatically list and display the images of tif, png, jpg, and bmp formats.
If you want to view the channels of a multi-channel image separately, check the split channels checkbox.
![](https://github.com/hiroalchem/napari-labelimg4classification/raw/main/docs/open.gif)

Initially, all channels will be opened in grayscale, but the pseudo-color and contrast adjustments you specified will be
 carried over when you open the next image.   
Thanks to napari, you can freely merge channels and turn them on and off.   
Label classes can be added, and can be removed by typing the same name as an already added class.
![](https://github.com/hiroalchem/napari-labelimg4classification/raw/main/docs/color_and_label.gif)


It will automatically save the labels.csv file with the image path and label, and the class.txt file with the class of the label.
![](https://github.com/hiroalchem/napari-labelimg4classification/raw/main/docs/class_and_labels.png)

If labels.csv and class.txt are already in the folder, they will be loaded and reflected automatically.
![](https://github.com/hiroalchem/napari-labelimg4classification/raw/main/docs/reopen.gif)

## Installation

You can install `napari-labelimg4classification` via [pip]:

    pip install napari-labelimg4classification



To install latest development version :

    pip install git+https://github.com/hiroalchem/napari-labelimg4classification.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-labelimg4classification"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hiroalchem/napari-labelimg4classification/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/hiroalchem/napari-labelimg4classification/issues', 'Documentation, https://github.com/hiroalchem/napari-labelimg4classification#README.md', 'Source Code, https://github.com/hiroalchem/napari-labelimg4classification', 'User Support, https://github.com/hiroalchem/napari-labelimg4classification/issues']",,,napari-labelimg4classification.L4CWidget,,,,
248,napari-kics,napari-kics,napari-kics,0.0.3rc6,2022-05-02,2022-05-22,Alexandr Dibrov,dibrov@mpi-cbg.de,BSD-3-Clause,,https://pypi.org/project/napari-kics/,None,,A plugin to estimate chromosome sizes from karyotype images.,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari[all]', 'scikit-image', 'pandas', 'pulp', 'pyqtgraph']","# napari-kics

![napari-kics](https://github.com/mpicbg-csbd/napari-kics/raw/main/docs/banner.png?sanitize=true&raw=true)

[![standard-readme compliant](https://img.shields.io/badge/readme%20style-standard-brightgreen.svg)](https://github.com/RichardLitt/standard-readme)
[![License](https://img.shields.io/pypi/l/napari-kics.svg?color=green)](./LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-kics.svg?color=green)](https://pypi.org/project/napari-kics)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-kics.svg?color=green)](https://python.org)
[![Python package](https://github.com/mpicbg-csbd/napari-kics/actions/workflows/python-package.yml/badge.svg)](https://github.com/mpicbg-csbd/napari-kics/actions/workflows/python-package.yml)


> A plugin to estimate chromosome sizes from karyotype images.

<small>*This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.*</small>


## Table of Contents

- Install
- Usage
- Example
- Citation
- Maintainer
- Contributing
- License


## Install

You can install `napari-kics` via [pip]:

```sh
pip install napari-kics
```

This will install all required dependencies as well. We recommend installing it in a virtual environment, e.g. using [conda]:

```sh
conda create -n kics python
conda activate kics
pip install napari-kics
```

We recommend using [mamba] as a faster alternative to conda.


## Usage

1. Launch Napari via command line (`napari`).
2. Activate the plugin via menu `Plugins -> napari-kics: Karyotype Widget`.
3. Select file via `File -> Open File`.
4. Follow instructions in the panel on the right.

You may use the interactive analysis plots directly via command line:

```sh
karyotype-analysis-plots
```


## Example

1. Launch Napari via command line (`napari`).
2. Activate the plugin via menu `Plugins -> napari-kics: Karyotype Widget`.
3. Select file via `File -> Open Sample -> napari-kics: sample`.
4. Follow instructions in the panel on the right.

Try out the interactive analysis plots directly via command line:

```sh
karyotype-analysis-plots --example
```


## Citation

> Arne Ludwig, Alexandr Dibrov, Gene Myers, Martin Pippel.
> Estimating chromosome sizes from karyotype images enables validation of
> *de novo* assemblies. To be published.


## License

Distributed under the terms of the [BSD-3] license,
""napari-kics"" is free and open source software


## Issues

If you encounter any problems, please [file an issue] along with a detailed description.


## Contributing

Contributions are very welcome. Please [file a pull request] with your
contribution.

You can setup a local development environment for `napari-kics` via [pip]:

```sh
git clone https://github.com/mpicbg-csbd/napari-kics.git
cd napari-kics
pip install -e .
```


[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[@napari]: https://github.com/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[conda]: https://www.anaconda.com/products/distribution
[mamba]: https://github.com/mamba-org/mamba
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[file an issue]: https://github.com/mpicbg-csbd/napari-kics/issues
[file a pull request]: https://github.com/mpicbg-csbd/napari-kics/pulls

## Overview
https://user-images.githubusercontent.com/17703905/139654249-685703b5-2196-4a73-a036-d40d578ebcdf.mp4




","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,napari-kics.KaryotypeWidget,napari-kics.load_sample_data,,,
249,napari-labeling,napari-labeling,napari Labeling,0.1.2,2022-05-09,2022-05-10,Tom Burke,burke@mpi-cbg.de,BSD-3-Clause,https://github.com/Labelings/napari-labeling,https://pypi.org/project/napari-labeling/,,https://github.com/Labelings/napari-labeling,A napari plugin for handling overlapping labeling data,>=3.7,"['numpy', 'labeling']","# napari-labeling

[![License](https://img.shields.io/pypi/l/napari-labeling.svg?color=green)](https://github.com/tomburke-rse/napari-labeling/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-labeling.svg?color=green)](https://pypi.org/project/napari-labeling)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-labeling.svg?color=green)](https://python.org)
[![tests](https://github.com/tomburke-rse/napari-labeling/workflows/tests/badge.svg)](https://github.com/tomburke-rse/napari-labeling/actions)
[![codecov](https://codecov.io/gh/tomburke-rse/napari-labeling/branch/main/graph/badge.svg)](https://codecov.io/gh/tomburke-rse/napari-labeling)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-labeling)](https://napari-hub.org/plugins/napari-labeling)

This is a napari-plugin based on the [labeling project].

It allows the generation of overlapping labels in one layer, save and load of this layer in a json-based file format and
it contains a widget to explore the overlapping labels layer and select specific segments with a mouse click .

Please note that currently, the widget part only works by adding it through code with:

    from napari_labeling import edit_widget
    viewer = napari.Viewer()
    viewer.window.add_dock_widget(edit_widget)

An example on how to achieve this can be found in the [main.py] on GitHub.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-labeling` via [pip]:

    pip install napari-labeling




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-labeling"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

[labeling project]: https://github.com/Labelings/Labeling
[main.py]: https://github.com/Labelings/Labeling/blob/main/main.py
[file an issue]: https://github.com/Labelings/napari-labeling/issues


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,napari-labeling.napari_get_reader,napari-labeling.write_single_image,napari-labeling.make_magic_widget,,['*.lbl.json'],,
250,napari-label-manager,napari-label-manager,Label Manager,0.1.4,2025-07-10,2025-07-26,JH Wang,wjh19937458882@mail.ustc.edu.cn,"Copyright (c) 2025, JH Wang
Al...",https://github.com/Wenlab/napari-label-manager/issues,https://pypi.org/project/napari-label-manager/,,,A plugin for management of label colormap generation and opacity control,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'napari[all]; extra == ""all""', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari[qt]; extra == ""testing""']","# napari-label-manager

[![License BSD-3](https://img.shields.io/pypi/l/napari-label-manager.svg?color=green)](https://github.com/Wenlab/napari-label-manager/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-label-manager.svg?color=green)](https://pypi.org/project/napari-label-manager)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-label-manager.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-label-manager)](https://napari-hub.org/plugins/napari-label-manager)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->
## Description
This is a plugin for management of label colormap generation and opacity control.
- Select your label layer from the dropdown
- Generate a new colormap or use existing colors
- Specify target label IDs (e.g., ""1-5,10,15-20"")
- Adjust opacity for selected labels and background
- Apply changes to visualize your selection

## Features

### Label Management
- Batch management of label colors and opacity
- Random colormap generation with customizable seeds
- Support for label ID ranges and individual selections
- Quick presets for common label selections (first 10, even/odd IDs, all current)

### Label Annotation
- **NEW**: Excel-like annotation table for labeling digital IDs
- Fill ranges of label IDs automatically
- Load current layer's labels into annotation table
- Add custom annotations/descriptions for each label
- Export annotations to Excel format (.xlsx)

### Performance Optimizations
- Memory-efficient processing for large datasets
- Time-series optimization (processes current slice only)
- Smart sampling strategies for extremely large arrays
- Background computation to maintain UI responsiveness

## Installation

You can install `napari-label-manager` via [pip]:

```
pip install napari-label-manager
```

If napari is not already installed, you can install `napari-label-manager` with napari and Qt via:

```
pip install ""napari-label-manager[all]""
```

### For Excel Export and Load Functionality

To enable Excel export features for label annotations, install the optional and pandas dependency:

```
pip install openpyxl pandas
```

Or install everything together:

```
pip install napari-label-manager openpyxl pandas
```



## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-label-manager"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/Wenlab/napari-label-manager/issues', 'Documentation, https://github.com/Wenlab/napari-label-manager#README.md', 'Source Code, https://github.com/Wenlab/napari-label-manager', 'User Support, https://github.com/Wenlab/napari-label-manager/issues']",,,napari-label-manager.LabelManager,,,,
251,napari-label-interpolator,napari-label-interpolator,napari label interpolator,0.1.1,2022-09-08,2024-01-24,Lorenzo Gaifas,brisvag@gmail.com,GPL-3.0-only,https://github.com/brisvag/napari-label-interpolator/issues,https://pypi.org/project/napari-label-interpolator/,,https://github.com/brisvag/napari-label-interpolator,A napari plugin to interpolate any number of nd-labels across a single dimension.,>=3.8,"['magicgui', 'edt', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-label-interpolator

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-label-interpolator.svg?color=green)](https://github.com/brisvag/napari-label-interpolator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-label-interpolator.svg?color=green)](https://pypi.org/project/napari-label-interpolator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-label-interpolator.svg?color=green)](https://python.org)
[![tests](https://github.com/brisvag/napari-label-interpolator/workflows/tests/badge.svg)](https://github.com/brisvag/napari-label-interpolator/actions)
[![codecov](https://codecov.io/gh/brisvag/napari-label-interpolator/branch/main/graph/badge.svg)](https://codecov.io/gh/brisvag/napari-label-interpolator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-label-interpolator)](https://napari-hub.org/plugins/napari-label-interpolator)

A napari plugin to interpolate any number of nd-labels across a single dimension.

To use, simply label a few slices along the desired dimension, then use the widget to interpolate along the desired axis.

![](https://user-images.githubusercontent.com/23482191/189153632-40ef38b7-be89-40b3-b583-b17f3241c67b.png)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-label-interpolator` via [pip]:

    pip install napari-label-interpolator



To install latest development version :

    pip install git+https://github.com/brisvag/napari-label-interpolator.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-label-interpolator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/brisvag/napari-label-interpolator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/brisvag/napari-label-interpolator/issues', 'Documentation, https://github.com/brisvag/napari-label-interpolator#README.md', 'Source Code, https://github.com/brisvag/napari-label-interpolator', 'User Support, https://github.com/brisvag/napari-label-interpolator/issues']",,,napari-label-interpolator.make_widget,,,,
252,napari-labels,napari-labels,Labels Control,0.0.4,2025-03-26,2025-03-28,Lars KrÃ¤mer,lars.kraemer@dkfz-heidelberg.de,"Apache License
               ...",https://github.com/MIC-DKFZ/napari-labels,https://pypi.org/project/napari-labels/,,,"Adding intuitive label color management, allowing custom class colors, per-class opacity, and colormap control to enhance visual clarity.",>=3.9,"['numpy', 'qtpy', 'napari_toolkit', 'seaborn', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-labels

A plugin for flexible and intuitive color management of label layers in Napari, designed to enhance the visual clarity and control of your labeled data.
Assign custom colors to individual classes using a color picker or RGB input, adjust per-class opacity, and apply colormaps to visually distinguish between labels with ease.

## Installation

You can install `napari-labels` via [pip]:

```
pip install napari-labels
```

## Seaborn Color palettes

You can use all color palette names which are valid for `seaborn.color_palette()`.
An overview can be found here:

- https://r02b.github.io/seaborn_palettes/
- https://www.practicalpythonfordatascience.com/ap_seaborn_palette

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-labels"" is free and open source software

## Acknowledgments

<p align=""left"">
  <img src=""https://github.com/MIC-DKFZ/napari-labels/raw/main/imgs/Logos/HI_Logo.png"" width=""150""> &nbsp;&nbsp;&nbsp;&nbsp;
  <img src=""https://github.com/MIC-DKFZ/napari-labels/raw/main/imgs/Logos/DKFZ_Logo.png"" width=""500"">
</p>

This repository is developed and maintained by the Applied Computer Vision Lab (ACVL)
of [Helmholtz Imaging](https://www.helmholtz-imaging.de/) and the
[Division of Medical Image Computing](https://www.dkfz.de/en/medical-image-computing) at DKFZ.

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

[apache software license 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[copier]: https://copier.readthedocs.io/en/stable/
[napari]: https://github.com/napari/napari
[napari-plugin-template]: https://github.com/napari/napari-plugin-template
[pip]: https://pypi.org/project/pip/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Homepage, https://github.com/MIC-DKFZ/napari-labels', 'Code, https://github.com/MIC-DKFZ/napari-labels']",,,napari-labels.LabelsControlWidget,,,,
253,napari-labelling-assistant,napari-labelling-assistant,napari-labelling-assistant,0.0.5,2022-01-19,2022-01-24,Pranjal Dhole,dhole.pranjal@gmail.com,MIT,https://github.com/pranjaldhole/napari-labelling-assistant/issues,https://pypi.org/project/napari-labelling-assistant/,,https://github.com/pranjaldhole/napari-labelling-assistant,A lightweight plugin for visualizing labelling statistics.,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'matplotlib']","# napari-labelling-assistant

[![License](https://img.shields.io/pypi/l/napari-labelling-assistant.svg?color=green)](https://github.com/pranjaldhole/napari-labelling-assistant/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-labelling-assistant.svg?color=green)](https://pypi.org/project/napari-labelling-assistant)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-labelling-assistant.svg?color=green)](https://python.org)
[![tests](https://github.com/pranjaldhole/napari-labelling-assistant/workflows/tests/badge.svg)](https://github.com/pranjaldhole/napari-labelling-assistant/actions)
[![codecov](https://codecov.io/gh/pranjaldhole/napari-labelling-assistant/branch/main/graph/badge.svg)](https://codecov.io/gh/pranjaldhole/napari-labelling-assistant)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-labelling-assistant)](https://napari-hub.org/plugins/napari-labelling-assistant)

A lightweight plugin for visualizing labelling statistics.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-labelling-assistant` via [pip]:

    pip install napari-labelling-assistant



To install latest development version :

    pip install git+https://github.com/pranjaldhole/napari-labelling-assistant.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-labelling-assistant"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/pranjaldhole/napari-labelling-assistant/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/pranjaldhole/napari-labelling-assistant/issues', 'Documentation, https://github.com/pranjaldhole/napari-labelling-assistant#README.md', 'Source Code, https://github.com/pranjaldhole/napari-labelling-assistant', 'User Support, https://github.com/pranjaldhole/napari-labelling-assistant/issues']",,,napari-labelling-assistant.LabellingAssistant,,,,
254,napari-labelprop,napari-labelprop,napari Label Propagation,1.0.0,2023-06-19,2023-06-21,nathandecaux,nathan.decaux@imt-atlantique.fr,BSD-3-Clause,,https://pypi.org/project/napari-labelprop/,None,,Label propagation through deep registration,>=3.8,"['deep-labelprop', 'napari-nifti', 'numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-labelprop

[![License](https://img.shields.io/pypi/l/napari-labelprop.svg?color=green)](https://github.com/nathandecaux/napari-labelprop/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-labelprop.svg?color=green)](https://pypi.org/project/napari-labelprop)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-labelprop.svg?color=green)](https://python.org)
[![tests](https://github.com/nathandecaux/napari-labelprop/workflows/tests/badge.svg)](https://github.com/nathandecaux/napari-labelprop/actions)
[![codecov](https://codecov.io/gh/nathandecaux/napari-labelprop/branch/main/graph/badge.svg)](https://codecov.io/gh/nathandecaux/napari-labelprop)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-labelprop)](https://napari-hub.org/plugins/napari-labelprop)



3D semi-automatic segmentation using deep registration-based 2D label propagation
---------------------------------------------------------------------------------
---

This [napari][napari] plugin was generated with [Cookiecutter][Cookiecutter] using [@napari][@napari]'s [cookiecutter-napari-plugin][cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## About

See ""Semi-automatic muscle segmentation in MR images using deep registration-based label propagation"" paper : 

[[Paper]![Paper](https://www.integrad.nl/assets/uploads/2016/02/cta-elsevier_logo-no_bg.png)](https://www.sciencedirect.com/science/article/pii/S0031320323002297?casa_token=r5FPBVXYXX4AAAAA:mStyUXb0i4lGqBmfF1j5fV1T9FuCMrpYfwh3lwQve2XAnzUBPZviAiFgMtH7lv6hdcWsA7yM) [[PDF]![PDF](https://www.ouvrirlascience.fr/wp-content/uploads/2018/12/HAL-3.png)](https://hal.science/hal-03945559/document)
<p>
  <img src=""https://github.com/nathandecaux/labelprop.github.io/raw/main/demo_cut.gif"" width=""600"">
</p>

## Installation

To install this project :

    pip install napari['all']
    pip install git+https://github.com/nathandecaux/napari-labelprop.git

## Usage

Download [pretrained weights](https://raw.githubusercontent.com/nathandecaux/napari-labelprop/main/pretrained.ckpt).

Open napari from terminal and start using functions from 'napari-labelprop' plugin (Under Plugins scrolling menu).

Available functions are :

- Inference : Propagate labels from trained weights (Pytorch checkpoint required)
- Training : Start training from scratch or from the pretrained weights.

PS : ""Unsupervised pretraining"" is not yet implemented. See CLI option at [LabelProp](https://github.com/nathandecaux/labelprop) repository.

Every operation is done in the main thread. So, napari is not responsive during training or inference, but you can still follow the progress in the terminal.

##### Training

To train a model, reach the plugin in the menu bar :

    Plugins > napari-labelprop > Training

Fill the fields with the following information :

- `Image` : Select a loaded napari.layers.Image layer to segment
- `Labels` : Select a loaded napari.layers.Labels layer with the initial labels
- `hints` : Select a loaded napari.layers.Labels layer with scribbled pseudo labels
- `Pretrained checkpoint` : Select a pretrained checkpoint from the server-side checkpoint directory
- `Slices shape` : Slices are resample to this shape for training and inference, then resampled to original shape. So far, slices must be squares.  
- `Propagation axis` : Set the axis to use for the propagation dimension
- `Max epochs` : Set the maximum number of epochs to train the model
- `Checkpoint output directory`
- `Checkpoint name`
- `Weighting criteria` : Defines the criteria used to weight each direction of propagation `ncc = normalized cross correlation (slow but smooth), distance = distance to the nearest label (fast but less accurate)`
- `Reduction` : When using ncc, defines the reduction to apply to the ncc map `mean / local_mean / none`. Default is `none`
- `Use GPU` : Set if whether to use the GPU or not. Default is `True` (GPU). GPU:0 is used by default. To use another GPU, set the `CUDA_VISIBLE_DEVICES` environment variable before launching napari.

##### Inference

To run inference on a model, reach the plugin in the menu bar :

    Plugins > napari-labelprop-remote > Inference

Fill the fields like in the training section. Then, click on the `Run` button.

## Contributing

Contributions are very welcome. Tests can be run with [tox][tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3][BSD-3] license,
""napari-labelprop"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,napari-labelprop.inference_widget,napari-labelprop.make_sample_data,,,
255,napari-labels-overlap,napari-labels-overlap,napari labels overlap,0.0.3,2021-11-30,2022-06-22,Chi-Li Chiu,cchiu@chanzuckerberg.com,BSD-3-Clause,https://github.com/chili-chiu/napari-labels-overlap/issues,https://pypi.org/project/napari-labels-overlap/,,https://github.com/chili-chiu/napari-labels-overlap,create an overlap labels layer from two labels layers,>=3.7,['scikit-image'],"# napari-labels-overlap

[![License](https://img.shields.io/pypi/l/napari-labels-overlap.svg?color=green)](https://github.com/chili-chiu/napari-labels-overlap/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-labels-overlap.svg?color=green)](https://pypi.org/project/napari-labels-overlap)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-labels-overlap.svg?color=green)](https://python.org)
[![tests](https://github.com/chili-chiu/napari-labels-overlap/workflows/tests/badge.svg)](https://github.com/chili-chiu/napari-labels-overlap/actions)
[![codecov](https://codecov.io/gh/chili-chiu/napari-labels-overlap/branch/main/graph/badge.svg)](https://codecov.io/gh/chili-chiu/napari-labels-overlap)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-labels-overlap)](https://napari-hub.org/plugins/napari-labels-overlap)

create an overlap labels layer from two labels layers

## Description

This plugin takes two labels layers (layerA, layerB) as inputs, and generate the overlapped regions as a binary labels layer.
Three modes:<br>
(1) A_OR_B: new layer = layerA OR layerB (union)<br>
(2) A_AND_B: new layer = layerA AND layerB (intersection)<br>
(3) A_OUTSIDE_B: new layer = layerA OUTSIDE layerB (complement)<br>

[comment]: <need to update the gif>

![labels_overlap](https://user-images.githubusercontent.com/89602983/144129087-9a88d55f-f1a0-4825-bd01-770909bfc64f.gif)

## Applicaions
- Object colocalization
- Merge separately identified objects

## Future work
- Support N labels layers
- Basic coloc stats (% volume overlap)
- Output Labels with distinct IDs and links to original label IDs

## Release log
- 0.0.2<br>
-- Run on npe2<br>
-- Add output types: binary/connected component<br>
- 0.0.1<br>
-- Run on npe1<br>


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-labels-overlap` via [pip]:

    pip install napari-labels-overlap



To install latest development version :

    pip install git+https://github.com/chili-chiu/napari-labels-overlap.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-labels-overlap"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/chili-chiu/napari-labels-overlap/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/chili-chiu/napari-labels-overlap/issues', 'Documentation, https://github.com/chili-chiu/napari-labels-overlap#README.md', 'Source Code, https://github.com/chili-chiu/napari-labels-overlap', 'User Support, https://github.com/chili-chiu/napari-labels-overlap/issues']",,,napari-labels-overlap.labels_overlap,,,,
256,napari-laber-manager,napari-laber-manager,Laber Manager,0.0.8,2025-07-07,2025-07-08,JH Wang,wjh19937458882@mail.ustc.edu.cn,"Copyright (c) 2025, JH Wang
Al...",https://github.com/Wenlab/napari-label-manager/issues,https://pypi.org/project/napari-laber-manager/,,,A plugin for management of label colormap generation and opacity control,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'napari[all]; extra == ""all""', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari[qt]; extra == ""testing""']","# napari-laber-manager

[![License BSD-3](https://img.shields.io/pypi/l/napari-laber-manager.svg?color=green)](https://github.com/Wenlab/napari-laber-manager/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-laber-manager.svg?color=green)](https://pypi.org/project/napari-laber-manager)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-laber-manager.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-laber-manager)](https://napari-hub.org/plugins/napari-laber-manager)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->
## Description
This is a plugin for management of label colormap generation and opacity control.
- Select your label layer from the dropdown
- Generate a new colormap or use existing colors
- Specify target label IDs (e.g., ""1-5,10,15-20"")
- Adjust opacity for selected labels and background
- Apply changes to visualize your selection

## Installation

You can install `napari-laber-manager` via [pip]:

```
pip install napari-laber-manager
```

If napari is not already installed, you can install `napari-laber-manager` with napari and Qt via:

```
pip install ""napari-laber-manager[all]""
```



## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-laber-manager"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/Wenlab/napari-label-manager/issues', 'Documentation, https://github.com/Wenlab/napari-label-manager#README.md', 'Source Code, https://github.com/Wenlab/napari-label-manager', 'User Support, https://github.com/Wenlab/napari-label-manager/issues']",,,napari-laber-manager.LabelManager,,,,
257,napari-layer-divider,napari-layer-divider,Layer Divider,0.0.3,2025-07-29,2025-07-30,LLLLAAAA2333,wjh19937458882@mail.ustc.edu.cn,"Copyright (c) 2025, LLLLAAAA23...",,https://pypi.org/project/napari-layer-divider/,None,,A plugin to divide an image layer into several parts,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'napari[all]; extra == ""all""', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'pytest-xvfb; sys_platform == ""linux"" and extra == ""testing""', 'napari[qt]; extra == ""testing""']","# napari-layer-divider

[![License BSD-3](https://img.shields.io/pypi/l/napari-layer-divider.svg?color=green)](https://github.com/Wenlab/napari-layer-divider/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-layer-divider.svg?color=green)](https://pypi.org/project/napari-layer-divider)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-layer-divider.svg?color=green)](https://python.org)
[![tests](https://github.com/Wenlab/napari-layer-divider/workflows/tests/badge.svg)](https://github.com/Wenlab/napari-layer-divider/actions)
[![codecov](https://codecov.io/gh/Wenlab/napari-layer-divider/branch/main/graph/badge.svg)](https://codecov.io/gh/Wenlab/napari-layer-divider)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-layer-divider)](https://napari-hub.org/plugins/napari-layer-divider)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

A plugin to divide an image layer into several parts

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-layer-divider` via [pip]:

```
pip install napari-layer-divider
```

If napari is not already installed, you can install `napari-layer-divider` with napari and Qt via:

```
pip install ""napari-layer-divider[all]""
```



## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-layer-divider"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-layer-divider.LayerDivider,,,,
258,napari-lattice,napari-lattice,Lattice Lightsheet Analysis,1.0.3,2022-07-19,2025-03-05,"Pradeep Rajasekhar, Lachlan Whitehead, Robert Haase, Michael Milton",,GPL-3.0-only,https://github.com/BioimageAnalysisCoreWEHI/napari_lattice/issues,https://pypi.org/project/napari-lattice/,,,Napari plugin for analysing and visualizing lattice lightsheet and Oblique Plane Microscopy data.,>=3.8,"['aicsimageio>=4.6.3', 'dask[distributed]', 'fsspec>=2022.8.2', 'importlib_resources', 'lls_core', 'magic-class>=0.7.5', 'magicgui<0.8.0', 'napari-aicsimageio>=0.7.2', 'napari-workflow-inspector', 'napari-workflows>=0.2.8', 'napari[all]>=0.4.11', 'npy2bdv', 'ome-types<0.6.0', 'numpy<2', 'psutil', 'pyclesperanto_prototype>=0.20.0', 'pydantic', 'qtpy', 'typing_extensions>=4.7.0', 'rich', 'StrEnum', 'xarray', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""']",,"['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']","['Repository, https://github.com/BioimageAnalysisCoreWEHI/napari_lattice', 'BugTracker, https://github.com/BioimageAnalysisCoreWEHI/napari_lattice/issues', 'Documentation, https://bioimageanalysiscorewehi.github.io/napari_lattice/', 'SourceCode, https://github.com/BioimageAnalysisCoreWEHI/napari_lattice', 'UserSupport, https://github.com/BioimageAnalysisCoreWEHI/napari_lattice/issues']",napari-lattice.get_reader,,napari-lattice.dock_widget,,['*.h5'],,
259,napari-layer-details-display,napari-layer-details-display,napari-layer-details-display,0.1.5,2021-11-13,2023-02-15,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-layer-details-display/issues,https://pypi.org/project/napari-layer-details-display/,,https://github.com/haesleinhuepf/napari-layer-details-display,A display for layer information and properties,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari-tools-menu']","# napari-layer-details-display

[![License](https://img.shields.io/pypi/l/napari-layer-details-display.svg?color=green)](https://github.com/haesleinhuepf/napari-layer-details-display/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-layer-details-display.svg?color=green)](https://pypi.org/project/napari-layer-details-display)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-layer-details-display.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-layer-details-display/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-layer-details-display/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-layer-details-display/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-layer-details-display)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-layer-details-display)](https://napari-hub.org/plugins/napari-layer-details-display)

A display for layer information and properties

![img.png](https://github.com/haesleinhuepf/napari-layer-details-display/raw/main/images/screenshot.png)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-layer-details-display` via [pip]:

    pip install napari-layer-details-display



To install latest development version :

    pip install git+https://github.com/haesleinhuepf/napari-layer-details-display.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-layer-details-display"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-layer-details-display/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-layer-details-display/issues', 'Documentation, https://github.com/haesleinhuepf/napari-layer-details-display#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-layer-details-display', 'User Support, https://github.com/haesleinhuepf/napari-layer-details-display/issues']",,,napari-layer-details-display.LayerDetailsDisplay,,,,
260,napari-large-image-importer,napari-large-image-importer,NLII,0.0.2,2023-02-21,2023-02-21,Hiroki Kawai,h.kawai888@gmail.com,BSD-3-Clause,https://github.com/hiroalchem/napari-large-image-importer/issues,https://pypi.org/project/napari-large-image-importer/,,https://github.com/hiroalchem/napari-large-image-importer,"Napari plugin for easy, memory-efficient import of large images.",>=3.8,"['numpy', 'magicgui', 'qtpy', 'tifffile', 'zarr', 'dask', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-large-image-importer

[![License BSD-3](https://img.shields.io/pypi/l/napari-large-image-importer.svg?color=green)](https://github.com/hiroalchem/napari-large-image-importer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-large-image-importer.svg?color=green)](https://pypi.org/project/napari-large-image-importer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-large-image-importer.svg?color=green)](https://python.org)
[![tests](https://github.com/hiroalchem/napari-large-image-importer/workflows/tests/badge.svg)](https://github.com/hiroalchem/napari-large-image-importer/actions)
[![codecov](https://codecov.io/gh/hiroalchem/napari-large-image-importer/branch/main/graph/badge.svg)](https://codecov.io/gh/hiroalchem/napari-large-image-importer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-large-image-importer)](https://napari-hub.org/plugins/napari-large-image-importer)

Napari plugin for easy, memory-efficient import of large images.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-large-image-importer` via [pip]:

    pip install napari-large-image-importer



To install latest development version :

    pip install git+https://github.com/hiroalchem/napari-large-image-importer.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-large-image-importer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hiroalchem/napari-large-image-importer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hiroalchem/napari-large-image-importer/issues', 'Documentation, https://github.com/hiroalchem/napari-large-image-importer#README.md', 'Source Code, https://github.com/hiroalchem/napari-large-image-importer', 'User Support, https://github.com/hiroalchem/napari-large-image-importer/issues']",,,napari-large-image-importer.make_qwidget,,,,
261,napari-layer-table,napari-layer-table,Layer Table,0.0.13,2022-04-20,2024-06-12,Robert Cudmore,rhcudmore@ucdavis.edu,GPL-3.0-only,https://github.com/mapmanager/napari-layer-table/issues,https://pypi.org/project/napari-layer-table/,,https://github.com/mapmanager/napari-layer-table,A plugin to display a layer as a table.,>=3.9,['numpy'],"# napari-layer-table

[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
[![PyPI version](https://badge.fury.io/py/napari-layer-table.svg)](https://badge.fury.io/py/napari-layer-table)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-layer-table)](https://napari-hub.org/plugins/napari-layer-table)
[![Python](https://img.shields.io/badge/python-3.7|3.8|3.9|3.10-blue.svg)](https://www.python.org/downloads/release/python-3100/)
[![OS](https://img.shields.io/badge/OS-Linux|Windows|macOS-blue.svg)]()
[![tests](https://github.com/mapmanager/napari-layer-table/workflows/Tests/badge.svg)](https://github.com/mapmanager/napari-layer-table/actions)
[![codecov](https://codecov.io/gh/mapmanager/napari-layer-table/branch/main/graph/badge.svg?token=8S8EFI8NBC)](https://codecov.io/gh/mapmanager/napari-layer-table)
<!-- [![PyPI](https://img.shields.io/pypi/v/napari-layer-table.svg?color=green)](https://pypi.org/project/napari-layer-table) -->
<!-- [![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-layer-table)](https://napari-hub.org/plugins/napari-layer-table) -->

A plugin to display a layer as a table.

This will work well with point layers. We are debugging shapes and labeled layers, come back to check on that!

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-layer-table` via [pip]:

    pip install napari-layer-table



To install latest development version :

    pip install git+https://github.com/mapmanager/napari-layer-table.git

## Using the Plugin

You can use the napari-layer-table plugin to display points layer as a table.

- Open a napari viewer with a Points layer
- Add the plugin to the napari viewer from Plugins menu -> Add dock widget -> napari-layer-table: Points Table
- The selected layer is displayed in the table.
- The table has columns for:
    - Point symbol with face color
    - Point coordinates (x,y,z)
    - If the layer has properties, they are also shown as columns

![](plugin-2.gif)

## Plugin Features

- Bi-directional selection between layer and table.
- Bi-directional deletion between layer and table.
- Points added to the layer are added to the table.
- Points moved in the layer are updated in the table.
- Multiple points selected in the layer are also selected in the table
- Changes to face color and symbol in the layer are updated in the table.
- Ability to sort individual columns from low to high or high to low
- `Refresh` button to manually refresh the table data
- `btf` button to manually bring the layer whose table data is being shown to front

Right-click for context menu to:

- Toggle table columns on/off.
- Toggle shift+click to add a point to the layer (no need to switch viewer mode)
- Copy table to clipboard

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-layer-table"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/mapmanager/napari-layer-table/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']","['Bug Tracker, https://github.com/mapmanager/napari-layer-table/issues', 'Documentation, https://github.com/mapmanager/napari-layer-table#README.md', 'Source Code, https://github.com/mapmanager/napari-layer-table', 'User Support, https://github.com/mapmanager/napari-layer-table/issues']",,,napari-layer-table.make_my_qwidget,,,,
262,napari-listener,napari-listener,Napari Listener,0.1.0b1.post1,2023-03-21,2023-03-21,Ashley Anderson,aandersoniii@chanzuckerberg.com,MIT,https://github.com/aganders3/napari-listener/issues,https://pypi.org/project/napari-listener/,,https://github.com/aganders3/napari-listener,Control napari via local socket.,>=3.8,"['napari', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-listener

[![License MIT](https://img.shields.io/pypi/l/napari-listener.svg?color=green)](https://github.com/aganders3/napari-listener/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-listener.svg?color=green)](https://pypi.org/project/napari-listener)
[![tests](https://github.com/aganders3/napari-listener/workflows/tests/badge.svg)](https://github.com/aganders3/napari-listener/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-listener)](https://napari-hub.org/plugins/napari-listener)

Opens a socket to listen for commands to control napari from other processes.
This can be useful for controlling napari programmatically from other
applications, or for improving general OS integration (e.g. opening data from a
file or UrL in a running instance of napari).

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s
[cookiecutter-napari-plugin] template.

## Installation

You can install `napari-listener` via [pip]:

    pip install napari-listener

## Usage

Once installed, `napari-listener` can be started from the `napari > Plugins >
Start Listening` menu. You will see a new docked widget that displays the
address and port for the listener.

The listener is a TCP server that expects app-model command IDs. It will
execute any valid app-model command, but `napari-listener` registers its own
additional commands for demonstration purposes in
https://github.com/aganders3/napari-listener/blob/main/src/napari_listener/_actions.py.

You can test `napari-listener` using a TCP client such as
[netcat](https://linux.die.net/man/1/nc) or
[curl](https://curl.se/docs/manpage.html) to send an app-model command (and
optional args). For example:

```shell
% nc 127.0.0.1 40256 <<< ""napari:open-file /path/to/local/file""
```

<img src=""https://raw.githubusercontent.com/aganders3/napari-listener/main/napari-listener-demo.gif"" alt=""quick demo of napari-listener"">

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-listener"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed
description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11']","['Bug Tracker, https://github.com/aganders3/napari-listener/issues', 'Documentation, https://github.com/aganders3/napari-listener#README.md', 'Source Code, https://github.com/aganders3/napari-listener', 'User Support, https://github.com/aganders3/napari-listener/issues']",,,napari-listener.start_listening,,,,
263,napari-lazy-openslide,napari-lazy-openslide,napari-lazy-openslide,0.3.0,2020-10-26,2022-05-19,Trevor Manz,trevor.j.manz@gmail.com,BSD-3,https://github.com/manzt/napari-lazy-openslide,https://pypi.org/project/napari-lazy-openslide/,,https://github.com/manzt/napari-lazy-openslide,A plugin to lazily load multiscale whole-slide images with openslide and dask,>=3.6,"['napari-plugin-engine (>=0.1.4)', 'zarr (>=2.11.0)', 'numpy', 'dask[array]', 'openslide-python']","# napari-lazy-openslide

[![License](https://img.shields.io/pypi/l/napari-lazy-openslide.svg?color=green)](https://github.com/manzt/napari-lazy-openslide/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-lazy-openslide.svg?color=green)](https://pypi.org/project/napari-lazy-openslide)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-lazy-openslide.svg?color=green)](https://python.org)
[![tests](https://github.com/manzt/napari-lazy-openslide/workflows/tests/badge.svg)](https://github.com/manzt/napari-lazy-openslide/actions)

An experimental plugin to lazily load multiscale whole-slide tiff images with openslide and dask.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

**Step 1.)** Make sure you have OpenSlide installed. Download instructions [here](https://openslide.org/download/).

> NOTE: Installation on macOS is easiest via Homebrew: `brew install openslide`. Up-to-date and multiplatform 
> binaries for `openslide` are also avaiable via `conda`: `conda install -c sdvillal openslide-python`

**Step 2.)** Install `napari-lazy-openslide` via `pip`:

    pip install napari-lazy-openslide

## Usage

### Napari plugin

```bash
$ napari tumor_004.tif
```
By installing this package via `pip`, the plugin should be recognized by `napari`. The plugin
attempts to read image formats recognized by `openslide` that are multiscale 
(`openslide.OpenSlide.level_count > 1`). 

It should be noted that `napari-lazy-openslide` is experimental and has primarily 
been tested with `CAMELYON16` and `CAMELYON17` datasets, which can be 
downloaded [here](https://camelyon17.grand-challenge.org/Data/).

![Interactive deep zoom of whole-slide image](tumor_004.gif)


### Using `OpenSlideStore` with Zarr and Dask

The `OpenSlideStore` class wraps an `openslide.OpenSlide` object as a valid Zarr store. 
The underlying `openslide` image pyramid is translated to the Zarr multiscales extension,
where each level of the pyramid is a separate 3D `zarr.Array` with shape `(y, x, 4)`.

```python
import dask.array as da
import zarr

from napari_lazy_openslide import OpenSlideStore

store = OpenSlideStore('tumor_004.tif')
grp = zarr.open(store, mode=""r"")

# The OpenSlideStore implements the multiscales extension
# https://forum.image.sc/t/multiscale-arrays-v0-1/37930
datasets = grp.attrs[""multiscales""][0][""datasets""]

pyramid = [grp.get(d[""path""]) for d in datasets]
print(pyramid)
# [
#   <zarr.core.Array '/0' (23705, 29879, 4) uint8 read-only>,
#   <zarr.core.Array '/1' (5926, 7469, 4) uint8 read-only>,
#   <zarr.core.Array '/2' (2963, 3734, 4) uint8 read-only>,
# ]

pyramid = [da.from_zarr(store, component=d[""path""]) for d in datasets]
print(pyramid)
# [
#   dask.array<from-zarr, shape=(23705, 29879, 4), dtype=uint8, chunksize=(512, 512, 4), chunktype=numpy.ndarray>,
#   dask.array<from-zarr, shape=(5926, 7469, 4), dtype=uint8, chunksize=(512, 512, 4), chunktype=numpy.ndarray>,
#   dask.array<from-zarr, shape=(2963, 3734, 4), dtype=uint8, chunksize=(512, 512, 4), chunktype=numpy.ndarray>,
# ]

# Now you can use numpy-like indexing with openslide, reading data into memory lazily!
low_res = pyramid[-1][:]
region = pyramid[0][y_start:y_end, x_start:x_end]
```

## Contributing

Contributions are very welcome. Tests can be run with `tox`, please ensure
the coverage at least stays the same before you submit a pull request.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/manzt/napari-lazy-openslide/issues
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License', 'Framework :: napari']",,napari-lazy-openslide.napari_get_reader,,,,['*'],,
264,napari-live-flim,napari-live-flim,Napari Live Flim,0.1.1,2022-11-09,2023-03-14,Kevin Tan,kktangent@gmail.com,GPL-3.0-only,,https://pypi.org/project/napari-live-flim/,None,,A plugin for real-time FLIM analysis,>=3.8,"['dataclasses-json', 'flimlib', 'magicgui', 'matplotlib', 'numpy', 'qtpy', 'scipy', 'superqt', 'vispy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-live-flim

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-live-flim.svg?color=green)](https://github.com/uw-loci/napari-live-flim/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-live-flim.svg?color=green)](https://pypi.org/project/napari-live-flim)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-live-flim.svg?color=green)](https://python.org)
[![tests](https://github.com/uw-loci/napari-live-flim/workflows/tests/badge.svg)](https://github.com/uw-loci/napari-live-flim/actions)
[![codecov](https://codecov.io/gh/uw-loci/napari-live-flim/branch/main/graph/badge.svg)](https://codecov.io/gh/uw-loci/napari-live-flim)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-live-flim)](https://napari-hub.org/plugins/napari-live-flim)

A plugin for real-time FLIM analysis

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Required dependencies

- [OpenScan] TCSPC module and all dependencies.
    - Verify FLIM electronics are compatible with OpenScan
- Python and the [napari] package and all dependencies

You can install `napari` via [pip]:

    pip install napari[all]

## Installation

You can install `napari-live-flim` via [pip]:

    pip install napari-live-flim

## Usage

1. In MicroManager, set a port number in the device property setting named `OpenScanFLIM-BH-TCSPC-SendFLIMHistogramsToUDPPort`
2. In Napari, select **Plugins > FLIM Viewer (napari-live-flim)** to run the plugin. Enter the same port number to connect to OpenScan.
3. Begin acquisition within MicroManager.
4. Interact with the FLIM data in real-time within napari.
    - Modify the FLIM Parameters and Display Filters settings as desired.
    - Add selections to the Lifetime Image or Phasor Plot by clicking the relevant New Selection buttons.
    - Manipulate the selections with the mouse cursor and modify the selection layer with the layer controls.
    - Click the Snapshot button during acquisition to take a snapshot.
    - Use the scroll bar under the Lifetime Image to recall a specific snapshot.
5. Stop scanning within MicroManager to end acquisition.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-live-flim"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/uw-loci/napari-live-flim/issues
[OpenScan]: https://github.com/openscan-lsm/OpenScan

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']",,,,napari-live-flim.open,,,,
265,napari-lf,napari-LF,napari LF,0.1.7,2022-07-21,2024-11-13,"Geneva Schlafly, Amitabh Verma, Rudolf Oldenbourg","gschlafly@uchicago.edu, averma@mbl.edu, rudolfo@mbl.edu",BSD-3-Clause,https://github.com/PolarizedLightFieldMicroscopy/napari-LF/issues,https://pypi.org/project/napari-LF/,,https://github.com/PolarizedLightFieldMicroscopy/napari-LF,Light field imaging plugin for napari,>=3.7,"['numpy', 'h5py', 'pyopencl', 'napari[all]', 'opencv-python', 'torch', 'torchvision', 'pytorch-lightning']","# napari-LF

[![License](https://img.shields.io/pypi/l/napari-LF.svg?color=green)](https://github.com/PolarizedLightFieldMicroscopy/napari-LF/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-LF.svg?color=green)](https://pypi.org/project/napari-LF)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-LF.svg?color=green)](https://python.org)
[![tests](https://github.com/PolarizedLightFieldMicroscopy/napari-LF/workflows/tests/badge.svg)](https://github.com/PolarizedLightFieldMicroscopy/napari-LF/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-LF)](https://napari-hub.org/plugins/napari-LF)
[![Downloads](https://static.pepy.tech/badge/napari-lf)](https://pepy.tech/project/napari-lf)
<!-- [![codecov](https://codecov.io/gh/PolarizedLightFieldMicroscopy/napari-LF/branch/main/graph/badge.svg)](https://codecov.io/gh/PolarizedLightFieldMicroscopy/napari-LF) -->

Light field imaging plugin for napari

----------------------------------

Deconvolves a 4D light field image into a full 3D focus stack reconstruction

https://user-images.githubusercontent.com/23206511/236919283-d53ca97a-9bdd-4598-b553-34996f688237.mp4

napari-LF contains an analytic and neural net analysis methods for light field images. To download example light field images, see our repository [napari-LF-docs-samples](https://github.com/PolarizedLightFieldMicroscopy/napari-LF-docs-samples).

### LF Analyze
**LF Analyze**, the analytic method, provides three basic processes to Calibrate, Rectify, and Deconvolve light field images:

The **Calibrate** process generates a calibration file that represents the optical setup that was used to record the light field images. The same calibration file can be used to rectify and deconvolve all light field images that were recorded with the same optical setup, usually the same microscope and light field camera. The Calibrate process requires as input the radiometry frame, dark frame, optical parameters, and volume parameters to generate the calibration file, which is subsequently used to rectify and deconvolve related light field images. The calibration file includes a point spread function (PSF) derived from the optical and volume parameters and is stored in HDF5 file format.

The **Rectify** process uses the calibration file for an affine transformation to scale and rotate experimental light field images that were recorded with a light field camera whose microlens array was (slightly) rotated with respect to the pixel array of the area detector and whose pixel pitch is not commensurate with the microlens pitch. After rectification, the rectified light field has the same integer number of pixels behind each microlens. When the Deconvolve process is called for an experimental light field image, rectifying the light field image is automatically applied before the iterative deconvolution does begin. However, the rectified light field image is not saved and is not available for viewing. Therefore, by pushing the Rectify button in the middle of the napari-LF widget, only the rectification step is invoked and the rectified light field image is saved to the project directory.

The **Deconvolve** process uses the PSF and a wave optics model to iteratively deconvolve a light field image into a stack of optical sections.

The **Parameter** panels, located in the lower half of the napari-LF widget, allows the user to specify settings for the reconstruction process. Once the appropriate parameters are selected, the Calibrate button followed by the Deconvolve button can be pushed to complete the reconstruction.

### Neural Net
**Neural Net** provides a method of applying a trained neural net model to deconvolve a light field image. Based on Pytorch Lightning and a provided [base class](https://github.com/PolarizedLightFieldMicroscopy/napari-LF/blob/main/src/napari_lf/lfa/neural_nets/LFNeuralNetworkProto.py), you can either create your own network, or use the pre-shipped networks (LFMNet, VCDNet, ...).

## Quickstart
1. Install the napari-LF plugin into your napari environment, as described below under **Installation**.
1. From the napari Plugins menu, select the napari-LF plugin to install its widget into the napari viewer.
### LF Analyze
1. Near the top of the widget, select your project folder containing the following images: light field, radiometry, and dark frame.
1. Calibration
    1. In the processing panel, navigate to **Calibrate, Required** (top tab **Calibrate**, bottom tab **Required**), which is the default selection.
    1. Select **radiometry** and **dark frame** images from pull down menus.
    1. Write the name of the **calibration file** you would like to produce, e.g. calibration.lfc.
    1. Enter the appropriate **optical parameters** according to your microscope and sample material.
    1. Enter the **volume parameters** you would like for your 3D reconstuction.
    1. Push the `Calibrate` button.
1. Deconvolution
    1. In the processing panel, navigate to **Deconvolve, Required**.
    1. Select **light field** image and **calibration file** from pull down menus.
    1. Write the name of the **output image stack** you would like to produce, e.g. output_stack.tif.
    1. Push the `Deconvolve` button.
The 3D focal stack reconstruction will display in the napari viewer and be saved in your original project folder.

### Neural Net
1. Click on the **LF Analyze** logo to toggle to the **Neural Net** mode.
1. Near the top of the widget, select your project folder containing the light field image and the trained neural net. If you do not already have a trained model, you can train a model using this [Jupyter notebook](https://github.com/PolarizedLightFieldMicroscopy/napari-LF/blob/main/src/napari_lf/lfa/main_train_neural_net.ipynb).
1. In the processing panel, select your **light field image** and **neural net model**.
1. Write the name of the **output image stack** you would like to produce, e.g. output_stack.tif.
1. Push the `Deconvolve` button.
The 3D focal stack reconstruction will display in the napari viewer and be saved in your original project folder.

## Getting Help
For details about each parameter, hover over each parameter textbox to read the tooltip description.
For additional information about the reconstruction process, see our [User Guide](docs/napari-LF_UserGuide_12May2023.pdf).

## Installation

After you have [napari] installed, you can one of the methods below to install `napari-LF`.

Method 1: You can install `napari-LF` via [pip]:

    pip install napari-LF

Method 2: Use the napari plugin menu.

1. Open napari from the command line:

        napari

1. From the napari menu, select **Plugins > Install/uninstall Packages**.

1. Either (a) scroll through the list of available plugins to find `napari-LF`, or (b) drag and drop a downloaded `napari-LF` directory into the bottom bar.

1. Select **Install** to install the light field plugin.

Method 3: Install the latest development version from the command line.

    pip install git+https://github.com/PolarizedLightFieldMicroscopy/napari-LF.git

Lastly, to access the installed plugin, open napari from the command line:

    napari

From the napari menu, select **Plugins > Main Menu (napari-LF)**. Note that you may need to close and reopen napari for the `napari-LF` to appear.

### Installation for developers

Create a virtual environment from the command line for napari with the python libraries necessary for the light field plugin:

    conda create -y -n napari-lf -c conda-forge python==3.9
    conda activate napari-lf

Clone the github repository:

    conda install git
    git clone https://github.com/PolarizedLightFieldMicroscopy/napari-LF.git
    cd napari-LF
    pip install -e .

The necessary dependencies should be installed automatically with `napari-LF`. If for some reason `pyopencl` does not get installed properly, try installing with conda:

    conda install -c conda-forge pyopencl

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-LF"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/PolarizedLightFieldMicroscopy/napari-LF/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/PolarizedLightFieldMicroscopy/napari-LF/issues', 'Documentation, https://github.com/PolarizedLightFieldMicroscopy/napari-LF#README.md', 'Source Code, https://github.com/PolarizedLightFieldMicroscopy/napari-LF', 'User Support, https://github.com/PolarizedLightFieldMicroscopy/napari-LF/issues']",napari-LF.get_reader,napari-LF.write_multiple,napari-LF.make_lfqwidget,napari-LF.make_sample_data,['*.npy'],,['.npy']
266,napari-live-recording,napari-live-recording,napari-live-recording,0.3.8,2021-10-05,2024-03-16,jacopo.abramo@gmail.com,jacopo.abramo@gmail.com,MIT,https://github.com/jacopoabramo/napari-live-recording/issues,https://pypi.org/project/napari-live-recording/,,https://github.com/jethro33/napari-live-recording,A napari plugin for live video recording with a generic camera device.,>=3.9,"['superqt', 'numpy', 'opencv-python', 'tifffile', 'napari[all]', 'qtpy', 'microscope >=0.7.0', 'pims', 'pyqtgraph', 'pymmcore-plus >=0.6.7', 'pymmcore-widgets', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-live-recording

[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/jacopoabramo/napari-live-recording/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-live-recording.svg?color=green)](https://pypi.org/project/napari-live-recording)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-live-recording.svg?color=green)](https://python.org)
![tests](https://github.com/jacopoabramo/napari-live-recording/actions/workflows/test_and_deploy.yaml/badge.svg)
[![codecov](https://codecov.io/github/jacopoabramo/napari-live-recording/graph/badge.svg?token=WhI2MO452Z)](https://codecov.io/github/jacopoabramo/napari-live-recording) \
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-live-recording)](https://napari-hub.org/plugins/napari-live-recording)
[![Chan-Zuckerberg Initiative](https://custom-icon-badges.demolab.com/badge/Chan--Zuckerberg_Initiative-red?logo=czi)](https://chanzuckerberg.com/)

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## Description

`napari-live-recording` (or `nlr`, if you like acronyms) is a <a href=""#why-medium-weight"">medium-weight</a> plugin part of the napari ecosystem that provides an easy 
access point for controlling area detector devices (most commonly reffered to as cameras) with a common interface.
Other than that, the plugin also allows to create computation pipelines that can be executed real-time in a flow starting directly from the camera stream.

> [!NOTE]
> 
> ### Why medium weight?
> `napari-live-recording` relies on multithreading to handle camera control,
> image processing and data storage via a common pipelined infrastructure.
> More details are provided in the documentation.

The plugin allows the following operations:

- snapping: capture a single image
- live view: continously acquiring from the currently active camera and show the collected data on the napari viewer;
- recording: stream data to disk from the currently active cameras

When recording, the plugin allows to store images according to the following formats:

- ImageJ TIFF
- OME-TIFF

> [!NOTE]
> Future releases will also add further file formats to the recording options, specifically:
> - HDF5
> - MP4
>
> We will also provide a method to add custom metadata to the recorded image files.

## Supported cameras

`napari-live-recording` aims to maintain itself agnostic for the type of cameras it controls. Via a common API (Application Programming Interface),
it possible to define a controller for a specific camera. Instructions
on how to do so are provided in the documentation.

By default, the plugin is shipped with the following interfaces:

- an [OpenCV](./src/napari_live_recording/control/devices/opencv.py) camera grabber;
- a [Micro-Manager](./src/napari_live_recording/control/devices/micro_manager.py) interface via the package [`pymmcore-plus`](https://pypi.org/project/pymmcore-plus/);
- an interface to the [microscope](./src/napari_live_recording/control/devices/pymicroscope.py) python package.

## Documentation

To install and use the plugin you can review the documentation [here](./docs/documentation.md).

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## Acknowledgments

The developers would like to thank the [Chan-Zuckerberg Initiative (CZI)](https://chanzuckerberg.com/) for providing funding
for this project via the [napari Ecosystem Grants](https://chanzuckerberg.com/science/programs-resources/imaging/napari/napari-live-recording-camera-control-through-napari/).

<p align=""center"">
  <img src=""https://images.squarespace-cdn.com/content/v1/63a48a2d279afe2a328b2823/5830fddc-a02b-451a-827b-3d4446dcf57b/Chan_Zuckerberg_Initiative.png"" width=""150"">
</p>

## License

Distributed under the terms of the [MIT] license,
""napari-live-recording"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/jacopoabramo/napari-live-recording/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'Intended Audience :: Education', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Visualization']","['Bug Tracker, https://github.com/jacopoabramo/napari-live-recording/issues', 'Documentation, https://github.com/jacopoabramo/napari-live-recording#README.md', 'Source Code, https://github.com/jacopoabramo/napari-live-recording', 'User Support, https://github.com/jacopoabramo/napari-live-recording/issues']",,,napari-live-recording.open,,,,
267,napari-maicrobe,napari-mAIcrobe,mAIcrobe,0.0.1,2025-08-01,2025-08-01,AntÃ³nio Brito,antmsbrito95@gmail.com,BSD-3-Clause,https://github.com/HenriquesLab/napari-mAIcrobe/issues,https://pypi.org/project/napari-mAIcrobe/,,https://github.com/HenriquesLab/napari-mAIcrobe,mAIcrobe,>=3.8,"['numpy<2.0', 'magicgui>=0.10.0', 'napari[all]', 'tensorflow<=2.15.0', 'napari-skimage-regionprops', 'stardist-napari==2022.12.6', 'scikit-learn', 'scikit-image==0.20.0', 'pandas', 'cellpose==3.1.1.1', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-mAIcrobe

ADD BADGES # TODO

mAIcrobe napari plugin

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `mAIcrobe` via [pip]:

    pip install napari-mAIcrobe



To install latest development version :

    pip install git+https://github.com/HenriquesLab/napari-mAIcrobe.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-mAIcrobe"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/HenriquesLab/napari-mAIcrobe/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/HenriquesLab/napari-mAIcrobe/issues', 'Documentation, https://github.com/HenriquesLab/napari-mAIcrobe#README.md', 'Source Code, https://github.com/HenriquesLab/napari-mAIcrobe', 'User Support, https://github.com/HenriquesLab/napari-mAIcrobe/issues']",,,napari-mAIcrobe.compute_label,napari-mAIcrobe.phase_example,,,
268,napari-manual-registration,napari-manual-registration,Manual registration,0.0.4,2024-08-13,2025-03-27,"Alice Gros, Jules Vanaret",jules.vanaret@univ-amu.fr,BSD-3-Clause,https://github.com/jules-vanaret/napari-manual-registration/issues,https://pypi.org/project/napari-manual-registration/,,https://github.com/jules-vanaret/napari-manual-registration,A simple plugin to register 2 views of the same object,>=3.8,"['numpy', 'scipy', 'magicgui', 'qtpy', 'pyclesperanto_prototype', 'scikit-image', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# :herb: napari-manual-registration

[![License BSD-3](https://img.shields.io/pypi/l/napari-manual-registration.svg?color=green)](https://github.com/jules-vanaret/napari-manual-registration/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-manual-registration.svg?color=green)](https://pypi.org/project/napari-manual-registration)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-manual-registration.svg?color=green)](https://python.org)
[![tests](https://github.com/jules-vanaret/napari-manual-registration/workflows/tests/badge.svg)](https://github.com/jules-vanaret/napari-manual-registration/actions)
[![codecov](https://codecov.io/gh/jules-vanaret/napari-manual-registration/branch/main/graph/badge.svg)](https://codecov.io/gh/jules-vanaret/napari-manual-registration)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-manual-registration)](https://napari-hub.org/plugins/napari-manual-registration)

<img src=""https://github.com/GuignardLab/tapenade/blob/main/imgs/tapenade3.png"" width=""100"">

A plugin to obtain parameters for affine transform used to register two views of the same object, e.g as obtained with dual-view microscopes. 

`napari-manual-registration` is a [napari] plugin that is part of the [Tapenade](https://github.com/GuignardLab/tapenade) project. Tapenade is a tool for the analysis of dense 3D tissues acquired with deep imaging microscopy. It is designed to be user-friendly and to provide a comprehensive analysis of the data.

If you use this plugin for your research, please [cite us](https://github.com/GuignardLab/tapenade/blob/main/README.md#how-to-cite).

## Overview

A. Registration by annotating salient landmarks|B. Registration by selecting explicit transformation parameters
--|--
<img src=""imgs/napari_registration_demo2_3.gif"" width=""100%"" />|<img src=""imgs/napari_registration_demo_3.gif"" width=""94%"" />

While working with large and dense 3D and 3D+time gastruloid datasets, we found that being able to visualise and interact with the data dynamically greatly helped processing it.
During the pre-processing stage, dynamical exploration and interaction led to faster tuning of the parameters by allowing direct visual feedback, and gave key biophysical insight during the analysis stage. 

When using our automatic registration tool to spatially register two views of the same organoid, we were sometimes faced with the issue that the tool would not converge to the true registration transformation. This happens when the initial position and orientation of the floating view are too far from their target values. We thus designed a Napari plugin to quickly find a transformation that can be used to initialize our registration tool close to the optimal transformation. From two images loaded in Napari representing two views of the same organoid, the plugin allows the user to 

1. **annotate matching salient landmarks** (e.g bright dead cells or lumen-like structures) in both the reference and floating views, from which an optimal rigid transformation can be found automatically using principal component analysis.



2. **manually define a rigid transformation** by continually varying 3D rotations and translations while observing the results until a satisfying fit is found

<img src=""imgs/Fig_Napari_registration.png"">

## Installation

The plugin obviously requires [napari] to run. If you don't have it yet, follow the instructions [here](https://napari.org/stable/tutorials/fundamentals/installation.html).

The simplest way to install `napari-manual-registration` is via the [napari] plugin manager. Open Napari, go to `Plugins > Install/Uninstall Packages...` and search for `napari-manual-registration`. Click on the install button and you are ready to go!

You can also install `napari-manual-registration` via [pip]:

    pip install napari-manual-registration

To install latest development version :

    pip install git+https://github.com/jules-vanaret/napari-manual-registration.git

## Usage

The plugin provides two methods to register two views of the same object. The first method consists in manually drawing landmarks in both views, from which the optimal transformation is found automatically using principal component analysis. The second one consists in selecting manually each transformation parameter (rotation and translation) while observing the result in real-time, either in 2D or 3D (the user can switch between 2D and 3D at any time).

> [!CAUTION]
> Be aware that the visualization does not accomodate for voxel anisotropy, so we recommend using isotropic data, or to resize you anisotropic data to an isotropic voxel size (e.g by using [napari-tapenade-processing](https://github.com/GuignardLab/napari-tapenade-processing)).

### A. Registration by annotating salient landmarks

<img src=""imgs/reg_2_3.png"">

Steps:
1. First, load your images in Napari. You can drag and drop them from your file explorer to the Napari viewer, or open them using the `File > Open files...` menu.
2. Click on the `Plugins > Manual Registration` menu to open the plugin.
3. Select the reference layer from the combo box. The reference layer is chosen to be the one that does not move.
4. Select the floating layer from the combo box. The floating layer is the one that will be transformed.
5. Click the `Create landmarks layers` button to create two new Labels layers that will be used to annotate the landmarks in the reference and floating views.
6. We recommend pressing the `Format layers for landmarks matching` button so that your layers are automatically formatted for you to begin the registration process. Napari offers a wide range of customisation options for the layers appearances, so feel free to play with them if our formatting does not fit your preferences. ;)
7. We first recommend hiding the reference layer and the reference landmarks layer by clicking on the eye icon next to the layer name in the layer list. This will allow you to focus on the floating layer and the floating landmarks layer.
8. Click on the `landmarks_floating` layer in the layer list to select it. 
9. Click on the `Activate the paint brush` button in the layer properties widget. This will allow you to draw landmarks in the floating view.
10. Navigate through the z-slices of your images using the slider at the bottom of the plugin window.
11. When you have found a salient landmark in the floating view, start drawing a ""blob"" around it by clicking and dragging your mouse. You can adjust the size of the brush using the `Brush size` slider in the layer properties widget. The shape of the ""blob"" you draw does not matter, as the plugin currently only uses the center of mass of the ""blob"" to locate the landmark.
12. Once you have drawn a landmark, click on the `+` button in the layer properties widget to increase the label value. This will allow you to draw another landmark. Change label value after each landmark you draw. Repeat steps 10 to 12 until you have annotated all the salient landmarks in the floating view.
13. Once you have annotated all the salient landmarks in the floating view, hide the floating layers, and show the reference layers and the reference landmarks layer by clicking on the eye icon next to the layer name in the layer list.
14. Click on the `landmarks_reference` layer in the layer list to select it.
15. Navigate to the z-slice of the reference view that corresponds to the z-slice of the floating view where you drew the first landmark.
16. Draw a ""blob"" around the corresponding landmark in the reference view by clicking and dragging your mouse.
17. Increment your label value by clicking on the `+` button in the layer properties widget each time you draw a new widget. Repeat steps 15 to 17 until you have annotated all the salient landmarks in the reference view.
18. Once you have annotated all the salient landmarks in the reference view, click on the `Run landmark registration` button. The plugin will automatically find the optimal transformation that aligns the floating landmarks to the reference landmarks using principal component analysis. 
19. If you are satisfied with the registration, choose a directory to save the transformation parameters by clicking on the `Choose directory` button. The transformation parameters will be saved in a `.json` file in this directory. Finally, click on the `Save to JSON` button to save the transformation parameters.

### B. Registration by selecting explicit transformation parameters


#### Registration with 3D view

We describe below the steps to register two views of the same object in a purely 3D manner. Note that the plugin also allows to switch between 2D and 3D at any time, and 2D view is described in the next section. 

<img src=""imgs/reg_0.png"">

Steps:
1. First, load your images in Napari. You can drag and drop them from your file explorer to the Napari viewer, or open them using the `File > Open files...` menu.
2. Click on the `Plugins > Manual Registration` menu to open the plugin.
3. Select the reference layer from the combo box. The reference layer is chosen to be the one that does not move.
4. Select the floating layer from the combo box. The floating layer is the one that will be transformed.
5. We recommend pressing the `Format layers for explicit registration` button so that your layers are automatically formatted for you to begin the registration process. Napari offers a wide range of customisation options for the layers appearances, so feel free to play with them if our formatting does not fit your preferences. ;)
6. You can now start the registration process by moving the `Translations` and `Rotations` sliders. The floating layer will be transformed in real-time according to the selected parameters. 
7. To optimize the visibility of your images, you can change the contrast limits and opacity of a layer by clicking on the layer name in the layer list and adjusting the sliders in the layer properties widget.
8. If you wish to hide a layer, you can click on the eye icon next to the layer name in the layer list.
9. Once you are satisfied with the registration, choose a directory to save the transformation parameters by clicking on the `Choose directory` button. The transformation parameters will be saved in a `.json` file in this directory.
10. Finally, click on the `Save to JSON` button to save the transformation parameters.

#### Registration with 2D view

<img src=""imgs/reg_1.png"">

Steps (the steps 1 to 5 are the same as for the 3D registration):
6. If you want to switch to the 2D view, click on the `Toggle 2D/3D view` button (it resembles a square when in 2D mode, or a cube when in 3D mode).
7. Again, feel free to play with the contrast limits and opacity of the layers to optimize the visibility of your images. First click on the layer name in the layer list, then adjust the sliders in the layer properties widget.
8. If you wish to hide a layer, you can click on the eye icon next to the layer name in the layer list.
9. In 2D mode, a slider appears at the bottom of the plugin window. You can use it to slide through the z-slices of your images.
10. You can now start the registration process by moving the `Translations` and `Rotations` sliders. The floating layer will be transformed in real-time according to the selected parameters.
11. Once you are satisfied with the registration, choose a directory to save the transformation parameters by clicking on the `Choose directory` button. The transformation parameters will be saved in a `.json` file in this directory. Finally, click on the `Save to JSON` button to save the transformation parameters.

## Demo dataset

A demo dataset is available [here](https://amubox.univ-amu.fr/s/HLktPNLGgMF4jHT).

### Content

This test dataset is composed of two 3D images `bottom_small.tif` and `top_small.tif` that correspond to two halves of the same sample.

### How to use

 - Load the images from the folder (either drag and drop, or ""File>Open file(s)"").
 - Specify one of the images as the ""Reference layer"" (which is fixed), and the other one as the ""Layer to move"" (usually called ""floating"").
 - Choose between the ""Explicit transforms"" or ""Landmarks matching"" modes, and follow instructions on the plugin repository for further use.   

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-manual-registration"" is free and open source software

## Issues

If you encounter any problem using this plugin, please [file an issue] on the GitHub repository.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/jules-vanaret/napari-manual-registration/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/jules-vanaret/napari-manual-registration/issues', 'Documentation, https://github.com/jules-vanaret/napari-manual-registration#README.md', 'Source Code, https://github.com/jules-vanaret/napari-manual-registration', 'User Support, https://github.com/jules-vanaret/napari-manual-registration/issues']",,,napari-manual-registration.run_registration,,,,
269,napari-locan,napari-locan,napari-locan,0.7.0,2023-10-29,2025-03-17,napari-locan Developers,,BSD 3-Clause,https://github.com/super-resolution/napari-locan/discussions,https://pypi.org/project/napari-locan/,,,Use locan methods in napari for single-molecule localization microscopy data.,>=3.9,"['locan>=0.18', 'matplotlib', 'napari', 'napari-matplotlib', 'numpy', 'qtpy', 'locan[http]>=0.18; extra == ""test""', 'pytest; extra == ""test""', 'pytest-qt; extra == ""test""', 'black~=25.0; extra == ""dev""', 'build; extra == ""dev""', 'coverage[toml]; extra == ""dev""', 'mypy; extra == ""dev""', 'pandas-stubs; extra == ""dev""', 'pre-commit; extra == ""dev""', 'ruff; extra == ""dev""', 'twine; extra == ""dev""', 'furo; extra == ""docs""', 'ipython; extra == ""docs""', 'myst-nb; extra == ""docs""', 'napari>=0.4.17; extra == ""docs""', 'sphinx; extra == ""docs""', 'sphinx-autodoc-typehints; extra == ""docs""', 'sphinx-copybutton; extra == ""docs""']","![logo](./docs/_static/logo.png) napari-locan
==================================================

[![License](https://img.shields.io/github/license/super-resolution/napari-locan)](https://github.com/super-resolution/napari-locan/blob/main/LICENSE.md)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-locan)](https://napari-hub.org/plugins/napari-locan)
[![PyPI](https://img.shields.io/pypi/v/napari-locan.svg?color=green)](https://pypi.org/project/napari-locan)
[![Conda (channel only)](https://img.shields.io/conda/vn/conda-forge/napari-locan)](https://anaconda.org/conda-forge/napari-locan)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-locan.svg?color=green)](https://python.org)
[![test-py-matrix](https://github.com/super-resolution/napari-locan/actions/workflows/test_py_matrix.yml/badge.svg)](https://github.com/super-resolution/napari-locan/actions/workflows/test_py_matrix.yml)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![codecov](https://codecov.io/gh/super-resolution/napari-locan/branch/main/graph/badge.svg)](https://codecov.io/gh/super-resolution/napari-locan)
[![Documentation Status](https://readthedocs.org/projects/napari-locan/badge/?version=latest)](https://napari-locan.readthedocs.io/en/latest/?badge=latest)

Load, visualize and analyze single-molecule localization microscopy (SMLM) data.

napari-locan is a napari plugin that implements a subset of methods from [locan],
a python-based library with code for analyzing SMLM data.
Locan provides extended functionality that is better suited for script- or
notebook-based analysis procedures.
napari-locan is well suited for exploratory data analysis within napari.

For details on usage and development of napari-locan please read the [documentation].

## Installation

Make sure to have Qt bindings installed in your python environment of choice.

You can install napari-locan from PyPI:

    pip install napari-locan

or from conda-forge:

    mamba install -c conda-forge napari-locan

Please read the [documentation on installation] for more details.

## Usage

![](https://github.com/super-resolution/napari-locan/raw/main/docs/resources/screenshot_0.png?raw=true)

Please read the [documentation] for details.

## Contributing

Contributions are very welcome.
Please read the [documentation on development] for details.

## Credit

The plugin was developed in the Department of Biotechnology and Biophysics,
WÃ¼rzburg University, Germany.
It is based on locan. So credit goes to the [locan developers]
and can be [cited](https://github.com/super-resolution/napari-locan/blob/main/CITATION.cff).

## License

Distributed under the terms of the
[BSD-3](http://opensource.org/licenses/BSD-3-Clause)
license, ""napari-locan"" is free and open source software.
See the [LICENSE](https://github.com/super-resolution/napari-locan/blob/main/LICENSE.md) file for details.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[locan]: https://github.com/super-resolution/locan
[locan developers]: https://github.com/super-resolution/locan

[documentation]: https://napari-locan.readthedocs.io
[documentation on installation]: https://napari-locan.readthedocs.io/en/latest/source/installation.html
[documentation on development]: https://napari-locan.readthedocs.io/en/latest/source/development.html
[file an issue]: https://github.com/super-resolution/napari-locan/issues
","['Development Status :: 3 - Alpha', 'Environment :: X11 Applications :: Qt', 'Framework :: napari', 'Intended Audience :: Education', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: BSD License', 'Operating System :: MacOS', 'Operating System :: Microsoft :: Windows', 'Operating System :: POSIX', 'Operating System :: Unix', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Topic :: Scientific/Engineering :: Visualization']","['homepage, https://github.com/super-resolution/napari-locan', 'documentation, https://napari-locan.readthedocs.io/', 'issues, https://github.com/super-resolution/napari-locan/issues', 'discussions, https://github.com/super-resolution/napari-locan/discussions', 'changelog, https://github.com/super-resolution/napari-locan/CHANGES.rst', 'Source Code, https://github.com/super-resolution/napari-locan', 'Bug Tracker, https://github.com/super-resolution/napari-locan/issues', 'User Support, https://github.com/super-resolution/napari-locan/discussions']",,,napari-locan.smlm_data_qwidget,napari-locan.make_image_npc,,,
270,napari-locpix,napari-locpix,napari-locpix,0.0.6,2023-01-16,2024-02-08,Oliver Umney,scou@leeds.ac.uk,MIT,https://github.com/oubino/napari-locpix/issues,https://pypi.org/project/napari-locpix/,,https://github.com/oubino/napari-locpix,Load in SMLM data and annotate within napari,>=3.8,"['numpy', 'qtpy', 'polars', 'pyarrow', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-locpix

[![License MIT](https://img.shields.io/pypi/l/napari-locpix.svg?color=green)](https://github.com/oubino/napari-locpix/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-locpix.svg?color=green)](https://pypi.org/project/napari-locpix)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-locpix.svg?color=green)](https://python.org)
[![tests](https://github.com/oubino/napari-locpix/workflows/tests/badge.svg)](https://github.com/oubino/napari-locpix/actions)
[![codecov](https://codecov.io/gh/oubino/napari-locpix/branch/main/graph/badge.svg)](https://codecov.io/gh/oubino/napari-locpix)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-locpix)](https://napari-hub.org/plugins/napari-locpix)

Load in SMLM data and annotate within napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-locpix` via [pip]:

    pip install napari-locpix


To install latest development version :

    pip install git+https://github.com/oubino/napari-locpix.git


## Usage

This plugin allows a user to

1. Read in SMLM data
2. Visualise SMLM data in a histogram
3. Add segmentations to the data
4. Extract the underlying localisations from the segmentations

### IO

The input data can be in the form of a .csv or .parquet.

We expect there to be 4 columns at least, which should he identified inthe file column selection:

* X coordinate
* Y coordinate
* Frame
* Channel

If the data has been annotated with this software we can also load this in.
Note however we currently only support loading in annotated data saved as a .parquet folder.
Therefore, we recommend always keeping a .parquet copy until loading in an annotated .csv
is supported.

The data can be outputted to a .parquet or a .csv

Drop localisations with zero label, gives you the option to only save the localisations which have been annotated i.e. labels 1 and above.

Channels labels allows you to give a real name label to each of the channels e.g. Chan 0 label: 'Alexa 647'

### Visualisation

Using the render button you can render the loaded in data according to the histogram settings

X/Y bins defines the number of bins for the histogram

Vis interpolation defines how to interpolate the image before viewing

### Annotations

Annotations can be added using Napari's viewer.

Simply click the add Labels.

Note that this software will expect the labels to be called ""Labels""

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-locpix"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/oubino/napari-locpix/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/oubino/napari-locpix/issues', 'Documentation, https://github.com/oubino/napari-locpix#README.md', 'Source Code, https://github.com/oubino/napari-locpix', 'User Support, https://github.com/oubino/napari-locpix/issues']",,,napari-locpix.widget,napari-locpix.make_sample_data,,,
271,napari-macrokit,napari-macrokit,napari macro-kit,0.0.1,2023-01-27,2023-01-27,Hanjin Liu,liuhanjin-sc@g.ecc.u-tokyo.ac.jp,BSD-3-Clause,https://github.com/hanjinliu/napari-macrokit/issues,https://pypi.org/project/napari-macrokit/,,https://github.com/hanjinliu/napari-macrokit,Executable script generation for napari plugins,>=3.8,"['numpy', 'magicgui', 'qtpy', 'macro-kit (>=0.4.0)', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-macrokit

[![License BSD-3](https://img.shields.io/pypi/l/napari-macrokit.svg?color=green)](https://github.com/hanjinliu/napari-macrokit/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-macrokit.svg?color=green)](https://pypi.org/project/napari-macrokit)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-macrokit.svg?color=green)](https://python.org)
[![tests](https://github.com/hanjinliu/napari-macrokit/workflows/tests/badge.svg)](https://github.com/hanjinliu/napari-macrokit/actions)
[![codecov](https://codecov.io/gh/hanjinliu/napari-macrokit/branch/main/graph/badge.svg)](https://codecov.io/gh/hanjinliu/napari-macrokit)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-macrokit)](https://napari-hub.org/plugins/napari-macrokit)

Executable script generation for napari plugins.

![](https://github.com/hanjinliu/napari-macrokit/blob/main/images/example.gif)
&uarr; [Example](https://github.com/hanjinliu/napari-macrokit/blob/main/examples/regionprops.py) showing the real-time recording of GUI operation.

This napari plugin aims at making image analysis reproducible with arbitrary input/output types.

## Usage

Create a macro object, decorate functions with `record` method and run!

```python
from napari_macrokit import get_macro

macro = get_macro(""my-plugin-specifier"")  # get macro object

# define a function
@macro.record
def add(a: float, b: float) -> float:
    return a + b

# run
result = add(3.2, 5.4)
add(result, 1.0)

macro

# Out:
# >>> float0 = add(3.2, 5.4)
# >>> float1 = add(float0, 1.0)
```

## Record GUI Operations

You can use recordable functions in your widgets to keep tracks of GUI operations.
More simply, you can double-decorate functions with `record` and `magicgui`.

```python
import numpy as np
from magicgui import magicgui
import napari
from napari.types import ImageData
from napari_macrokit import get_macro

macro = get_macro(""my-plugin-specifier"")  # get macro object

# define recordable magicgui
@magicgui
@macro.record
def add(image: ImageData, b: float) -> ImageData:
    return image + b

viewer = napari.Viewer()  # launch a viewer
viewer.add_image(np.random.random((100, 100)))  # image data
viewer.window.add_dock_widget(add)  # add magicgui to the viewer
```

Running add twice in GUI and you'll find macro updated like below.

```python
macro
# Out
# >>> image0 = add(viewer.layers['Image'].data, 0.06)
# >>> image1 = add(image0, 0.12)
```

## Combining Plugins

Suppose you have two modules that use `napari-macrokit`.

```python
# napari_module_0.py

from napari.types import ImageData
from scipy import ndimage as ndi
from napari_macrokit import get_macro

macro = get_macro(""napari-module-0"")

@macro.record
def gaussian_filter(image: ImageData, sigma: float) -> ImageData:
    return ndi.gaussian_filter(image, sigma=sigma)

@macro.record
def threshold(image: ImageData, value: float) -> ImageData:
    return image > value
```

```python
# napari_module_1.py

from napari.types import ImageData
import numpy as np
from napari_macrokit import get_macro
macro = get_macro(""napari-module-1"")

@macro.record
def estimate_background(image: ImageData) -> float:
    return np.percentile(image, 10.0)

```

You can use functions from both modules to build an analysis workflow by collecting existing macro objects with `collect_macro` function. All the recordable actions in the modules will also be recorded to the returned macro object.

```python
import numpy as np
from napari_macrokit import collect_macro
from napari_module_0 import gaussian_filter, threshold
from napari_module_1 import estimate_background

# global_macro will record all the macro available at this point
global_macro = collect_macro()

# start image analysis!
image = np.random.random((100, 100))

out = gaussian_filter(image, 2.0)
thresh = estimate_background(out)
binary = threshold(out, thresh)

macro
# Out
# >>> image0 = gaussian_filter(arr0, 2.0)
# >>> float0 = estimate_background(image0)
# >>> image1 = threshold(image1, float0)
```

---------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-macrokit` via [pip]:

    pip install napari-macrokit



To install latest development version :

    pip install git+https://github.com/hanjinliu/napari-macrokit.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-macrokit"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hanjinliu/napari-macrokit/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hanjinliu/napari-macrokit/issues', 'Documentation, https://github.com/hanjinliu/napari-macrokit#README.md', 'Source Code, https://github.com/hanjinliu/napari-macrokit', 'User Support, https://github.com/hanjinliu/napari-macrokit/issues']",,,napari-macrokit.make_qwidget,,,,
272,napari-mask-density,napari-mask-density,Mask Analyzer,0.1,2025-04-11,2025-04-11,Da Kuang,kuangda@seas.upenn.edu,"Copyright (c) 2025, Da Kuang
A...",,https://pypi.org/project/napari-mask-density/,None,,A napari plugin for analyzing mask density in regions of interest,>=3.10,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-mask-density

[![License BSD-3](https://img.shields.io/pypi/l/napari-mask-density.svg?color=green)](https://github.com/kuang-da/napari-mask-density/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-mask-density.svg?color=green)](https://pypi.org/project/napari-mask-density)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-mask-density.svg?color=green)](https://python.org)
[![tests](https://github.com/kuang-da/napari-mask-density/workflows/tests/badge.svg)](https://github.com/kuang-da/napari-mask-density/actions)
[![codecov](https://codecov.io/gh/kuang-da/napari-mask-density/branch/main/graph/badge.svg)](https://codecov.io/gh/kuang-da/napari-mask-density)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-mask-density)](https://napari-hub.org/plugins/napari-mask-density)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

A napari plugin for analyzing mask density in regions of interest

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-mask-density` via [pip]:

    pip install napari-mask-density




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-mask-density"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-mask-density.widget,,,,
273,napari-mass,napari-mass,Microscopy Array Section Setup,0.6.7,2025-06-30,2025-06-30,Joost de Folter,folterj@gmail.com,Unavailable,https://github.com/FrancisCrickInstitute/napari-mass/issues,https://pypi.org/project/napari-mass/,,,Microscopy Array Section Setup napari plugin,>=3.10,"['numpy', 'napari-ome-zarr', 'dask', 'scikit-learn', 'scikit-image', 'opencv-contrib-python-headless', 'tifffile', 'matplotlib', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-mass

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-mass.svg?color=green)](https://github.com/FrancisCrickInstitute/napari-mass/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-mass.svg?color=green)](https://pypi.org/project/napari-mass)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-mass.svg?color=green)](https://python.org)
[![tests](https://github.com/FrancisCrickInstitute/napari-mass/workflows/tests/badge.svg)](https://github.com/FrancisCrickInstitute/napari-mass/actions)
[![codecov](https://codecov.io/gh/FrancisCrickInstitute/napari-mass/branch/main/graph/badge.svg)](https://codecov.io/gh/FrancisCrickInstitute/napari-mass)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-mass)](https://napari-hub.org/plugins/napari-mass)

Microscopy Array Section Setup napari plugin: A napari plugin for annotation and guided acquisition working together
with [SBEMimage](https://github.com/SBEMimage/SBEMimage).

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

This plugin can be installed via the plugin manager inside napari. For more information on how to install plugins, please refer to the [napari plugin documentation](https://napari.org/stable/plugins/start_using_plugins/finding_and_installing_plugins.html).

Alternatively, you can install `napari-mass` via [pip]:

    pip install napari-mass



To install latest development version :

    pip install git+https://github.com/FrancisCrickInstitute/napari-mass.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0](LICENSE.md) license,
""napari-mass"" is free and open source software

## Issues

If you encounter any problems, please file an issue along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/FrancisCrickInstitute/napari-mass/issues', 'Documentation, https://github.com/FrancisCrickInstitute/napari-mass#README.md', 'Source Code, https://github.com/FrancisCrickInstitute/napari-mass', 'User Support, https://github.com/FrancisCrickInstitute/napari-mass/issues']",napari-mass.get_reader,,napari-mass.mass,,"['*.tif', '*.tiff', '*.zarr']",,
274,napari-manual-transforms,napari-manual-transforms,Manual Transforms,0.0.3,2022-04-28,2022-04-29,Talley Lambert,talley.lambert@gmail.com,BSD-3-Clause,https://github.com/tlambert03/napari-manual-transforms/issues,https://pypi.org/project/napari-manual-transforms/,,https://github.com/tlambert03/napari-manual-transforms,Interface to manually edit layer affine transforms,>=3.8,"['magicgui', 'napari', 'numpy', 'pytransform3d', 'qtpy', 'scipy', 'vispy', ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-manual-transforms

[![License](https://img.shields.io/pypi/l/napari-manual-transforms.svg?color=green)](https://github.com/tlambert03/napari-manual-transforms/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-manual-transforms.svg?color=green)](https://pypi.org/project/napari-manual-transforms)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-manual-transforms.svg?color=green)](https://python.org)
[![tests](https://github.com/tlambert03/napari-manual-transforms/workflows/tests/badge.svg)](https://github.com/tlambert03/napari-manual-transforms/actions)
[![codecov](https://codecov.io/gh/tlambert03/napari-manual-transforms/branch/main/graph/badge.svg)](https://codecov.io/gh/tlambert03/napari-manual-transforms)

Interface to manually edit layer affine transforms.

- express rotations as quaternion, euler angle, or axis + angle.
- allows rotation around arbitrary origin
- currently, focusing on rigid rotations
- Alt-Drag to rotate a layer independently of the rest.
- image resampling (i.e. ""apply"" the transformation to create new dataset that can be saved)

![Plugin Preview](/preview.jpeg)

caveats:

- only works on 3D Image layers for now, open a feature request for other dims/layers.
- will likely result in ""Non-orthogonal slicing is being requested"" warnings in 2D view.

## Try it out

```python

import napari

v = napari.Viewer()
v.dims.ndisplay = 3
v.open_sample('napari', 'cells3d')
v.window.add_plugin_dock_widget('napari-manual-transforms')

napari.run()

```

----------------------------------

## Installation

You can install `napari-manual-transforms` via [pip]:

```sh
pip install napari-manual-transforms
```

To install latest development version :

```sh
pip install git+https://github.com/tlambert03/napari-manual-transforms.git
```

## License

Distributed under the terms of the [BSD-3] license,
""napari-manual-transforms"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/tlambert03/napari-manual-transforms/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/tlambert03/napari-manual-transforms/issues', 'Documentation, https://github.com/tlambert03/napari-manual-transforms#README.md', 'Source Code, https://github.com/tlambert03/napari-manual-transforms', 'User Support, https://github.com/tlambert03/napari-manual-transforms/issues']",,,napari-manual-transforms.make_rotation_helper,,,,
275,napari-mat-file-reader,napari-mat-file-reader,napari mat file reader,0.0.2,2022-11-01,2022-11-01,Ruben Lopez,rjlopez2@gmail.com,BSD-3-Clause,https://github.com/rjlopez2/napari-mat-file-reader/issues,https://pypi.org/project/napari-mat-file-reader/,,https://github.com/rjlopez2/napari-mat-file-reader,This is a simple wraper to read .mat files from Matlab,>=3.8,"['numpy', 'mat73', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-mat-file-reader

[![License BSD-3](https://img.shields.io/pypi/l/napari-mat-file-reader.svg?color=green)](https://github.com/rjlopez2/napari-mat-file-reader/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-mat-file-reader.svg?color=green)](https://pypi.org/project/napari-mat-file-reader)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-mat-file-reader.svg?color=green)](https://python.org)
[![tests](https://github.com/rjlopez2/napari-mat-file-reader/workflows/tests/badge.svg)](https://github.com/rjlopez2/napari-mat-file-reader/actions)
[![codecov](https://codecov.io/gh/rjlopez2/napari-mat-file-reader/branch/main/graph/badge.svg)](https://codecov.io/gh/rjlopez2/napari-mat-file-reader)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-mat-file-reader)](https://napari-hub.org/plugins/napari-mat-file-reader)

This is a simple wraper to read .mat files from Matlab

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-mat-file-reader` via [pip]:

    pip install napari-mat-file-reader



To install latest development version :

    pip install git+https://github.com/rjlopez2/napari-mat-file-reader.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-mat-file-reader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/rjlopez2/napari-mat-file-reader/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/rjlopez2/napari-mat-file-reader/issues', 'Documentation, https://github.com/rjlopez2/napari-mat-file-reader#README.md', 'Source Code, https://github.com/rjlopez2/napari-mat-file-reader', 'User Support, https://github.com/rjlopez2/napari-mat-file-reader/issues']",napari-mat-file-reader.get_reader,,,napari-mat-file-reader.make_sample_data,['*.mat'],,
276,napari-math,napari-math,napari math,0.0.1b0,2022-01-18,2022-03-29,"Zach Marin, Talley Lambert",zach.marin@yale.edu,MIT,https://github.com/zacsimile/napari-math/issues,https://pypi.org/project/napari-math/,,https://github.com/zacsimile/napari-math,"Simple mathematical operations on image, point and surface layers.",>=3.7,['numpy'],"# napari-math

[![License](https://img.shields.io/pypi/l/napari-math.svg?color=green)](https://github.com/zacsimile/napari-math/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-math.svg?color=green)](https://pypi.org/project/napari-math)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-math.svg?color=green)](https://python.org)
[![tests](https://github.com/zacsimile/napari-math/workflows/tests/badge.svg)](https://github.com/zacsimile/napari-math/actions)
[![codecov](https://codecov.io/gh/zacsimile/napari-math/branch/main/graph/badge.svg)](https://codecov.io/gh/zacsimile/napari-math)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-math)](https://napari-hub.org/plugins/napari-math)

This package provides a GUI interfrace for simple mathematical operations on image, point and surface layers.

- addition
- subtraction
- multiplication
- division
- logical and, or, xor
- z-projection (mean and sum)

Operations can be peformed on a single layer or between Image layers (functionaly pending for Surface and Point layers), 
for example adding one layer to another.

When performing operations on two images of different sizes, the result will be the size of the smallest
of the two images.

----------------------------------

<!--
This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.
-->

## Installation

You can install `napari-math` via [pip]:

    pip install napari-math




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-math"" is free and open source software

## Issues

If you encounter any problems, please file an [issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/zacsimile/napari-math/issues', 'Documentation, https://github.com/zacsimile/napari-math#README.md', 'Source Code, https://github.com/zacsimile/napari-math', 'User Support, https://github.com/zacsimile/napari-math/issues']",,,napari-math.math_widget,,,,
277,napari-matplotlib,napari-matplotlib,napari Matplotlib,3.0.0,2022-05-02,2024-10-07,David Stansby,d.stansby@ucl.ac.uk,BSD-3-Clause,https://github.com/matplotlib/napari-matplotlib/issues,https://pypi.org/project/napari-matplotlib/,,https://github.com/matplotlib/napari-matplotlib,A plugin to use Matplotlib with napari,>=3.10,"['matplotlib', 'napari >=0.5', 'numpy >=1.23', 'tinycss2', ""napari[all] ; extra == 'docs'"", ""numpydoc ; extra == 'docs'"", ""pydantic <2 ; extra == 'docs'"", ""pydata-sphinx-theme ; extra == 'docs'"", ""sphinx ; extra == 'docs'"", ""sphinx-automodapi ; extra == 'docs'"", ""sphinx-gallery ; extra == 'docs'"", ""napari[pyqt6_experimental] >=0.4.18 ; extra == 'testing'"", ""pooch ; extra == 'testing'"", ""pyqt6 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-mock ; extra == 'testing'"", ""pytest-mpl ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'"", 'pytest-xvfb ; (sys_platform == ""linux"") and extra == \'testing\'']","# napari-matplotlib

[![License](https://img.shields.io/pypi/l/napari-matplotlib.svg?color=green)](https://github.com/matplotlib/napari-matplotlib/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-matplotlib.svg?color=green)](https://pypi.org/project/napari-matplotlib)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-matplotlib.svg?color=green)](https://python.org)
[![tests](https://github.com/matplotlib/napari-matplotlib/workflows/tests/badge.svg)](https://github.com/matplotlib/napari-matplotlib/actions)
[![codecov](https://codecov.io/gh/matplotlib/napari-matplotlib/branch/main/graph/badge.svg)](https://codecov.io/gh/matplotlib/napari-matplotlib)
[![pre-commit.ci status](https://results.pre-commit.ci/badge/github/matplotlib/pytest-mpl/master.svg)](https://results.pre-commit.ci/latest/github/matplotlib/pytest-mpl/master)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-matplotlib)](https://napari-hub.org/plugins/napari-matplotlib)

A plugin to create Matplotlib plots from napari layers

----------------------------------

## Introduction
`napari-matplotlib` is a bridge between `napari` and `matplotlib`, making it easy to create publication quality `Matplotlib` plots based on the data loaded in `napari` layers.

Documentation can be found at https://napari-matplotlib.github.io/

## Contributing

Contributions are very welcome! Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
`napari-matplotlib` is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause

[file an issue]: https://github.com/dstansby/napari-matplotlib/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 5 - Production/Stable', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/matplotlib/napari-matplotlib/issues', 'Documentation, https://napari-matplotlib.github.io', 'Source Code, https://github.com/matplotlib/napari-matplotlib', 'User Support, https://github.com/matplotlib/napari-matplotlib/issues']",,,napari-matplotlib.histogram,,,,
278,napari-memmap-tiff,napari-memmap-tiff,Loading tiffs using memory map,1.1.0,2025-06-10,2025-06-11,Matthew Einhorn,matt@einhorn.dev,MIT,https://github.com/matham/napari-memmap-tiff/issues,https://pypi.org/project/napari-memmap-tiff/,,,"When installed and enabled in the options, it adds an option that when enabled will make napari load tiffs via memory mapping instead of fully into RAM.",>=3.10,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'tifffile', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-memmap-tiff

[![License MIT](https://img.shields.io/pypi/l/napari-memmap-tiff.svg?color=green)](https://github.com/matham/napari-memmap-tiff/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-memmap-tiff.svg?color=green)](https://pypi.org/project/napari-memmap-tiff)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-memmap-tiff.svg?color=green)](https://python.org)
[![tests](https://github.com/matham/napari-memmap-tiff/workflows/tests/badge.svg)](https://github.com/matham/napari-memmap-tiff/actions)
[![codecov](https://codecov.io/gh/matham/napari-memmap-tiff/branch/main/graph/badge.svg)](https://codecov.io/gh/matham/napari-memmap-tiff)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-memmap-tiff)](https://napari-hub.org/plugins/napari-memmap-tiff)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

When installed and enabled in the options, it adds an option that when enabled
will make napari load tiffs via memory mapping instead of fully into RAM.

That is, `.tif` and `.tiff` files will be loaded into memory using memory
mapping, which loads the data directly from disk instead of loading the file
at once into RAM. This is beneficial for large files that may not fit into
available RAM.

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-memmap-tiff` via [pip]:

    pip install napari-memmap-tiff



To install latest development version :

    pip install git+https://github.com/matham/napari-memmap-tiff.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-memmap-tiff"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/matham/napari-memmap-tiff/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/matham/napari-memmap-tiff/issues', 'Documentation, https://github.com/matham/napari-memmap-tiff#README.md', 'Source Code, https://github.com/matham/napari-memmap-tiff', 'User Support, https://github.com/matham/napari-memmap-tiff/issues']",,,napari-memmap-tiff.make_function_widget,,,,
279,napari-medical-image-formats,napari-medical-image-formats,napari-medical-image-formats,0.3.8,2021-04-24,2022-01-11,"Marc Boucsein, Marc Buckmakowski",,BSD-3,https://github.com/MBPhys/napari-medical-image-formats,https://pypi.org/project/napari-medical-image-formats/,,https://github.com/MBPhys/napari-medical-image-formats,A Plugin in order to read medical image formats such as DICOM and NIfTI,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'pydicom', 'SimpleITK', 'itk', 'itk-napari-conversion']","# napari-medical-image-formats

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/napari-medical-image-formats/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-medical-image-formats.svg?color=green)](https://pypi.org/project/napari-medical-image-formats)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-medical-image-formats.svg?color=green)](https://python.org)


A Plugin in order to read and write medical image formats such as DICOM, DICOM Series and NIfTI. The meta information is supported by the package napari-itk-io. 

----------------------------------

## Installation

You can install `napari-medical-image-formats` via [pip]:

    pip install napari-medical-image-formats

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-medical-image-formats"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/napari-medical-image-formats/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,napari-medical-image-formats.napari_get_reader,napari-medical-image-formats.napari_write_image,,,['*'],,
280,napari-mclabel,napari-mclabel,napari-mclabel,1.0.1.dev0,2023-07-09,2023-07-09,Jonas Utz,jonas.utz@fau.de,BSD-3-Clause,,https://pypi.org/project/napari-mclabel/,,https://gitlab.cs.fau.de/xo04syge/mclabel,Napari plugin for semi-automatic labeling of macrophages,>=3.8,"['napari[all]', 'napari-plugin-engine (>=0.1.4)', 'imaris-ims-file-reader (>=0.1.5)', 'numpy', 'h5py', 'dask', 'napari-imaris-loader', 'scikit-image', 'scipy']","# Napari McLabel

## What is the purpose of this tool?

McLabel is a semi-automatic local thresholding tool that can help to label cellular objects such as macrophages in fluorescence microscopy images. In cases where a global threshold does not yield satisfactory results, a local threshold based on a ROI drawn by the user may give better results. See the video for an example:
![Mclabel](./img/Mclabel.gif)



## Installation

The plugin can be installed using pip:
```bash
pip install napari-mclabel
```

After succesfull installation the plugin will appear in the plugins menu of napari.

## Usage

![gui](./img/gui.png)

The GUI of McLabel lives in the right pane of napari. If multiple layers are loaded, select the layer that you want to segment. The theshold finding algorithm is by default is triangle, however there are plenty of alternatives and depending on the data another algorithm might be better suited. 

1. Press ""Draw Label""
2. Draw a rough outline around the object of interest. 
3. Press ""Compute Label""
4. If not satisfied with result, adjust threshold using the slider
5. Continue with next object

![gui](./img/gui.gif) 

## Reference

If you use McLabel in your work, consider citing our background paper:
https://doi.org/10.1007/978-3-658-41657-7_20



```tex
@InProceedings{10.1007/978-3-658-41657-7_20,
author=""Utz, Jonas
and Schlereth, Maja
and Qiu, Jingna
and Thies, Mareike
and Wagner, Fabian
and Brahim, Oumaima B.
and Gu, Mingxuan
and Uderhardt, Stefan
and Breininger, Katharina"",
editor=""Deserno, Thomas M.
and Handels, Heinz
and Maier, Andreas
and Maier-Hein, Klaus
and Palm, Christoph
and Tolxdorff, Thomas"",
title=""McLabel"",
booktitle=""Bildverarbeitung f{\""u}r die Medizin 2023"",
year=""2023"",
publisher=""Springer Fachmedien Wiesbaden"",
address=""Wiesbaden"",
pages=""82--87"",
abstract=""In this work, we present a semi-automatic labelling tool for the annotation of complex cellular structures such as macrophages in fluorescence microscopy images. We present McLabel, a napari plugin that allows users to label structures of interest by simply scribbling outlines around the area of interest, using the triangle thresholding method with post-processing to identify the desired structure. Additionally, manual adaption of the threshold allows for quick and fine-grained local correction of the segmentation. The tool is evaluated in a user study with five experts, who annotated images both with and without the tool. The results show that variability in annotations between experts is reduced when the labelling tool is used and annotation time is reduced by a factor of five on average."",
isbn=""978-3-658-41657-7""
}
```

","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://gitlab.cs.fau.de/xo04syge/mclabel/-/issues', 'Documentation, https://gitlab.cs.fau.de/xo04syge/mclabel/-/blob/main/README.md', 'Source Code, https://gitlab.cs.fau.de/xo04syge/mclabel', 'User Support, https://gitlab.cs.fau.de/xo04syge/mclabel/-/issues']",,,napari-mclabel.McLabel,,,,
281,napari-mat-images,napari-mat-images,napari-mat-images,0.1.3,2021-06-03,2021-06-30,Hector Munoz,hectormz.git@gmail.com,BSD-3,https://github.com/hectormz/napari-mat-images,https://pypi.org/project/napari-mat-images/,,https://github.com/hectormz/napari-mat-images,A plugin to load images stored in MATLAB .mat files with napari,>=3.6,"['dask[delayed]', 'h5py', 'numpy', 'pluggy', 'scipy']","# napari-mat-images

[![PyPI version](https://img.shields.io/pypi/v/napari-mat-images.svg)](https://pypi.org/project/napari-mat-images)

[![Python versions](https://img.shields.io/pypi/pyversions/napari-mat-images.svg)](https://pypi.org/project/napari-mat-images)

[![See Build Status on Azure Pipelines](https://dev.azure.com/hectormz-1/napari-mat-images/_apis/build/status/hectormz.napari-mat-images?branchName=main)](https://dev.azure.com/hectormz-1/napari-mat-images/_build/latest?definitionId=1&branchName=main)

## Features

This plugin loads image variables stored in `MATLAB` `.mat` files into [napari](https://github.com/napari/napari).

It loads any variable that looks like an image.
Presently, that includes any array with more than two dimensions with size greater than 20 pixels (determined by `shape_is_image()`).

If loading a variable with 3 or more dimensions, the plugin assumes that it is a stack of images, and the dimension with greatest size is the axis of the stack.

### Loading Large Files

If loading a large `.mat` file saved in `HDF5`/`v7.3` format, chunks of the images are loaded as needed, resulting in fast initial load, but potentially slower scrolling.

Slices of the image stacks are randomly sampled to determine min/max contrast values.

## Requirements

This plugin relies on `scipy` to load small `.mat` files and `h5py` (with `dask`) to load larger `HDF5`/`v7.3` `.mat` files.

It implicitly requires `napari` for use.

## Installation

`napari-mat-images` requires [napari](https://github.com/napari/napari) to be installed, although it is not listed as a requirement for installation.
This plugin relies on plugin functionality found in `napari` version \> `0.2.12`. This can be installed via [pip](https://pypi.org/project/pip/) from [PyPI](https://pypi.org/project):

    $ pip install napari>0.2.12

You can install `napari-mat-images` via [pip](https://pypi.org/project/pip/) from [PyPI](https://pypi.org/project):

    $ pip install napari-mat-images

## Usage

Once installed, the plugin will be used whenever trying to load a `.mat` file.
This can be done from the `napari` GUI or commandline:

    $ napari my_file.mat

## Contributing

Contributions are very welcome.
Tests can be run with [pytest](https://docs.pytest.org/en/latest/),
please ensure the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3](http://opensource.org/licenses/BSD-3-Clause) license, `napari-mat-images` is free and open source software

## Issues

If you encounter any problems, please [file an issue](https://github.com/hectormz/napari-mat-images/issues) along with a detailed description.

---

This [napari](https://github.com/napari/napari) plugin was generated with [Cookiecutter](https://github.com/audreyr/cookiecutter) along with [napari](https://github.com/napari/napari)\'s [cookiecutter-napari-plugin](https://github.com/napari/cookiecutter-napari-plugin) template.


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.6', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: Implementation :: CPython', 'Programming Language :: Python :: Implementation :: PyPy', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,,,,,
282,napari-melt-pool-tracker,napari-melt-pool-tracker,Melt Pool Tracker,0.1.3,2023-11-02,2025-02-20,Florian Aymanns,florian.aymanns@epfl.ch,BSD-3-Clause,https://github.com/EPFL-Center-for-Imaging/napari-melt-pool-tracker,https://pypi.org/project/napari-melt-pool-tracker/,,https://github.com/EPFL-Center-for-Imaging/napari-melt-pool-tracker,Plugin for tracking the width and depth of the melt pool and keyhole in x-ray images of laser powder bed fusion experiments.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'h5py', 'napari-cursor-tracker', 'napari', 'pandas', 'scikit-image', 'tifffile', 'scipy', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","<img style=""float: right;"" src=""https://imaging.epfl.ch/resources/logo-for-gitlab.svg"">


# napari-melt-pool-tracker
Developed by the [EPFL Center for Imaging](https://imaging.epfl.ch/) for the [Thermomechanical Metallurgy Laboratory](https://www.epfl.ch/labs/lmtm/) in Sep 2023.
Plugin for tracking the width and depth of the melt pool and keyhole in x-ray images of laser powder bed fusion experiments.

[![License BSD-3](https://img.shields.io/pypi/l/napari-melt-pool-tracker.svg?color=green)](https://github.com/EPFL-Center-for-Imaging/napari-melt-pool-tracker/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-melt-pool-tracker.svg?color=green)](https://pypi.org/project/napari-melt-pool-tracker)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-melt-pool-tracker.svg?color=green)](https://python.org)
[![tests](https://github.com/EPFL-Center-for-Imaging/napari-melt-pool-tracker/workflows/tests/badge.svg)](https://github.com/EPFL-Center-for-Imaging/napari-melt-pool-tracker/actions)
[![codecov](https://codecov.io/gh/EPFL-Center-for-Imaging/napari-melt-pool-tracker/branch/main/graph/badge.svg)](https://codecov.io/gh/EPFL-Center-for-Imaging/napari-melt-pool-tracker)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-melt-pool-tracker)](https://napari-hub.org/plugins/napari-melt-pool-tracker)
[![DOI](https://zenodo.org/badge/700413345.svg)](https://zenodo.org/doi/10.5281/zenodo.11366048)


----------------------------------

## Installation

You can install `napari-melt-pool-tracker` via [pip]:

    pip install napari-melt-pool-tracker

# Getting Started with napari-melt-pool-tracker

## Reading Data

- The `napari-melt-pool-tracker` plugin can read h5 files from the ID19 and TOMCAT beam lines.
- When opening an h5 file in napari, select the ""Melt Pool Tracker"" as the reader for the mentioned beamlines.
- Once the data is loaded, you have the option to save the layer as a tif file if needed.

## Pre-processing

- For large images, it is recommended to crop them in both time and space to include only the relevant parts of the image stack.

## 1. Determine Laser Speed and Position

- This step helps identify the laser in the images for later reslicing the stack with a moving window following the laser.
- It generates a projection of the stack along the y-axis, creating an x-t image where the laser's position appears as an oblique line in the projection.

**To perform this step:**

1. Select the stack you want to work on using the ""Input"" drop-down menu.
2. Choose one of three projection modes:
   - Default: Maximum projection along y.
   - Pre mean: Divide each frame by the mean projection along the t-axis (to remove background) and then perform a maximum projection along y.
   - Post median: Perform a maximum projection along y and then divide the projected images by a median-filtered version in the x-direction (to remove horizontal strips).
3. Click ""Run"" to generate a new layer with the projected image and a shapes layer with a line.
4. Select the line layer, use the ""Select vertices"" tool to match the line with the laser in the projected image.

## 2. Reslice with Moving Window

- This step reslices the stack with a moving window that follows the laser's position.

**To perform this step:**

1. Select the input stack using the ""Stack"" drop-down menu.
2. Choose the line layer with the laser's position using the ""Line"" drop-down menu.
3. Adjust the ""Left margin"" and ""Right margin"" sliders to set the size of the window to the left and right of the laser's position.
4. Click ""Run"" to create three new layers: a resliced stack, a shapes layer indicating the laser's position based on your previous annotation, and a shapes layer with lines indicating the window's position in the original image.
5. If the window size doesn't fit the melt pool correctly, adjust it using the margin sliders. Disable the ""Auto run"" checkbox for large stacks to control when reslicing occurs.

## 3. Filter Image

- This step aims to reduce noise in the images by applying a median filter.

**To filter the image:**

- Select the resliced layer as the input.
- Use the ""Kernel"" sliders to set the size of the median filter along different axes.
- Disable ""Auto run"" for large stacks due to the computational cost. After median filtering, the function applies Otsu thresholding to remove the background. Adjust the contrast as needed.

## 4. Calculate Radial Gradient

- This step calculates the gray value gradient in the radial direction with respect to a point on the surface, forming the origin. You can set the horizontal position of the origin using the position slider.

**To calculate the radial gradient:**

- Select the resliced and filtered stack as input.
- Adjust the contrast for the new radial gradient layer.

## 5. Annotate

- Annotation of points is done using the [napari-cursor-tracker](https://www.napari-hub.org/plugins/napari-cursor-tracker) plugin.

**To annotate points:**

- Select any of the resliced layers as your reference image.
- Change the name in the ""Name of the tracked point"" text box to define the point you want to track, e.g., 'MP depth'.
- Click ""Add new layer"" to create a new points layer with the specified name, automatically selected as the active layer.
- Start tracking by pressing 't' on your keyboard. Enable ""Auto play when tracking is started"" for automatic playback.
- Adjust playback parameters as needed. Setting ""Loop mode"" to 'once' is advised to prevent overwriting tracked points. You can track points manually by scrolling through slices/frames (hold down `ctrl`) and saving your cursor positions at each index change.

## Saving and Processing Results

- You can save the 'window_coordinates' layer and point layers with tracked points as CSV files for further processing with external software.


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-melt-pool-tracker"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-melt-pool-tracker.get_reader,napari-melt-pool-tracker.write_multiple,napari-melt-pool-tracker.make_qwidget,napari-melt-pool-tracker.make_sample_data,['*.h5'],,['.npy']
283,napari-mesofield,napari-mesofield,MesoField,0.1.0,2024-07-13,2024-07-13,Jacob Gronemeyer,jgronemeyer@psu.edu,Mozilla Public License Version...,https://github.com/Gronemeyer/napari-mesofield/issues,https://pypi.org/project/napari-mesofield/,,,"A plugin that extends napari functionality as an image acquisition software to automate multi-modal experimental control, setup, and analysis for mesoscopic widefield acquistion of 1P epiflourescent signals in the mouse cortex.",>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-mesofield

[![License Mozilla Public License 2.0](https://img.shields.io/pypi/l/napari-mesofield.svg?color=green)](https://github.com/Gronemeyer/napari-mesofield/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-mesofield.svg?color=green)](https://pypi.org/project/napari-mesofield)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-mesofield.svg?color=green)](https://python.org)
[![tests](https://github.com/Gronemeyer/napari-mesofield/workflows/tests/badge.svg)](https://github.com/Gronemeyer/napari-mesofield/actions)
[![codecov](https://codecov.io/gh/Gronemeyer/napari-mesofield/branch/main/graph/badge.svg)](https://codecov.io/gh/Gronemeyer/napari-mesofield)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-mesofield)](https://napari-hub.org/plugins/napari-mesofield)

A plugin that extends napari functionality as an image acquisition software to automate multi-modal experimental control, setup, and analysis for mesoscopic widefield acquistion of 1P epiflourescent signals in the mouse cortex.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-mesofield` via [pip]:

    pip install napari-mesofield



To install latest development version :

    pip install git+https://github.com/Gronemeyer/napari-mesofield.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Mozilla Public License 2.0] license,
""napari-mesofield"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/Gronemeyer/napari-mesofield/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/Gronemeyer/napari-mesofield/issues', 'Documentation, https://github.com/Gronemeyer/napari-mesofield#README.md', 'Source Code, https://github.com/Gronemeyer/napari-mesofield', 'User Support, https://github.com/Gronemeyer/napari-mesofield/issues']",napari-mesofield.get_reader,napari-mesofield.write_multiple,napari-mesofield.make_container_widget,napari-mesofield.make_sample_data,['*.npy'],,['.npy']
284,napari-merge-stardist-masks,napari-merge-stardist-masks,StarDist OPP,0.1.1,2022-08-31,2023-08-08,Niklas Netter,niknett@gmail.com,BSD-3-Clause,https://github.com/gatoniel/napari-merge-stardist-masks/issues,https://pypi.org/project/napari-merge-stardist-masks/,,https://github.com/gatoniel/napari-merge-stardist-masks,Segment non-star-convex objects with StarDist by merging masks.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'importlib-resources', 'stardist-napari >=2022.7.5', 'merge-stardist-masks >=0.1.0', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# StarDist OPP napari plugin

[![License BSD-3](https://img.shields.io/pypi/l/napari-merge-stardist-masks.svg?color=green)](https://github.com/gatoniel/napari-merge-stardist-masks/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-merge-stardist-masks.svg?color=green)](https://pypi.org/project/napari-merge-stardist-masks)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-merge-stardist-masks.svg?color=green)](https://python.org)
[![tests](https://github.com/gatoniel/napari-merge-stardist-masks/workflows/tests/badge.svg)](https://github.com/gatoniel/napari-merge-stardist-masks/actions)
[![codecov](https://codecov.io/gh/gatoniel/napari-merge-stardist-masks/branch/main/graph/badge.svg)](https://codecov.io/gh/gatoniel/napari-merge-stardist-masks)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-merge-stardist-masks)](https://napari-hub.org/plugins/napari-merge-stardist-masks)

This is the [napari] plugin for [StarDist OPP]. Checkout our [paper] for more information.

----------------------------------

## Usage

Read the [tutorial] and download pre-trained models from our [Zenodo repository].

In PowerShell, when you do not have sufficient GPU support, run napari without CUDA support, i.e.,:
```
$env:CUDA_VISIBLE_DEVICES=-1; napari
```


## Installation

You can install `napari-merge-stardist-masks` via [pip]:

    pip install napari-merge-stardist-masks



To install latest development version :

    pip install git+https://github.com/gatoniel/napari-merge-stardist-masks.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-merge-stardist-masks"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

## How to cite
```bibtex
@article{https://doi.org/10.1111/mmi.15064,
author = {Jelli, Eric and Ohmura, Takuya and Netter, Niklas and Abt, Martin and JimÃ©nez-Siebert, Eva and Neuhaus, Konstantin and Rode, Daniel K. H. and Nadell, Carey D. and Drescher, Knut},
title = {Single-cell segmentation in bacterial biofilms with an optimized deep learning method enables tracking of cell lineages and measurements of growth rates},
journal = {Molecular Microbiology},
volume = {n/a},
number = {n/a},
pages = {},
keywords = {3D segmentation, biofilm, deep learning, image analysis, image cytometry, Vibrio cholerae},
doi = {https://doi.org/10.1111/mmi.15064},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/mmi.15064},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/mmi.15064},
abstract = {Abstract Bacteria often grow into matrix-encased three-dimensional (3D) biofilm communities, which can be imaged at cellular resolution using confocal microscopy. From these 3D images, measurements of single-cell properties with high spatiotemporal resolution are required to investigate cellular heterogeneity and dynamical processes inside biofilms. However, the required measurements rely on the automated segmentation of bacterial cells in 3D images, which is a technical challenge. To improve the accuracy of single-cell segmentation in 3D biofilms, we first evaluated recent classical and deep learning segmentation algorithms. We then extended StarDist, a state-of-the-art deep learning algorithm, by optimizing the post-processing for bacteria, which resulted in the most accurate segmentation results for biofilms among all investigated algorithms. To generate the large 3D training dataset required for deep learning, we developed an iterative process of automated segmentation followed by semi-manual correction, resulting in >18,000 annotated Vibrio cholerae cells in 3D images. We demonstrate that this large training dataset and the neural network with optimized post-processing yield accurate segmentation results for biofilms of different species and on biofilm images from different microscopes. Finally, we used the accurate single-cell segmentation results to track cell lineages in biofilms and to perform spatiotemporal measurements of single-cell growth rates during biofilm development.}
}
```

## Credits

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

[paper]: https://doi.org/10.1111/mmi.15064
[StarDist OPP]: https://github.com/gatoniel/merge-stardist-masks
[tutorial]: https://merge-stardist-masks.readthedocs.io/en/latest/napari-plugin.html
[Zenodo repository]: https://doi.org/10.5281/zenodo.7704410

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/gatoniel/napari-merge-stardist-masks/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/gatoniel/napari-merge-stardist-masks/issues', 'Documentation, https://github.com/gatoniel/napari-merge-stardist-masks#README.md', 'Source Code, https://github.com/gatoniel/napari-merge-stardist-masks', 'User Support, https://github.com/gatoniel/napari-merge-stardist-masks/issues']",,,napari-merge-stardist-masks.stardist_opp_widget,napari-merge-stardist-masks.stardist_opp_sample_data,,,
285,napari-meshio,napari-meshio,meshio,0.0.1,2023-03-07,2023-03-07,Genevieve Buckley,yourname@example.com,MIT,https://github.com/GenevieveBuckley/napari-meshio/issues,https://pypi.org/project/napari-meshio/,,https://github.com/GenevieveBuckley/napari-meshio,I/O for mesh files.,>=3.8,"['numpy', 'meshio', 'pooch', 'rich', ""mkdocs ; extra == 'testing'"", ""mkdocs-gen-files ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-meshio

[![License MIT](https://img.shields.io/pypi/l/napari-meshio.svg?color=green)](https://github.com/GenevieveBuckley/napari-meshio/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-meshio.svg?color=green)](https://pypi.org/project/napari-meshio)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-meshio.svg?color=green)](https://python.org)
[![tests](https://github.com/GenevieveBuckley/napari-meshio/workflows/tests/badge.svg)](https://github.com/GenevieveBuckley/napari-meshio/actions)
[![codecov](https://codecov.io/gh/GenevieveBuckley/napari-meshio/branch/main/graph/badge.svg)](https://codecov.io/gh/GenevieveBuckley/napari-meshio)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-meshio)](https://napari-hub.org/plugins/napari-meshio)

This napari plugin uses [meshio](https://github.com/nschloe/meshio) to read and write mesh files to surfaces in napari.

![Screenshot: Stanford bunny example data in napari](assets/bunny-screenshot.png)

*Image caption: screenshot of the [Stanford bunny](http://graphics.stanford.edu/data/3Dscanrep/) example surface mesh open in napari.*

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

- [Installation](#installation)
- [How to use napari-meshio](#how-to-use-napari-meshio)
    - [Read surface data from file](#read-surface-data-from-file)
    - [Open example surface data](#open-example-surface-data)
    - [Save surface data](#save-surface-data)
    - [Supported mesh file formats](#supported-mesh-file-formats)
- [Contributing](#contributing)
- [License](#license)
- [Issues](#issues)

## Installation

You can install `napari-meshio` via [pip]:

    pip install napari-meshio



To install latest development version :

    pip install git+https://github.com/GenevieveBuckley/napari-meshio.git


## How to use napari-meshio

### Read surface data from file

Drag and drop the file onto the napari viewer.

*Note: [Here](https://people.sc.fsu.edu/~jburkardt/data/ply/ply.html) are a number of `.ply` example files you can download to try, like [this airplane](https://people.sc.fsu.edu/~jburkardt/data/ply/airplane.ply) (see [image](https://people.sc.fsu.edu/~jburkardt/data/ply/airplane.png)).*

### Open example surface data

Launch the napari viewer, then open one of the sample datasets (eg: the [Stanford bunny](http://graphics.stanford.edu/data/3Dscanrep/)) from the file menu:

`File` > `Open Sample` > `napari-meshio` > `bunny`

Or, open sample data from python with:

```python
import napari

viewer = napari.Viewer(ndisplay=3)
viewer.open_sample('napari-meshio', 'bunny')
```

### Save surface data

To save a surface layer, click the layer name to select it, and then choose save from the file menu:

`File` > `Save selected layer(s)`

You can also use keyboard shortcuts to save the selected surface layer:
- Windows/Linux: `Control` + `S`
- Mac: `â` + `S`

Or, save surface layers from python with:
```python
filename = ""bunny.stl""
viewer.layers['bunny'].save(filename)
```
*Note: this code example assumes you have the Stanford bunny example dataset loaded.*

A [wide variety of surface mesh file formats are supported](#supported-mesh-file-formats) by
[meshio](https://github.com/nschloe/meshio).
If no file extension is provided when saving a surface layer,
the default is the `.ply` polygon file format.

### Supported mesh file formats

*Note: Only triangular mesh faces are supported by napari.*

The [meshio](https://github.com/nschloe/meshio) library documentation describes the supported file formats:

> There are various mesh formats available for representing unstructured meshes.
meshio can read and write all of the following and smoothly converts between them:
>
>> [Abaqus](http://abaqus.software.polimi.it/v6.14/index.html) (`.inp`),
>> ANSYS msh (`.msh`),
>> [AVS-UCD](https://lanl.github.io/LaGriT/pages/docs/read_avs.html) (`.avs`),
>> [CGNS](https://cgns.github.io/) (`.cgns`),
>> [DOLFIN XML](https://manpages.ubuntu.com/manpages/jammy/en/man1/dolfin-convert.1.html) (`.xml`),
>> [Exodus](https://nschloe.github.io/meshio/exodus.pdf) (`.e`, `.exo`),
>> [FLAC3D](https://www.itascacg.com/software/flac3d) (`.f3grid`),
>> [H5M](https://www.mcs.anl.gov/~fathom/moab-docs/h5mmain.html) (`.h5m`),
>> [Kratos/MDPA](https://github.com/KratosMultiphysics/Kratos/wiki/Input-data) (`.mdpa`),
>> [Medit](https://people.sc.fsu.edu/~jburkardt/data/medit/medit.html) (`.mesh`, `.meshb`),
>> [MED/Salome](https://docs.salome-platform.org/latest/dev/MEDCoupling/developer/med-file.html) (`.med`),
>> [Nastran](https://help.autodesk.com/view/NSTRN/2019/ENU/?guid=GUID-42B54ACB-FBE3-47CA-B8FE-475E7AD91A00) (bulk data, `.bdf`, `.fem`, `.nas`),
>> [Netgen](https://github.com/ngsolve/netgen) (`.vol`, `.vol.gz`),
>> [Neuroglancer precomputed format](https://github.com/google/neuroglancer/tree/master/src/neuroglancer/datasource/precomputed#mesh-representation-of-segmented-object-surfaces),
>> [Gmsh](https://gmsh.info/doc/texinfo/gmsh.html#File-formats) (format versions 2.2, 4.0, and 4.1, `.msh`),
>> [OBJ](https://en.wikipedia.org/wiki/Wavefront_.obj_file) (`.obj`),
>> [OFF](https://segeval.cs.princeton.edu/public/off_format.html) (`.off`),
>> [PERMAS](https://www.intes.de) (`.post`, `.post.gz`, `.dato`, `.dato.gz`),
>> [PLY](<https://en.wikipedia.org/wiki/PLY_(file_format)>) (`.ply`),
>> [STL](<https://en.wikipedia.org/wiki/STL_(file_format)>) (`.stl`),
>> [Tecplot .dat](http://paulbourke.net/dataformats/tp/),
>> [TetGen .node/.ele](https://wias-berlin.de/software/tetgen/fformats.html),
>> [SVG](https://www.w3.org/TR/SVG/) (2D output only) (`.svg`),
>> [SU2](https://su2code.github.io/docs_v7/Mesh-File/) (`.su2`),
>> [UGRID](https://www.simcenter.msstate.edu/software/documentation/ug_io/3d_grid_file_type_ugrid.html) (`.ugrid`),
>> [VTK](https://vtk.org/wp-content/uploads/2015/04/file-formats.pdf) (`.vtk`),
>> [VTU](https://vtk.org/Wiki/VTK_XML_Formats) (`.vtu`),
>> [WKT](https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry) ([TIN](https://en.wikipedia.org/wiki/Triangulated_irregular_network)) (`.wkt`),
>> [XDMF](https://xdmf.org/index.php/XDMF_Model_and_Format) (`.xdmf`, `.xmf`).

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-meshio"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/GenevieveBuckley/napari-meshio/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/GenevieveBuckley/napari-meshio/issues', 'Documentation, https://github.com/GenevieveBuckley/napari-meshio#README.md', 'Source Code, https://github.com/GenevieveBuckley/napari-meshio', 'User Support, https://github.com/GenevieveBuckley/napari-meshio/issues']",napari-meshio.get_reader,napari-meshio.write_multiple,,napari-meshio.bunny,"['*.inp', '*.msh', '*.avs', '*.cgns', '*.xml', '*.e', '*.exo', '*.f3grid', '*.h5m', '*.mdpa', '*.mesh', '*.meshb', '*.med', '*.bdf', '*.fem', '*.nas', '*.vol', '*.vol.gz', '*.msh', '*.obj', '*.off', '*.post', '*.post.gz', '*.dato', '*.dato.gz', '*.ply', '*.stl', '*.dat', '*.node', '*.ele', '*.su2', '*.ugrid', '*.vtk', '*.vtu', '*.wkt', '*.xdmf', '*.xmf']",,"['.inp', '.msh', '.avs', '.cgns', '.xml', '.e', '.exo', '.f3grid', '.h5m', '.mdpa', '.mesh', '.meshb', '.med', '.bdf', '.fem', '.nas', '.vol', '.vol.gz', '.msh', '.obj', '.off', '.post', '.post.gz', '.dato', '.dato.gz', '.ply', '.stl', '.dat', '.node', '.ele', '.su2', '.ugrid', '.vtk', '.vtu', '.wkt', '.xdmf', '.xmf']"
286,napari-mm3,napari-mm3,napari-mm3,0.0.16,2022-06-02,2024-05-06,"Gursharan Ahir, Michael Sandler, Ryan Thiermann",ryan.thiermann@gmail.com,BSD-3-Clause,https://github.com/junlabucsd/napari-mm3/issues,https://pypi.org/project/napari-mm3/,,https://github.com/junlabucsd/napari-mm3,a plugin for mother machine image analysis,>=3.9,"['napari-plugin-engine >=0.1.4', 'numpy', 'h5py', 'tifffile ==2021.11.2', 'scikit-learn', 'scikit-image', 'tensorflow', 'nd2reader', 'seaborn', 'elasticdeform']","# napari-mm3

[![License](https://img.shields.io/pypi/l/napari-mm3.svg?color=green)](https://github.com/junlabucsd/napari-mm3/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-mm3.svg?color=green)](https://pypi.org/project/napari-mm3)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-mm3.svg?color=green)](https://python.org)
[![tests](https://github.com/junlabucsd/napari-mm3/workflows/tests/badge.svg)](https://github.com/junlabucsd/napari-mm3/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-mm3)](https://napari-hub.org/plugins/napari-mm3)

A plugin for mother machine image analysis by the [Jun Lab](https://jun.ucsd.edu/).

Reference:
[Tools and methods for high-throughput single-cell imaging with the mother machine. Ryan Thiermann, Michael Sandler, Gursharan Ahir, John T. Sauls, Jeremy W. Schroeder, Steven D. Brown, Guillaume Le Treut, Fangwei Si, Dongyang Li, Jue D. Wang, Suckjoon Jun. eLife12:RP88463
https://doi.org/10.7554/eLife.88463.1](https://elifesciences.org/reviewed-preprints/88463)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->


https://github.com/junlabucsd/napari-mm3/assets/40699438/1b3e6121-f5e1-475f-aca3-c6ed1b5bab3a



## Installation

We describe installation with mamba, a faster version of conda which we recommend. Installation with conda is the exact same, except replace `mamba` with `conda` Run the following command:

```
mamba create -n napari-mm3 -c conda-forge conda-build tensorflow napari
``` 
Now, you need to install our code (please let us know if this causes problems -- it has been a pain point in the past). To do so, clone the repository:

```
git clone https://github.com/junlabucsd/napari-mm3.git
```

Then, run the following commands from within your conda environment:
```
cd napari-mm3
pip install -e .
```
This supplies you with the latest, most recent version of our code.

If you would like to have a more stable version, simply run `pip install napari-mm3`. In general, we recommend going off of the github version.

napari-MM3 can use the [python-bioformats](https://pypi.org/project/python-bioformats/) library to import various image file formats. It can be installed with pip:
```
pip install python-bioformats
```
If your raw images are in the .nd2 format, they will be read in with the nd2reader package. In this case, Bio-Formats is not required.

NOTES:
Not running the conda command above and trying to install things in a different way may lead to difficult issues with PyQt5. We recommend following the above commands to simplify the situation.
Using `pip -e .` instead of `mamba develop .` is a deliberate choice, the former did not seem to register the plugin with napari.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## Usage guide


https://github.com/junlabucsd/napari-mm3/assets/8302475/68c726be-620e-4375-b1c9-3db56ac9a82a

Additional reference information is available below.
### a. Preprocessing

* [TIFFConverter](https://github.com/junlabucsd/napari-mm3/blob/main/docs/tiffconvert-widget.md) -- Turn your nd2 microscopy data, or other format via bioformats, into TIFFs. If your data is already exported as individual TIFF files, skip to the [Compile](https://github.com/junlabucsd/napari-mm3/blob/main/docs/compile-widget.md) widget. Take note of the [input image guidelines](https://github.com/junlabucsd/napari-mm3/blob/main/docs/Input-images-guidelines.md).

* [Compile](https://github.com/junlabucsd/napari-mm3/blob/main/docs/compile-widget.md) -- Locate traps, separate their timelapses into their own TIFFs, and return metadata.

* [PickChannels](https://github.com/junlabucsd/napari-mm3/blob/main/docs/pickchannels-widget.md) -- User guided selection of empty and full traps.

### b. Segmentation

___With Otsu's method:___

* [Subtract](https://github.com/junlabucsd/napari-mm3/blob/main/docs/subtract-widget.md) -- Remove (via subtraction) empty traps from the background of traps that contain cells; run this on the phase contrast channel.

* [SegmentOtsu](https://github.com/junlabucsd/napari-mm3/blob/main/docs/segmentotsu-widget.md) -- Use Otsu's method to segment cells.

___With U-Net:___

* [Annotate](https://github.com/junlabucsd/napari-mm3/blob/main/docs/annotate-widget.md) -- annotate images for ML (U-Net or similar) training purposes.

* [Train U-Net](https://github.com/junlabucsd/napari-mm3/blob/main/docs/trainunet-widget.md) -- Train a U-Net model for cell segmentation.

* [SegmentUnet](https://github.com/junlabucsd/napari-mm3/blob/main/docs/segmentunet-widget.md) -- Run U-Net segmentation.

### c. Tracking

* [Track](https://github.com/junlabucsd/napari-mm3/blob/main/docs/track-widget.md) -- Acquire individual cell properties and track lineages.

### d. Fluorescence data analysis

* [Subtract](https://github.com/junlabucsd/napari-mm3/blob/main/docs/subtract-widget.md) -- Remove (via subtraction) empty traps from the background of traps that contain cells. This time, run this on your fluorescence channels.

* [Colors](https://github.com/junlabucsd/napari-mm3/blob/main/docs/colors-widget.md) -- Calculate fluorescence information.

### e. Focus tracking

* [Foci](https://github.com/junlabucsd/napari-mm3/blob/main/docs/foci-widget.md) -- We use this to track `foci` (bright fluorescent spots) inside of cells.

### f. Extracting data and plotting

* The notebook [here](https://github.com/junlabucsd/napari-mm3/blob/main/notebooks/napari_mm3_analysis_template.ipynb) demonstrates how to extract, filter and visualize the lineage data output by the [Track](https://github.com/junlabucsd/napari-mm3/blob/main/docs/track-widget.md) widget.


### g. Outputs, inputs, and file structure
Finally, to better understand the data formats, you may wish to refer to the following documents:

* [Input image guidelines](https://github.com/junlabucsd/napari-mm3/blob/main/docs/Input-images-guidelines.md)

* [File structure](https://github.com/junlabucsd/napari-mm3/blob/main/docs/file-structure.md)

* [Output data structure](https://github.com/junlabucsd/napari-mm3/blob/main/docs/Cell-class-docs.md)

## License

Distributed under the terms of the [BSD-3] license,
""napari-mm3"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/junlabucsd/napari-mm3/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/junlabucsd/napari-mm3/issues', 'Documentation, https://github.com/junlabucsd/napari-mm3#README.md', 'Source Code, https://github.com/junlabucsd/napari-mm3', 'User Support, https://github.com/junlabucsd/napari-mm3/issues']",,,napari-mm3.TIFFConverter,,,,
287,napari-microscope,napari-microscope,napari-microscope,0.0.3,2021-11-23,2021-11-23,David Miguel Susano Pinto,david.pinto@bioch.ox.ac.uk,GPL-3.0-or-later,,https://pypi.org/project/napari-microscope/,None,,Napari plugin for Microscope.,>=3.6,"['Pyro4', 'microscope', 'napari_plugin_engine']","Microscope control plugin for Napari via Python Microscope.

Current development stage is whatever comes before alpha and ""proof of
concept"".

To test
-------

I haven't had access to real hardware yet, so this has all been
developed with simulated devices.

1. Start the device server with simulated devices.

    a. Create a device server configuration file like so::

        import microscope
        from microscope.device_server import device
        from microscope.simulators import (
            SimulatedCamera,
            SimulatedFilterWheel,
            SimulatedLightSource,
            SimulatedStage,
        )

        DEVICES = [
            device(SimulatedCamera, ""localhost"", 8000,),
            device(SimulatedLightSource, ""localhost"", 8001),
            device(SimulatedFilterWheel, ""localhost"", 8002,
                   {""positions"": 6}),
            device(SimulatedStage, ""localhost"", 8003,
                   {""limits"": {""X"": microscope.AxisLimits(0, 25000),
                               ""Y"": microscope.AxisLimits(0, 12000)}}),
        ]

    b. Start the device server (ensure port 8000-8003 are unused)::

        $ device-server path-to-microscope-config.py

2. Start napari

3. Plugins > Add Dock Widget > microscope: MicroscopeWidget

4. Connect to the camera:

    a. On the new widget, click on the ""Add device"" button.

    b. Enter the camera URI `PYRO:SimulatedCamera@localhost:8000`

5. Tick the `Enabled` box to enable the camera and then press the
""Snap"" button.

6. A random values image will appear displayed on the napari viewer.
Keep pressing the ""Snap"" button to get new images.  The top left
corner of the image is the simulated image number.

7. Connect to the other simulated devices.  Their URIs are:

    a. PYRO:SimulatedLightSource@localhost:8001
    b. PYRO:SimulatedFilterWheel@localhost:8002
    c. PYRO:SimulatedStage@localhost:8003

8. Changing the other simulated devices, doesn't really do much (but
does change state of the devices, as can be seen in the logs)


Test with stage aware camera
----------------------------

This is pretty much the same as before but one can use a large RGB
TIFF (histology samples are perfect) to simulate a camera that returns
subsections of the image file based on the simulated stage position.

For quick example, try::

    wget https://zenodo.org/record/1445489/files/B0002.tif

And use the following device server configuration file::

    from microscope.device_server import device
    from microscope.simulators.stage_aware_camera import simulated_setup_from_image

    DEVICES = [
        device(simulated_setup_from_image, ""localhost"", 8000,
               conf={""filepath"": ""B0002.tif""}),
    ]

The URI for the devices will be::

    PYRO:camera@localhost:8000
    PYRO:filterwheel@localhost:8000
    PYRO:stage@localhost:8000

Changing the filterwheel changes which channel from the image is
returned.  Changing the stage coordinates changes the image that is
returned (but beware of the corners, pixels outside the image size are
not handled yet and will give an error).
","['Development Status :: 3 - Alpha', 'Environment :: Plugins', 'Framework :: napari ', 'Intended Audience :: Science/Research', 'Operating System :: OS Independent', 'Topic :: Scientific/Engineering']",,,,napari-microscope.MicroscopeWidget,,,,
288,napari-metroid,napari-metroid,napari METROID,0.0.5,2022-03-24,2022-07-20,Marcelo Leomil Zoccoler,marcelo.zoccoler@tu-dresden.de,BSD-3-Clause,https://github.com/zoccoler/napari-metroid/issues,https://pypi.org/project/napari-metroid/,,https://github.com/zoccoler/napari-metroid,This napari plugin creates several regions of interest of similar area over cells in a fluorescence video (2D+time). It then gets ROIs means over time and performs signal denoising: fixes photobleaching and separates signal from noise by means of blind source separation (with or without wavelet filtering).,"<3.9,>=3.7","['numpy', 'scikit-learn', 'scikit-image', 'statsmodels', 'scipy', 'matplotlib', 'napari-skimage-regionprops (>=0.3.1)']","# napari-metroid

[![License](https://img.shields.io/pypi/l/napari-metroid.svg?color=green)](https://github.com/zoccoler/napari-metroid/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-metroid.svg?color=green)](https://pypi.org/project/napari-metroid)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-metroid.svg?color=green)](https://python.org)
[![tests](https://github.com/zoccoler/napari-metroid/workflows/tests/badge.svg)](https://github.com/zoccoler/napari-metroid/actions)
[![codecov](https://codecov.io/gh/zoccoler/napari-metroid/branch/main/graph/badge.svg)](https://codecov.io/gh/zoccoler/napari-metroid)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-metroid)](https://napari-hub.org/plugins/napari-metroid)

This napari plugin is an adaptation of [metroid](https://github.com/zoccoler/metroid). It creates several regions of interest of similar area over cells in a fluorescence video (2D+time). It then gets ROIs means over time and performs signal denoising: fixes photobleaching and separates signal from noise by means of blind source separation (with or without wavelet filtering).

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## A Picture (to boil down a thousand words)

Below is the graphical abstract of the Metroid software. This napari plugin works very similarly.

![](https://github.com/zoccoler/metroid/blob/master/Metroid_flowchart.png)

## Table of Contents

- [Quick Walktrough](#quick-walkthrough)
- [Installation](#installation)
- [Usage](#usage)
  - [Open Sample Data](#open-sample-data)
  - [Open Plugin Main Interface](#open-plugin-main-interface)
  - [Auto-generate Cell Mask](#auto-generate-cell-mask)
  - [Split Mask into ROIs](#split-mask-into-rois)
  - [Get ROI Means over Time](#get-roi-means-over-time)
  - [Remove Photobleaching](#remove-photobleaching)
  - [Filter Signals](#filter-signals)
  - [Save outputs](#save-outputs)
- [Contributing](#contributing)
- [Citing napari-metroid](#citing-napari-metroid)
- [License](#license)
- [Issues](#issues)

## Quick Walkthrough

Below is a full demonstration of using napari-metroid. It shows the following:
  * Open sample data;
  * Create cell mask;
  * Split mask into ROIs of similar area;
  * Get ROIs signals over time and plots two of them;
  * Remove photobleaching;
  * Remove noise:
    * Use ICA to decompose ROIs signals into independent components;
    * Plot 4 components;
    * Manually select the component of interest (source);
    * Perform inverse transformation with selected source;
        
![](https://github.com/zoccoler/napari-metroid/raw/main/figures/napari_metroid_demo.gif)

## Installation

Download and install [Anaconda](https://www.anaconda.com/products/individual) or [Miniconda](https://docs.conda.io/en/latest/miniconda.html#).

Create a new conda environment:

    conda create -n metroid-env python=3.8

Install napari, e.g. via pip:

    pip install ""napari[all]""

Install `napari-metroid` via [pip]:

    pip install napari-metroid

To install latest development version :

    pip install git+https://github.com/zoccoler/napari-metroid.git

## Usage
### Open Sample Data

This plugin comes with two sample videos:
- Cell1 Video Action Potential: 2D + time fluorescence video of a rat isolated cardiomyocyte labeled with a membrane potential dye upon which an external electrical field pulse is applied.
- Cell1 Video Electroporation: Same cell, but submitted to a strong external electrical field pulse.

You can open them under ""File -> Open Sample -> napari-metroid"", as shown below. Both videos are loaded from the [metroid main repository](https://github.com/zoccoler/metroid). To know more about the experimental conditions, please refer to the [original publication](https://doi.org/10.1186/s12859-020-03661-9).

![](https://github.com/zoccoler/napari-metroid/raw/main/figures/load_sample_data.gif)

### Open Plugin Main Interface

![](https://github.com/zoccoler/napari-metroid/raw/main/figures/open_plugin.gif)

### Auto-generate Cell Mask

Metroid can generate cell binary masks automatically by cumulative sum of images until any pixel saturation happens. It then applies Otsu thresholding and removes small objects.

![](https://github.com/zoccoler/napari-metroid/raw/main/figures/auto_create_mask.png)

### Split Mask into ROIs

By default, a cell mask is split into 32 regions of interest (ROIs) in a double-layer fashion: An outer layer of ROIs and an inner layer. 
The method is solely based on the shape of the cell mask and the main criteria is that ROIs must have similar areas. The number of ROIs in each layer can be editted. 

![](https://github.com/zoccoler/napari-metroid/raw/main/figures/mess.png)

### Get ROI Means over Time

The 'Get Signals' button serves to collect each ROI mean fluorescence over time and enable plotting. There, you can optionally provide the frame rate so that the time axis is properly displayed.
Double click over a ROI to have its signal plotted. Hold the 'ALT' key to plot multiple signals together.

![](https://github.com/zoccoler/napari-metroid/raw/main/figures/get_signals.gif)

### Remove Photobleaching

Metroid removes photobleaching by curve fitting over time periods that lack the cellular signal (which can be an action potential or an electroporation signal). That is why the 'Transitory' parameter is important. Action potentials are transitory signals whereas electroporation (at least for the duration of this experiment) are not, and the algorithm must be informed about that for proper trend removal.

![](https://github.com/zoccoler/napari-metroid/raw/main/figures/remov_photob.gif)

### Filter Signals

Cellular signals are filtered by separating signal components with either PCA or ICA (plus optional wavelet filtering). It then chooses one (or several) components and it applies the inverse transform using only the selected components. Metroid can do this component/source selection automatically based on estimations of signal power. Instead, we show below the manual selection procedure, where 4 components are plotted and the user selects one of them.

![](https://github.com/zoccoler/napari-metroid/raw/main/figures/bssd.gif)

### Save Outputs

Raw, corrected and filtered signals, as well as time and components, are arranged in a table with values for each time point. The table is displayed as a widget after each Run button click. Estimated signal-to-noise (SNR) in dB for each label/ROI are also provided (in this case, each line corresponds to a ROI, not a time point).
The user can save these data by clicking on the buttons ""Copy to clipboard"" or ""Save as csv..."".

![](https://github.com/zoccoler/napari-metroid/raw/main/figures/table_widget.png)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## Citing napari-metroid

If you use this plugin in your research, please be kind to cite the original paper below:

Zoccoler, M., de Oliveira, P.X. METROID: an automated method for robust quantification of subcellular fluorescence events at low SNR. BMC Bioinformatics 21, 332 (2020). https://doi.org/10.1186/s12859-020-03661-9

## License

Distributed under the terms of the [BSD-3] license,
""napari-metroid"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/zoccoler/napari-metroid/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/zoccoler/napari-metroid/issues', 'Documentation, https://github.com/zoccoler/napari-metroid#README.md', 'Source Code, https://github.com/zoccoler/napari-metroid', 'User Support, https://github.com/zoccoler/napari-metroid/issues']",,napari-metroid.write_multiple,napari-metroid.make_qwidget,napari-metroid.make_cell1_AP1_data,,,['.npy']
289,napari-microtubule-analyzer,napari-microtubule-analyzer,Microtubule Analyzer,0.0.1a7,2023-10-03,2023-10-24,Daniel Krentzel,dkrentzel@pm.me,MIT,https://github.com/krentzd/napari-microtubule-analyzer/issues,https://pypi.org/project/napari-microtubule-analyzer/,,https://github.com/krentzd/napari-microtubule-analyzer,A plugin to analyze microtubule organization,>=3.8,"['setuptools', 'packaging', 'numpy', 'magicgui', 'qtpy', 'opencv-python', 'matplotlib', 'scikit-image', 'tqdm', 'tifffile', 'scipy', 'pyefd', 'pyqtgraph', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-microtubule-analyzer

[![License MIT](https://img.shields.io/pypi/l/napari-microtubule-analyzer.svg?color=green)](https://github.com/krentzd/napari-microtubule-analyzer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-microtubule-analyzer.svg?color=green)](https://pypi.org/project/napari-microtubule-analyzer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-microtubule-analyzer.svg?color=green)](https://python.org)
[![tests](https://github.com/krentzd/napari-microtubule-analyzer/workflows/tests/badge.svg)](https://github.com/krentzd/napari-microtubule-analyzer/actions)
[![codecov](https://codecov.io/gh/krentzd/napari-microtubule-analyzer/branch/main/graph/badge.svg)](https://codecov.io/gh/krentzd/napari-microtubule-analyzer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-microtubule-analyzer)](https://napari-hub.org/plugins/napari-microtubule-analyzer)

A plugin to analyze microtubule organization 

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-microtubule-analyzer` via [pip]:

    pip install napari-microtubule-analyzer



To install latest development version :

    pip install git+https://github.com/krentzd/napari-microtubule-analyzer.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-microtubule-analyzer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/krentzd/napari-microtubule-analyzer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/krentzd/napari-microtubule-analyzer/issues', 'Documentation, https://github.com/krentzd/napari-microtubule-analyzer#README.md', 'Source Code, https://github.com/krentzd/napari-microtubule-analyzer', 'User Support, https://github.com/krentzd/napari-microtubule-analyzer/issues']",napari-microtubule-analyzer.get_reader,,napari-microtubule-analyzer.degree_of_radiality,napari-microtubule-analyzer.sample_data,"['*.tif', '*.tiff']",,
290,napari-molseeq,napari-molseeq,molSEEQ,1.0.8,2024-07-25,2025-07-06,Piers Turner,piers.turner@physics.ox.ac.uk,MIT,https://github.com/piedrro/napari-molseeq/issues,https://pypi.org/project/napari-molseeq/,,,A Napari plugin for extracting single molecule sequences from single/multi-channel SMLM microscopy data.,>=3.9,"['napari[all]==0.5.0', 'numpy', 'magicgui', 'qtpy', 'scipy', 'pyqtgraph', 'picassosr==0.7.3', 'pandas', 'matplotlib>=3.7.0', 'scipy', 'opencv-python', 'tqdm', 'originpro', 'pyqt5-tools', 'trackpy', 'shapely', 'astropy', 'mat4py', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-molSEEQ

[![License MIT](https://img.shields.io/pypi/l/napari-GapSeq2.svg?color=green)](https://github.com/piedrro/napari-molseeq/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-GapSeq2.svg?color=green)](https://pypi.org/project/napari-molseeq/)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-GapSeq2.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-GapSeq2)](https://napari-hub.org/plugins/napari-molseeq)

A **Napari** plugin for extracting single molecule sequences from single/multi-channel SMLM microscopy data. 

Compatible with both ALEX and FRET data. All functions are parallelised/GPU accelerated where possible to increase performance.
Multiple datasets can be loaded and processed in parallel.

napari-molseeq uses **Picasso** (picassosr) as a backend and includes features for **aligning** image channels/datasets, **undrifting** images, **detecting/fitting** localisations and extracting **traces**, and supports both **ALEX** and **FRET** data. Traces can be exported in different formats for downstream analysis.

napari-molseeq traces can be analysed with TraceAnalyser: https://github.com/piedrro/TraceAnalyser

This is still undergoing development, so some features may not work as expected.

This was built by Dr Piers Turner from the Kapanidis Lab, University of Oxford.

----------------------------------

## Installation

You can install `napari-molseeq` via [pip]:

    pip install napari-molseeq

You can install `napari-molseeq` via [GitHub]:

    conda create â-name napari-molseeq python==3.9
    conda activate napari-molseeq
    conda install -c anaconda git
    conda update --all

    pip install git+https://github.com/piedrro/napari-molseeq.git

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-molseeq"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/piedrro/napari-GapSeq2/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/piedrro/napari-molseeq/issues', 'Documentation, https://github.com/piedrro/napari-molseeq#README.md', 'Source Code, https://github.com/piedrro/napari-molseeq', 'User Support, https://github.com/piedrro/napari-molseeq/issues']",,,napari-molseeq.make_qwidget,,,,
291,napari-micromanager,napari-micromanager,napari-micromanager,0.1.3,2021-08-15,2024-09-26,"Federico Gasparoli, Talley Lambert","Federico Gasparoli <federico.gasparoli@gmail.com>, Talley Lambert <talley.lambert@gmail.com>",BSD 3-Clause,https://github.com/pymmcore-plus/napari-micromanager/issues,https://pypi.org/project/napari-micromanager/,,,Micro-Manager GUI interface in napari.,>=3.9,"['fonticon-materialdesignicons6', 'napari>=0.4.13', 'pymmcore-plus>=0.9.3', 'pymmcore-widgets>=0.7.0rc1', 'superqt>=0.5.1', 'tifffile', 'useq-schema>=0.4.1', 'zarr', ""mda-simulator; extra == 'dev'"", ""mypy; extra == 'dev'"", ""pre-commit; extra == 'dev'"", ""ruff; extra == 'dev'"", ""mkdocs-material; extra == 'docs'"", ""mkdocstrings-python; extra == 'docs'"", ""pyqt5; extra == 'pyqt5'"", ""pyqt6; extra == 'pyqt6'"", ""pyside2; extra == 'pyside2'"", ""pyside6; extra == 'pyside6'"", ""pytest; extra == 'test'"", ""pytest-cov; extra == 'test'"", ""pytest-qt; extra == 'test'""]","# napari-micromanager

[![License](https://img.shields.io/pypi/l/napari-micromanager.svg?color=green)](https://github.com/napari/napari-micromanager/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-micromanager.svg?color=green)](https://pypi.org/project/napari-micromanager)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-micromanager.svg?color=green)](https://python.org)
[![Tests](https://github.com/pymmcore-plus/napari-micromanager/actions/workflows/ci.yml/badge.svg)](https://github.com/pymmcore-plus/napari-micromanager/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/pymmcore-plus/napari-micromanager/branch/main/graph/badge.svg?token=tf6lYDWV1s)](https://codecov.io/gh/pymmcore-plus/napari-micromanager)

GUI interface between napari and micromanager powered by [pymmcore-plus](https://pymmcore-plus.github.io/pymmcore-plus/) and [pymmcore-widgets](https://pymmcore-plus.github.io/pymmcore-widgets/)

----------------------------------
<img width=""1840"" alt=""napari-micromanager"" src=""https://github.com/pymmcore-plus/napari-micromanager/assets/1609449/e1f395cd-2d57-488e-89e2-b1923310fc2a"">

## Installation

You can install `napari-micromanager` via [pip]:

    pip install napari-micromanager

You will also need a Qt backend such as PySide2/6, or PyQt5/6.  **PyQt is
preferred and receives more testing**. If you've previously installed napari
into this environment with `pip install napari[all]`, then you will likely
already have it. If not, you will also need to install a Qt backend of your
choice:

    pip install pyqt5  # or any of {pyqt5, pyqt6, pyside2, pyside6}

### Getting micromanager adapters

The easiest way to get the micromanager adapters is to use:

```
mmcore install
```

this will install micromanager to the pymmcore_plus folder in your site-package; use this to see where:

```
python -c ""from pymmcore_plus import find_micromanager; print(find_micromanager())""
```

alternatively, you can direct pymmcore_plus to your own micromanager installation with the `MICROMANAGER_PATH`
environment variable:

```
export MICROMANAGER_PATH='/path/to/Micro-Manager-...'
```

## Contributing

Contributions are very welcome.

### Launching napari with plugin

You can launch napari and automatically load this plugin using the `launch-dev.py` script:

```bash
python launch-dev.py
```

Alternatively you can run:

```bash
napari -w napari-micromanager
```

## License

Distributed under the terms of the [BSD-3] license,
""napari-micromanager"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[file an issue]: https://github.com/pymmcore-plus/napari-micromanager/issues
[pip]: https://pypi.org/project/pip/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: System :: Hardware', 'Topic :: System :: Hardware :: Hardware Drivers', 'Topic :: Utilities']","['Source, https://github.com/pymmcore-plus/napari-micromanager', 'Tracker, https://github.com/pymmcore-plus/napari-micromanager/issues']",,,napari-micromanager.MainWindow,,,,
292,napari-moltrack,napari-moltrack,MolTrack,0.1.9,2024-05-30,2025-07-15,Piers Turner,piers.turner@physics.ox.ac.uk,"Copyright (c) 2024, Piers Turn...",https://github.com/piedrro/napari-moltrack/issues,https://pypi.org/project/napari-moltrack/,,,"A user-friendly SMLM analysis platfrom for napari, which includes single molecule localisation, tracking, and analysis features.",>=3.9,"['napari[all]==0.5.0', 'bactfit>=0.1.6', 'numpy', 'magicgui', 'qtpy', 'scipy', 'pyqtgraph', 'picassosr==0.8.0', 'pandas', 'matplotlib>=3.7.0', 'scipy', 'opencv-python', 'tqdm', 'originpro', 'pyqt5-tools', 'torch', 'torchvision', 'cellpose==3.0.1', 'omnipose', 'trackpy', 'shapely', 'astropy', 'mat4py', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-moltrack

[![License BSD-3](https://img.shields.io/pypi/l/napari-moltrack.svg?color=green)](https://github.com/piedrro/napari-moltrack/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-moltrack.svg?color=green)](https://pypi.org/project/napari-moltrack)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-moltrack.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-moltrack)](https://napari-hub.org/plugins/napari-moltrack)

A user-friendly SMLM analysis platfrom for napari, which includes single molecule localisation, tracking, and analysis features. 
Based on established python packages such as **Picasso**, **GPUfit** and **Trackpy**.
This plugin was designed to detect/track single molecules inside cells, but can be used for any other SMLM/tracking application.

All functions are parallelised/GPU accelerated where possible to increase performance.
Multiple datasets can be loaded and processed in parallel.

Single molecule localisations can be filtered by their properties (e.g. photons, width, etc.) and can be rendered as a super resolution image.

Napari-moltrack is also compatible with **FRET** and **ALEX FRET** image data, can be used to calculate FRET efficiencies of single molecules/tracks.

Segmentations can be used to exclude regions from single molecule localisation and tracking.
Segmentations can be added automatically using Cellpose or can be added manually. Includes tools for editing/modifying segmentations at a sub-pixel resolution.

Compatible with both single and multi-channel .tif and .fits files.

napari-moltrack was written by Piers Turner, Kapanidis Group, University of Oxford.

https://www.physics.ox.ac.uk/research/group/gene-machines

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-moltrack` via [pip]:

    pip install napari-moltrack

To update `napari-moltrack` to the latest version, use:

    pip install napari-moltrack --upgrade

To install latest development version :

    pip install git+https://github.com/piedrro/napari-moltrack.git


## BactFit

napari-moltrack integrates BactFit, a package for fitting the shape of rod shaped bacterial cells to an ideal cell model.
BactFit allows cell renders and heatmaps to be generated through the transformation of SMLM localisations to an ideal cell model.

### BactFit Heatmap

![Feature Image](resources/heatmap.png)

### BactFit Cell Render

![Feature Image](resources/render.png)


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-moltrack"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/piedrro/napari-moltrack/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/piedrro/napari-moltrack/issues', 'Documentation, https://github.com/piedrro/napari-moltrack#README.md', 'Source Code, https://github.com/piedrro/napari-moltrack', 'User Support, https://github.com/piedrro/napari-moltrack/issues']",,,napari-moltrack.make_qwidget,,,,
293,napari-molecule-reader,napari-molecule-reader,napari molecule reader,0.1.4,2021-12-21,2025-05-12,Lorenzo Gaifas,brisvag@gmail.com,"GNU GENERAL PUBLIC LICENSE
   ...",https://github.com/brisvag/napari-molecule-reader/issues,https://pypi.org/project/napari-molecule-reader/,,,A napari plugin that read molecular structure files.,>=3.10,"['atomium', 'numpy', 'pandas', 'scipy', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""']","# napari-molecule-reader

[![License](https://img.shields.io/pypi/l/napari-molecule-reader.svg?color=green)](https://github.com/brisvag/napari-molecule-reader/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-molecule-reader.svg?color=green)](https://pypi.org/project/napari-molecule-reader)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-molecule-reader.svg?color=green)](https://python.org)
[![tests](https://github.com/brisvag/napari-molecule-reader/workflows/tests/badge.svg)](https://github.com/brisvag/napari-molecule-reader/actions)
[![codecov](https://codecov.io/gh/brisvag/napari-molecule-reader/branch/main/graph/badge.svg)](https://codecov.io/gh/brisvag/napari-molecule-reader)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-molecule-reader)](https://napari-hub.org/plugins/napari-molecule-reader)

A napari plugin that read molecular structure files. It reads PDB and MMCIF files using [`atomium`](https://github.com/samirelanduk/atomium), expanding molecular assemblies to a full visualization. Data is loaded into napari as `Points` for ball representation and `Vectors` for stick representation. If multiple models or assemblies are detected, they will be loaded as separate objects.

https://user-images.githubusercontent.com/23482191/150109390-bd7fb3b4-79b4-43da-aafc-20921714df25.mp4

TODO list:
- [] handle alternate locations (i.e: different conformations in the same pdb model)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-molecule-reader` via [pip]:

    pip install napari-molecule-reader



To install latest development version :

    pip install git+https://github.com/brisvag/napari-molecule-reader.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-molecule-reader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/brisvag/napari-molecule-reader/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/brisvag/napari-molecule-reader/issues', 'Documentation, https://github.com/brisvag/napari-molecule-reader#README.md', 'Source Code, https://github.com/brisvag/napari-molecule-reader', 'User Support, https://github.com/brisvag/napari-molecule-reader/issues']",napari-molecule-reader.get_reader,,,,"['*.pdb', '*.cif']",,
294,napari-morphodynamics,napari-morphodynamics,napari-morphodynamics,0.1.2,2023-11-08,2024-01-22,Guillaume Witz,guillaume.witz@unibe.ch,BSD-3-Clause,https://github.com/guiwitz/napari-morphodynamics/issues,https://pypi.org/project/napari-morphodynamics/,,https://github.com/guiwitz/napari-morphodynamics,Interface to run the morphodynamics package.,>=3.9,"['morphodynamics', 'napari-convpaint', 'napari-guitils', 'napari-matplotlib', ""cellpose ; extra == 'cellpose'""]","# napari-morphodynamics

[![License](https://img.shields.io/pypi/l/napari-morphodynamics.svg?color=green)](https://github.com/guiwitz/napari-morphodynamics/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-morphodynamics.svg?color=green)](https://pypi.org/project/napari-morphodynamics)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-morphodynamics.svg?color=green)](https://python.org)
[![tests](https://github.com/guiwitz/napari-morphodynamics/workflows/tests/badge.svg)](https://github.com/guiwitz/napari-morphodynamics/actions)
[![codecov](https://codecov.io/gh/guiwitz/napari-morphodynamics/branch/main/graph/badge.svg)](https://codecov.io/gh/guiwitz/napari-morphodynamics)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-morphodynamics)](https://napari-hub.org/plugins/napari-morphodynamics)

This plugin offers an interface for the [Morphodynamics](https://github.com/guiwitz/MorphoDynamics) package which allows to study the shape and intra-cellular dynamics of cells imaged as time-lapses by fluorescence microscopy. The plugin offers a single place to perfrom segmentation, windowing (partition cells into small regions of interests that are tracked over time) and results visualization. The software depends on [napari-convpaint](https://github.com/guiwitz/napari-convpaint) a pixel-classifier and/or on [cellpose](https://cellpose.readthedocs.io/en/latest/index.html) for segmentation. 

## Installation

You can install the plugin via [pip] with:

    pip install napari-morphodynamics

To install latest development version :

    pip install git+https://github.com/guiwitz/napari-morphodynamics.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-morphodynamics"" is free and open source software

## Authors

This plugin has been developed by Guillaume Witz and Ana Stojiljkovic at the Data Science Lab, University of Bern, in collaboration with Lucien Hinderling and Olivier Pertz from the Pertz Lab, University of Bern. Development has been partially funded by a [Chan Zuckerberg Initiative grant](https://chanzuckerberg.com/science/programs-resources/imaging/napari/napari-morphodynamics-a-plugin-to-quantify-cellular-dynamics/).

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/guiwitz/napari-morphodynamics/issues

[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/guiwitz/napari-morphodynamics/issues', 'Documentation, https://github.com/guiwitz/napari-morphodynamics#README.md', 'Source Code, https://github.com/guiwitz/napari-morphodynamics', 'User Support, https://github.com/guiwitz/napari-morphodynamics/issues']",,,napari-morphodynamics.make_qwidget,,,,
295,napari-mouse-controls,napari-mouse-controls,napari-mouse-controls,0.1.3,2021-10-30,2022-01-01,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-mouse-controls/issues,https://pypi.org/project/napari-mouse-controls/,,https://github.com/haesleinhuepf/napari-mouse-controls,Control napari using a touch screen,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari', 'napari-tools-menu']","# napari-mouse-controls

[![License](https://img.shields.io/pypi/l/napari-mouse-controls.svg?color=green)](https://github.com/haesleinhuepf/napari-mouse-controls/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-mouse-controls.svg?color=green)](https://pypi.org/project/napari-mouse-controls)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-mouse-controls.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-mouse-controls/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-mouse-controls/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-mouse-controls/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-mouse-controls)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-mouse-controls)](https://napari-hub.org/plugins/napari-mouse-controls)

Control zoom, slicing and contrast windowing with mouse and touch screen

----------------------------------

## Usage

You find the mouse control panel in the menu `Tools > Utilities > Mouse controls`

### Zoom

After clicking the Zoom button ![](https://github.com/haesleinhuepf/napari-mouse-controls/raw/main/src/napari_mouse_controls/icons/Zoom.png), you can click in the napari canvas and move the mouse up and down to zoom in and out.

![](https://github.com/haesleinhuepf/napari-mouse-controls/raw/main/docs/zoom.gif)

### Slicing

After clicking the Slicing button ![](https://github.com/haesleinhuepf/napari-mouse-controls/raw/main/src/napari_mouse_controls/icons/Slicing.png), you can control the currently displayed slice by moving the mouse.
By moving the mouse up and down, you control the currently selected Z-plane.
By moving the mouse left and right, you control the currently seleted time point.

![](https://github.com/haesleinhuepf/napari-mouse-controls/raw/main/docs/slicing.gif)

### Windowing

After clicking the Windowing button ![](https://github.com/haesleinhuepf/napari-mouse-controls/raw/main/src/napari_mouse_controls/icons/Windowing.png), you can modify the brightness and contrast by moving the mouse. 
By moving the mouse up and down, you control window width of the range of displayed grey values (max - min).
By moving the mouse left and right, you control the center of the grey value window. 

![](https://github.com/haesleinhuepf/napari-mouse-controls/raw/main/docs/windowing.gif)

### Normal / default mode

Click the Default button ![](https://github.com/haesleinhuepf/napari-mouse-controls/raw/main/src/napari_mouse_controls/icons/Default.png)
to return to napari's normal mode.


This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.


## Installation

You can install `napari-mouse-controls` via [pip]:

    pip install napari-mouse-controls

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-mouse-controls"" is free and open source software

## Issues

If you encounter any problems, please create a thread on [image.sc] along with a detailed description and tag [@haesleinhuepf].

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-mouse-controls/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[image.sc]: https://image.sc

[@haesleinhuepf]: https://twitter.com/haesleinhuepf


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-mouse-control/issues', 'Documentation, https://github.com/haesleinhuepf/napari-mouse-controls#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-mouse-controls', 'User Support, https://github.com/haesleinhuepf/napari-mouse-controls/issues']",,,napari-mouse-controls.MouseControls,,,,
296,napari-mrcfile-handler,napari-mrcfile-handler,napari-mrcfile-handler,0.0.6,2021-08-30,2021-09-01,Philipp Schoennenbeck,p.schoennenbeck@fz-juelich.de,BSD-3-Clause,https://github.com/Croxa/napari-mrcfile_handler/issues,https://pypi.org/project/napari-mrcfile-handler/,,https://github.com/Croxa/napari-mrcfile_handler,"A simple plugin to read, write and adjust mrcfiles in napari.",>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'mrcfile']","# napari-mrcfile_handler

[![License](https://img.shields.io/pypi/l/napari-mrcfile_handler.svg?color=green)](https://github.com/Croxa/napari-mrcfile_handler/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-mrcfile_handler.svg?color=green)](https://pypi.org/project/napari-mrcfile_handler)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-mrcfile_handler.svg?color=green)](https://python.org)
[![tests](https://github.com/Croxa/napari-mrcfile_handler/workflows/tests/badge.svg)](https://github.com/Croxa/napari-mrcfile_handler/actions)
[![codecov](https://codecov.io/gh/Croxa/napari-mrcfile_handler/branch/master/graph/badge.svg)](https://codecov.io/gh/Croxa/napari-mrcfile_handler)

A simple plugin to read, write and adjust mrcfiles in napari.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-mrcfile_handler` via [pip]:

    pip install napari-mrcfile_handler

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-mrcfile_handler"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/Croxa/napari-mrcfile_handler/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/Croxa/napari-mrcfile_handler/issues', 'Documentation, https://github.com/Croxa/napari-mrcfile_handler#README.md', 'Source Code, https://github.com/Croxa/napari-mrcfile_handler', 'User Support, https://github.com/Croxa/napari-mrcfile_handler/issues']",napari-mrcfile-handler.napari_get_reader,napari-mrcfile-handler.napari_write_image,napari-mrcfile-handler.PixelSpacing,,['*'],,
297,napari-mrcfile-reader,napari-mrcfile-reader,napari-mrcfile-reader,0.2.0,2021-09-16,2023-06-08,Alister Burt,alisterburt@gmail.com,BSD-3-Clause,https://github.com/alisterburt/napari-mrcfile-reader/issues,https://pypi.org/project/napari-mrcfile-reader/,,https://github.com/alisterburt/napari-mrcfile-reader,Read MRC2014 files in napari using mrcfile.,>=3.8,"['numpy', 'mrcfile', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-mrcfile-reader

[![License](https://img.shields.io/pypi/l/napari-mrcfile-reader.svg?color=green)](https://github.com/alisterburt/napari-mrcfile-reader/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-mrcfile-reader.svg?color=green)](https://pypi.org/project/napari-mrcfile-reader)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-mrcfile-reader.svg?color=green)](https://python.org)
[![tests](https://github.com/alisterburt/napari-mrcfile-reader/workflows/tests/badge.svg)](https://github.com/alisterburt/napari-mrcfile-reader/actions)
[![codecov](https://codecov.io/gh/alisterburt/napari-mrcfile-reader/branch/master/graph/badge.svg)](https://codecov.io/gh/alisterburt/napari-mrcfile-reader)

Read MRC format image files into napari using the [mrcfile] package from [CCP-EM]

----------------------------------
![example usage](example.gif)
----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.


## Installation

You can install `napari-mrcfile-reader` via [pip]:

    pip install napari-mrcfile-reader

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-mrcfile-reader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.


[CCP-EM]: https://www.ccpem.ac.uk/
[mrcfile]: https://github.com/ccpem/mrcfile
[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/alisterburt/napari-mrcfile-reader/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/alisterburt/napari-mrcfile-reader/issues', 'Documentation, https://github.com/alisterburt/napari-mrcfile-reader#README.md', 'Source Code, https://github.com/alisterburt/napari-mrcfile-reader', 'User Support, https://github.com/alisterburt/napari-mrcfile-reader/issues']",napari-mrcfile-reader.get_reader,,,,"['*.mrc', '*.mrcs', '*.map', '*.st', '*.rec', '*.preali', '*.ali']",,
298,napari-mzarr,napari-mzarr,Napari Mzarr,0.0.3,2023-06-02,2023-09-26,Karol Gotkowski,karol.gotkowski@dkfz.de,Apache-2.0,,https://pypi.org/project/napari-mzarr/,None,,A reader and writer plugin for the Mzarr image format.,>=3.8,"['numpy', 'zarr', 'numcodecs', 'imagecodecs ==2023.1.23', 'dask', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-mzarr

[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-mzarr.svg?color=green)](https://github.com/Karol-G/napari-mzarr/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-mzarr.svg?color=green)](https://pypi.org/project/napari-mzarr)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-mzarr.svg?color=green)](https://python.org)
[![tests](https://github.com/Karol-G/napari-mzarr/workflows/tests/badge.svg)](https://github.com/Karol-G/napari-mzarr/actions)
[![codecov](https://codecov.io/gh/Karol-G/napari-mzarr/branch/main/graph/badge.svg)](https://codecov.io/gh/Karol-G/napari-mzarr)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-mzarr)](https://napari-hub.org/plugins/napari-mzarr)

A reader and writer plugin for the Mzarr image format.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-mzarr` via [pip]:

    pip install napari-mzarr




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-mzarr"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-mzarr.get_reader,napari-mzarr.write_multiple,,,"['*.mzarr', '*.mzz']",,['.mzarr']
299,napari-nanopyx,napari-nanopyx,napari NanoPyx,0.2.4,2023-06-14,2025-07-09,"Ricardo Henriques, Bruno Saraiva, InÃªs Cunha, AntÃ³nio Brito",bruno.msaraiva2@gmail.com,LGPL-3.0-only,https://github.com/HenriquesLab/napari-NanoPyx/issues,https://pypi.org/project/napari-nanopyx/,,,"napari plugin of Nanoscopy Python library (NanoPyx, the successor to NanoJ) - focused on light microscopy and super-resolution imaging",>=3.9,"['napari', 'nanopyx>=1.2', 'scikit-image', 'magicgui', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""']","# napari-nanopyx

<img src=""https://github.com/HenriquesLab/NanoPyx/blob/main/.github/logo.png"" align=""right"" width=""230""/>

[![License](https://img.shields.io/github/license/HenriquesLab/NanoPyx?color=Green)](https://github.com/HenriquesLab/NanoPyx/blob/main/LICENSE.txt)
[![PyPI](https://img.shields.io/pypi/v/napari-nanopyx.svg?color=green)](https://pypi.org/project/napari-nanopyx)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nanopyx.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-nanopyx)](https://napari-hub.org/plugins/napari-nanopyx)
[![Docs](https://img.shields.io/badge/documentation-link-blueviolet)](https://github.com/HenriquesLab/napari-NanoPyx/wiki/3.-Methods)
[![Wiki](https://img.shields.io/badge/wiki-click_me-blue)](https://github.com/HenriquesLab/napari-NanoPyx/wiki)

napari plugin of [NanoPyx](https://github.com/HenriquesLab/NanoPyx) (the successor to NanoJ) - focused on light microscopy and super-resolution imaging.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## What is the NanoPyx ð¬ Library?

NanoPyx is a library specialized in the analysis of light microscopy and super-resolution data.
It is a successor to [NanoJ](https://github.com/HenriquesLab/NanoJ-Core), which is a Java library for the analysis of super-resolution microscopy data.

NanoPyx focuses on performance, by heavily exploiting cython aided multiprocessing and simplicity. It implements methods for the bioimage analysis field, with a special emphasis on those developed by the [Henriques Laboratory](https://henriqueslab.github.io/).
It will be distributed as a Python Library and also as [Codeless Jupyter Notebooks](https://github.com/HenriquesLab/NanoPyx#codeless-jupyter-notebooks-available), that can be run locally or on Google Colab, and as a [napari plugin](https://github.com/HenriquesLab/napari-NanoPyx).

You can read more about NanoPyx in our [publication].

Currently it implements the following approaches:
- A reimplementation of the NanoJ image registration, SRRF and Super Resolution metrics
- eSRRF
- Non-local means denoising
- More to come soonâ¢


## Installation

You can install `napari-nanopyx` via [pip]:

    pip install napari-nanopyx

## User Documentation

You can find installation and usage instructions in the [wiki](https://github.com/HenriquesLab/napari-NanoPyx/wiki).

## Contributing

Contributions are very welcome.
Please read our [Contribution Guidelines](https://github.com/HenriquesLab/NanoPyx/blob/main/CONTRIBUTING.md) to know how to proceed.

## License

Distributed under the terms of the [CC-By v4.0] license,
""napari-nanopyx"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[CC-By v4.0]: https://creativecommons.org/licenses/by/4.0/
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[publication]: https://doi.org/10.1038/s41592-024-02562-6

## Citing

If you found this work useful, please cite our [publication].
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU Lesser General Public License v3 (LGPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/HenriquesLab/napari-NanoPyx/issues', 'Documentation, https://github.com/HenriquesLab/napari-NanoPyx/wiki', 'Source Code, https://github.com/HenriquesLab/napari-NanoPyx', 'User Support, https://github.com/HenriquesLab/napari-NanoPyx/issues']",,,napari-nanopyx.benchmark,,,,
300,napari-multitask,napari-multitask,napari-multitask,0.0.2,2021-12-06,2021-12-13,Hanjin Liu,liuhanjin-sc@g.ecc.u-tokyo.ac.jp,BSD 3-Clause,,https://pypi.org/project/napari-multitask/,UNKNOWN,UNKNOWN,Multitasking in napari,>=3.8,['magic-class (>=0.5.11)'],"# napari-multitask

Multitasking on napari.

![](https://github.com/hanjinliu/napari-multitask/raw/main/Figs/output.gif)

Layers and opened dock widgets are stored in the task panels below. Switch your tasks at any time.

# Installation

```
pip install napari-multitask
```


","['Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9']",,,,napari-multitask.TaskView,,,,
301,napari-n2v,napari-n2v,napari n2v,0.1.1,2022-10-24,2023-08-29,"Tom Burke, Joran Deschamps",joran.deschamps@fht.org,BSD-3-Clause,https://github.com/juglab/napari-n2v/issues,https://pypi.org/project/napari-n2v/,,https://github.com/juglab/napari-n2v,A self-supervised denoising algorithm now usable by all in napari.,>=3.8,"['scikit-image', 'bioimageio.core', 'n2v >=0.3.2', 'napari-time-slicer >=0.4.9', 'napari', 'qtpy', 'pyqtgraph', 'tensorflow >=2.10.0 ; platform_system != ""Darwin"" or platform_machine != ""arm64""', 'tensorflow-macos ; platform_system == ""Darwin"" and platform_machine == ""arm64""', 'tensorflow-metal ; platform_system == ""Darwin"" and platform_machine == ""arm64""', 'numpy <1.24.0 ; python_version < ""3.9""', 'numpy ; python_version >= ""3.9""', ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-n2v

[![License](https://img.shields.io/pypi/l/napari-n2v.svg?color=green)](https://github.com/juglab/napari-n2v/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-n2v.svg?color=green)](https://pypi.org/project/napari-n2v)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-n2v.svg?color=green)](https://python.org)
[![tests](https://github.com/juglab/napari-n2v/workflows/build/badge.svg)](https://github.com/juglab/napari-n2v/actions)
[![codecov](https://codecov.io/gh/juglab/napari-n2v/branch/main/graph/badge.svg)](https://codecov.io/gh/juglab/napari-n2v)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-n2v)](https://napari-hub.org/plugins/napari-n2v)

A self-supervised denoising algorithm now usable by all in napari.

<img src=""https://raw.githubusercontent.com/juglab/napari-n2v/master/docs/images/noisy_denoised.png"" width=""800"" />
----------------------------------

## Installation

Check out the [documentation](https://juglab.github.io/napari-n2v/installation.html) for more detailed installation 
instructions. 

You can then start the napari plugin by clicking on ""Plugins > napari_n2v > Training"",
or run the plugin directly from a [script](scripts/start_plugin.py).



## Quick demo

You can try out a demo by loading the `N2V Demo prediction` plugin and directly clicking on `Predict`. This model was trained using the [N2V2 example](https://juglab.github.io/napari-n2v/examples.html).


<img src=""https://raw.githubusercontent.com/juglab/napari-n2v/master/docs/images/demo.gif"" width=""800"" />


## Documentation

Documentation is available on the [project website](https://juglab.github.io/napari-n2v/).


## Contributing and feedback

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request. You can also 
help us improve by [filing an issue] along with a detailed description or contact us
through the [image.sc](https://forum.image.sc/) forum (tag @jdeschamps).


## Citations

### N2V

Alexander Krull, Tim-Oliver Buchholz, and Florian Jug. ""[Noise2void-learning denoising from single noisy images.](https://ieeexplore.ieee.org/document/8954066)"" 
*Proceedings of the IEEE/CVF conference on computer vision and pattern recognition*. 2019.

### structN2V

Coleman Broaddus, et al. ""[Removing structured noise with self-supervised blind-spot networks.](https://ieeexplore.ieee.org/document/9098336)"" *2020 IEEE 17th 
International Symposium on Biomedical Imaging (ISBI)*. IEEE, 2020.

### N2V2

Eva Hoeck, Tim-Oliver Buchholz, et al. ""[N2V2 - Fixing Noise2Void Checkerboard Artifacts with Modified Sampling Strategies and a Tweaked Network Architecture](https://arxiv.org/abs/2211.08512)"", arXiv (2022). 

## Acknowledgements

This plugin was developed thanks to the support of the Silicon Valley Community Foundation (SCVF) and the 
Chan-Zuckerberg Initiative (CZI) with the napari Plugin Accelerator grant _2021-240383_.


Distributed under the terms of the [BSD-3] license,
""napari-n2v"" is a free and open source software.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[filing an issue]: https://github.com/juglab/napari-n2v/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Framework :: napari', 'Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/juglab/napari-n2v/issues', 'Documentation, https://juglab.github.io/napari-n2v/', 'Source Code, https://github.com/juglab/napari-n2v', 'User Support, https://github.com/juglab/napari-n2v/issues']",,,napari-n2v.make_n2v_trainwidget,napari-n2v.data_2D,,,
302,napari-nasa-samples,napari-nasa-samples,NASA sample images,0.0.5,2022-07-12,2022-07-16,Loic A. Royer,royerloic@gmail.com,MPL-2.0,https://github.com/royerloic/napari-nasa-samples/issues,https://pypi.org/project/napari-nasa-samples/,,https://github.com/royerloic/napari-nasa-samples,This napari plugin provides sample datasets from NASA.,>=3.8,"['numpy', 'requests', 'pillow', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-nasa-samples

[![License Mozilla Public License 2.0](https://img.shields.io/pypi/l/napari-nasa-samples.svg?color=green)](https://github.com/royerlab/napari-nasa-samples/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-nasa-samples.svg?color=green)](https://pypi.org/project/napari-nasa-samples)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nasa-samples.svg?color=green)](https://python.org)
[![tests](https://github.com/royerloic/napari-nasa-samples/workflows/tests/badge.svg)](https://github.com/royerlab/napari-nasa-samples/actions)
[![codecov](https://codecov.io/gh/royerloic/napari-nasa-samples/branch/main/graph/badge.svg)](https://codecov.io/gh/royerlab/napari-nasa-samples)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-nasa-samples)](https://napari-hub.org/plugins/napari-nasa-samples)

This napari plugin written [by Loic A. Royer](https://twitter.com/loicaroyer) provides sample datasets from NASA.
In particular, you can access directly from napari the recently released images for the [James Webb Space Telescope](https://webb.nasa.gov/), as well as
some of the classic and most beautiful images obtained by the venerable and still strong [Hubble Space Telescope](https://hubblesite.org/). 
More images will be added over time.

Thanks to (NASA)[https://www.nasa.gov/] for releasing these incredible images!

![](https://github.com/royerloic/napari-nasa-samples/raw/main/docs/images/teaser.gif)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-nasa-samples` via [pip]:

    pip install napari-nasa-samples



To install latest development version :

    pip install git+https://github.com/royerloic/napari-nasa-samples.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Mozilla Public License 2.0] license,
""napari-nasa-samples"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/royerlab/napari-nasa-samples/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/royerloic/napari-nasa-samples/issues', 'Documentation, https://github.com/royerloic/napari-nasa-samples#README.md', 'Source Code, https://github.com/royerloic/napari-nasa-samples', 'User Support, https://github.com/royerloic/napari-nasa-samples/issues']",,,,napari-nasa-samples.messier_101,,,
303,napari-napari,napari-napari,Napari Napari,0.0.1,2023-04-23,2023-04-23,Jordao Bragantini,jordao.bragantini@gmail.com,BSD-3-Clause,https://github.com/jookuma/napari-napari/issues,https://pypi.org/project/napari-napari/,,https://github.com/jookuma/napari-napari,A napari viewer of the napari viewer,>=3.8,"['numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# [napari-napari](https://github.com/jookuma/napari-napari)

[![License BSD-3](https://img.shields.io/pypi/l/napari-napari.svg?color=green)](https://github.com/jookuma/napari-napari/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-napari.svg?color=green)](https://pypi.org/project/napari-napari)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-napari.svg?color=green)](https://python.org)
[![tests](https://github.com/jookuma/napari-napari/workflows/tests/badge.svg)](https://github.com/jookuma/napari-napari/actions)
[![codecov](https://codecov.io/gh/jookuma/napari-napari/branch/main/graph/badge.svg)](https://codecov.io/gh/jookuma/napari-napari)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-napari)](https://napari-hub.org/plugins/napari-napari)

A viewer of the napari viewer.

https://user-images.githubusercontent.com/21022743/233817006-67ab4165-0b9a-46aa-9731-5964448252de.mp4

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-napari` via [pip]:

    pip install napari-napari



To install latest development version :

    pip install git+https://github.com/jookuma/napari-napari.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-napari"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/jookuma/napari-napari/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/jookuma/napari-napari/issues', 'Documentation, https://github.com/jookuma/napari-napari#README.md', 'Source Code, https://github.com/jookuma/napari-napari', 'User Support, https://github.com/jookuma/napari-napari/issues']",,,napari-napari.napari,,,,
304,napari-nd-cropper,napari-nd-cropper,napari-nd-cropper,0.1.3,2022-01-12,2022-01-12,"Marc Boucsein, Robin Koch",,BSD-3-Clause,https://github.com/MBPhys/napari-nd-cropper/issues,https://pypi.org/project/napari-nd-cropper/,,https://github.com/MBPhys/napari-nd-cropper,A napari plugin in order to crop nd-images via different modes,>=3.9,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari-tools-menu', 'qtpy', 'superqt', 'magicgui']","# napari-nd-cropper

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/napari-nd-cropper/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-nd-cropper.svg?color=green)](https://pypi.org/project/napari-nd-cropper)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nd-cropper.svg?color=green)](https://python.org)


A napari plugin in order to crop nd-images via different modes:

- Cropping via Drag&Drop interaction box (available for napari releases > 0.4.12)
- Cropping of double-clicked regions based on predefined size (Integer or Tuple of integer) 
- Cropping based on view 
- Cropping via Sliders 


----------------------------------

## Installation

You can install `napari-nd-cropper` via [pip]:

    pip install napari-nd-cropper

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-nd-cropper"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/napari-nd-cropper/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/MBPhys/napari-nd-cropper/issues', 'Documentation, https://github.com/MBPhys/napari-nd-cropper', 'Source Code, https://github.com/MBPhys/napari-nd-cropper', 'User Support, https://github.com/MBPhys/napari-nd-cropper/issues']",,,napari-nd-cropper.nd_Cropper,,,,
305,napari-nd-annotator,napari-nD-annotator,Annotation Toolbox,0.3.1,2022-06-01,2025-06-20,"David Bauer, Jozsef Molnar, Dominik Hirling",dbauer@brc.hu,BSD-3-Clause,https://github.com/bauerdavid/napari-nD-annotator/issues,https://pypi.org/project/napari-nD-annotator/,,,A toolbox for annotating objects one by one in nD,>=3.8,"['numpy', 'magic-class', 'qtpy', 'opencv-python', 'matplotlib', 'napari>=0.4.11', 'scikit-image>=0.19', 'SimpleITK', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'numpy; extra == ""testing""', 'napari-bbox; extra == ""bbox""', 'minimal-surface; extra == ""ms""', 'napari-bbox; extra == ""all""', 'minimal-surface; extra == ""all""']","# napari-nD-annotator

[![License BSD-3](https://img.shields.io/pypi/l/napari-nD-annotator.svg?color=green)](https://github.com/bauerdavid/napari-nD-annotator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-nD-annotator.svg?color=green)](https://pypi.org/project/napari-nD-annotator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nD-annotator.svg?color=green)](https://python.org)
[![tests](https://github.com/bauerdavid/napari-nD-annotator/workflows/tests/badge.svg)](https://github.com/bauerdavid/napari-nD-annotator/actions)
[![codecov](https://codecov.io/gh/bauerdavid/napari-nD-annotator/branch/main/graph/badge.svg)](https://codecov.io/gh/bauerdavid/napari-nD-annotator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-nD-annotator)](https://napari-hub.org/plugins/napari-nD-annotator)

**A toolbox for annotating objects one by one in nD.**

This plugin contains some tools to make 2D/3D (and technically any dimensional) annotation easier.
Main features:
 * auto-filling labels
 * label slice interpolation (geometric mean, RPSV representation)
 * minimal contour segmentation

If the <code>[napari-bbox]</code> plugin is also installed (see [Installation](#installation)), you can also
 * list objects annotated with bounding boxes 
 * visualize selected objects from different projections

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-nD-annotator` via [pip]:

    pip install napari-nD-annotator

The plugin is also available in [napari-hub], to install it directly from napari, please refer to
[plugin installation instructions] at the official [napari] website.


### Optional packages
There are some functionalities which require additional Python packages.

#### Bounding boxes
The bounding box and object list functionality requires the <code>[napari-bbox]</code> Python package.
If you want to use these features, install <code>[napari-bbox]</code> separately either using [pip] or directly from napari.
You can also install it together with this plugin:
```
pip install napari-nD-annotator[bbox]
```

#### Minimal surface
To use the minimal surface method, you will need the <code>[minimal-surface]</code> Python package as well. Please install it using [pip]:

Separately:
```
pip install minimal-surface
```

Or bundled with the plugin:
```
pip install napari-nD-annotator[ms]
```
> [!WARNING]
> The <code>[minimal-surface]</code> package is only available for Windows at the time. We are actively working on bringing it to Linux and Mac systems as well.

#

If you would like to install all optional packages, use
```
pip install napari-nD-annotator[all]
```
###
If any problems occur during installation or while using the plugin, please [file an issue].

## Usage
You can start napari with the plugin's widgets already opened as:

    napari -w napari-nD-annotator ""Object List"" ""Annotation Toolbox""


### Bounding boxes
The main idea is to create bounding boxes around objects we want to annotate, crop them, and annotate them one by one. This has mainly two advantages when visualizing in 3D:

1. We don't have to load the whole data into memory
2. The surrounding objects won't occlude the annotated ones, making it easier to check the annotation.

Bounding boxes can be created from the `Object list` widget. The dimensionality of the bounding box layer will be determined from the image layer. As bounding boxes are created, a small thumbnail will be displayed.

The proposed pipeline goes as follows:

 1. Create a bounding box layer
 2. Select data parts using the bounding boxes
 3. Select an object from the object list
 4. Annotate the object
 5. Repeat from 3.

### Slice interpolation
The `Interpolation` tab contains tools for estimating missing annotation slices from existing ones. There are multiple options:
 * Geometric: the interpolation will be determined by calculating the average of the corresponding contour points.
 * RPSV: A more sophisticated average contour calculation, see the preprint [here](https://arxiv.org/pdf/1901.02823.pdf).
 * Distance-based: a signed distance transform is applied to the annotations. The missing slices will be filled in using their 
weighted sum.

> **Note**: Geometric and RPSV interpolation works only when there's a single connected mask on each slice. If you want to 
> interpolate disjoint objects (*e.g.* dividing cells), use distance based interpolation instead.

> **Note**: Distance-based interpolation might give bad results if some masks are too far away from each other on the same slice
> and there's a big offset compared to the other slice used in the interpolation. If you get unsatisfactory results, try
> annotating more slices (skip less frames).

https://user-images.githubusercontent.com/36735863/188876826-1771acee-93ba-4905-982e-bfb459329659.mp4

### Minimal contour
This plugin can estimate a minimal contour, which is calculated from a point set on the edges of the object, which are provided by the user. This contour will follow some kind of image feature (pixels with high gradient or high/low intensity).
Features:
 * With a single click a new point can be added to the set. This will also extend the contour with the curve shown in red
 * A double click will close the curve by adding both the red and gray curves to the minimal contour
 * When holding `Shift`, the gray and red highlight will be swapped, so the other curve can be added to the contour
 * With the `Ctrl` button down a straight line can be added instead of the minimal path
 * If the anchor points were misplaced, the last point can be removed by right-clicking, or the whole point set can be cleared by pressing `Esc`
 * The `Param` value at the widget will decide, how strongly should the contour follow edges on the image. Higher value means higher sensitivity to image data, while a lower value will be closer to straight lines.
 * Different features can be used, like image gradient or pixel intensities, and also user-defined features (using Python)
   * the image is accessed as the `image` variable, and the features should be stored in the `features` variable in the small code editor widget

This functionality can be used by selecting the `Minimal Contour` tab in the `Annotation Toolbox` widget, which will create a new layer called `Anchors`.

> **Warning**: Do not remove the `Anchors` layer!

> **Warning**: Some utility layers appear in the layer list when using the plugin. These are marked with a lock (:lock:) symbol.
> __Do not remove them or modify their data, as this will most probably break the plugin!__ However, you can change their appearance,
> *e.g.* their color settings.

#### Intensity-based:

https://user-images.githubusercontent.com/36735863/191023482-0dfafb5c-003a-47f6-a21b-8582a4e3930f.mp4

#### Gradient-based:

https://user-images.githubusercontent.com/36735863/191024941-f20f63a0-8281-47d2-be22-d1ec34fe1f5d.mp4

#### Custom feature:

https://user-images.githubusercontent.com/36735863/191025028-3f807bd2-1f2e-40d2-800b-48af820a7dbe.mp4

### Shortcuts

| Action                                        | Mouse               | Keyboard       |
|-----------------------------------------------|---------------------|----------------|
| Increment selected label                      | `Shift + Wheel â¬ï¸`  | `E`            |
| Decrement selected label                      | `Shift + Wheel â¬ï¸`  | `Q`            |
| Previous slice                                | `Ctrl + Wheel â¬ï¸`\* | `A`            |
| Next slice                                    | `Ctrl + Wheel â¬ï¸`\* | `D`            |
| Increase paint brush size of labels layer     | `Alt + Wheel â¬ï¸`    | `W`            |
| Decrease paint brush size of labels layer     | `Alt + Wheel â¬ï¸`    | `S`            |
| Interpolate                                   | -                   | `Ctrl+I`       |
| Change between 'Anchors' and the labels layer | -                   | `Ctrl+Tab`     |
| Jump to layer `#i`                            | -                   | `Ctrl+'i'`\*\* |

> *Built-in functionality of [napari]
> 
> **`i`: 0-9

> **Note**: you can check the list of available shortcuts by clicking the `?` button in the bottom right corner of the main widget.

## License

Distributed under the terms of the [BSD-3] license,
""napari-nD-annotator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[napari-hub]: https://napari-hub.org/
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[plugin installation instructions]: https://napari.org/plugins/find_and_install_plugin.html
[file an issue]: https://github.com/bauerdavid/napari-nD-annotator/issues/new/choose
[napari-bbox]: https://github.com/bauerdavid/napari-bbox
[minimal-surface]: https://pypi.org/project/minimal-surface
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: C', 'Programming Language :: Cython', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Programming Language :: Python :: Implementation :: CPython', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/bauerdavid/napari-nD-annotator/issues', 'Documentation, https://github.com/bauerdavid/napari-nD-annotator/blob/main/README.md', 'Source Code, https://github.com/bauerdavid/napari-nD-annotator', 'User Support, https://github.com/bauerdavid/napari-nD-annotator/issues']",,,napari-nD-annotator.annotator_widget,,,,
306,napari-nd2-folder-viewer,napari-nd2-folder-viewer,napari nd2 folder viewer,0.0.13,2022-08-02,2023-02-01,Niklas Netter,niknett@gmail.com,BSD-3-Clause,https://github.com/gatoniel/napari-nd2-folder-viewer/issues,https://pypi.org/project/napari-nd2-folder-viewer/,,https://github.com/gatoniel/napari-nd2-folder-viewer,Look through separate nd2 files in one viewer.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'pyyaml', 'marshmallow', 'desert', 'nd2 (>=0.4.3)', 'dask', 'pandas', 'openpyxl', 'julian', 'napari-animation', 'scikit-learn', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-nd2-folder-viewer

[![License BSD-3](https://img.shields.io/pypi/l/napari-nd2-folder-viewer.svg?color=green)](https://github.com/gatoniel/napari-nd2-folder-viewer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-nd2-folder-viewer.svg?color=green)](https://pypi.org/project/napari-nd2-folder-viewer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nd2-folder-viewer.svg?color=green)](https://python.org)
[![tests](https://github.com/gatoniel/napari-nd2-folder-viewer/workflows/tests/badge.svg)](https://github.com/gatoniel/napari-nd2-folder-viewer/actions)
[![codecov](https://codecov.io/gh/gatoniel/napari-nd2-folder-viewer/branch/main/graph/badge.svg)](https://codecov.io/gh/gatoniel/napari-nd2-folder-viewer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-nd2-folder-viewer)](https://napari-hub.org/plugins/napari-nd2-folder-viewer)

Look through separate nd2 files in one viewer.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-nd2-folder-viewer` via [pip]:

    pip install napari-nd2-folder-viewer



To install latest development version :

    pip install git+https://github.com/gatoniel/napari-nd2-folder-viewer.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-nd2-folder-viewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/gatoniel/napari-nd2-folder-viewer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/gatoniel/napari-nd2-folder-viewer/issues', 'Documentation, https://github.com/gatoniel/napari-nd2-folder-viewer#README.md', 'Source Code, https://github.com/gatoniel/napari-nd2-folder-viewer', 'User Support, https://github.com/gatoniel/napari-nd2-folder-viewer/issues']",,,napari-nd2-folder-viewer.make_qwidget,,,,
307,napari-nibabel,napari-nibabel,Napari NiBabel,0.1.0,2023-02-10,2023-02-10,Ashley Anderson,aandersoniii@chanzuckerberg.com,MIT,,https://pypi.org/project/napari-nibabel/,None,,Read access to some common neuroimaging file formats,>=3.8,"['numpy', 'nibabel[dicom,dicomfs,spm]', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-nibabel

[![License MIT](https://img.shields.io/pypi/l/napari-nibabel.svg?color=green)](https://github.com/aganders3/napari-nibabel/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-nibabel.svg?color=green)](https://pypi.org/project/napari-nibabel)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nibabel.svg?color=green)](https://python.org)
[![tests](https://github.com/aganders3/napari-nibabel/workflows/tests/badge.svg)](https://github.com/aganders3/napari-nibabel/actions)
[![codecov](https://codecov.io/gh/aganders3/napari-nibabel/branch/main/graph/badge.svg)](https://codecov.io/gh/aganders3/napari-nibabel)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-nibabel)](https://napari-hub.org/plugins/napari-nibabel)

Read access to some common neuroimaging file formats, thanks to the
[NiBabel](https://nipy.org/nibabel/) and [pydicom](https://pydicom.github.io/)
libraries.

Also check out [napari-medical-image-formats](https://www.napari-hub.org/plugins/napari-medical-image-formats)!

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


## Installation

You can install `napari-nibabel` via [pip]:

    pip install napari-nibabel


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-nibabel"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-nibabel.get_reader,,,,"['*.par', '*.hdr', '*.nii', '*.nii.gz', '*.gii', '*.dcm']",,
308,napari-ndev,napari-ndev,nDev,0.11.6,2023-01-31,2025-05-09,Tim Monko,Tim Monko <timmonko@gmail.com>,BSD-3-Clause,https://github.com/TimMonko/napari-ndev,https://pypi.org/project/napari-ndev/,,,napari widgets to (batch) process images from start to finish.,>=3.9,"['numpy<2.0,>=1.26', 'siphash24>=1.6', 'magicgui>=0.8.3', 'magic-class', 'napari[optional]>=0.4.19', 'apoc', 'pyclesperanto-prototype', 'pyclesperanto', 'dask', 'napari-workflows', 'napari-pyclesperanto-assistant', 'napari-segment-blobs-and-things-with-membranes', 'natsort', 'seaborn', 'stackview', 'tifffile<2025.2.18,>=2023.3.15', 'scikit-image>=0.18.0', 'ngff-zarr>0.10.0', 'zarr<3', 'bioio>=1.1.0', 'bioio-base==1.0.4', 'bioio-imageio>=1', 'bioio-tifffile>=1', 'bioio-ome-tiff>=1', 'bioio-ome-zarr>=1', 'bioio-nd2>=1', 'matplotlib-scalebar>=0.8.1', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'tox; extra == ""testing""', 'tox-uv; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari[all]; extra == ""testing""', 'pyqt5; extra == ""testing""', 'bioio-czi>=1.0.1; extra == ""testing""', 'napari-ndev[extras]; extra == ""testing""', 'mkdocs; extra == ""docs""', 'mkdocs-autorefs; extra == ""docs""', 'mkdocs-material; extra == ""docs""', 'mkdocstrings; extra == ""docs""', 'mkdocstrings-python; extra == ""docs""', 'mkdocs-jupyter; extra == ""docs""', 'mkdocs-pdf; extra == ""docs""', 'mkdocs-spellcheck[all]; extra == ""docs""', 'mkdocs-literate-nav; extra == ""docs""', 'mkdocs-table-reader-plugin; extra == ""docs""', 'black; extra == ""docs""', 'ruff; extra == ""dev""', 'pre-commit; extra == ""dev""', 'napari-ndev[testing]; extra == ""dev""', 'napari-ndev[docs]; extra == ""dev""', 'napari-ndev[pyqt6]; extra == ""qtpy-backend""', 'napari[pyqt6]; extra == ""pyqt6""', 'napari[pyqt5]; extra == ""pyqt5""', 'napari[pyside]; extra == ""pyside""', 'napari-simpleitk-image-processing; extra == ""extras""', 'bioio-czi>=1.0.1; extra == ""gpl-extras""', 'bioio-lif>=1; extra == ""gpl-extras""', 'napari-ndev[qtpy-backend]; extra == ""all""', 'napari-ndev[extras]; extra == ""all""', 'napari-ndev[gpl_extras]; extra == ""all""']","# napari-ndev

[![License BSD-3](https://img.shields.io/pypi/l/napari-ndev.svg?color=green)](https://github.com/TimMonko/napari-ndev/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-ndev.svg?color=green)](https://pypi.org/project/napari-ndev)
[![Python package index download statistics](https://img.shields.io/pypi/dm/napari-ndev.svg)](https://pypistats.org/packages/napari-ndev)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-ndev.svg?color=green)](https://python.org)
[![tests](https://github.com/TimMonko/napari-ndev/workflows/tests/badge.svg)](https://github.com/TimMonko/napari-ndev/actions)
[![codecov](https://codecov.io/gh/TimMonko/napari-ndev/branch/main/graph/badge.svg)](https://codecov.io/gh/TimMonko/napari-ndev)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-ndev)](https://napari-hub.org/plugins/napari-ndev)
![Static Badge](https://img.shields.io/badge/plugin-npe2-brightgreen?style=flat-square&label=plugin)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.14787853.svg)](https://doi.org/10.5281/zenodo.14787853)

<img src=""./resources/nDev-logo-large.png"" alt=""logo"" width=""400"" style=""display: block; margin: auto;"">

A collection of widgets intended to serve any person seeking to process microscopy images from start to finish, *with no coding necessary*. `napari-ndev` was designed to address the **gap between the napari viewer and batch python scripting**.

* Accepts **diverse image formats**, dimensionality, file size, and maintains key metadata.
* Allows **advanced, arbitrary image processing** workflows to be used by novices.
* **User-friendly** sparse annotation and batch training of **machine learning classifiers**.
* Flexible label measurements, parsing of metadata, and summarization for **easily readable datasets**.
* Designed for ease of use, modification, and reproducibility.

## [Check out the Docs to learn more!](https://timmonko.github.io/napari-ndev/)

### See the [poster presented at BINA 2024](https://timmonko.github.io/napari-ndev/BINA_poster/) for an overview of the plugins in action

### Try out the [Virtual I2K 2024 Workshop](https://timmonko.github.io/napari-ndev/tutorial/00_setup/) for an interactive tutorial

## Installation

**napari-ndev** is a pure Python package, and can be installed with [pip]:

```bash
pip install napari-ndev
```

If napari is currently not installed in your environment, you will also need to include a QtPy backend:

```bash
pip install napari-ndev[qtpy-backend]
```

The easiest way to get started with **napari-ndev** is to install all the optional dependencies (see note below) with:

```bash
pip install napari-ndev[all]
```

----------------------------------

### Optional Libraries

**napari-ndev** is most useful when interacting with some other napari plugins (e.g. napari-assistant) and can read additional filetypes. A few extra BSD3 compatible napari-plugins may be installed with [pip]:

```bash
pip install napari-ndev[extras]
```

**napari-ndev** can optionally use GPL-3 licensed libraries to enhance its functionality, but are not required. If you choose to install and use these optional dependencies, you must comply with the GPL-3 license terms. The main functional improvement is from some `bioio` libraries to support extra image formats, including `czi` and `lif` files. These libraries can be installed with [pip]:

```bash
pip install napari-ndev[gpl-extras]
```

In addition, you may need to install specific [`bioio` readers](https://github.com/bioio-devs/bioio) to support your specific image, such as `bioio-czi` and `bioio-lif` (included in `[gpl-extras]`) or `bioio-bioformats`.

### Development Libraries

For development use the `[dev]` optional libraries to verify your changes, which includes the `[docs]` and `[testing]` optional groups. However, the Github-CI will test pull requests with `[testing]` only.

----------------------------------

The wide breadth of this plugin's scope is only made possible by the amazing libraries and plugins from the python and napari community, especially [Robert Haase](https://github.com/haesleinhuepf).

This [napari] plugin was generated with [Cookiecutter] using [napari]'s [cookiecutter-napari-plugin] template.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-ndev"" is free and open source software.

Some optional libraries can be installed to add functionality to `napari-ndev`, including some that may be more restrictive than this package's BSD-3-Clause.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Education', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Software Development :: User Interfaces', 'Topic :: Software Development :: Libraries :: Python Modules', 'Topic :: Utilities']","['Bug Tracker, https://github.com/TimMonko/napari-ndev/issues', 'Documentation, https://timmonko.github.io/napari-ndev/', 'Source Code, https://github.com/TimMonko/napari-ndev']",napari-ndev.get_reader,,napari-ndev.make_ndev_container,,"['*.1sc', '*.2fl', '*.3fr', '*.acff', '*.acqp', '*.afi', '*.afm', '*.aim', '*.al3d', '*.ali', '*.am', '*.amiramesh', '*.ano', '*.apl', '*.arf', '*.array-like', '*.arw', '*.avi', '*.bay', '*.bif', '*.bin', '*.bip', '*.bmp', '*.bmq', '*.bsdf', '*.bufr', '*.bw', '*.c01', '*.cap', '*.cat', '*.cfg', '*.ch5', '*.cif', '*.cine', '*.cr2', '*.crw', '*.cs1', '*.csv', '*.ct', '*.ct.img', '*.cur', '*.cut', '*.cxd', '*.czi', '*.dat', '*.db', '*.dc2', '*.dcm', '*.dcr', '*.dcx', '*.dds', '*.df3', '*.dicom', '*.dm2', '*.dm3', '*.dng', '*.drf', '*.dsc', '*.dti', '*.dv', '*.ecw', '*.emf', '*.eps', '*.epsi', '*.erf', '*.exp', '*.exr', '*.fake', '*.fdf', '*.fff', '*.ffr', '*.fid', '*.fit', '*.fits', '*.flc', '*.flex', '*.fli', '*.fpx', '*.frm', '*.ftc', '*.fts', '*.ftu', '*.fz', '*.g3', '*.gbr', '*.gdcm', '*.gel', '*.gif', '*.gipl', '*.grey', '*.grib', '*.h5', '*.hdf', '*.hdf5', '*.hdp', '*.hdr', '*.hed', '*.his', '*.htd', '*.htm', '*.html', '*.hx', '*.i2i', '*.ia', '*.icns', '*.ico', '*.ics', '*.ids', '*.iff', '*.iim', '*.iiq', '*.im', '*.im3', '*.img', '*.imggz', '*.ims', '*.inf', '*.inr', '*.ipl', '*.ipm', '*.ipw', '*.j2c', '*.j2k', '*.jfif', '*.jif', '*.jng', '*.jp2', '*.jpc', '*.jpe', '*.jpeg', '*.jpf', '*.jpg', '*.jpk', '*.jpx', '*.jxr', '*.k25', '*.kc2', '*.kdc', '*.klb', '*.koa', '*.l2d', '*.labels', '*.lbm', '*.lei', '*.lfp', '*.lfr', '*.lif', '*.liff', '*.lim', '*.lms', '*.lsm', '*.mdb', '*.mdc', '*.mef', '*.mgh', '*.mha', '*.mhd', '*.mic', '*.mkv', '*.mnc', '*.mnc2', '*.mng', '*.mod', '*.mos', '*.mov', '*.mp4', '*.mpeg', '*.mpg', '*.mpo', '*.mrc', '*.mri', '*.mrw', '*.msp', '*.msr', '*.mtb', '*.mvd2', '*.naf', '*.nd', '*.nd2', '*.ndpi', '*.ndpis', '*.nef', '*.nhdr', '*.nia', '*.nii', '*.nii.gz', '*.niigz', '*.npz', '*.nrrd', '*.nrw', '*.obf', '*.oib', '*.oif', '*.oir', '*.ome', '*.ome.tif', '*.ome.tiff', '*.orf', '*.par', '*.pbm', '*.pcd', '*.pcoraw', '*.pct', '*.pcx', '*.pef', '*.pfm', '*.pgm', '*.pic', '*.pict', '*.png', '*.pnl', '*.ppm', '*.pr3', '*.ps', '*.psd', '*.ptx', '*.pxn', '*.pxr', '*.qptiff', '*.qtk', '*.r3d', '*.raf', '*.ras', '*.raw', '*.rcpnl', '*.rdc', '*.rec', '*.rgb', '*.rgba', '*.rw2', '*.rwl', '*.rwz', '*.scan', '*.scn', '*.sdt', '*.seq', '*.sif', '*.sld', '*.sm2', '*.sm3', '*.spc', '*.spe', '*.spi', '*.sr2', '*.srf', '*.srw', '*.st', '*.sti', '*.stk', '*.stp', '*.svs', '*.swf', '*.sxm', '*.targa', '*.tfr', '*.tga', '*.thm', '*.tif', '*.tiff', '*.tim', '*.tnb', '*.top', '*.txt', '*.v', '*.vff', '*.vms', '*.vsi', '*.vtk', '*.vws', '*.wap', '*.wat', '*.wav', '*.wbm', '*.wbmp', '*.wdp', '*.webp', '*.wlz', '*.wmf', '*.wmv', '*.wpi', '*.xbm', '*.xdce', '*.xml', '*.xpm', '*.xqd', '*.xqf', '*.xv', '*.xys', '*.zfp', '*.zfr', '*.zip', '*.zpo', '*.zvi']",,
309,napari-nifti-viewer,napari-nifti-viewer,NIfTI Viewer,0.1.2,2025-06-28,2025-06-28,Yohanchiu,Yohanchiu <qyhohh@163.com>,MIT,https://github.com/yohanchiu/napari-nifti-viewer/blob/main/CHANGELOG.md,https://pypi.org/project/napari-nifti-viewer/,,https://github.com/yohanchiu/napari-nifti-viewer,A comprehensive napari plugin for NIfTI file analysis and visualization,>=3.8,"['napari>=0.4.18', 'numpy>=1.21.0', 'nibabel>=5.2.1', 'qtpy>=2.0.0', 'magicgui>=0.7.0', 'pytest>=7.0; extra == ""dev""', 'pytest-cov; extra == ""dev""', 'black; extra == ""dev""', 'isort; extra == ""dev""', 'flake8; extra == ""dev""', 'pre-commit; extra == ""dev""', 'pytest>=7.0; extra == ""test""', 'pytest-cov; extra == ""test""']","# napari-nifti-viewer

A powerful napari plugin for comprehensive NIfTI file analysis and visualization.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-nifti-viewer)](https://napari-hub.org/plugins/napari-nifti-viewer)

## Overview

napari-nifti-viewer is a comprehensive napari plugin specifically designed for reading, analyzing, and visualizing NIfTI (.nii/.nii.gz) files. It provides detailed metadata extraction, intelligent label detection, and seamless integration with napari's visualization capabilities.

## Features

### ð **Complete NIfTI Support**
- Read .nii and .nii.gz format files
- Support for NIfTI-1 standard
- Compatible with both image and label data

### ð **Comprehensive Metadata Analysis**
- Extract complete NIfTI header information (40+ fields)
- Display affine transformation matrices
- Show coordinate system information
- Analyze voxel spacing and orientation

### ð·ï¸ **Intelligent Label Detection**
- Automatic label image detection
- Statistical analysis of label distributions
- Label value counting and percentage calculations

### ð **Data Statistics**
- Complete data shape and type information
- Statistical measures (min, max, mean, std)
- Non-zero voxel counting
- Unique value analysis

### ð¾ **Export Capabilities**
- Export complete metadata as JSON
- Preserve all numerical precision
- Human-readable format

### ð¨ **User-Friendly Interface**
- Clean, organized tabbed interface
- Real-time data loading
- Seamless napari integration

## Interface

The plugin provides a clean, organized interface with three main tabs:

### ð File Overview Tab
Displays basic file information and data statistics including file size, format, data shape, and statistical measures.

### ð Detailed Information Tab  
Shows complete NIfTI header fields and metadata in an organized table format, alongside full JSON metadata export.

### ð·ï¸ Label Analysis Tab
Provides intelligent label detection and statistical analysis with automatic identification of label images and distribution analysis.

## Installation

### From PyPI (Recommended)
```bash
pip install napari-nifti-viewer
```

### From Source
```bash
git clone https://github.com/yohanchiu/napari-nifti-viewer.git
cd napari-nifti-viewer
pip install -e .
```

## Quick Start

1. **Launch napari** with the plugin installed
2. **Open the plugin** from the Plugins menu â napari-nifti-viewer
3. **Load a file** by clicking ""Browse..."" and selecting a .nii/.nii.gz file
4. **Explore the data** across three informative tabs:
   - **File Overview**: Basic information and statistics
   - **Detailed Info**: Complete NIfTI headers and metadata
   - **Label Analysis**: Label detection and analysis
5. **Visualize in napari** by clicking ""Load to Napari""

## Usage Examples

### Loading a Medical Image
```python
import napari
from napari_nifti_viewer import NiftiViewerWidget

# Create napari viewer
viewer = napari.Viewer()

# The plugin will be available in the Plugins menu
# Or you can add it programmatically:
widget = NiftiViewerWidget(viewer)
viewer.window.add_dock_widget(widget, name=""NIfTI Viewer"")
```

### Exporting Metadata
The plugin allows you to export complete metadata including:
- File information (size, format, version)
- NIfTI header fields (all 40+ standard fields)
- Data statistics (shape, type, value ranges)
- Coordinate system information
- Affine transformation matrices

## Requirements

- **napari** >= 0.4.18
- **nibabel** >= 5.2.1
- **numpy** >= 1.21.0
- **qtpy** >= 2.0.0
- **magicgui** >= 0.7.0
- **Python** >= 3.8

## Supported File Formats

- `.nii` - Uncompressed NIfTI files
- `.nii.gz` - Compressed NIfTI files
- Compatible with NIfTI-1 standard
- Support for both neuroimaging and medical imaging data

## Development

### Setting up Development Environment

```bash
# Clone the repository
git clone https://github.com/yohanchiu/napari-nifti-viewer.git
cd napari-nifti-viewer

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install in development mode
pip install -e "".[dev]""

# Run tests
python -m pytest
```

### Running Tests

```bash
# Basic functionality test
python test_plugin.py

# Test with napari interface
python test_plugin.py --napari
```

## Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Ways to Contribute
- ð Report bugs
- ð¡ Suggest new features
- ð Improve documentation
- ð§ Submit pull requests

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Citation

If you use this plugin in your research, please consider citing:

```bibtex
@software{napari_nifti_viewer,
  title={napari-nifti-viewer: Comprehensive NIfTI Analysis for napari},
  author={Qiu Yuheng},
  year={2024},
  url={https://github.com/yohanchiu/napari-nifti-viewer}
}
```

## Acknowledgments

- Built with [napari](https://napari.org/) - a fast, interactive, multi-dimensional image viewer
- Uses [nibabel](https://nipy.org/nibabel/) for NIfTI file handling
- Inspired by the neuroimaging and medical imaging communities

## Support

- ð [Documentation](https://github.com/yohanchiu/napari-nifti-viewer/wiki)
- ð [Issue Tracker](https://github.com/yohanchiu/napari-nifti-viewer/issues)
- ð¬ [Discussions](https://github.com/yohanchiu/napari-nifti-viewer/discussions)

---

Made with â¤ï¸ for the napari and neuroimaging communities 
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Science/Research', 'Intended Audience :: Healthcare Industry', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Medical Science Apps.', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Software Development :: Libraries :: Python Modules']","['Homepage, https://github.com/yohanchiu/napari-nifti-viewer', 'Bug Tracker, https://github.com/yohanchiu/napari-nifti-viewer/issues', 'Documentation, https://github.com/yohanchiu/napari-nifti-viewer/wiki', 'Source Code, https://github.com/yohanchiu/napari-nifti-viewer', 'Changelog, https://github.com/yohanchiu/napari-nifti-viewer/blob/main/CHANGELOG.md']",,,napari-nifti-viewer.make_widget,,,,
310,napari-ndtiffs,napari-ndtiffs,napari-ndtiffs,0.2.1,2021-06-24,2023-03-29,Talley Lambert,Talley Lambert <talley.lambert@gmail.com>,BSD-3-Clause,https://github.com/tlambert03/napari-ndtiffs/issues,https://pypi.org/project/napari-ndtiffs/,,,napari plugin for nd tiff folders with OpenCl deskew,>=3.8,"['dask[array]', 'napari-plugin-engine>=0.1.4', 'numpy', 'python-dateutil', 'scipy', 'tifffile', ""black; extra == 'dev'"", ""ipython; extra == 'dev'"", ""mypy; extra == 'dev'"", ""pdbpp; extra == 'dev'"", ""rich; extra == 'dev'"", ""ruff; extra == 'dev'"", ""pyopencl; extra == 'opencl'"", ""pyopencl; extra == 'test'"", ""pytest; extra == 'test'"", ""pytest-cov; extra == 'test'""]","# napari-ndtiffs

[![License](https://img.shields.io/pypi/l/napari-ndtiffs.svg?color=green)](https://raw.githubusercontent.com/tlambert03/napari-ndtiffs/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-ndtiffs.svg?color=green)](https://pypi.org/project/napari-ndtiffs)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-ndtiffs.svg?color=green)](https://python.org)
[![tests](https://github.com/tlambert03/napari-ndtiffs/workflows/tests/badge.svg)](https://github.com/tlambert03/napari-ndtiffs/actions)
[![codecov](https://codecov.io/gh/tlambert03/napari-ndtiffs/branch/main/graph/badge.svg)](https://codecov.io/gh/tlambert03/napari-ndtiffs)

napari plugin for nd tiff folders with optional CUDA or OpenCL-based deskewing.

Built-in support for folders of (skewed) lattice light sheet tiffs.

![napari-ndtiffs demo](https://github.com/tlambert03/napari-ndtiffs/raw/main/demo.gif)

----------------------------------

*This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.*

## Features

- Drag and drop a folder of tiffs onto napari window to view easily 
  - (currently designed to detect  lattice light sheet tiffs, but easily
    adjustable)
- If lattice `Settings.txt` file is found, will deskew automatically (only if
  necessary)
- Lazily loads dataset on demand.  quickly load preview your data.
- Handles `.zip` archives as well!  Just directly compress your tiff folder,
  then drop it into napari.
- All OpenCL deskewing, works on GPU as well as CPU, falls back to scipy if
  [PyOpenCL] is unavailable.
- CuPy-based deskewing will work for cards with NVIDIA GPUs that support CUDA.
  CuPy 8.x releases should work, although CuPy >= 9 is recommended. If [CuPy]
  is unavailable, the [PyOpenCL] implementation is used instead.

It would not be hard to support arbitrary filenaming patterns!  If you have a
folder of tiffs with a consistent naming scheme and would like to take advantage
of this plugin, feel free to open an issue!

## Installation

You can install `napari-ndtiffs` via [pip]:

```shell
pip install napari-ndtiffs
```

To also install PyOpenCL (for faster deskewing):

```shell
pip install napari-ndtiffs[opencl]
```

On NVIDIA GPUs with CUDA support, the [CuPy] implementation may be faster than
[PyOpenCL]. CuPy also has experimental support for AMD GPUs via HIP/ROCm. See
the CuPy [installation instructions](https://docs.cupy.dev/en/stable/install.html)


## Usage

In most cases, just drop your folder onto napari, or use `viewer.open(""path"")`

### Overriding parameters

You can control things like voxel size and deskewing angle as follows:

```python
from napari_ndtiffs import parameter_override
import napari

viewer = napari.Viewer()
with parameter_override(angle=45, name=""my image""):
    viewer.open(""path/to/folder"", plugin=""ndtiffs"")
```

Valid keys for `parameter_override` include:

- **dx**: (`float`) the pixel size, in microns
- **dz**: (`float`)the z step size, in microns
- **deskew**: (`bool`) whether or not to deskew, (by default, will deskew if angle > 0, or if a lattice metadata file is detected that requires deskewing) 
- **angle**: (`float`) the angle of the light sheet relative to the coverslip
- **padval**: (`float`) the value with which to pad the image edges when deskewing (default is 0)
- **contrast_limits**: (`2-tuple of int`) (min, max) contrast_limits to use when viewing the image
- **name**: (`str`) an optional name for the image

### Sample data

Try it out with test data: [download sample data](https://www.dropbox.com/s/up4ywrn2sckjunc/lls_mitosis.zip?dl=1)

You can unzip if you like, or just drag the zip file onto the napari window.

Or, from command line, use:

```bash
napari path/to/lls_mitosis.zip
```

## Debugging

To monitor file io and deskew activity, enter the following in the napari console:

```python
import logging
logging.getLogger('napari_ndtiffs').setLevel('DEBUG')
```


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-ndtiffs"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/tlambert03/napari-ndtiffs/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[PyOpenCL]: https://documen.tician.de/pyopencl/
[CuPy]: https://docs.cupy.dev/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10']","['Bug Tracker, https://github.com/tlambert03/napari-ndtiffs/issues', 'Documentation, https://github.com/tlambert03/napari-ndtiffs#README.md', 'Source Code, https://github.com/tlambert03/napari-ndtiffs', 'User Support, https://github.com/tlambert03/napari-ndtiffs/issues']",napari-ndtiffs.get_reader,,,,['*'],,
311,napari-nifti,napari-nifti,napari-nifti,0.0.17,2023-04-18,2024-11-18,Karol Gotkowski,karol.gotkowski@dkfz.de,Apache-2.0,https://github.com/MIC-DKFZ/napari-nifti/issues,https://pypi.org/project/napari-nifti/,,https://github.com/MIC-DKFZ/napari-nifti,A napari plugin for reading and writing NIFTI files that have the extension .nii or .nii.gz.,>=3.8,"['medvol', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""']","# napari-nifti

[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-nifti.svg?color=green)](https://github.com/MIC-DKFZ/napari-nifti/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-nifti.svg?color=green)](https://pypi.org/project/napari-nifti)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nifti.svg?color=green)](https://python.org)
[![tests](https://github.com/MIC-DKFZ/napari-nifti/workflows/tests/badge.svg)](https://github.com/MIC-DKFZ/napari-nifti/actions)
[![codecov](https://codecov.io/gh/MIC-DKFZ/napari-nifti/branch/main/graph/badge.svg)](https://codecov.io/gh/MIC-DKFZ/napari-nifti)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-nifti)](https://napari-hub.org/plugins/napari-nifti)

A napari plugin for reading and writing NIFTI files that have the extension .nii or .nii.gz.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-nifti` via [pip]:

    pip install napari-nifti



To install latest development version :

    pip install git+https://github.com/MIC-DKFZ/napari-nifti.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-nifti"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/MIC-DKFZ/napari-nifti/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

# Acknowledgements
<img src=""HI_Logo.png"" height=""100px"" />

<img src=""dkfz_logo.png"" height=""100px"" />

napari-nifti is developed and maintained by the Applied Computer Vision Lab (ACVL) of [Helmholtz Imaging](http://helmholtz-imaging.de) 
and the [Division of Medical Image Computing](https://www.dkfz.de/en/mic/index.php) at the 
[German Cancer Research Center (DKFZ)](https://www.dkfz.de/en/index.html).
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/MIC-DKFZ/napari-nifti/issues', 'Documentation, https://github.com/MIC-DKFZ/napari-nifti#README.md', 'Source Code, https://github.com/MIC-DKFZ/napari-nifti', 'User Support, https://github.com/MIC-DKFZ/napari-nifti/issues']",napari-nifti.get_reader,napari-nifti.write_single_image,,,"['*.gz', '*.nii', '*.nii.gz', '*.nrrd']","['.gz', '.nii', '.nii.gz', '.nrrd']","['.gz', '.nii', '.nii.gz', '.nrrd']"
312,napari-nninteractive,napari-nninteractive,nnInteractive,1.0.5,2025-03-11,2025-07-30,"Lars KrÃ¤mer, Fabian Isensee, Maximilian Rokuss","lars.kraemer@dkfz-heidelberg.de, f.isensee@dkfz-heidelberg.de, maximilian.rokuss@dkfz-heidelberg.de","Apache License
               ...",https://github.com/MIC-DKFZ/napari-nninteractive,https://pypi.org/project/napari-nninteractive/,,,nnInteractive plugin for Napari,>=3.10,"['torch', 'numpy', 'qtpy', 'napari-nifti', 'huggingface_hub', 'hf_transfer', 'nnInteractive>=1.0.0', 'napari_toolkit', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","<img src=""https://github.com/MIC-DKFZ/napari-nninteractive/raw/main/imgs/nnInteractive_header.png""  width=""1200"">

# nnInteractive: Redefining 3D Promptable Segmentation

This repository contains the napari plugin for nnInteractive. Check out the
[python backend](https://github.com/MIC-DKFZ/nnInteractive) and [MITK integration](https://www.mitk.org/MITK-nnInteractive) for more.

## What is nnInteractive?

> Isensee, F.\*, Rokuss, M.\*, KrÃ¤mer, L.\*, Dinkelacker, S., Ravindran, A., Stritzke, F., Hamm, B., Wald, T., Langenberg, M., Ulrich, C., Deissler, J., Floca, R., & Maier-Hein, K. (2025). nnInteractive: Redefining 3D Promptable Segmentation. https://arxiv.org/abs/2503.08373 \
> \*: equal contribution

Link: [![arXiv](https://img.shields.io/badge/arXiv-2503.08373-b31b1b.svg)](https://arxiv.org/abs/2503.08373)

##### Abstract:

Accurate and efficient 3D segmentation is essential for both clinical and research applications.
While foundation models like SAM have revolutionized interactive segmentation, their 2D design and domain shift limitations make them ill-suited for 3D medical images.
Current adaptations address some of these challenges but remain limited, either lacking volumetric awareness, offering restricted interactivity, or supporting only a small set of structures and modalities.
Usability also remains a challenge, as current tools are rarely integrated into established imaging platforms and often rely on cumbersome web-based interfaces with restricted functionality.
We introduce nnInteractive, the first comprehensive 3D interactive open-set segmentation method.
It supports diverse promptsâincluding points, scribbles, boxes, and a novel lasso promptâwhile leveraging intuitive 2D interactions to generate full 3D segmentations.
Trained on 120+ diverse volumetric 3D datasets (CT, MRI, PET, 3D Microscopy, etc.), nnInteractive sets a new state-of-the-art in accuracy, adaptability, and usability.
Crucially, it is the first method integrated into widely used image viewers (e.g., Napari, MITK), ensuring broad accessibility for real-world clinical and research applications.
Extensive benchmarking demonstrates that nnInteractive far surpasses existing methods, setting a new standard for AI-driven interactive 3D segmentation.

<img src=""https://github.com/MIC-DKFZ/napari-nninteractive/raw/main/imgs/figure1_method.png"" width=""1200"">

## Demo Videos

<a href=""https://www.youtube.com/watch?v=H_L6LL0FRoo"">
    <img src=""https://img.youtube.com/vi/H_L6LL0FRoo/0.jpg"" width=""270"">
</a>
<a href=""https://www.youtube.com/watch?v=YoMZ7Xv7gKI"">
    <img src=""https://img.youtube.com/vi/YoMZ7Xv7gKI/0.jpg"" width=""270"">
</a>
<a href=""https://www.youtube.com/watch?v=V0rqPYA3sjA"">
    <img src=""https://img.youtube.com/vi/V0rqPYA3sjA/0.jpg"" width=""270"">
</a>

## Installation

### Prerequisites

You need a Linux or Windows computer with a Nvidia GPU. 10GB of VRAM is recommended. Small objects should work with \<6GB.

##### 1. Create a virtual environment:

nnInteractive supports Python 3.10+ and works with Conda, pip, or any other virtual environment. Hereâs an example using Conda:

```
conda create -n nnInteractive python=3.12
conda activate nnInteractive
```

##### 2. Install the correct PyTorch for your system

Go to the [PyTorch homepage](https://pytorch.org/get-started/locally/) and pick the right configuration.
Note that since recently PyTorch needs to be installed via pip. This is fine to do within your conda environment.

For Ubuntu with a Nvidia GPU, pick 'stable', 'Linux', 'Pip', 'Python', 'CUDA12.6' (if all drivers are up to date, otherwise use and older version):

```
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu126
```

##### 3. Install this repository + dependencies via

Install napari if necessary

```bash
pip install napari[all]
```

Install the plugin via pip:

```bash
pip install napari-nninteractive
```

Or clone and install this repository:

```bash
git clone https://github.com/MIC-DKFZ/napari-nninteractive
cd napari-nninteractive
pip install -e .
```

**Note:** Model weights are automatically downloaded on first use. This can take up to a couple of minutes depending on your internet connection

## Getting Started

Use one of these three options to start napari and activate the plugin.
Afterward, Drag and drop your images into napari.

\***Note if getting asked which plugin to use for opening .nii.gz files use napari-nifti.**

a) Start napari, then Plugins -> nnInteractive.

```
napari
```

b) Run this to start napari with the plugin already started.

```
napari -w napari-nninteractive
```

c) Run this to start napari with the plugin and open an image directly

```
napari demo_data/liver_145_0000.nii.gz -w napari-nninteractive
```

# How to use

**Note:** To open Nifti (.nii.gz, .nii) files we recommend to select napari-nifti.

<img src=""https://github.com/MIC-DKFZ/napari-nninteractive/raw/main/imgs/gui_instuctions.png"" width=""1200"">

## Citation

When using nnInteractive, please cite the following paper:

> Isensee, F.\*, Rokuss, M.\*, KrÃ¤mer, L.\*, Dinkelacker, S., Ravindran, A., Stritzke, F., Hamm, B., Wald, T., Langenberg, M., Ulrich, C., Deissler, J., Floca, R., & Maier-Hein, K. (2025). nnInteractive: Redefining 3D Promptable Segmentation. https://arxiv.org/abs/2503.08373 \
> \*: equal contribution

Link: [![arXiv](https://img.shields.io/badge/arXiv-2503.08373-b31b1b.svg)](https://arxiv.org/abs/2503.08373)

# License

Note that while this repository is available under Apache-2.0 license (see [LICENSE](./LICENSE)), the [model checkpoint](https://huggingface.co/nnInteractive/nnInteractive) is `Creative Commons Attribution Non Commercial Share Alike 4.0`!

______________________________________________________________________

## Acknowledgments

<p align=""left"">
  <img src=""https://github.com/MIC-DKFZ/napari-nninteractive/raw/main/imgs/Logos/HI_Logo.png"" width=""150""> &nbsp;&nbsp;&nbsp;&nbsp;
  <img src=""https://github.com/MIC-DKFZ/napari-nninteractive/raw/main/imgs/Logos/DKFZ_Logo.png"" width=""500"">
</p>

This repository is developed and maintained by the Applied Computer Vision Lab (ACVL)
of [Helmholtz Imaging](https://www.helmholtz-imaging.de/) and the
[Division of Medical Image Computing](https://www.dkfz.de/en/medical-image-computing) at DKFZ.

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

[copier]: https://copier.readthedocs.io/en/stable/
[napari]: https://github.com/napari/napari
[napari-plugin-template]: https://github.com/napari/napari-plugin-template
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Homepage, https://github.com/MIC-DKFZ/napari-nninteractive', 'Code, https://github.com/MIC-DKFZ/napari-nninteractive']",,,napari-nninteractive.nnInteractiveWidget,,,,
313,napari-nucleaizer,napari-nucleaizer,Napari nucleAIzer plugin,0.2.5,2021-09-08,2023-09-01,Ervin Tasnadi,tasnadi.ervin@brc.hu,BSD-3,https://github.com/etasnadi/napari_nucleaizer/issues,https://pypi.org/project/napari-nucleaizer/,,https://github.com/etasnadi/napari_nucleaizer,A GUI interface for training and prediction using the nucleAIzer nuclei detection method.,>=3.8,"['napari', 'qtpy', 'jsonpickle', 'numpy', 'scikit-image', 'imageio', 'nucleaizer-backend']","# napari_nucleaizer

[![License](https://img.shields.io/pypi/l/napari-nucleaizer.svg?color=green)](https://github.com/etasnadi/napari-nucleaizer/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-nucleaizer.svg?color=green)](https://pypi.org/project/napari-nucleaizer)
[![Python package](https://github.com/etasnadi/napari_nucleaizer/actions/workflows/test_and_deploy.yml/badge.svg)](https://github.com/etasnadi/napari_nucleaizer/actions/workflows/test_and_deploy.yml)
[![codecov](https://codecov.io/gh/etasnadi/napari_nucleaizer/branch/master/graph/badge.svg?token=5XC36PA6OQ)](https://codecov.io/gh/etasnadi/napari_nucleaizer)
[![Documentation Status](https://readthedocs.org/projects/napari-nucleaizer-docs/badge/?version=latest)](https://napari-nucleaizer-docs.readthedocs.io/en/latest/?badge=latest)

<!--
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nucleaizer.svg?color=green)](https://python.org)
[![tests](https://github.com/etasnadi/napari_nucleaizer/workflows/tests/badge.svg)](https://github.com/etasnadi/napari-nucleaizer/actions)
[![codecov](https://codecov.io/gh/etasnadi/napari-nucleaizer/branch/master/graph/badge.svg)](https://codecov.io/gh/etasnadi/napari-nucleaizer)
-->

GUI for the nucleaAIzer method in Napari.

![Plugin interface in napari.](https://github.com/etasnadi/napari_nucleaizer/blob/main/napari_screenshot.png?raw=true)

## Overview

This is a napari plugin to execute the nucleaizer nuclei segmentation algorithm.

### Main functionalities

Using this plugin will be able to

1. Load your image into Napar, then outline the nuclei.
2. Specify an image folder containing lots of images and an output folder, and automatically segment all of the images in the input folder.
3. If you are not satisfied with the results, you can train your own model:
    1. You can use our pretrained models and fine tune them on your data.
    2. You can skip the nucleaizer pipeline and train only on your data.


### Supported image types

We have several pretrained models for the following image modelities:
* fluorescent microscopy images
* IHC stained images
* brightfield microscopy images,

among others. For the detailed descriptions of our models, see: https://zenodo.org/record/6800341.

### How it works?

For the description of the algorithm, see our paper: ""Hollandi et al.: nucleAIzer: A Parameter-free Deep Learning Framework for Nucleus Segmentation Using Image Style Transfer, Cell Systems, 2020. https://doi.org/10.1016/j.cels.2020.04.003""

The original code (https://github.com/spreka/biomagdsb) is partially transformed into a python package (nucleaizer_backend) to actually perform the operations. See the project page of the backend at: https://github.com/etasnadi/nucleaizer_backend.

If you wish to use the web interface, check: http://nucleaizer.org.

![All functionalities.](https://github.com/etasnadi/napari_nucleaizer/blob/main/nucleaizer_screenshot.png?raw=true)

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Install

1. Create an environment (recommended).

2. Install napari: `pip install ""napari[pyqt5]""`. Other methods: https://napari.org/tutorials/fundamentals/installation.html

3. Install the plugin into napari:

    * User mode from [PyPI](https://pypi.org/project/napari-nucleaizer/): start Napari (command line: `napari`) and select he **Install/Uninstall Plugins...** under the **Plugins** menu. In the popup, filter for `napari-nucleaizer`.

    * Developer mode: clone this project and use `pythhon3 -m pip install -e <path>` to install the project locally **into the same evnrionment as napari**. It has the advantage that you will have the latest version.
## Run

1. Start Napari by calling `napari` from the command line.
2. Then, activate the plugin in the `Plugins` menu. If you successfully installed the plugin, you have to see something like this:

![Plugin interface in napari.](https://github.com/etasnadi/napari_nucleaizer/blob/main/napari_plugin_launch.png?raw=true)

## Further help

See the [documentation](https://napari-nucleaizer-docs.readthedocs.io/en/latest/index.html) (work in progress).

## Issues

Use the github issue tracker if you experinece unexpected behaviour.

## Contact

You can contact me in [e-mail](mailto:tasnadi.ervin@MY-INSTITUTE) where MY-INSTITUTE is `brc.hu`.
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/etasnadi/napari_nucleaizer/issues', 'Documentation, https://napari-nucleaizer-docs.readthedocs.io/en/latest/index.html', 'Source Code, https://github.com/etasnadi/napari_nucleaizer', 'User Support, https://github.com/etasnadi/napari_nucleaizer/issues']",,,napari-nucleaizer.launch,,,,
314,napari-nikon-nd2,napari-nikon-nd2,napari-nikon-nd2,0.1.3,2021-02-03,2021-02-03,Chris Wood,cwood1967@gmail.com,Apache Software License 2.0,https://github.com/cwood1967/napari-nikon-nd2,https://pypi.org/project/napari-nikon-nd2/,,https://github.com/cwood1967/napari-nikon-nd2,Opens Nikon ND2 files into napari.,>=3.6,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'nd2reader']","# napari-nikon-nd2

[![License](https://img.shields.io/pypi/l/napari-nikon-nd2.svg?color=green)](https://github.com/cwood1967/napari-nikon-nd2/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-nikon-nd2.svg?color=green)](https://pypi.org/project/napari-nikon-nd2)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nikon-nd2.svg?color=green)](https://python.org)
[![tests](https://github.com/cwood1967/napari-nikon-nd2/workflows/tests/badge.svg)](https://github.com/cwood1967/napari-nikon-nd2/actions)
[![codecov](https://codecov.io/gh/cwood1967/napari-nikon-nd2/branch/main/graph/badge.svg)](https://codecov.io/gh/cwood1967/napari-nikon-nd2)

Opens Nikon ND2 files into napari. This plugin uses the [nd2reader] and [pims] python packages. 

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-nikon-nd2` via [pip]:

    pip install napari-nikon-nd2

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-nikon-nd2"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

## Credits

This [napari] plugin was created using [Napari Delta Vision Reader] and
the [Allen Institute IO] plugin as examples.


[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/cwood1967/napari-nikon-nd2/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[nd2reader]: https://github.com/rbnvrw/nd2reader
[pims]: https://github.com/soft-matter/pims
[Allen Institute IO]: https://github.com/AllenCellModeling/napari-aicsimageio
[Napari Delta Vision Reader]: https://github.com/tlambert03/napari-dv

","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: Apache Software License']",,napari-nikon-nd2.napari_get_reader,,,,['*'],,
315,napari-nlm,napari-nlm,napari NLM,0.0.4,2022-07-25,2022-07-26,Martin Weigert,marweigert@gmail.com,BSD-3-Clause,https://github.com/maweigert/napari-nlm/issues,https://pypi.org/project/napari-nlm/,,https://github.com/maweigert/napari-nlm,NLM (non local means) denoising,>=3.8,"['numpy', 'magicgui', 'qtpy', 'pyopencl (==2022.1.5)', 'gputools', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-nlm

[![License BSD-3](https://img.shields.io/pypi/l/napari-nlm.svg)](https://github.com/maweigert/napari-nlm/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-nlm.svg)](https://pypi.org/project/napari-nlm)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nlm.svg)](https://python.org)
[![tests](https://github.com/maweigert/napari-nlm/workflows/tests/badge.svg)](https://github.com/maweigert/napari-nlm/actions)
[![codecov](https://codecov.io/gh/maweigert/napari-nlm/branch/main/graph/badge.svg)](https://codecov.io/gh/maweigert/napari-nlm)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-nlm)](https://napari-hub.org/plugins/napari-nlm)

----------------------------------


GPU accelerated non local means (NLM) denoising plugin for napari (WIP)

* currently only supports single-channel 2D or 3D images
* requires a OpenCL capable GPU

![Screenshot](images/screenshot.jpg)


## Installation

You can install `napari-nlm` via [pip]:

    pip install napari-nlm

## Usage

1. Open example image `Open Sample > napari-nlm: noisy bricks`
2. Adjust parameters 
   * `sigma`: denoising strength (the larger sigma, the greater the smoothing)
   * `patch_radius`: size of local patches, 2 or 3 is a good default
   * `search_radius`: size of search area around each pixel to find similar patches, 7-11 is a good default
3. Denoise by pressing `run`


## License

Distributed under the terms of the [BSD-3] license,
""napari-nlm"" is free and open source software
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/maweigert/napari-nlm/issues', 'Documentation, https://github.com/maweigert/napari-nlm#README.md', 'Source Code, https://github.com/maweigert/napari-nlm', 'User Support, https://github.com/maweigert/napari-nlm/issues']",,,napari-nlm.denoise_nlm,napari-nlm.make_sample_data_2d,,,
316,napari-nuclephaser,napari-nuclephaser,NuclePhaser,0.2.2,2025-04-02,2025-06-07,Nikita Voloshin,nikita.voloshin.98@gmail.com,MIT,https://github.com/nikvo1/napari-nuclephaser/issues,https://pypi.org/project/napari-nuclephaser/,,,A Napari plugin to detect and count nuclei on phase contrast images,>=3.10,"['setuptools', 'wheel', 'napari', 'ultralytics', 'yolov5', 'magicgui', 'sahi', 'scikit-image', 'torch', 'pathlib', 'numpy', 'typing', 'pandas', 'openpyxl', 'seaborn', 'opencv-python', 'imagecodecs', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'pytest-mock; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'opencv-python-headless; extra == ""testing""']","# NuclePhaser: Cell Proliferation Measurement & Cell Tracking Assistant Plugin for Timelapse Images

[![License MIT](https://img.shields.io/pypi/l/napari-nuclephaser.svg?color=green)](https://github.com/nikvo1/napari-nuclephaser/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-nuclephaser.svg?color=green)](https://pypi.org/project/napari-nuclephaser)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-nuclephaser.svg?color=green)](https://python.org)
[![tests](https://github.com/nikvo1/napari-nuclephaser/workflows/tests/badge.svg)](https://github.com/nikvo1/napari-nuclephaser/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-nuclephaser)](https://napari-hub.org/plugins/napari-nuclephaser)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

A Napari plugin for automated cell nuclei detection, proliferation and population growth analysis, and single-cell tracking in brightfield and fluorescent nuclei timelapse microscopy images.

napari-nuclephaser is an open-source Napari plugin designed for scientists who need to measure cell proliferation rates, analyze population growth, and perform individual cell tracking on timelapse microscopy images. It utilizes [Ultralytics](https://docs.ultralytics.com/) YOLO object detection models and [obss/sahi](https://github.com/obss/sahi) sliced inference methods to detect cell nuclei on brightfield and fluorescent images of any size, including large whole slide ones. Learn more with [documentation](https://napari-nuclephaser.readthedocs.io/en/latest/index.html) and [paper](https://www.biorxiv.org/content/10.1101/2025.05.13.653705v1).

## Nuclei detection

We trained a series of [YOLOv5](https://github.com/ultralytics/yolov5) and [YOLOv11](https://github.com/ultralytics/ultralytics) models to detect nuclei on phase contrast images. It can be used for counting cells or for individual cell tracking (using nuclei detections as tracking markers). Prominent features of this approach are:
- Napari-nuclephaser plugin includes [obss/sahi](https://github.com/obss/sahi) functionality, allowing detection on images of arbitrary sizes.

<p align=""center"">
	<picture>
	  <source media=""(prefers-color-scheme: dark)"" srcset=https://github.com/user-attachments/assets/aa321f17-b0e2-4161-8a69-cb732d7065a7 height=400>
	  <img alt=""Image didn't load"" src=https://github.com/user-attachments/assets/fe4d6436-3490-4c06-8ddd-7c797976f407 height=400>
	</picture>
</picture>

- YOLO models are fast, providing reasonable inference speed even with CPU.
- Ability to predict and automatically count nuclei on stacks of images, making it convenient for cell population growth studies and individual cell tracking.

<picture>
  <source media=""(prefers-color-scheme: dark)"" srcset=https://github.com/user-attachments/assets/feba9a99-1d37-4962-a2e6-175052aa4925>
  <img alt=""Image didn't load"" src=""https://github.com/user-attachments/assets/c7e4d0e6-44c1-4268-aae5-6bb78500d928"">
</picture>

- Calibration algorithm that allows measuring accuracy for each specific use case.

## Calibration algorithm

Result of object detection model inference is highly dependent on _confidence threshold_ parameter.

<p align=""center"">
  <picture>
  <source media=""(prefers-color-scheme: dark)"" srcset=https://github.com/user-attachments/assets/8a13085f-c7ea-45f0-8931-6851f21b68a0 height=""300"">
  <img alt=""Image didn't load"" src=https://github.com/user-attachments/assets/89f76cd7-2db7-4241-bc35-36d23332b2b5 height=""300"">
  </picture>
</p>

We created several calibration (finding optimal confidence threshold) algorithms that allow adjusting models to specific use cases (cell types, magnifications, illumination settings, cameras etc.):
- Calibration using known number of objects on an image. Doesn't produce accuracy metrics.
- Calibration using fluorescent nuclei stain image (for example, DAPI image). Produces accuracy metrics.
- Calibration using manual annotation of nuclei. Produces accuracy metrics.

Apart from optimal confidence threshold search, these algorithms return accuracy metrics for specific use cases. Given that the calibration image is large, only part of it is used for search of threshold, while the second part is used for evaluation model's accuracy.
Accuracy metrics are [Mean Absolute Percentage Error (MAPE)](https://en.wikipedia.org/wiki/Mean_absolute_percentage_error) and prediction-ground truth scatterplot, which shows how well model performs with different densities of cells.

Learn more about calibration in [documentation](https://napari-nuclephaser.readthedocs.io/en/latest/Biological%20tasks%20guidelines/Individual%20cells%20tracking.html).

<p align=""center"">
  <picture>
  <source media=""(prefers-color-scheme: dark)"" srcset=https://github.com/user-attachments/assets/6d89e22b-2728-40fb-839d-3c6681e29c97>
  <img alt=""Image didn't load"" src=https://github.com/user-attachments/assets/6a574845-4ad2-4802-b0f8-f1d908aa585a>
  </picture>
</p>

## Cell Proliferation Measurement & Population Growth Analysis

With NuclePhaser you can reconstruct population growth curves from timelapse images of growing cell population by counting number of nuclei on each image. Key features of this approach are:

- No special equipment, reagents or dyes required, only regular culture plastic and cell growth medium, microscope with mechanical stage and a PC (even without GPU).
- [Accuracy measurement for each specific use case](https://napari-nuclephaser.readthedocs.io/en/latest/General%20information/Confidence%20threshold%20calibration.html), so you will be sure the tool is working with appropriate precision.
- Measuring the number of cells, not the area occupied by cells, which can be significantly influenced by spreading/narrowing of cells. 
- Complete reproducibility of results with metadata.txt files saved for each experiment.

<p align=""center"">
  <picture>
  <source media=""(prefers-color-scheme: dark)"" srcset=https://github.com/user-attachments/assets/47b6cee0-7f4a-440f-84ed-de2a5aa2aa36>
  <img alt=""Image didn't load"" src=https://github.com/user-attachments/assets/5a084f1a-f977-41fa-b4be-55f37bdf9996>
  </picture>
</p>

For more detailed information about how NuclePhaser can be used for cell proliferation measurement & population growth analysis, visit our [documentation](https://napari-nuclephaser.readthedocs.io/en/latest/Biological%20tasks%20guidelines/Population%20growth%20curves.html#).

## Individual cell tracking

NuclePhaser can be used as an assistant for individual cells tracking. This task is extremely difficult, and manual tracking is still the only method with 100% proof against false tracks. With NuclePhaser, you can significantly simplify manual tracking: instead of marking each cell on each image, you can predict nuclei location with NuclePhaser and then correct the result, which is **much** faster. Learn more in [documentation](https://napari-nuclephaser.readthedocs.io/en/latest/Biological%20tasks%20guidelines/Individual%20cells%20tracking.html).

## Models

Currently only YOLOv5n, YOLOv5s, YOLOv11n and YOLOv11s models, as well as fluorescent nuclei detector YOLOv5n are downloaded automatically with pip install napari-nuclephaser. To use larger models, download them with these links:

<div align=""center"">

Fluorescent nuclei detectors
| Model                    | Link |
| :----------------------: | :-----: |
| Fluorescence_v5n         | [Donwload](https://zenodo.org/records/15388030/files/Fluorescence_v5n.pt?download=1) |
| Fluorescence_v5s         | [Donwload](https://zenodo.org/records/15388030/files/Fluorescence_v5s.pt?download=1) |
| Fluorescence_v5m         | [Donwload](https://zenodo.org/records/15388030/files/Fluorescence_v5m.pt?download=1) |
| Fluorescence_v5l         | [Donwload](https://zenodo.org/records/15388030/files/Fluorescence_v5l.pt?download=1) |
| Fluorescence_v5x         | [Donwload](https://zenodo.org/records/15388030/files/Fluorescence_v5x.pt?download=1) |
| Fluorescence_v11n        | [Donwload](https://zenodo.org/records/15388030/files/Fluorescence_v11n.pt?download=1)|
| Fluorescence_v11s        | [Donwload](https://zenodo.org/records/15388030/files/Fluorescence_v11s.pt?download=1)|
| Fluorescence_v11m        | [Donwload](https://zenodo.org/records/15388030/files/Fluorescence_v11m.pt?download=1)|
| Fluorescence_v11l        | [Donwload](https://zenodo.org/records/15388030/files/Fluorescence_v11l.pt?download=1)|
| Fluorescence_v11x        | [Donwload](https://zenodo.org/records/15388030/files/Fluorescence_v11x.pt?download=1)|

Brighfield nuclei detectors
| Model                    | Link |
| :----------------------: | :-----: |
| Brightfield_v5n          | [Donwload](https://zenodo.org/records/15388030/files/Brightfield_v5n.pt?download=1)  |
| Brightfield_v5s          | [Donwload](https://zenodo.org/records/15388030/files/Brightfield_v5s.pt?download=1)  |
| Brightfield_v5m          | [Donwload](https://zenodo.org/records/15388030/files/Brightfield_v5m.pt?download=1)  |
| Brightfield_v5l          | [Donwload](https://zenodo.org/records/15388030/files/Brightfield_v5l.pt?download=1)  |
| Brightfield_v5x          | [Donwload](https://zenodo.org/records/15388030/files/Brightfield_v5x.pt?download=1)  |
| Brightfield_v11n         | [Donwload](https://zenodo.org/records/15388030/files/Brightfield_v11n.pt?download=1) |
| Brightfield_v11s         | [Donwload](https://zenodo.org/records/15388030/files/Brightfield_v11s.pt?download=1) |
| Brightfield_v11m         | [Donwload](https://zenodo.org/records/15388030/files/Brightfield_v11m.pt?download=1) |
| Brightfield_v11l         | [Donwload](https://zenodo.org/records/15388030/files/Brightfield_v11l.pt?download=1) |
| Brightfield_v11x         | [Donwload](https://zenodo.org/records/15388030/files/Brightfield_v11x.pt?download=1) |

</div>

> [!NOTE]
> Feel free to use the models published here without the plugin!

# Plugin functionality
napari-nuclephaser plugin offers following widgets:
- Widget for inference on single image. Result can be in the form of points or boxes with or without confidence scores. Automatically returns number of cells in the name of result layer.
- Widget for inference on stack of images. Optionally can create .csv or .xlsx file at given location with counting results.
- Widget for calibration using known number of cells.
- Widget for calibration using fluorescent nuclei image (fluorescent nuclei detection model is used as a perfect predictor).
- Widget for calibration using manual annotations.
- Widget for transforming Napari Points layer into Labels layer, which allows turning detection in tracking algorithms-digestible form (in particular, [btrack](https://github.com/quantumjot/btrack)).
- Widget for counting number of points in Points layer.

Learn more about widgets and their functionality at [documentation](https://napari-nuclephaser.readthedocs.io/en/latest/index.html).

## Citation
If you use NuclePhaser in your work, please cite our preprint:
```bibtex
@article {Voloshin2025.05.13.653705,
	author = {Voloshin, Nikita and Putlyaev, Egor and Chechekhina, Elizaveta and Usachev, Vladimir and Karagyaur, Maxim and Bozov, Kirill and Grigorieva, Olga and Tyurin-Kuzmin, Pyotr and Kulebyakin, Konstantin},
	title = {NuclePhaser: a YOLO-based framework for cell nuclei detection and counting in phase contrast images of arbitrary size with support of fast calibration and testing on specific use cases},
	year = {2025},
	doi = {10.1101/2025.05.13.653705},
	URL = {https://www.biorxiv.org/content/early/2025/05/16/2025.05.13.653705},
	eprint = {https://www.biorxiv.org/content/early/2025/05/16/2025.05.13.653705.full.pdf},
	journal = {bioRxiv}
}
```

## Installation

For detailed installation instructions, visit our [documentation](https://napari-nuclephaser.readthedocs.io/en/latest/Installation/Installation.html).

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-nuclephaser"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/nikvo1/napari-nuclephaser/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

This [napari] plugin was generated with [copier] using the [napari-plugin-template].
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/nikvo1/napari-nuclephaser/issues', 'Documentation, https://github.com/nikvo1/napari-nuclephaser#README.md', 'Source Code, https://github.com/nikvo1/napari-nuclephaser', 'User Support, https://github.com/nikvo1/napari-nuclephaser/issues']",,,napari-nuclephaser.make_points,,,,
317,napari-nyxus,napari-nyxus,napari-nyxus,0.2.1,2023-05-05,2024-12-30,Jesse McKinzie,Jesse.McKinzie@axleinfo.com,Unavailable,https://github.com/PolusAI/napari-nyxus,https://pypi.org/project/napari-nyxus/,,https://github.com/PolusAI/napari-nyxus,A napari plugin for calculating features from intensity-label image data,,"['napari', 'pandas', 'numpy', 'pandas', 'nyxus>=0.5.0', 'imagecodecs', 'magicgui', 'napari-workflows', 'qtpy', 'superqt', 'napari-skimage-regionprops>=0.10.1', 'matplotlib', 'filepattern>=2.0.0']","# Nyxus Napari

Nyxus Napari is a Napari plugin for running feature calculations on image-segmentation image pairs, using the
Nyxus application to compute features. Nyxus is a feature-rich, highly optimized, Python/C++ application capable 
of analyzing images of arbitrary size and assembling complex regions of interest (ROIs) split across multiple image tiles and files. 

For more information on Nyxus, see https://github.com/PolusAI/nyxus.
 
# Installation 

To install Napari, it is recommended to first create a separate Conda environment. 

```
conda create -y -n napari-env -c conda-forge python=3.9
conda activate napari-env
```

After creating the Conda environment,
install Napari using pip

```
python -m pip install ""napari[all]""
python -m pip install ""napari[all]"" --upgrade
```

or using conda

```
conda install -c conda-forge napari
conda update napari
```

Next, Nyxus must be installed. Note that the version of Nyxus must be greater than or equal to `0.50` to run the Napari plugin.

`pip install nyxus`

or build from source using the instructions at https://github.com/PolusAI/nyxus#building-from-source using the conda build for the
python API.

After installing Napari and Nyxus, the Nyxus Napari plugin can be installed by cloning this repo and then building the plugin from the source. 
An example of this process is provided below.

```
git clone https://github.com/PolusAI/napari-nyxus.git
cd napari_nyxus
pip install -e .
```

Napari can then be ran by running 

```
napari
````

# Use
After installing the plugin, start Napari by running the command `napari` from the command line. Once the Napari 
GUI is loaded, the Nyxus plugin can be loaded from the `Plugins` menu in the toolbar by going to Plugins -> nyxus-napari.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/plugin_menu.png)

A widget will appear in the Napari viewer to run Nyxus.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/nyxus_loaded.png)

As shown by the example above, Nyxus will take in Intensity and Segmentation images. These parameters can either be a stack
of images or a single image pair. To load an image pair, use File -> Open File(s)... and select the images to load.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/open_image.png)


Note that this method can also be used to open a stack of image, by using File -> Open Folder... instead of images. 

If the segmentation is loaded as an Image type in the napari viewer, it must first be converted to the Labels type. The image can converted as shown below.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/convert_to_labels.png)

The loaded files can then be selected with the Intensity and Segmentation drop down menus. Other parameters can also be changed,
such as which features to calculate. For more information on the available features, see https://nyxus.readthedocs.io/en/latest/featurelist.html.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/setup_calculation.png)

After running Nyxus, the feature calculations will also appear in the Napari viewer.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/feature_results.png)

The Nyxus Napari plugin provides functionality to interact with the table containing the feature calculations. First, click on the segmentation image and then select `show selected` in the layer controls. 


Then, if a value is clicked in the `label` column of the table, the respective ROI will be highlighted in the segmentation image in the viewer.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/click_label.png)

To select the ROI and have it added to a separate Labels image, the label in the table can be double clicked. Each double clicked label will be added to the same Labels image as show below. To unselect, the ROI, double click its respective label again.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/double_click_label.png)

This feature can also be used in the opposite way, i.e. if an ROI is clicked in the segmentation image, the respective row in the 
feature table will be highlighted.

If one of the column headers are double clicked, a colormap will be generated in the Napari viewer showing the values of the features in the clicked
column. For example, if `Intensity` features are calculated, the `INTEGRATED_INTENSITY` column can be clicked and the colormap will appear.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/feature_colormap.png)

Once the colormap is loaded, a slider will appear in the window with the minimum value being the minimum value of the feature colormap and the 
maximum value of the slider is the maximum value of the colormap. By adjusting the ranges in the slider, a new label image will appear in the viewer
that contains the ROIs who's features values fall within the slider values.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/slider_feature.png)

The new labels resulting from the range slider selector can then be used to run Nyxus on by using the labels image as the `Segmentation` parameter.

![](https://github.com/PolusAI/napari-nyxus/raw/main/docs/source/img/run_on_colormap_labels.png)

# Limitations

While Nyxus Napari provides batched processing for large sets of images where each individual image will fit into RAM, 
it does not provide functionality to handle large single images that do not fit into RAM or that are larger than the 
limitations of Napari. For large images, it is recommended to install the Python or CLI version of Nyxus. 
For more information, see https://github.com/PolusAI/nyxus. 
",['Framework :: napari'],,,,napari-nyxus.nyxus_widget,,,,
318,napari-ome-zarr-navigator,napari-ome-zarr-navigator,napari OME-Zarr Navigator,0.2.0,2024-07-19,2025-05-01,Fabio Steffen and Joel Luethi,fabio.steffen@uzh.ch,BSD-3-Clause,https://github.com/fractal-analytics-platform/napari-ome-zarr-navigator/issues,https://pypi.org/project/napari-ome-zarr-navigator/,,https://github.com/fractal-analytics-platform/napari-ome-zarr-navigator,"A plugin to browse OME-Zarr plates by conditions and load images, labels and features from ROIs",>=3.11,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'napari-ome-zarr', 'ome-zarr', 'wget', 'ngio<0.3,>=0.2.4', 'numcodecs!=0.14.0,!=0.14.1,!=0.16', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-ome-zarr-navigator <img align=""right"" height=""150"" src=""https://raw.githubusercontent.com/fractal-napari-plugins-collection/napari-ome-zarr-navigator/master/docs/images/navigator_logo.png"">

[![License BSD-3](https://img.shields.io/pypi/l/napari-ome-zarr-navigator.svg?color=green)](https://github.com/fractal-analytics-platform/napari-ome-zarr-navigator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-ome-zarr-navigator.svg?color=green)](https://pypi.org/project/napari-ome-zarr-navigator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-ome-zarr-navigator.svg?color=green)](https://python.org)
[![tests](https://github.com/fractal-analytics-platform/napari-ome-zarr-navigator/workflows/tests/badge.svg)](https://github.com/fractal-analytics-platform/napari-ome-zarr-navigator/actions)
[![codecov](https://codecov.io/gh/fractal-analytics-platform/napari-ome-zarr-navigator/branch/main/graph/badge.svg)](https://codecov.io/gh/fractal-analytics-platform/napari-ome-zarr-navigator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-ome-zarr-navigator)](https://napari-hub.org/plugins/napari-ome-zarr-navigator)

A plugin to browse OME-Zarr plates by conditions and load images, labels and features from ROIs


## Usage

The ImageBrowser recognizes OME-Zarr plates that were loaded via [napari-ome-zarr](https://github.com/ome/napari-ome-zarr) and allows the selection of wells in the multiwell plate.

<img width=""1624"" alt=""navigator_1"" src=""https://github.com/user-attachments/assets/86c0c0d5-df4c-4579-8719-c36efe67485c"">

The ImageBrowser allows to zoom to a given well (""Go to well"") & puts a white bounding box around the selected well.

<img width=""1624"" alt=""navigator_2"" src=""https://github.com/user-attachments/assets/13ead72a-de0e-4b03-8051-b9759af4a131"">

Using prototype `condition tables` (to be defined better, see sample data provided by the plugin orthe example in the test data below), the ImageBrowser allows for selecting subsets of the well list based on conditions defined in the `condition table`. The [operetta-compose Fractal task package](https://github.com/leukemia-kispi/operetta-compose) provides a task to create such condition tables.


<img width=""1624"" alt=""navigator_3"" src=""https://github.com/user-attachments/assets/f8cb9311-49ef-43fd-9358-4193ffb58877"">

The ROI loader (formerly [available separately as a napari plugin](https://github.com/jluethi/napari-ome-zarr-roi-loader)) can be used standalone or integrated with the ImageBrowser. If a well is selected from the ImageBrowser, all the images in that well can be loaded via the ROI loader.
This supports:
- Loading images from different multiplexing acquisitions
- Loading any ROI based on [Fractal ROI tables](https://fractal-analytics-platform.github.io/fractal-tasks-core/tables/#roi-tables)
- Loading label images
- Loading feature measurements (based on [Fractal feature tables](https://fractal-analytics-platform.github.io/fractal-tasks-core/tables/#feature-tables) in the AnnData format)

This approach of loading label images and feature data has been optimized for and tested with the [napari feature classifier](https://github.com/fractal-napari-plugins-collection/napari-feature-classifier).

<img width=""1624"" alt=""navigator_4"" src=""https://github.com/user-attachments/assets/0548c8f1-23c3-4c55-9388-c818bb94bbc3"">

This plugin is meant to work well for OME-Zarr files generated by [Fractal](https://fractal-analytics-platform.github.io/).

----------------------------------


## Test data

Test data is available at https://zenodo.org/records/11262587


## Installation

You can install `napari-ome-zarr-navigator` via [pip]:

    pip install napari-ome-zarr-navigator



To install latest development version :

    pip install git+https://github.com/fractal-analytics-platform/napari-ome-zarr-navigator.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-ome-zarr-navigator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/fractal-analytics-platform/napari-ome-zarr-navigator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/fractal-analytics-platform/napari-ome-zarr-navigator/issues', 'Documentation, https://github.com/fractal-analytics-platform/napari-ome-zarr-navigator#README.md', 'Source Code, https://github.com/fractal-analytics-platform/napari-ome-zarr-navigator', 'User Support, https://github.com/fractal-analytics-platform/napari-ome-zarr-navigator/issues']",,,napari-ome-zarr-navigator.make_img_browser,napari-ome-zarr-navigator.hiPSC_zarr,,,
319,napari-open-ctc,napari-open-ctc,Open CTC data,0.1.2,2024-06-03,2024-06-03,Benjamin Gallusser,benjamin.gallusser@epfl.ch,BSD-3-Clause,https://github.com/bentaculum/napari-open-ctc/issues,https://pypi.org/project/napari-open-ctc/,,https://github.com/bentaculum/napari-open-ctc,"""Drag and drop annotations/results in the Cell Tracking Challenge (CTC) format into napari.""",>=3.9,"['napari', 'numpy', 'scikit-image', 'tifffile', 'pandas', 'imagecodecs', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-open-ctc

[![PyPI](https://img.shields.io/pypi/v/napari-open-ctc.svg?color=green)](https://pypi.org/project/napari-open-ctc)
[![tests](https://github.com/bentaculum/napari-open-ctc/workflows/tests/badge.svg)](https://github.com/bentaculum/napari-open-ctc/actions)
[![codecov](https://codecov.io/gh/bentaculum/napari-open-ctc/branch/main/graph/badge.svg)](https://codecov.io/gh/bentaculum/napari-open-ctc)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-open-ctc)](https://napari-hub.org/plugins/napari-open-ctc)

Drag and drop annotations/results in the [Cell Tracking Challenge (CTC) format](https://celltrackingchallenge.net) into napari.

Works for `TRA`, `RES`, etc. folders, which contain a time sequence of segmentations in `tiff` format, and a corresponding tracklet file `*.txt`.

https://github.com/bentaculum/napari-open-ctc/assets/8866751/197c9ea2-4115-4829-851a-4b77eb843bf2


## Installation

You can install `napari-open-ctc` via [pip]:

    pip install napari-open-ctc



To install latest development version :


    pip install git+https://github.com/bentaculum/napari-open-ctc.git


## Contributing

Contributions are very welcome. Tests can be run with [tox].

## License

Distributed under the terms of the [BSD-3] license,
`napari-open-ctc` is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/bentaculum/napari-open-ctc/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/bentaculum/napari-open-ctc/issues', 'Documentation, https://github.com/bentaculum/napari-open-ctc#README.md', 'Source Code, https://github.com/bentaculum/napari-open-ctc', 'User Support, https://github.com/bentaculum/napari-open-ctc/issues']",napari-open-ctc.get_reader,,,,"['TRA', '*RES']",,
320,napari-obj,napari-obj,obj file reader,1.0.0,2023-04-05,2023-04-05,LÃ©o Guignard,leo.guignard@univ-amu.fr,MIT,https://github.com/guignardlab/napari-obj/issues,https://pypi.org/project/napari-obj/,,https://github.com/guignardlab/napari-obj,A plugin to read .obj files,>=3.8,"['numpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-obj

<!-- [![License MIT](https://img.shields.io/pypi/l/napari-obj.svg?color=green)](https://github.com/guignardlab/napari-obj/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-obj.svg?color=green)](https://pypi.org/project/napari-obj)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-obj.svg?color=green)](https://python.org)
[![tests](https://github.com/guignardlab/napari-obj/workflows/tests/badge.svg)](https://github.com/guignardlab/napari-obj/actions)
[![codecov](https://codecov.io/gh/guignardlab/napari-obj/branch/main/graph/badge.svg)](https://codecov.io/gh/guignardlab/napari-obj)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-obj)](https://napari-hub.org/plugins/napari-obj) -->

A plugin to read .obj files

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-obj` via [pip]:

    pip install napari-obj

To install latest development version :

    pip install git+https://github.com/guignardlab/napari-obj.git

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-obj"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/guignardlab/napari-obj/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/guignardlab/napari-obj/issues', 'Documentation, https://github.com/guignardlab/napari-obj#README.md', 'Source Code, https://github.com/guignardlab/napari-obj', 'User Support, https://github.com/guignardlab/napari-obj/issues']",napari-obj.get_reader,,,,['*.obj'],,
321,napari-omaas,napari-omaas,napari OMAAS,1.0.4,2022-08-09,2025-03-06,Ruben Lopez,rjlopez2@gmail.com,BSD-3-Clause,https://github.com/rjlopez2/napari-omaas/issues,https://pypi.org/project/napari-omaas/,,https://github.com/rjlopez2/napari-omaas,napari-OMAAS stands for Optical Mapping Acquisition and Analysis Software,>=3.10,"['numpy', 'tqdm', 'superqt', 'magicgui', 'qtpy', 'opencv-python-headless', 'sif_parser', 'napari_matplotlib', 'napari-tiff', 'napari-mat-file-reader', 'opticalmapping', 'scikit-image', 'matplotlib', 'pandas', 'scipy', 'tifffile', 'toml', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'sphinx; extra == ""docs""', 'sphinxcontrib-napoleon; extra == ""docs""', 'sphinxcontrib-bibtex; extra == ""docs""', 'sphinxcontrib-video; extra == ""docs""', 'sphinx-autobuild; extra == ""docs""', 'sphinx-copybutton; extra == ""docs""', 'sphinx-codeautolink; extra == ""docs""', 'furo; extra == ""docs""', 'myst_nb>=1.0.0; extra == ""docs""', 'jupytext; extra == ""docs""', 'jupyter-cache; extra == ""docs""', 'cupy-cuda11x; extra == ""gpu""']","# napari-omaas

[![License BSD-3](https://img.shields.io/pypi/l/napari-omaas.svg?color=green)](https://github.com/rjlopez2/napari-omaas/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-omaas.svg?color=green)](https://pypi.org/project/napari-omaas)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-omaas.svg?color=green)](https://python.org)
[![tests](https://github.com/rjlopez2/napari-omaas/workflows/tests/badge.svg)](https://github.com/rjlopez2/napari-omaas/actions)
[![codecov](https://codecov.io/gh/rjlopez2/napari-omaas/branch/main/graph/badge.svg)](https://codecov.io/gh/rjlopez2/napari-omaas)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-omaas)](https://napari-hub.org/plugins/napari-omaas)

napari-OMAAS stands for **Optical Mapping Acquisition and Analysis Software** for panoramic heart imaging.

This napari plugin intends to be an analysis and acquisition tool for optical mapping in potentiometric (V<sub>m</sub>) or calcium (Ca<sup>2+</sup>) fluorescence signals obtained from panoramic imaging of intact hearts.

 It supports reading images in `.sif` format and binary files generated from Andor Technologies cameras powered by the [sif_parser] python module.



<!-- ```{admonition} Experimental âï¸ð²ð§ªð­ðð£ð¨ðª²â£ï¸âï¸
:class: warning
This plugin is in early development/experimental stage so expect braking changes and bugs at anytime.
``` -->
## Examples

<br /> 

### Plot profile

The following example ilustrate how to perform normalization (pixelwise) on a time serie image and plot its 2d profile along the *t* dimension withing the averaged ROI selected pixels.

![](https://github.com/rjlopez2/napari-omaas/blob/documentation/example_imgs/Oct-31-2023%2016-45-55_plot_profile.gif?raw=true)

----------------------------------

### APD estimation 

The next example shows how to compute action potential duration (APD) in the same image stack.

![](https://github.com/rjlopez2/napari-omaas/blob/documentation/example_imgs/Oct-31-2023%2016-49-02_APD_analysis.gif?raw=true)

----------------------------------

You can also perform additional operations on images, such as normalization, temporal/spatial filters, segmentation, but also apply more advanced image processing methods such as motion tracking/compensation, etc.

----------------------------------

## Roadmap

This plugin was aimed to have two major components: **analysis** and **acquisition**. Bellow is a list of the current features that napari-omaas supports:

### Analysis Features
    
- [x] Read sif files from Andor Technologies.
- [x] Display time profile of ROIs on image sequences.
- [x] Normalize images.
    - [x] Perform peak analysis of action potential / Calcium traces.
    - [x] Add motion correction.
    - [x] APD analysis.
    - [x] Create activation maps.
    - [x] Segment images.
    - [x] Automatic crop and alignment of heart ROIs.
- [x] Export results, metadata and analysis log.

### Acquisition Features

- [ ] Control Zyla camera for the acquisition of data
    - [ ] test using the PYME module
- [ ] Real-time analysis(?)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

Also review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->


## Contributing

Contributions are very welcome. Run tests with [tox], ensuring
the coverage remains the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-omaas"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue] and a  detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/rjlopez2/napari-omaas/issues

[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[sif_parser]: https://pypi.org/project/sif-parser/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/rjlopez2/napari-omaas/issues', 'Documentation, https://github.com/rjlopez2/napari-omaas#README.md', 'Source Code, https://github.com/rjlopez2/napari-omaas', 'User Support, https://github.com/rjlopez2/napari-omaas/issues']",napari-omaas.get_reader,napari-omaas.write_multiple,napari-omaas.make_qwidget,napari-omaas.make_sif_sample_data,"['*.sif', '*.tif', '*.tiff']",,['.npy']
322,napari-ome-zarr,napari-ome-zarr,napari-ome-zarr,0.6.1,2021-06-14,2024-07-15,OME Team,ome-team@openmicroscopy.org,BSD-3,https://github.com/ome/napari-ome-zarr/issues,https://pypi.org/project/napari-ome-zarr/,,https://github.com/ome/napari-ome-zarr,A reader for zarr backed OME-NGFF images.,>=3.7,"['ome-zarr >=0.3.0', 'numpy', 'vispy', 'napari >=0.4.13']","# napari-ome-zarr

[![License](https://img.shields.io/pypi/l/napari-ome-zarr.svg?color=green)](https://github.com/ome/napari-ome-zarr/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-ome-zarr.svg?color=green)](https://pypi.org/project/napari-ome-zarr)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-ome-zarr.svg?color=green)](https://python.org)
[![tests](https://github.com/ome/napari-ome-zarr/workflows/tests/badge.svg)](https://github.com/ome/napari-ome-zarr/actions)
[![codecov](https://codecov.io/gh/ome/napari-ome-zarr/branch/master/graph/badge.svg)](https://codecov.io/gh/ome/napari-ome-zarr)
[![pre-commit.ci status](https://results.pre-commit.ci/badge/github/ome/napari-ome-zarr/main.svg)](https://results.pre-commit.ci/latest/github/ome/napari-ome-zarr/main)


A reader for zarr backed [OME-NGFF](https://ngff.openmicroscopy.org/) images.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

[Install napari] if not already installed.

You can install `napari-ome-zarr` via [pip]. Activate the same environment as you installed napari into, then:

    pip install napari-ome-zarr

## Usage

Napari will use `napari-ome-zarr` plugin to open images that the plugin recognises as ome-zarr.
The image metadata from OMERO will be used to set channel names and rendering settings
in napari::

    napari ""https://uk1s3.embassy.ebi.ac.uk/idr/zarr/v0.3/9836842.zarr/""


If a dialog in napari pops up, encouraging you to choose a reader, choose ``napari-ome-zarr`` and click OK. You can stop it happening with addition of ``--plugin napari-ome-zarr`` as in the example below.

To open a local file::

    napari --plugin napari-ome-zarr 13457227.zarr

OR in python::

    import napari

    viewer = napari.Viewer()
    viewer.open(""https://uk1s3.embassy.ebi.ac.uk/idr/zarr/v0.4/idr0101A/13457537.zarr"", plugin=""napari-ome-zarr"")

    napari.run()


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-ome-zarr"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[Install napari]: https://napari.org/stable/tutorials/fundamentals/installation.html
[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/ome/napari-ome-zarr/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/ome/napari-ome-zarr/issues', 'Documentation, https://github.com/ome/napari-ome-zarr#README.md', 'Source Code, https://github.com/ome/napari-ome-zarr', 'User Support, https://github.com/ome/napari-ome-zarr/issues', 'Twitter, https://twitter.com/openmicroscopy']",napari-ome-zarr.get_reader,,,,"['*.zarr', '*.zarr*']",,
323,napari-omero,napari-omero,napari-omero,0.5.1,2021-06-24,2025-05-15,Peter Sobolewski,"Talley Lambert <talley.lambert@gmail.com>, Will Moore <w.moore@dundee.ac.uk>, Johannes Soltwedel <johannes_richard.soltwedel@tu-dresden.de>",GPL-2.0-or-later,https://github.com/tlambert03/napari-omero,https://pypi.org/project/napari-omero/,,,napari/OMERO interoperability,>=3.9,"['dask[array]>=2021.10.0', 'napari>=0.5.0', 'omero-marshal', 'omero-py', 'omero-rois', 'qtpy>=1.10.0', 'superqt>=0.6.7', ""napari[all]; extra == 'all'"", ""ipython; extra == 'dev'"", ""mypy; extra == 'dev'"", ""napari[all]; extra == 'dev'"", ""pdbpp; extra == 'dev'"", ""pre-commit; extra == 'dev'"", ""pytest; extra == 'dev'"", ""pytest-cov; extra == 'dev'"", ""pytest-qt; extra == 'dev'"", ""pytest-regressions; extra == 'dev'"", ""pywin32; (sys_platform == 'win32') and extra == 'dev'"", ""rich; extra == 'dev'"", ""ruff; extra == 'dev'"", ""pytest; extra == 'test'"", ""pytest-cov; extra == 'test'"", ""pytest-qt; extra == 'test'"", ""pytest-regressions; extra == 'test'"", ""pywin32; (sys_platform == 'win32') and extra == 'test'""]","# napari-omero

[![License](https://img.shields.io/pypi/l/napari-omero.svg?color=green)](https://github.com/tlambert03/napari-omero/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-omero.svg?color=green)](https://pypi.org/project/napari-omero)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-omero.svg?color=green)](https://python.org)
[![CI](https://github.com/tlambert03/napari-omero/actions/workflows/ci.yml/badge.svg)](https://github.com/tlambert03/napari-omero/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/tlambert03/napari-omero/branch/main/graph/badge.svg)](https://codecov.io/gh/tlambert03/napari-omero)
[![conda-forge](https://img.shields.io/conda/vn/conda-forge/napari-omero)](https://anaconda.org/conda-forge/napari-omero)

This package provides interoperability between the
[OMERO](https://www.openmicroscopy.org/omero/) image management platform, and
[napari](https://github.com/napari/napari): a fast, multi-dimensional image
viewer for python.

It provides a GUI interface for browsing an OMERO instance from within napari,
as well as command line interface extensions for both OMERO and napari CLIs.

![demo](https://github.com/tlambert03/napari-omero/blob/master/demo.gif?raw=true)

## Features

- GUI interface to browse remote OMERO data, with thumbnail previews.
- Loads remote nD images from an OMERO server into napari
- Upload annotsations (``Labels`, `Shapes` and `Points`) to OMERO.
- Planes are loading on demand as sliders are moved (""lazy loading"").
- Loading of pyramidal images as napari multiscale layers
- session management (login memory)
- OMERO rendering settings (contrast limits, colormaps, active channels, current
  Z/T position) are applied in napari

> [!NOTE]
> The user experience when working with remote images, particularly large multiscale (pyramidal) ones, like whole slide images, can be significantly improved by using napari 0.5.0 or newer and enabling the experimental asynchronous mode (n the GUI in `Preferences > Experimental > Render Images Asynchronously` or with the environmental variable `NAPARI_ASYNC=1`).

### as a napari dock widget

To launch napari with the OMERO browser added, [install](#installation) this
package and run:

```bash
napari-omero
```

The OMERO browser widget can also be manually added to the napari viewer using the Plugins menu
or programmatically using:

```python
import napari

viewer = napari.Viewer()
viewer.window.add_plugin_dock_widget('napari-omero')

napari.run()
```

### as a napari reader contribution

This package provides a napari reader contribution that accepts OMERO resources as
""proxy strings"" (e.g. `omero://Image:<ID>`) or as [OMERO webclient
URLS](https://help.openmicroscopy.org/urls-to-data.html).

```python
import napari
viewer = napari.Viewer()

# omero object identifier string
viewer.open(""omero://Image:1"", plugin=""napari-omero"")

# or URLS: https://help.openmicroscopy.org/urls-to-data.html
viewer.open(""http://yourdomain.example.org/omero/webclient/?show=image-314"", plugin=""napari-omero"")
```

these will also work on the napari command line interface, e.g.:

```bash
# quotes are needed if using zsh
napari ""omero://Image:1""
# or
napari ""http://yourdomain.example.org/omero/webclient/?show=image-314""
```

### as an OMERO CLI plugin

This package also serves as a plugin to the OMERO CLI

```bash
omero napari view Image:1
```

- ROIs created in napari can be saved back to OMERO via a ""Save ROIs"" button.
- napari viewer console has BlitzGateway 'conn' and 'omero_image' in context.

## installation

While this package supports anything above python 3.9,
In practice, python support is limited by `omero-py` and `zeroc-ice`,
compatibility, which is limited to python <=3.12 at the time of writing.

### from conda

It's easiest to install `omero-py` from conda, so the recommended procedure
is to install everything from conda, using the `conda-forge` channel.
For example, to install the plugin, napari, and the default Qt backend, use:

```sh
conda install -c conda-forge napari-omero pyqt
```

### from pip

`napari-omero` itself can be installed from pip, but you will still need
`omero-py`

```sh
conda create -n omero -c conda-forge python=3.10 omero-py
conda activate omero
pip install napari-omero[all]  # the [all] here is the same as `napari[all]`
```

## issues

| â  | This is alpha software & some things will be broken or sub-optimal!  |
| --- | -------------------------------------------------------------------- |

- experimental & definitely still buggy!  [Bug
  reports](https://github.com/tlambert03/napari-omero/issues/new) are welcome!
- remote loading can be very slow still... though this is not strictly an issue
  of this plugin.  Datasets are wrapped as delayed dask stacks, and remote data
  fetching time can be significant.  Enabling [asynchronous
  rendering](https://napari.org/stable/guides/rendering.html#asynchronous-slicing) in
  napari improves the subjective performance... but remote data loading
  will likely always be a limitation here.
  To try asyncronous loading, start the program with `NAPARI_ASYNC=1 napari-omero`
  or look in the Preferences on the Experimental tab.
  Also, keep an eye on the [napari progressive loading implementation progress](https://github.com/napari/napari/issues/5561).
- For plugin developers: As napari-OMERO provides images as lazily-loaded [dask arrays](https://docs.dask.org/en/stable/array.html),
  napari-plugins need to account for this when retrieving data from napari layers.
  Keep in mind that forwarding the data to processing steps in plugins may lead to signficant loading
  and processing times.

## contributing

Contributions are welcome!  To get setup with a development environment:

```bash
# clone this repo:
git clone https://github.com/tlambert03/napari-omero.git
# change into the new directory
cd napari-omero
# create conda environment
conda env create -n napari-omero python=3.10 omero-py
# activate the new env
conda activate napari-omero

# install in editable mode with dev dependencies
pip install -e "".[dev]""      # quotes are needed on zsh
```

To maintain good code quality, this repo uses
[ruff](https://github.com/astral-sh/ruff),
[mypy](https://github.com/python/mypy).

To enforce code quality when you commit code, you can install pre-commit

```bash
# install pre-commit which will run code checks prior to commits
pre-commit install
```

The original OMERO data loader and CLI extension was created by [Will
Moore](https://github.com/will-moore).

The napari reader plugin and GUI browser was created by [Talley
Lambert](https://github.com/tlambert03/)

## release

To psuh a release to PyPI, one of the maintainers needs to do, for example:
```sh
git tag -a v0.2.0 -m v0.2.0
git push upstream --follow-tags
```
Then, the workflow should handle everything!
","['Development Status :: 4 - Beta', 'Environment :: X11 Applications :: Qt', 'Framework :: napari', 'Intended Audience :: Developers', 'Intended Audience :: Education', 'Intended Audience :: End Users/Desktop', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: GNU General Public License v2 or later (GPLv2+)', 'Natural Language :: English', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Information Analysis', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Software Development :: Libraries :: Python Modules', 'Topic :: Utilities', 'Typing :: Typed']","['homepage, https://github.com/tlambert03/napari-omero', 'repository, https://github.com/tlambert03/napari-omero']",napari-omero.get_reader,,napari-omero.widget,,['*omero*'],,
324,napari-openfibsem,napari-openfibsem,OpenFIBSEM Napari,0.1.5,2023-09-22,2024-02-01,Patrick Cleeve,patrick.cleeve@monash.edu,MIT,https://github.com/DeMarcoLab/napari-openfibsem/issues,https://pypi.org/project/napari-openfibsem/,,https://github.com/DeMarcoLab/napari-openfibsem,OpenFIBSEM Applications,>=3.9,"['fibsem >=0.3.2a1', 'autolamella >=0.3.2a1', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-openfibsem

[![License MIT](https://img.shields.io/pypi/l/napari-openfibsem.svg?color=green)](https://github.com/DeMarcoLab/napari-openfibsem/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-openfibsem.svg?color=green)](https://pypi.org/project/napari-openfibsem)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-openfibsem.svg?color=green)](https://python.org)
[![tests](https://github.com/DeMarcoLab/napari-openfibsem/workflows/tests/badge.svg)](https://github.com/DeMarcoLab/napari-openfibsem/actions)
[![codecov](https://codecov.io/gh/DeMarcoLab/napari-openfibsem/branch/main/graph/badge.svg)](https://codecov.io/gh/DeMarcoLab/napari-openfibsem)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-openfibsem)](https://napari-hub.org/plugins/napari-openfibsem)

OpenFIBSEM Applications

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-openfibsem` via [pip]:

    pip install napari-openfibsem



To install latest development version :

    pip install git+https://github.com/DeMarcoLab/napari-openfibsem.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-openfibsem"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/DeMarcoLab/napari-openfibsem/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/DeMarcoLab/napari-openfibsem/issues', 'Documentation, https://github.com/DeMarcoLab/napari-openfibsem#README.md', 'Source Code, https://github.com/DeMarcoLab/napari-openfibsem', 'User Support, https://github.com/DeMarcoLab/napari-openfibsem/issues']",,,napari-openfibsem.fibsem,,,,
325,napari-opt-handler,napari-opt-handler,OPT Preprocessing,0.0.3,2024-07-03,2024-07-03,"David Palecek, Giorgia Tortora","David Palecek <david@stanka.de>, Giorgia Tortora <giorgia.tortora@polimi.it>","Copyright (c) 2024, David Pale...",https://github.com/QBioImaging/napari-opt-handler/issues,https://pypi.org/project/napari-opt-handler/,,,Optical Projection Tomography preprocessing plugin for napari,>=3.9,"['numpy', 'magicgui', 'scikit-image', 'matplotlib', ""magicgui ; extra == 'napari'"", ""napari[pyqt5] ; extra == 'napari'"", ""pooch >=1 ; extra == 'napari'"", ""qtpy ; extra == 'napari'"", ""pre-commit ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""pytest-mock ; extra == 'testing'"", ""pytest-timeout ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-opt-handler

[![License BSD-3](https://img.shields.io/pypi/l/napari-opt-handler.svg?color=green)](https://raw.githubusercontent.com/QBioImaging/napari-opt-handler/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-opt-handler.svg?color=green)](https://pypi.org/project/napari-opt-handler)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-opt-handler.svg?color=green)](https://python.org)
[![tests](https://github.com/QBioImaging/napari-opt-handler/workflows/tests/badge.svg)](https://github.com/QBioImaging/napari-opt-handler/actions)
[![codecov](https://codecov.io/gh/QBioImaging/napari-opt-handler/branch/main/graph/badge.svg)](https://codecov.io/gh/QBioImaging/napari-opt-handler)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-opt-handler)](https://napari-hub.org/plugins/napari-opt-handler)

Optical Projection Tomography preprocessing plugin for napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

place for the gif
<img src="""" width=""700""/>

Jump to:
- [Usage](#usage)
  - [Starting point](#starting-point)
  - [Global settings](#settings)
  - [Corrections](#corrections)
  - [Other](#other)
- [Installation](#installation)
- [Troubleshooting installation](#troubleshooting-installation)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgements](#acknowledgements)

## ð Usage

### Starting point
1. Data streamed from ImSwitch OPT widget (see details here[LINK])
2. Loaded images as data stack
3. Other stack 3D volume data formats

### Global settings
Tracking

Inplace operations

### Corrections
Dark-field correction
Bright-field correction
Bad-pixel correction
Intensity correction

### Other
Binning
ROI
-Log

## ð» Installation

You can install `napari-opt-handler` via [pip]:

    pip install napari-opt-handler



To install latest development version :

    pip install git+https://github.com/QBioImaging/napari-opt-handler.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## ð License

Distributed under the terms of the [BSD-3] license,
""napari-opt-handler"" is free and open source software

## ð¨ Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/QBioImaging/napari-opt-handler/issues
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/QBioImaging/napari-opt-handler/issues', 'Documentation, https://github.com/QBioImaging/napari-opt-handler#README.md', 'Source Code, https://github.com/QBioImaging/napari-opt-handler', 'User Support, https://github.com/QBioImaging/napari-opt-handler/issues']",,,napari-opt-handler.make_qtwidget,napari-opt-handler.make_sample_data,,,
326,napari-patchcreator,napari-patchcreator,napari patch creator,0.1.4,2022-08-23,2022-08-24,Tom Burke,burke@mpi-cbg.de,BSD-3-Clause,https://github.com/juglab/napari-patchcreator/issues,https://pypi.org/project/napari-patchcreator/,,https://github.com/juglab/napari-patchcreator,A simple plugin to use with napari,>=3.8,"['numpy', 'napari', 'napari-plugin-engine (>=0.1.4)', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-patchcreator

[![License BSD-3](https://img.shields.io/pypi/l/napari-patchcreator.svg?color=green)](https://github.com/juglab/napari-patchcreator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-patchcreator.svg?color=green)](https://pypi.org/project/napari-patchcreator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-patchcreator.svg?color=green)](https://python.org)
[![tests](https://github.com/juglab/napari-patchcreator/workflows/tests/badge.svg)](https://github.com/juglab/napari-patchcreator/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-patchcreator)](https://napari-hub.org/plugins/napari-patchcreator)

A simple plugin to create quadratic patches from images through selection and clicking with the left mouse button.
The patches can then be exported to a folder of your own choosing.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-patchcreator` via [pip]:

    pip install napari-patchcreator



To install latest development version :

    pip install git+https://github.com/juglab/napari-patchcreator.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-patchcreator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/juglab/napari-patchcreator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 5 - Production/Stable', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/juglab/napari-patchcreator/issues', 'Documentation, https://github.com/juglab/napari-patchcreator#README.md', 'Source Code, https://github.com/juglab/napari-patchcreator', 'User Support, https://github.com/juglab/napari-patchcreator/issues']",,,napari-patchcreator.make_patch_widget,,,,
327,napari-parallel,napari-parallel,Napari Parallel,0.0.2,2023-09-20,2023-09-24,"Artem Tomilo, Nafisa Anjum, Himanshu Kaloni",artem.tomilo@mailbox.tu-dresden.de,BSD-3-Clause,,https://pypi.org/project/napari-parallel/,None,,Plugin to process images in parallel using several computers,>=3.8,"['numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-parallel

This plugin is used for parallel computing of image processing using the code
generation capabilities of the `napari-assistant` plugin and the distributed
computing library `dask`.

[![License BSD-3](https://img.shields.io/pypi/l/napari-parallel.svg?color=green)](https://github.com/bridgeArchitect/napari-parallel/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-parallel.svg?color=green)](https://pypi.org/project/napari-parallel)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-parallel.svg?color=green)](https://python.org)
[![tests](https://github.com/bridgeArchitect/napari-parallel/workflows/tests/badge.svg)](https://github.com/bridgeArchitect/napari-parallel/actions)
[![codecov](https://codecov.io/gh/bridgeArchitect/napari-parallel/branch/main/graph/badge.svg)](https://codecov.io/gh/bridgeArchitect/napari-parallel)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-parallel)](https://napari-hub.org/plugins/napari-parallel)

Plugin to process images in parallel using several computers

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-parallel` via [pip]:

    pip install napari-parallel


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-parallel"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-parallel.get_reader,napari-parallel.write_multiple,napari-parallel.make_qwidget,napari-parallel.make_sample_data,['*.npy'],,['.npy']
328,napari-phasors,napari-phasors,Napari Phasors,0.0.5,2024-11-22,2025-08-01,"Bruno Pannunzio, Marcelo L. Zoccoler, Bruno Schuty, Leonel Malacrida","bpannunzio@pasteur.edu.uy, marzoccoler@gmail.com, schutyb@schutyb.com, lmalacrida@pasteur.edu.uy",BSD-3-Clause,https://github.com/napari-phasors/napari-phasors/issues,https://pypi.org/project/napari-phasors/,,https://github.com/napari-phasors/napari-phasors,A simple plugin to use phasor analysis,>=3.11,"['phasorpy==0.6', 'qtpy', 'scikit-image', 'biaplotter>=0.4.2', 'lfdfiles', 'sdtfile', 'ptufile', 'tifffile', 'pandas', 'pyqt5', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'qtpy; extra == ""testing""', 'scikit-image; extra == ""testing""', 'biaplotter>=0.2.0; extra == ""testing""', 'PyQt5; extra == ""testing""', 'pandas; extra == ""testing""', 'black; extra == ""testing""', 'isort; extra == ""testing""', 'phasorpy==0.6; extra == ""testing""', 'tifffile; extra == ""testing""', 'lfdfiles; extra == ""testing""', 'sdtfile; extra == ""testing""', 'ptufile; extra == ""testing""']","# napari-phasors

[![License BSD-3](https://img.shields.io/pypi/l/napari-phasors.svg?color=green)](https://github.com/napari-phasors/napari-phasors/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-phasors.svg?color=green)](https://pypi.org/project/napari-phasors)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-phasors.svg?color=green)](https://python.org)
[![tests](https://github.com/napari-phasors/napari-phasors/workflows/tests/badge.svg)](https://github.com/napari-phasors/napari-phasors/actions)
[![codecov](https://codecov.io/gh/napari-phasors/napari-phasors/branch/main/graph/badge.svg)](https://codecov.io/gh/napari-phasors/napari-phasors)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-phasors)](https://napari-hub.org/plugins/napari-phasors)

A simple plugin to do phasor analysis in napari. Based on the [phasorpy](https://www.phasorpy.org/) library.

[Jump to Intallation](#installation)

----------------------------------

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Usage

napari-phasors is composed of a few widgets that allow reading a few specific FLIM and hyperspectral file formats, perform phasor analysis, and display and export the results of manual phasor selections.

### Sample Data

Two sample datasets for FLIM are provided, along with their corresponding calibration images. Additionally, a paramecium image is included as sample data for hyperspectral analysis.

![sample_data](https://github.com/napari-phasors/napari-phasors/raw/main/gifs/sample_data.gif)

### Phasor Analysis

#### Plot FLIM Data

FLIM phasor data can be plotted as a 2D histogram or scatter plot. The colormap, the number of bins and the scale of the colors can be customized.
Filtering and thresholding can also be applied to process phasor data and the mean intensity image. 

![phasors_flim](https://github.com/napari-phasors/napari-phasors/raw/main/gifs/phasors_flim.gif)

#### Plot Hyperspectral Data

Hyperspectral phasor data can also be plotted as a 2D histogram or scatter plot and visualized in the full universal circle.

![phasors_hyperspectral](https://github.com/napari-phasors/napari-phasors/raw/main/gifs/phasors_hyperspectral.gif)

### Apparent Lifetime Display

A FLIM image can be colormapped according to the phase or modulation apparent lifetime. A histogram is also created for visualization of the distribution of apparent lifetimes of the FLIM image.

![lifetimes](https://github.com/napari-phasors/napari-phasors/raw/main/gifs/lifetimes.gif)

### Phasor Calibration

FLIM images can be calibrated using a reference image acquired under the same experimental parameters. This reference image should consist of a homogeneous solution of a fluorophore with a known fluorescence lifetime and the laser frequency used in the experiment. This ensures accuracy and consistency in lifetime measurements.

![calibration](https://github.com/napari-phasors/napari-phasors/raw/main/gifs/calibration.gif)

### Phasor Custom Import

Supported file formats (`.tif`, `.ptu`, `.sdt`, `.fbd`, `.lsm`, `.ome.tif`) can be read and transformed to the phasor space. Additional options, such as the harmonics, channels and frames, can be specified depending on the file format to be read.

![custom_import](https://github.com/napari-phasors/napari-phasors/raw/main/gifs/custom_import.gif)

### Phasor Export

The average intensity image and the phasor coordinates can be exported as OME-TIF files that can be read by napari-phasors and PhasorPy. Alternatively, the phasor coordinates, as well as the selections (cursors) can be exported as a CSV file.

![export_phasors](https://github.com/napari-phasors/napari-phasors/raw/main/gifs/export_phasors.gif)

## Installation

You can install `napari-phasors` via [pip]. Follow these steps from a terminal.

We recommend using `miniforge` whenever possible. Click [here](https://github.com/conda-forge/miniforge?tab=readme-ov-file#miniforge) to choose the right download option for your OS.
**If you do not use `miniforge`, but rather Anaconda or Miniconda, replace the `mamba` term whenever you see it below with `conda`.**

Create a conda environment with napari by typing :

    mamba create -n napari-phasors-env napari pyqt python=3.10
    
Activate the environment :

    mamba activate napari-phasors-env

Install `napari-phasors` via [pip] :

    pip install napari-phasors

Alternatively, install latest development version with :

    pip install git+https://github.com/napari-phasors/napari-phasors.git

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-phasors"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/napari-phasors/napari-phasors/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/napari-phasors/napari-phasors/issues', 'Documentation, https://github.com/napari-phasors/napari-phasors#README.md', 'Source Code, https://github.com/napari-phasors/napari-phasors', 'User Support, https://github.com/napari-phasors/napari-phasors/issues']",napari-phasors.get_reader,napari-phasors.write_ome_tiff,napari-phasors.PhasorTransform,napari-phasors.convallaria_FLIM_sample_data,"['*.fbd', '*.ptu', '*.lsm', '*ome.tif', '*.tif', '*.sdt']",,
329,napari-organoid-counter,napari-organoid-counter,napari organoid counter,0.2.5,2022-04-13,2024-12-05,christinab12,christina.bukas@helmholtz-muenchen.de,MIT,https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/issues,https://pypi.org/project/napari-organoid-counter/,,https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter,A plugin to automatically count lung organoids using Deep Learning.,"<3.11,>=3.9","['napari[all]<0.5.0,>=0.4.17', 'napari-aicsimageio>=0.7.2', 'torch>=2.3.1', 'torchvision>=0.18.1', 'openmim', 'mmengine>=0.10.4', 'mmdet>=3.3.0', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# Napari Organoid Counter - Version 0.2 is out! 

[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-organoid-counter)](https://napari-hub.org/plugins/napari-organoid-counter)
![stability-stable](https://img.shields.io/badge/stability-stable-green.svg)
[![DOI](https://zenodo.org/badge/476715320.svg)](https://zenodo.org/badge/latestdoi/476715320)
[![License](https://img.shields.io/pypi/l/napari-organoid-counter.svg?color=green)](https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-organoid-counter.svg?color=green)](https://pypi.org/project/napari-organoid-counter)
[![Python Version](https://img.shields.io/badge/python-3.9%20%7C%203.10-blue)](https://python.org)
[![tests](https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/workflows/tests/badge.svg)](https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/actions)
[![codecov](https://codecov.io/gh/HelmholtzAI-Consultants-Munich/napari-organoid-counter/branch/main/graph/badge.svg)](https://codecov.io/gh/HelmholtzAI-Consultants-Munich/napari-organoid-counter)


A napari plugin to automatically count lung organoids from microscopy imaging data. Note: this plugin only supports single channel grayscale images.

***Hold it for the demo!***

![Alt Text](https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/blob/main/readme-content/demo-plugin-v2.gif)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


## Installation

This plugin has been tested with python 3.9 and 3.10 - you may consider using conda to create your dedicated environment before running the `napari-organoid-counter`.

1. You can install `napari-organoid-counter` via [pip](https://pypi.org/project/napari-organoid-counter/):

    ``` pip install napari-organoid-counter```

   To install latest development version :

    ```pip install git+https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter.git```

2. Additionally, you will then need to install one additional dependency:

     ``` mim install ""mmcv<2.2.0,>=2.0.0rc4"" ```

For installing on a Windows machine directly from within napari, follow the instuctions [here](https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/blob/main/readme-content/How%20to%20install%20on%20a%20Windows%20machine.pdf). Step 2 additionally needs to be performed here too (mim install ""mmcv<2.2.0,>=2.0.0rc4"").

## What's new in v2?
Checkout our *What's New in v2* [here](https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/blob/main/.napari/DESCRIPTION.md#whats-new-in-v2).

## How to use?
After installing, you can start napari (either by typing ```napari``` in your terminal or by launching the application) and select the plugin from the drop down menu.

For more information on this plugin, its' intended audience, as well as Quickstart guide go to our [Quickstart guide](https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/blob/main/.napari/DESCRIPTION.md#quickstart).

## Contributing

Contributions are very welcome. Tests can be run with [pytest], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-organoid-counter"" is free and open source software

## Dependencies


```napari-organoid-counter``` uses the ```napari-aicsimageio```<sup>[1]</sup> <sup>[2]</sup> plugin for reading and processing CZI images.

[1] Eva Maxfield Brown, Dan Toloudis, Jamie Sherman, Madison Swain-Bowden, Talley Lambert, AICSImageIO Contributors (2021). AICSImageIO: Image Reading, Metadata Conversion, and Image Writing for Microscopy Images in Pure Python [Computer software]. GitHub. https://github.com/AllenCellModeling/aicsimageio

[2] Eva Maxfield Brown, Talley Lambert, Peter Sobolewski, Napari-AICSImageIO Contributors (2021). Napari-AICSImageIO: Image Reading in Napari using AICSImageIO [Computer software]. GitHub. https://github.com/AllenCellModeling/napari-aicsimageio

The latest version also uses models developed with the ```mmdetection``` package <sup>[3]</sup>, see [here](https://github.com/open-mmlab/mmdetection)

[3] Chen, Kai, et al. ""MMDetection: Open mmlab detection toolbox and benchmark."" arXiv preprint arXiv:1906.07155 (2019).

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/issues

[napari]: https://github.com/napari/napari
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

## Citing

If you use this plugin for your work, please cite it using the following:

> Christina Bukas, Harshavardhan Subramanian, & Marie Piraud. (2023). HelmholtzAI-Consultants-Munich/napari-organoid-counter: v0.2.0 (v0.2.0). Zenodo. https://doi.org/10.5281/zenodo.7859571
> 
bibtex:
```
@software{christina_bukas_2022_6457904,
  author       = {Christina Bukas, Harshavardhan Subramanian, & Marie Piraud},
  title        = {{HelmholtzAI-Consultants-Munich/napari-organoid- 
                   counter: second release of the napari plugin for lung
                   organoid counting}},
  month        = apr,
  year         = 2023,
  publisher    = {Zenodo},
  version      = {v0.2.0},
  doi          = {10.5281/zenodo.7859571},
  url          = {https://doi.org/10.5281/zenodo.7859571}
}
```

","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/issues', 'Documentation, https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter#README.md', 'Source Code, https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter', 'User Support, https://github.com/HelmholtzAI-Consultants-Munich/napari-organoid-counter/issues']",napari-organoid-counter.get_reader,,napari-organoid-counter.OrganoidCounterWidget,,['*.json'],,
330,napari-owncloud,napari-owncloud,napari-owncloud,0.1.2,2022-11-16,2022-11-19,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-owncloud/issues,https://pypi.org/project/napari-owncloud/,,https://github.com/haesleinhuepf/napari-owncloud,Browse folders and images in owncloud / nextcloud servers and open them using just a double-click!,>=3.8,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari-tools-menu', 'pyocclient']","# napari-owncloud

[![License](https://img.shields.io/pypi/l/napari-owncloud.svg?color=green)](https://github.com/haesleinhuepf/napari-owncloud/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-owncloud.svg?color=green)](https://pypi.org/project/napari-owncloud)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-owncloud.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-owncloud/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-owncloud/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-owncloud/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-owncloud)

## Usage

Browse folders and images in [owncloud](https://owncloud.com/) / [nextcloud](https://nextcloud.com/) servers and open them using just a double-click! 

Login to an owncloud or nextcloud server by clicking the menu `Tools > Utilities > Browse owncloud / nextcloud storage`

![](https://github.com/haesleinhuepf/napari-owncloud/raw/main/docs/login.png)

You can then navigate through folders by double-clicking `folder/` items in the list.
You can also open images by double-clicking them. Alternatively, use the arrow-up and arrow-down key to navigate the list and hit ENTER to open an image or folder.

![](https://github.com/haesleinhuepf/napari-owncloud/raw/main/docs/browse.png)

Store images in your cloud storage using the button `Save / upload current layer`. Note: Currently, only single selected layers can be saved.

![](https://github.com/haesleinhuepf/napari-owncloud/raw/main/docs/upload.png)

[Demo](https://github.com/haesleinhuepf/napari-owncloud/raw/main/docs/demo.mp4)

![](https://github.com/haesleinhuepf/napari-owncloud/raw/main/docs/demo.gif)

## Installation

You can install `napari-owncloud` via [pip]:

    pip install napari-owncloud

## Related plugins

There are other napari plugins that allow you browsing local and online image storage
* [napari-omero](https://www.napari-hub.org/plugins/napari-omero)
* [napari-folder-browser](https://www.napari-hub.org/plugins/napari-folder-browser)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-owncloud"" is free and open source software

## Issues

If you encounter any problems, please create a thread on [image.sc] along with a detailed description and tag [@haesleinhuepf].

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-owncloud/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[image.sc]: https://image.sc
[@haesleinhuepf]: https://twitter.com/haesleinhuepf

","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-owncloud/issues', 'Documentation, https://github.com/haesleinhuepf/napari-owncloud#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-owncloud', 'User Support, https://github.com/haesleinhuepf/napari-owncloud/issues']",,,napari-owncloud.OwncloudBrowser,,,,
331,napari-pdr-reader,napari-pdr-reader,PDS reader plugin for Napari,0.0.1,2022-07-14,2022-07-14,Dr. Andrew Annex,ama6fy@virginia.edu,BSD-3-Clause,https://github.com/AndrewAnnex/napari-pdr-reader/issues,https://pypi.org/project/napari-pdr-reader/,,https://github.com/AndrewAnnex/napari-pdr-reader,A reader plugin for Napari for PDS data powered by the PDR library,>=3.9,"['astropy', 'dustgoggles', 'napari', 'numpy', 'pandas', 'pdr', 'pds4-tools', 'pillow', 'pvl', ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-pdr-reader

[![License BSD-3](https://img.shields.io/pypi/l/napari-pdr-reader.svg?color=green)](https://github.com/AndrewAnnex/napari-pdr-reader/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-pdr-reader.svg?color=green)](https://pypi.org/project/napari-pdr-reader)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-pdr-reader.svg?color=green)](https://python.org)
[![tests](https://github.com/AndrewAnnex/napari-pdr-reader/workflows/tests/badge.svg)](https://github.com/AndrewAnnex/napari-pdr-reader/actions)
[![codecov](https://codecov.io/gh/AndrewAnnex/napari-pdr-reader/branch/main/graph/badge.svg)](https://codecov.io/gh/AndrewAnnex/napari-pdr-reader)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-pdr-reader)](https://napari-hub.org/plugins/napari-pdr-reader)

A reader plugin for Napari for PDS data powered by the PDR library

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-pdr-reader` via [pip]:

    pip install napari-pdr-reader



To install latest development version :

    pip install git+https://github.com/AndrewAnnex/napari-pdr-reader.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-pdr-reader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/AndrewAnnex/napari-pdr-reader/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/AndrewAnnex/napari-pdr-reader/issues', 'Documentation, https://github.com/AndrewAnnex/napari-pdr-reader#README.md', 'Source Code, https://github.com/AndrewAnnex/napari-pdr-reader', 'User Support, https://github.com/AndrewAnnex/napari-pdr-reader/issues']",napari-pdr-reader.get_reader,,,napari-pdr-reader.get_m2020_data,"['*.fits', '*.FITS', '*.lbl', '*.img', '*.LBL', '*.IMG']",,
332,napari-pdf-reader,napari-pdf-reader,napari-pdf-reader,0.0.1a3,2021-11-05,2021-11-05,Daniel Krentzel,dkrentzel@pm.me,MIT,https://github.com/krentzd/napari-pdf-reader/issues,https://pypi.org/project/napari-pdf-reader/,,https://github.com/krentzd/napari-pdf-reader,Reader for PDF files,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'pillow', 'pdf2image']","# PDF reader for napari
Reads PDF files into napari


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/krentzd/napari-pdf-reader/issues', 'Documentation, https://github.com/krentzd/napari-pdf-reader#README.md', 'Source Code, https://github.com/krentzd/napari-pdf-reader', 'User Support, https://github.com/krentzd/napari-pdf-reader/issues']",napari-pdf-reader.napari_get_reader,,,,['*'],,
333,napari-philow,napari-PHILOW,napari-PHILOW,0.2.0,2022-05-02,2024-05-20,Hiroki Kawai,h.kawai888@gmail.com,GPLv3,https://github.com/neurobiology-ut/PHILOW/issues,https://pypi.org/project/napari-PHILOW/,,https://github.com/neurobiology-ut/PHILOW,PHILOW is an interactive deep learning-based platform for 3D datasets,>=3.8,"['numpy', 'scikit-image', 'dask-image', 'opencv-python', 'matplotlib', 'pandas', 'torch', 'torchvision', 'segmentation-models-pytorch', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-PHILOW

[![License](https://img.shields.io/pypi/l/napari-PHILOW.svg?color=green)](https://github.com/neurobiology-ut/PHILOW/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-PHILOW.svg?color=green)](https://pypi.org/project/napari-PHILOW)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-PHILOW.svg?color=green)](https://python.org)
[![tests](https://github.com/neurobiology-ut/napari-PHILOW/workflows/tests/badge.svg)](https://github.com/neurobiology-ut/PHILOW/actions)
[![codecov](https://codecov.io/gh/neurobiology-ut/napari-PHILOW/branch/main/graph/badge.svg)](https://codecov.io/gh/neurobiology-ut/PHILOW)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-PHILOW)](https://napari-hub.org/plugins/napari-PHILOW)

# PHILOW <br>
***P***ython-based platform for ***h***uman-***i***n-the-***lo***op (HITL)  ***w***orkflow (PHILOW) <br>

PHILOW is an interactive deep learning-based platform for 3D datasets implemented on top of [napari](https://github.com/napari/napari)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

Install napari and Pytorch first.   
See [napari] and [Pytorch](https://pytorch.org/) for more information.

You can install `napari-PHILOW` via [pip]:

    pip install napari-PHILOW
    
or clone this repository   
then
```angular2
cd PHILOW
pip install -e .
```
    

## Usage

Launch napari 

```angular2
napari
```


#### load dataset


1) Plugins > napari-PHILOW > Annotation Mode

2) Select original dir : all slices must be in separate 8bit PNG and must be sequentially numbered (e.g. 000.png, 001.png ...)

3) Select mask dir : To resume from the middle of the annotation, specify here the name of the directory containing the mask image. The directory must contain the same number of files with the same name as the original image.   
 If you are starting a completely new annotation, you do not need to specify a directory. The directory for mask is automatically created and blank images are generated and stored.

4) Enter a name for the label or model you want to create (e.g. mito, cristae, ...)   
This name will be used as the directory name of the newly created mask dir if no mask dir is specified, 
and as the name of the csv file for training dataset management.

5) Check if you want to create new dataset (new model)
When checked, if there is already a csv file for training dataset management, a new csv file with one sequential number will be generated.

6) Start tracing


#### create labels
Create a label with the brush function.
more information â https://napari.org/tutorials/fundamentals/labels.html

#### Orthogonal view
If you want to see orthogonal view, click on the location you want to see while holding down the Shift button.    
The image from xy, yz, and zx will be displayed on the right side of the screen.

#### Low confident layer
If you are in the second iteration and you are loading the prediction results, you will see a low confidence layer.    
This shows the area where the confidence of the prediction result is low.    
Use this as a reference for correction.   

#### Small object layer
We provide a small object layer to find small painted areas.   
This is a layer for displaying small objects.   
The slider widget on the left allows you to change the maximum object size to be displayed.   

#### save labels
If you want to save your label, click the ""save"" button on the bottom right.

#### select training dataset
We are providing a way to manage the dataset for use in training.   
If you want to use the currently displayed slice as your training data, click the 'Not Checked' button near the center left to display 'Checked'.


### Train and pred with your gpu machine
#### Train
To train on your GPU machine (or with CPU), 

1) Plugins > napari-PHILOW > Trainer
   
2) Select original dir : all slices must be in separate 8bit PNG and must be sequentially numbered (e.g. 000.png, 001.png ...)   
   
3) Select labels dir : all label images should be named same as original images and contains data management csv file   
   
4) Select dir for save trained model   
   
5) Click on the ""start training"" button   

6) Dice score and dice loss are displayed. For more detail, check the command line for the progress of training. If you want to stop in the middle, click stop button.   

##### IF YOU WANT TO SEGMENT CRISTAE AREA IN THE EM DATASET

1) Plugins > napari-PHILOW > Trainer

2) Click on the ""Cristae segmentation mode"" button   

3) Select original dir : all slices must be in separate PNG and must be sequentially numbered (e.g. 000.png, 001.png ...)  

4) Select mito mask dir : all label images should be named same as original images

5) Select dir for save trained model  

6) Select cristae labels dir : all label images should be named same as original images and contains data management csv file  

7) Click on the ""start training"" button   

8) Dice score and dice loss are displayed. For more detail, check the command line for the progress of training. If you want to stop in the middle, click stop button.   
   
#### Predict
To predict labels on your machine,  

1) Plugins > napari-PHILOW > Predicter
   
2) Select original dir : all slices must be in separate 8bit PNG and must be sequentially numbered (e.g. 000.png, 001.png ...)   
   
3) (Optional) Select labels dir if you want to keep labels witch were used on training, and data management csv file   
   
4) Select model dir contains hdf5 file   
   
5) Select output dir for predicted labels   

6) Uncheck the box if you DO NOT want to use TAP (Three-Axis-Prediction)   
   
7) Click on the ""predict"" button  

8) Check the command line for the progress of prediction. If you want to stop in the middle, use ctrl+C.   

9) You can start the next round of annotation by selecting the merged_prediction directory as the mask dir in Annotation mode.

##### IF YOU WANT TO SEGMENT CRISTAE AREA IN THE EM DATASET

1) Plugins > napari-PHILOW > Predicter

2) Select original dir : all slices must be in separate PNG and must be sequentially numbered (e.g. 000.png, 001.png ...)   

3) (Optional) Select cristae labels dir if you want to keep labels witch were used on training, and data management csv file  

4) Select model dir contains hdf5 file   

5) Select output dir for predicted labels   

6) Uncheck the box if you DO NOT want to use TAP (Three-Axis-Prediction)   

7) Click on the ""Use cristae inference mode"" button   

8) Select mitochondria mask dir : all label images should be named same as original images

9) Click on the ""predict"" button  

10) Check the command line for the progress of prediction. If you want to stop in the middle, use ctrl+C.   

11) You can start the next round of annotation by selecting the merged_prediction directory as the mask dir in Annotation mode.

### Train and predict with Google Colab   
If you don't have a GPU machine, you can use Google Colab to perform GPU-based training and prediction for free.    

1) Open [train and predict notebook](https://github.com/neurobiology-ut/PHILOW/blob/develop/notebooks/train_and_pred_using_PHILOW.ipynb) and click ""Open in Colab"" button

2) You can upload your own dataset to train and predict, or try it on demo data   


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-PHILOW"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

# Authors <br>

Shogo Suga <br>
Hiroki Kawai <br>
<a href=""http://park.itc.u-tokyo.ac.jp/Hirabayashi/WordPress/"">Yusuke Hirabayashi</a> 


# How to Cite <br>
Shogo Suga, Koki Nakamura, Yu Nakanishi, Bruno M Humbel, Hiroki Kawai, Yusuke Hirabayashi, An interactive deep learning-based approach reveals mitochondrial cristae topologies. PLoS Biol 21(8): e3002246.
<a href=""https://doi.org/10.1371/journal.pbio.3002246"">https://doi.org/10.1371/journal.pbio.3002246</a>


```
@article {Suga_Nakamura_Nakanishi_Humbel_Kawai_Hirabayashi_2023,
	title={An interactive deep learning-based approach reveals mitochondrial cristae topologies},
	volume={21},
	ISSN={1545-7885},
	DOI={10.1371/journal.pbio.3002246},
	number={8},
	journal={PLOS Biology},
	publisher={Public Library of Science},
	author={Suga, Shogo and Nakamura, Koki and Nakanishi, Yu and Humbel, Bruno M. and Kawai, Hiroki and Hirabayashi, Yusuke},
	year={2023},
	month={Aug},
	pages={e3002246},
	language={en}
}
```

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/neurobiology-ut/PHILOW/issues', 'Documentation, https://github.com/neurobiology-ut/PHILOW#README.md', 'Source Code, https://github.com/neurobiology-ut/PHILOW', 'User Support, https://github.com/neurobiology-ut/PHILOW/issues']",,,napari-PHILOW.AnnotationMode,,,,
334,napari-pitcount-cfim,napari-pitcount-cfim,napari-pitcount-cfim,1.0.0,2025-04-24,2025-06-04,Markus L. Bille,github+markus@bille.dk,BSD-3-Clause,https://github.com/MaxusTheOne/napari-pitcount-cfim,https://pypi.org/project/napari-pitcount-cfim/,,https://github.com/MaxusTheOne/napari-pitcount-cfim,A pipeline for stuff #TODO: Get knowledge to write a proper description Pitcount,>=3.9,"['QtPy', 'pydantic', 'xmltodict', 'napari-czi-reader', 'aicsimageio', 'aicspylibczi', 'czifile', 'matplotlib', 'adjustText', 'cellpose<4.0.0', 'tensorflow', 'joblib', 'torch', 'torchvision', 'napari[all]; extra == ""napari""', 'pytest; extra == ""test""', 'pytest-cov; extra == ""test""', 'pytest-qt; extra == ""test""', 'codecov; extra == ""test""', 'napari[all]; extra == ""dev""', 'pytest; extra == ""dev""', 'pytest-cov; extra == ""dev""', 'pytest-qt; extra == ""dev""', 'codecov; extra == ""dev""']","# napari-pitcount-cfim

## License
BSD 3-Clause

## About
This napari plugin was developed in partnership with CFIM (Centre for Microscopy and Image Analysis, Copenhagen University).

The plugin enables image analysis for microscopy, focused on identifying pits and segmenting cells, then generating detailed statistics. It is tailored for using `.czi` files and integrates well with the [`napari-czi-reader`](https://github.com/MaxusTheOne/napari-czi-reader).

For training the VGG19 2_2 Ã Random Forest Classifier used in this plugin, visit the [pitcount-ml-training](https://github.com/MaxusTheOne/pitcount-ml-training) repository.

## Features
- Detects pits in images using a trained `torchvision` model.
- Performs cell segmentation via Cellpose (default model: `cyto3`).
- Calculates and outputs statistics such as:
  - Total cell count
  - Total pit count
  - Percentage of cells containing pits
  - Average number of pits per cell

## Usage

### Graphical Mode (GUI)
You can launch the plugin in napari with:
```bash
napari-pitcount-cfim --dev
```
or open napari and activate the plugin manually.
## Headless Mode (NO GUI)
```bash
napari-pitcount-cfim --no-gui 
```
Run --help to list all options:
```bash
napari-pitcount-cfim --no-gui -h
```
## Command-Line Arguments
| Argument            | Alias | Type      | Description                                                                            |
| ------------------- | ----- | --------- | -------------------------------------------------------------------------------------- |
| `--no-gui`          |       | flag      | Runs the pipeline without GUI. Required for headless automation.                       |
| `--dev`             |       | flag      | Launches napari in developer mode for plugin debugging.                                |
| `--verbosity`       | `-v`  | int (0â2) | Sets the level of console output. Default: `0`.                                        |
| `--input-folder`    | `-i`  | str       | Input directory for image data (required with `--no-gui`).                             |
| `--output-folder`   | `-o`  | str       | Directory to save results. Default: `'output'`.                                        |
| `--pit-mask-folder` | `-p`  | path      | If specified, skips pit prediction and uses this directory for pit masks.              |
| `--save-raw-data`   |       | flag      | Saves raw, unprocessed data to the output folder (only in `--no-gui` mode).            |
| `--family-grouping` |       | str       | Grouping method for output: `default`, `file`, `folder`, or `all`. Default: `default`. |

## Notes
- --input-folder must be used with --no-gui.

- --pit-mask-folder must be a valid existing directory.

- Set environment variables are used internally to control behavior.

## Requirements
Napari recommends installing napari seperately, as it is not included in this package. You can install it with:
```bash
pip install napari[all]
```
Or you can just
```bash
pip install napari-pitcount-cfim[napari]
```

## Known Issues
- The plugin might not support the formats of most model output.
- It's not possible to link masks directly to images in the GUI.
- The default pit model, is a stub and mostly for decoration.









","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-pitcount-cfim.Init,,,,
335,napari-pixel-correction,napari-pixel-correction,Pixel correction,0.1.4,2022-09-19,2022-09-21,Herearii Metuarea,herearii.metuarea@gmail.com,BSD-3-Clause,https://github.com/hereariim/napari-pixel-correction/issues,https://pypi.org/project/napari-pixel-correction/,,https://github.com/hereariim/napari-pixel-correction,Plugin to correct manually pixel wrongly predicted on image by annotation,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'napari', 'matplotlib', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-pixel-correction

[![License BSD-3](https://img.shields.io/pypi/l/napari-pixel-correction.svg?color=green)](https://github.com/hereariim/napari-pixel-correction/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-pixel-correction.svg?color=green)](https://pypi.org/project/napari-pixel-correction)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-pixel-correction.svg?color=green)](https://python.org)
[![tests](https://github.com/hereariim/napari-pixel-correction/workflows/tests/badge.svg)](https://github.com/hereariim/napari-pixel-correction/actions)
[![codecov](https://codecov.io/gh/hereariim/napari-pixel-correction/branch/main/graph/badge.svg)](https://codecov.io/gh/hereariim/napari-pixel-correction)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-pixel-correction)](https://napari-hub.org/plugins/napari-pixel-correction)

Plugin to correct manually pixel wrongly predicted on image by annotation

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

This plugin allows you to manually correct the images of the apple tree flowers by annotation. Below, a piece of an image shows the predicted pixels (in brown). A pixel in brown is assigned to the flower class. We can see that the brown colour does not necessarily cover a flower in this image.

![Capture dâÃ©cran 2022-09-21 152404](https://user-images.githubusercontent.com/93375163/191530483-5ce230af-e34c-4fd5-ab91-1d611fd774d1.png)

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-pixel-correction` via [pip]:

    pip install napari-pixel-correction



To install latest development version :

    pip install git+https://github.com/hereariim/napari-pixel-correction.git

## How does it work

First, you need a compressed file (in .zip format) were you have all your images. For a compressed file named as `input.zip`, the compressed file should be built like :

```
.
âââ input.zip
    âââ repository
        âââ image
        â   âââ im_1.JPG
        â   âââ im_2.JPG  
        â   âââ im_3.JPG
        â   ...
        â   âââ im_n.JPG
        â
        âââ mask
            âââ im_1_mask.JPG
            âââ im_2_mask.JPG
            âââ im_3_mask.JPG
            ...
            âââ im_n_mask.JPG
```
In repository, each image folder should have two elements : image in RGB and the segmented mask in binary image (where no-flower class is 0 and flower class is 255)

![napari-tutorial_simple](https://user-images.githubusercontent.com/93375163/191527225-47ba8667-e3bd-467b-b5f3-f8f7d97617a5.gif)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-pixel-correction"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hereariim/napari-pixel-correction/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/hereariim/napari-pixel-correction/issues', 'Documentation, https://github.com/hereariim/napari-pixel-correction#README.md', 'Source Code, https://github.com/hereariim/napari-pixel-correction', 'User Support, https://github.com/hereariim/napari-pixel-correction/issues']",napari-pixel-correction.get_reader,napari-pixel-correction.write_multiple,napari-pixel-correction.load,,['*.npy'],,['.npy']
336,napari-pixseq,napari-PixSeq,PixSeq,1.0.3,2024-02-29,2024-05-21,Piers Turner,piers.turner@physics.ox.ac.uk,MIT,https://github.com/piedrro/napari-PixSeq/issues,https://pypi.org/project/napari-PixSeq/,,https://github.com/piedrro/napari-PixSeq,A Napari plugin for extracting time series traces from Single Molecule Localisation Microsocpy (SMLM) data.,>=3.8,"['napari[all]', 'numpy', 'magicgui', 'qtpy', 'scipy', 'pyqtgraph', 'picassosr', 'pandas', 'matplotlib', 'opencv-python', 'tqdm', 'originpro', 'pyqt5-tools', 'torch', 'cellpose >=3.0.1', 'omnipose', 'trackpy', 'shapely', 'astropy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-PixSeq

[![License MIT](https://img.shields.io/pypi/l/napari-GapSeq2.svg?color=green)](https://github.com/piedrro/napari-PixSeq/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-GapSeq2.svg?color=green)](https://pypi.org/project/napari-PixSeq/)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-GapSeq2.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-GapSeq2)](https://napari-hub.org/plugins/napari-PixSeq)

A **Napari** plugin for extracting time series traces from single molecule FRET data.

napari-PixSeq uses **Picasso** (picassosr) as a backend and includes features for **aligning** image channels/datasets, **undrifting** images, **detecting/fitting** localisations and extracting **traces**, and supports both **ALEX** and **FRET** data. Traces can be exported in different formats for downstream analysis.

napari-PixSeq traces can be analysed with TraceAnalyser: https://github.com/piedrro/TraceAnalyser

This is still undergoing development, so some features may not work as expected.

This was built by Dr Piers Turner from the Kapanidis Lab, University of Oxford.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-PixSeq` via [pip]:

    pip install napari-PixSeq

You can install `napari-PixSeq` via [GitHub]:

    conda create â-name napari-pixseq python==3.9
    conda activate napari-pixseq
    conda install -c anaconda git
    conda update --all

    pip install git+https://github.com/piedrro/napari-PixSeq.git

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-PixSeq"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/piedrro/napari-GapSeq2/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/piedrro/napari-PixSeq/issues', 'Documentation, https://github.com/piedrro/napari-PixSeq#README.md', 'Source Code, https://github.com/piedrro/napari-PixSeq', 'User Support, https://github.com/piedrro/napari-PixSeq/issues']",,,napari-PixSeq.make_qwidget,,,,
337,napari-picasso,napari-PICASSO,napari-PICASSO,0.3.0,2022-06-01,2022-06-29,Kunal Pandit,kpandit@nygenome.org,GPL-3.0-only,https://github.com/nygctech/PICASSO/issues,https://pypi.org/project/napari-PICASSO/,,https://github.com/nygctech/PICASSO,Blind fluorescence unmixing,>=3.8,"['numpy', 'magicgui', 'qtpy', 'dask', 'psutil', ""tox ; extra == 'testing'"", ""napari[all] ; extra == 'testing'"", ""torch ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""xarray ; extra == 'testing'""]","# napari-PICASSO

[![License](https://img.shields.io/pypi/l/napari-curtain.svg?color=green)](https://github.com/nygctech/PICASSO/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-PICASSO.svg?color=green)](https://pypi.org/project/napari-PICASSO)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-PICASSO.svg?color=green)](https://python.org)
[![tests](https://github.com/nygctech/PICASSO/actions/workflows/test_and_deploy.yml/badge.svg?event=push)](https://github.com/nygctech/PICASSO/actions/workflows/test_and_deploy.yml)
[![codecov](https://codecov.io/gh/nygctech/napari-PICASSO/branch/main/graph/badge.svg)](https://codecov.io/gh/nygctech/napari-PICASSO)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-PICASSO)](https://napari-hub.org/plugins/napari-PICASSO)

Unmix spectral spillover

![](https://user-images.githubusercontent.com/72306584/176486552-50e1bca9-65fd-4466-8c92-a114e48d2278.gif)

## Automatic Usage

You can find the `PICASSO` plugin in the menu `Plugins > napari-PICASSO: PICASSO`. Select sink images that have spectral spillover from corresponding source images, then click run to optimise the mixing parameters with PICASSO. 

## Manual Usage

![](https://user-images.githubusercontent.com/72306584/176505151-572bd762-abe6-47b1-9821-4f3aaa4704c9.gif)

Select the manual button in options pop up window. Then select sink images that have spectral spillover from corresponding source images. In the source images window, sliders for each $source$ control the mixing spillover, $m$ (top), and background, $b$ (bottom, optional).

## Mixing model

$$ sink = \sum_{i} m_i(source - b_i) $$

## Installation

You can install `napari-PICASSO` via [pip]:

    pip install napari-PICASSO

## Details

napari-PICASSO is a napari widget to blindly unmix fluorescence images of known members using PICASSO<sup>1</sup>. 

For example, if 2 fluorophores with overlapping spectra are imaged, spillover fluorescesce from a channel into an adjacent channel could be removed if you know which channel is the source of the spillover fluorescence and which channel is the sink of the spillover fluorescence. 

PICASSO is an algorithm to remove spillover fluorescence by minimizing the mutual information between sink and source images. The original algorithm described by Seo et al, minimized the mutual information between pairs of sink and source images using a Nelson-Mead simplex algorithm and computing the mutual information outright with custom written MATLAB code<sup>1</sup>. The napari plugin uses a neural net to estimate and minimize the mutual information (MINE<sup>2</sup>) between pairs of sink and source images using stochastic gradient descent with GPU acceleration.

## References

1. Seo, J. et al. PICASSO allows ultra-multiplexed fluorescence imaging of spatially overlapping proteins without reference spectra measurements. Nat Commun 13, 2475 (2022).
2. Belghazi, M. I. et al. MINE: Mutual Information Neural Estimation. arXiv:1801.04062 [cs, stat] (2018).


[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']","['Bug Tracker, https://github.com/nygctech/PICASSO/issues']",,,napari-PICASSO.PicassoWidget,,,,
338,napari-plot,napari-plot,napari-plot,0.1.5,2022-01-09,2022-03-22,Lukasz G. Migas,lukas.migas@yahoo.com,BSD-3,https://github.com/lukasz-migas/napari-1d/issues,https://pypi.org/project/napari-plot/,,https://github.com/lukasz-migas/napari-1d,Plugin providing support for 1d plotting in napari.,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'qtpy', 'qtawesome', 'napari (<0.4.15,>=0.4.13)', 'matplotlib', 'vispy (>=0.9.6)', ""PySide2 (!=5.15.0,>=5.13.2) ; extra == 'all'"", ""pre-commit (>=2.9.0) ; extra == 'dev'"", ""black (==22.1.0) ; extra == 'dev'"", ""flake8 (==4.0.1) ; extra == 'dev'"", ""PySide2 (!=5.15.0,>=5.13.2) ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""scikit-image ; extra == 'dev'"", ""PyQt5 (!=5.15.0,>=5.12.3) ; extra == 'pyqt'"", ""PyQt5 (!=5.15.0,>=5.12.3) ; extra == 'pyqt5'"", ""PySide2 (!=5.15.0,>=5.13.2) ; extra == 'pyside'"", ""PySide2 (!=5.15.0,>=5.13.2) ; extra == 'pyside2'"", ""PyQt5 (!=5.15.0,>=5.12.3) ; extra == 'qt'"", ""pytest ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""scikit-image ; extra == 'testing'""]","# napari-plot

[![License](https://img.shields.io/pypi/l/napari-plot.svg?color=green)](https://github.com/lukasz-migas/napari-1d/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-plot.svg?color=green)](https://pypi.org/project/napari-plot)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-plot.svg?color=green)](https://python.org)
[![tests](https://github.com/lukasz-migas/napari-1d/workflows/tests/badge.svg)](https://github.com/lukasz-migas/napari-1d/actions)
[![codecov](https://codecov.io/gh/lukasz-migas/napari-1d/branch/main/graph/badge.svg)](https://codecov.io/gh/lukasz-migas/napari-1d)

Plugin providing support for 1d plotting in napari.

This plugin is in very early stages of development and many things are still in a state of disarray. New features and bug fixes
will be coming over the coming months. 

## Note

`napari-plot` provides several custom icons and stylesheets to take advantage of the `Qt` backend. Since it would be a bit busy to add multiple layer lists,
I opted to include a toolbar that quickly pulls the layer list whenever requested. Simple use the toolbar to access several commonly accessed elements.

## Usage

You can use `napari-plot` alongside `napari` where it is embedded as a dock widget. If using this option, controls are relegated to toolbar
where you can adjust layer properties like you would do in `napari`.

![embedded](https://github.com/lukasz-migas/napari-1d/blob/main/misc/embedded.png)

Or as a standalone app where only one-dimensional plotting is enabled. In this mode, controls take central stage and reflect `napari's` own
behaviour where layer controls are embedded in the main application.

![live-view](https://github.com/lukasz-migas/napari-1d/blob/main/misc/napariplot-live-line.gif)

## Roadmap:

This is only provisional list of features that I would like to see implemented. It barely scratches the surface of what plotting tool should cover so as soon as the basics are covered,
focus will be put towards adding more exotic features. If there are features that you certainly wish to be included,
please modify the list below or create a [new issue](https://github.com/lukasz-migas/napari-1d/issues/new)

- [ ] Support for new layer types. Layers are based on `napari's` `Layer`, albeit in a two-dimensional setting. Supported and planned layers:
  - [x] Line Layer - simple line plot.
  - [x] Scatter Layer - scatter plot (similar to `napari's Points` layer).
  - [x] Centroids/Segments Layer - horizontal or vertical line segments.
  - [x] InfLine Layer - infinite horizontal or vertical lines that span over very broad range. Useful for defining regions of interest.
  - [x] Region Layer - infinite horizontal or vertical rectangular boxes that span over very broad range. Useful for defining regions of interest.
  - [x] Shapes Layer - `napari's` own `Shapes` layer
  - [x] Points Layer - `napari's` own `Points` layer
  - [x] Multi-line Layer - more efficient implementation of `Line` layer when multiple lines are necessary.
  - [ ] Bar - horizontal and vertical barchart (TODO)
- [x] Proper interactivity of each layer type (e.g. moving `Region` or `InfLine`, adding points, etc...)
- [x] Intuitive interactivity. `napari-plot` will provide excellent level of interactivity with the plotted data. We plan to support several types of `Tools` that permit efficient interrogation of the data. We currently provide several `zoom` and `select` tools and hope to add few extras in the future.
  - [x] Box-zoom - standard zooming rectangle. Simply `left-mouse + drag/release` in the canvas on region of interest
  - [x] Horizontal span - zoom-in only in the y-axis by `Ctrl + left-mouse + drag/release` in the canvas.
  - [x] Vertical span - span-in only in the x-axis by `Shift + left-mouse + drag/release` in the canvas.
  - [x] Rectangle select - rectangle tool allowing sub-selection of data in the canvas. Similar to the `Box-zoom` but without the zooming part.
  - [x] Polygon select - polygon tool allowing sub-selection of data in the canvas.
  - [x] Lasso select - lasso tool allowing sub-selection of data in the canvas.
- [ ] Interactive plot legend
- [ ] Customizable axis visuals.
  - [x] Plot axis enabling customization of tick/label size and color
  - [ ] Support for non-linear scale
- [ ] Add convenient plotting interface:
  - [ ] Add `.plot` functionality
  - [ ] Add `.scatter` functionality
  - [ ] Add `.hbar` and `.vbar` functionality
  - [ ] Add `.imshow` functionality

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-plot` directly from PyPI via:

```python
pip install napari-plot
```

or from the git repo:

```python
git clone https://github.com/lukasz-migas/napari-1d.git
cd napari-1d
pip install -e '.[all]'
```

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-plot"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/lukasz-migas/napari-1d/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/lukasz-migas/napari-1d/issues', 'Documentation, https://github.com/lukasz-migas/napari-1d#README.md', 'Source Code, https://github.com/lukasz-migas/napari-1d', 'User Support, https://github.com/lukasz-migas/napari-1d/issues']",,,napari-plot.NapariPlotWidget,,,,
339,napari-points2regions,napari-points2regions,Points2Regions,0.0.2,2024-01-26,2024-01-26,Jonas Windhager,jonas@windhager.io,MIT,https://github.com/wahlby-lab/napari-points2regions/issues,https://pypi.org/project/napari-points2regions/,,https://github.com/wahlby-lab/napari-points2regions,A napari plugin for Points2Regions,>=3.9,"['colorcet', 'magicgui', 'napari', 'numpy', 'pandas', 'points2regions >=0.0.4', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-points2regions

[![License MIT](https://img.shields.io/pypi/l/napari-points2regions.svg?color=green)](https://github.com/wahlby-lab/napari-points2regions/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-points2regions.svg?color=green)](https://pypi.org/project/napari-points2regions)
[![tests](https://github.com/wahlby-lab/napari-points2regions/workflows/tests/badge.svg)](https://github.com/wahlby-lab/napari-points2regions/actions)
[![codecov](https://codecov.io/gh/wahlby-lab/napari-points2regions/branch/main/graph/badge.svg)](https://codecov.io/gh/wahlby-lab/napari-points2regions)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-points2regions.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-points2regions)](https://napari-hub.org/plugins/napari-points2regions)

A napari plugin for Points2Regions

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-points2regions` via [pip]:

    pip install napari-points2regions



To install latest development version :

    pip install git+https://github.com/wahlby-lab/napari-points2regions.git


## Contributing

Contributions are very welcome.

## License

Distributed under the terms of the [MIT] license,
""napari-points2regions"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/wahlby-lab/napari-points2regions/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Framework :: napari', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/wahlby-lab/napari-points2regions/issues', 'Documentation, https://github.com/wahlby-lab/napari-points2regions#README.md', 'Source Code, https://github.com/wahlby-lab/napari-points2regions', 'User Support, https://github.com/wahlby-lab/napari-points2regions/issues']",,,napari-points2regions.load_points,,,,
340,napari-plugin-search,napari-plugin-search,napari-plugin-search,0.1.4,2021-08-21,2023-01-04,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-plugin-search/issues,https://pypi.org/project/napari-plugin-search/,,https://github.com/haesleinhuepf/napari-plugin-search,Find napari plugins,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari-tools-menu']","# napari-plugin-search

[![License](https://img.shields.io/pypi/l/napari-plugin-search.svg?color=green)](https://github.com/haesleinhuepf/napari-plugin-search/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-plugin-search.svg?color=green)](https://pypi.org/project/napari-plugin-search)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-plugin-search.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-plugin-search/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-plugin-search/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-plugin-search/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-plugin-search)

Find napari plugins
![img.png](https://github.com/haesleinhuepf/napari-plugin-search/raw/main/docs/napari-plugin-search-screencast.gif)

## Usage
Enter the name of the plugin you are searching for and use the `up` and `down` arrow keys to navigate between them. 
Hit `Enter` to start a plugin.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-plugin-search` via [pip]:

    pip install napari-plugin-search

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-plugin-search"" is free and open source software

## Issues

If you encounter any problems, please create a thread on [image.sc] along with a detailed description and tag [@haesleinhuepf].

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-plugin-search/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[image.sc]: https://image.sc
[@haesleinhuepf]: https://twitter.com/haesleinhuepf
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-plugin-search/issues', 'Documentation, https://github.com/haesleinhuepf/napari-plugin-search#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-plugin-search', 'User Support, https://github.com/haesleinhuepf/napari-plugin-search/issues']",,,napari-plugin-search.PluginSearch,,,,
341,napari-plot-profile,napari-plot-profile,napari-plot-profile,0.2.2,2021-08-20,2022-10-05,"Robert Haase, Marcelo Leomil Zoccoler",robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-plot-profile/issues,https://pypi.org/project/napari-plot-profile/,,https://github.com/haesleinhuepf/napari-plot-profile,Plot intensity along a line and create topographical views in napari,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'pyqtgraph', 'napari', 'napari-tools-menu', 'napari-skimage-regionprops (>=0.2.4)', 'imageio (!=2.22.1)']","# napari-plot-profile (npp)

[![License](https://img.shields.io/pypi/l/napari-plot-profile.svg?color=green)](https://github.com/haesleinhuepf/napari-plot-profile/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-plot-profile.svg?color=green)](https://pypi.org/project/napari-plot-profile)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-plot-profile.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-plot-profile/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-plot-profile/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-plot-profile/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-plot-profile)
[![Development Status](https://img.shields.io/pypi/status/napari-plot-profile.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-plot-profile)](https://napari-hub.org/plugins/napari-plot-profile)

## Plot a Line Profile

Plot intensities along a line in [napari].

![img.png](https://github.com/haesleinhuepf/napari-plot-profile/raw/main/docs/napari-plot-profile-screencast.gif)

* Open some images in [napari].
  
* Add a shapes layer.

![img.png](https://github.com/haesleinhuepf/napari-plot-profile/raw/main/docs/add_shapes_layer_screenshot.png)
  
* Activate the line drawing tool or the path tool and draw a line.

![img.png](https://github.com/haesleinhuepf/napari-plot-profile/raw/main/docs/draw_line_tool_screenshot.png)
  
* After drawing a line, click on the menu Plugins > Measurements (Plot Profile)
* If you modify the line, you may want to click the ""Refresh"" button to redraw the profile.

![img.png](https://github.com/haesleinhuepf/napari-plot-profile/raw/main/docs/redraw_screenshot.png)

To see how these steps can be done programmatically from python, check out the [demo notebook](https://github.com/haesleinhuepf/napari-plot-profile/blob/main/docs/demo.ipynb)

## Create a Topographical View

Create a 3D view of a 2D image by warping pixel intensities to heights. It can be displayed as a 3D image layer, a points cloud layer or a surface layer.

![](https://github.com/haesleinhuepf/napari-plot-profile/raw/main/docs/topographical_view_screencast.gif)

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

----------------------------------

## Installation

You can install `napari-plot-profile` via [pip]:

    pip install napari-plot-profile

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-plot-profile"" is free and open source software

## Issues

If you encounter any problems, please create a thread on [image.sc] along with a detailed description and tag [@haesleinhuepf].

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-plot-profile/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[image.sc]: https://image.sc
[@haesleinhuepf]: https://twitter.com/haesleinhuepf
","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-plot-profile/issues', 'Documentation, https://github.com/haesleinhuepf/napari-plot-profile#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-plot-profile', 'User Support, https://github.com/haesleinhuepf/napari-plot-profile/issues']",,,napari-plot-profile.PlotProfile,,,,
342,napari-potential-field-navigation,napari-potential-field-navigation,Differentiable Potential Field Navigation,0.1.1,2024-02-02,2024-02-02,Robin CREMESE,robin.cremese@gmail.com,MPL-2.0,https://github.com/rcremese/napari-potential-field-navigation/issues,https://pypi.org/project/napari-potential-field-navigation/,,https://github.com/rcremese/napari-potential-field-navigation,A simple plugin for trajectories visualisations in napari for lung navigation in CTs scans,>=3.8,"['napari', 'numpy', 'magicgui', 'qtpy', 'scikit-image', 'napari-itk-io', 'taichi', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-potential-field-navigation

[![License Mozilla Public License 2.0](https://img.shields.io/pypi/l/napari-potential-field-navigation.svg?color=green)](https://github.com/rcremese/napari-potential-field-navigation/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-potential-field-navigation.svg?color=green)](https://pypi.org/project/napari-potential-field-navigation)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-potential-field-navigation.svg?color=green)](https://python.org)
[![tests](https://github.com/rcremese/napari-potential-field-navigation/workflows/tests/badge.svg)](https://github.com/rcremese/napari-potential-field-navigation/actions)
[![codecov](https://codecov.io/gh/rcremese/napari-potential-field-navigation/branch/main/graph/badge.svg)](https://codecov.io/gh/rcremese/napari-potential-field-navigation)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-potential-field-navigation)](https://napari-hub.org/plugins/napari-potential-field-navigation)

A simple plugin for trajectories visualisations in napari for lung navigation in CTs scans

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-potential-field-navigation` via [pip]:

    pip install napari-potential-field-navigation



To install latest development version :

    pip install git+https://github.com/rcremese/napari-potential-field-navigation.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Mozilla Public License 2.0] license,
""napari-potential-field-navigation"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/rcremese/napari-potential-field-navigation/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/rcremese/napari-potential-field-navigation/issues', 'Documentation, https://github.com/rcremese/napari-potential-field-navigation#README.md', 'Source Code, https://github.com/rcremese/napari-potential-field-navigation', 'User Support, https://github.com/rcremese/napari-potential-field-navigation/issues']",napari-potential-field-navigation.get_reader,napari-potential-field-navigation.write_multiple,napari-potential-field-navigation.make_diff_apf_widget,napari-potential-field-navigation.make_sample_data,['*.npy'],,['.npy']
343,napari-pointslayer-projection,napari-pointslayer-projection,Projection of Points layers,0.0.2,2023-02-14,2023-02-14,Niklas Netter,niknett@gmail.com,BSD-3-Clause,https://github.com/gatoniel/napari-pointslayer-projection/issues,https://pypi.org/project/napari-pointslayer-projection/,,https://github.com/gatoniel/napari-pointslayer-projection,This plugin creates a 2d projection of all your points.,>=3.8,"['numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-pointslayer-projection

[![License BSD-3](https://img.shields.io/pypi/l/napari-pointslayer-projection.svg?color=green)](https://github.com/gatoniel/napari-pointslayer-projection/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-pointslayer-projection.svg?color=green)](https://pypi.org/project/napari-pointslayer-projection)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-pointslayer-projection.svg?color=green)](https://python.org)
[![tests](https://github.com/gatoniel/napari-pointslayer-projection/workflows/tests/badge.svg)](https://github.com/gatoniel/napari-pointslayer-projection/actions)
[![codecov](https://codecov.io/gh/gatoniel/napari-pointslayer-projection/branch/main/graph/badge.svg)](https://codecov.io/gh/gatoniel/napari-pointslayer-projection)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-pointslayer-projection)](https://napari-hub.org/plugins/napari-pointslayer-projection)

This plugin creates a 2d projection of all your points.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-pointslayer-projection` via [pip]:

    pip install napari-pointslayer-projection



To install latest development version :

    pip install git+https://github.com/gatoniel/napari-pointslayer-projection.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-pointslayer-projection"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/gatoniel/napari-pointslayer-projection/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/gatoniel/napari-pointslayer-projection/issues', 'Documentation, https://github.com/gatoniel/napari-pointslayer-projection#README.md', 'Source Code, https://github.com/gatoniel/napari-pointslayer-projection', 'User Support, https://github.com/gatoniel/napari-pointslayer-projection/issues']",,,napari-pointslayer-projection.make_func_widget,,,,
344,napari-power-spectrum,napari-power-spectrum,Power Spectrum,0.0.6,2022-04-08,2022-04-22,Giorgia Tortora,giorgiatortora2@gmail.com,BSD-3-Clause,https://github.com/GiorgiaTortora/napari-power-spectrum/issues,https://pypi.org/project/napari-power-spectrum/,,https://github.com/GiorgiaTortora/napari-power-spectrum,A simple plugin to get the power spectrum of frames of a stack image,>=3.8,"['numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-power-spectrum

[![License](https://img.shields.io/pypi/l/napari-power-spectrum.svg?color=green)](https://github.com/GiorgiaTortora/napari-power-spectrum/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-power-spectrum.svg?color=green)](https://pypi.org/project/napari-power-spectrum)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-power-spectrum.svg?color=green)](https://python.org)
[![tests](https://github.com/GiorgiaTortora/napari-power-spectrum/workflows/tests/badge.svg)](https://github.com/GiorgiaTortora/napari-power-spectrum/actions)
[![codecov](https://codecov.io/gh/GiorgiaTortora/napari-power-spectrum/branch/main/graph/badge.svg)](https://codecov.io/gh/GiorgiaTortora/napari-power-spectrum)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-power-spectrum)](https://napari-hub.org/plugins/napari-power-spectrum)

A simple plugin to get the power spectrum of frames of a stack image

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-power-spectrum` via [pip]:

    pip install napari-power-spectrum



To install latest development version :

    pip install git+https://github.com/GiorgiaTortora/napari-power-spectrum.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-power-spectrum"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/GiorgiaTortora/napari-power-spectrum/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/GiorgiaTortora/napari-power-spectrum/issues', 'Documentation, https://github.com/GiorgiaTortora/napari-power-spectrum#README.md', 'Source Code, https://github.com/GiorgiaTortora/napari-power-spectrum', 'User Support, https://github.com/GiorgiaTortora/napari-power-spectrum/issues']",,,napari-power-spectrum.make_powerspectrum_widget,,,,
345,napari-prism,napari-prism,napari prism,0.1.6,2024-11-14,2025-04-16,Rafael Tubelleza,rafaelrtubelleza@gmail.com,MIT,https://github.com/clinicalomx/napari-prism/issues,https://pypi.org/project/napari-prism/,,https://github.com/clinicalomx/napari-prism,A Python package for the inteRactive and Integrated analySis of Multiplexed tissue microarrays,>=3.10,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'spatialdata<=0.2.5.post0', 'imagecodecs', 'napari[all]>=0.4.19.post1', 'napari_matplotlib<2.0.2', 'napari_spatialdata<=0.5.3', 'dask<2024.12.1', 'qtpy', 'matplotlib', 'PyComplexHeatmap', 'scikit-learn', 'cellpose>=3.0.10', 'scanpy>=1.10.0', 'phenograph', 'squidpy', 'kneed', 'xarray<=2024.7.0', 'ome-types', 'forestplot', 'scikit-survival', 'spatialdata-plot<=0.2.7', 'dask-cudf-cu12==24.10.*; extra == ""gpu""', 'rapids-singlecell[rapids12]; extra == ""gpu""', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-lazy-fixtures; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'qtpy; extra == ""testing""', 'ipykernel; extra == ""docs""', 'ipython; extra == ""docs""', 'myst-nb>=1.1; extra == ""docs""', 'myst-parser; extra == ""docs""', 'sphinx>=4; extra == ""docs""', 'sphinx-autodoc-typehints; extra == ""docs""', 'sphinx-book-theme>=1; extra == ""docs""', 'sphinx-copybutton; extra == ""docs""', 'sphinx-qt-documentation; extra == ""docs""', 'sphinxcontrib-bibtex>=1; extra == ""docs""', 'sphinx-tabs; extra == ""docs""', 'sphinxext-opengraph; extra == ""docs""']","# PRISM: A **P**ython package for the inte**R**active and **I**ntegrated analy**S**is of **M**ultiplexed tissue microarrays

<!--
#FUTURE: package logo
-->

[![License MIT](https://img.shields.io/pypi/l/napari-prism.svg?color=green)](https://github.com/clinicalomx/napari-prism/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-prism.svg?color=green)](https://pypi.org/project/napari-prism)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-prism.svg?color=green)](https://python.org)
[![tests](https://github.com/clinicalomx/napari-prism/workflows/tests/badge.svg)](https://github.com/clinicalomx/napari-prism/actions)
[![codecov](https://codecov.io/gh/clinicalomx/napari-prism/branch/main/graph/badge.svg)](https://codecov.io/gh/clinicalomx/napari-prism)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-prism)](https://napari-hub.org/plugins/napari-prism)

**NOTE: PRISM is still in heavy development.**
PRISM or napari-prism is a package and [napari] plugin designed for interactively processing, analysing and visualising multiplxed tissue microarrays.

Currently, end-to-end capabilities (i.e. starting from importing the raw image file, to basic spatial analysis of annotated cells) are available for images generated from the
Akoya Phenocyclerâ¢-Fusion platform. However, the modular structure of the
package allows for usage at any stage of processing and/or analysis, given a pre-built SpatialData object using readers from either
[spatialdata-io] or [sopa].

PRISM uses [spatialdata] as the core data framework, allowing for:

1. The rich integration of tools from the ([scverse]) Python bioinformatics ecosystem with highly interactive graphical user interfaces from [napari] and [napari-spatialdata].
2. The storage of images, shapes, annotations and their linked `AnnData` objects in a standardized, FAIR-compliant data structure, addressing the non-standard and fragmented organization of files before, during, and after a multiplexed image analysis pipeline.

The package was designed to be used completely within the [napari] application and therefore require little to no knowledge of Python programming. Documentation for usage via the API is currently in progress.

## Requirements

Install [miniconda] or anaconda.

Open the conda terminal and create a simple environment:

```bash
conda create -n prism python=3.10 -c conda-forge
```

Activate the environment before executing the instructions in the Installation section.

```bash
conda activate prism
```

### List of Dependencies

```
python==3.10
spatialdata<=0.2.5.post0
spatialdata-plot<=0.2.7
napari[all]>=0.4.19.post1
napari_matplotlib<2.0.2
napari_spatialdata<=0.5.3
dask<2024.12.1
cellpose>=3.0.10
scanpy>=1.10.0
xarray<=2024.7.0
spatialdata_plot<=0.2.7
```

## Installation: CPU only

Install this package via [pip]:

```bash
pip install napari-prism
```

Install the latest development version:

```bash
pip install git+https://github.com/clinicalomx/napari-prism.git@main
```

## Installation: GPU-accelerated

### General computations with RAPIDS and rapids-singlecell

General larger scale and/or computationally demanding functions can be accelerated with the [NVIDIA RAPIDS suite](https://rapids.ai/). We utilise some packages from this suite, as well as the GPU-accelerated implementation of scanpy with [rapids-singlecell].

1. [Check and configure the system requirements from RAPIDS](https://docs.rapids.ai/install/#system-req).
    - Currently, only Linux distributions (or Windows systems with WSL2) are supported.
    - Install the [CUDA12.2](https://developer.nvidia.com/cuda-12-2-2-download-archive) or [CUDA12.5](https://developer.nvidia.com/cuda-12-5-1-download-archive) toolkit.
2. Install the package together with [RAPIDS] and [rapids-singlecell] via [pip]:

```bash
pip install napari-prism[gpu] --extra-index-url=https://pypi.nvidia.com
```

### Cell segmentation with Cellpose

To run [cellpose] on the GPU, install the [CUDA version of PyTorch](https://pytorch.org/get-started/locally/). You may need to [remove any installed CPU versions of PyTorch](https://github.com/MouseLand/cellpose?tab=readme-ov-file#gpu-version-cuda-on-windows-or-linux).

## Getting Started

To start using `napari-prism`, please see the [tutorials](https://napari-prism.readthedocs.io/en/latest/notebooks/getting_started.html#):

- [Getting started](https://napari-prism.readthedocs.io/en/latest/notebooks/getting_started.html)
- To learn how to interactively analyse raw .qptiff TMAs, see [TMA Image Analysis](https://napari-prism.readthedocs.io/en/latest/notebooks/tma_usage.html)
- To learn how to interactively analyse AnnData-contained SpatialData objects, see [Anndata Analysis](https://napari-prism.readthedocs.io/en/latest/notebooks/adata_usage.html)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-prism"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

## Known Issues

Adding shapes like `tma_envelopes` may cause segmentation faults (https://github.com/napari/napari/issues/6709). A workaround is to uninstall triangle (`pip uninstall triangle`)

## Citation

\*\*tba

[napari]: https://github.com/napari/napari
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[file an issue]: https://github.com/clinicalomx/napari-prism/issues
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[PyTorch]: https://pytorch.org/
[cellpose]: https://github.com/MouseLand/cellpose
[RAPIDS]: https://rapids.ai/
[rapids-singlecell]: https://github.com/scverse/rapids_singlecell
[spatialdata]: https://github.com/scverse/spatialdata/tree/main
[napari-spatialdata]: https://github.com/scverse/napari-spatialdata/tree/main
[spatialdata-io]: https://github.com/scverse/spatialdata-io
[sopa]: https://github.com/gustaveroussy/sopa
[scverse]: https://scverse.org/
[miniconda]: https://www.anaconda.com/docs/getting-started/miniconda/install
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/clinicalomx/napari-prism/issues', 'Documentation, https://github.com/clinicalomx/napari-prism#README.md', 'Source Code, https://github.com/clinicalomx/napari-prism', 'User Support, https://github.com/clinicalomx/napari-prism/issues']",napari-prism.get_reader,,napari-prism.TMAImageAnalysis,,"['*.qptiff', '*.zarr']",,
346,napari-power-widgets,napari-power-widgets,napari-power-widgets,0.0.1,2022-11-11,2022-11-11,Hanjin Liu,liuhanjin-sc@g.ecc.u-tokyo.ac.jp,BSD-3-Clause,https://github.com/hanjinliu/napari-power-widgets/issues,https://pypi.org/project/napari-power-widgets/,,https://github.com/hanjinliu/napari-power-widgets,Powerful widgets and type annotations for napari plugin widgets,>=3.8,"['numpy', 'pandas', 'typing-extensions', 'magicgui', 'napari', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-power-widgets

[![License BSD-3](https://img.shields.io/pypi/l/napari-power-widgets.svg?color=green)](https://github.com/hanjinliu/napari-power-widgets/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-power-widgets.svg?color=green)](https://pypi.org/project/napari-power-widgets)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-power-widgets.svg?color=green)](https://python.org)
[![tests](https://github.com/hanjinliu/napari-power-widgets/workflows/tests/badge.svg)](https://github.com/hanjinliu/napari-power-widgets/actions)
[![codecov](https://codecov.io/gh/hanjinliu/napari-power-widgets/branch/main/graph/badge.svg)](https://codecov.io/gh/hanjinliu/napari-power-widgets)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-power-widgets)](https://napari-hub.org/plugins/napari-power-widgets)

Powerful `magicgui` widgets and type annotations for general-purpose napari plugin development.

`napari-power-widgets` makes the full use of type-to-widget mapping strategy of `magicgui` to provide napari-specific types and value-widgets, which will be very useful to improve UI/UX of your napari plugins with simple codes.

Currently, `napari-power-widgets` does not provide any reader, writer or widget. It is supposed to be used programmatically.

### Examples

Some types/widgets and the possible usage are picked up here ([&rarr; check all](https://github.com/hanjinliu/napari-power-widgets/blob/main/src/napari_power_widgets/types.py)). If you have any neat ideas, please open an issue.

#### 1. `BoxSelection`

Alias of a four-float tuple for 2D selection. You can set the value by drawing a interaction box in the viewer.

*e. g. : image cropper, rectangular labeling etc.*

```python
@magicgui
def f(box: BoxSelection):
    print(box)
viewer.window.add_dock_widget(f)
```

![](images/BoxSelection.gif)

#### 2. `OneOfRectangles`

Alias of `np.ndarray` for one of rectangles in a `Shapes` layer.

*e. g. : image cropper, rectangular labeling etc.*

```python
@magicgui
def f(rect: OneOfRectangles):
    print(rect)
viewer.window.add_dock_widget(f)
```

![](images/OneOfRectangles.gif)

#### 3. `LineData`

Alias of `np.ndarray` for a line data. You can obtain the data by manually drawing a line in the viewer.

*e. g. : line profiling, kymograph etc.*

```python
@magicgui
def f(line: LineData):
    print(line)
viewer.window.add_dock_widget(f)
```

![](images/LineData.gif)

#### 4. `OneOfLabels`

Alias of boolean `np.ndarray` for a labeled region. You can choose ones by directly clicking the viewer.

*e. g. : image masking, feature measurement etc.*

```python
@magicgui
def f(label: OneOfLabels):
    pass
viewer.window.add_dock_widget(f)
```

![](images/OneOfLabels.gif)


#### 5. `ZRange`

Alias of a tuple of float that represents the limit of the third dimension. You can select the values by moving the dimension slider.

*e. g. : movie trimming, partial image projection etc.*

```python
@magicgui
def f(zrange: ZRange):
    print(zrange)
viewer.window.add_dock_widget(f)
```

![](images/ZRange.gif)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-power-widgets` via [pip]:

    pip install napari-power-widgets



To install latest development version :

    pip install git+https://github.com/hanjinliu/napari-power-widgets.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-power-widgets"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hanjinliu/napari-power-widgets/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hanjinliu/napari-power-widgets/issues', 'Documentation, https://github.com/hanjinliu/napari-power-widgets#README.md', 'Source Code, https://github.com/hanjinliu/napari-power-widgets', 'User Support, https://github.com/hanjinliu/napari-power-widgets/issues']",,,,,,,
347,napari-process-points-and-surfaces,napari-process-points-and-surfaces,napari-process-points-and-surfaces,0.5.0,2022-02-05,2023-04-09,"Robert Haase, Johannes Soltwedel",robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-process-points-and-surfaces/issues,https://pypi.org/project/napari-process-points-and-surfaces/,,https://github.com/haesleinhuepf/napari-process-points-and-surfaces,Process and analyze surfaces using open3d and vedo in napari,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari', 'napari-tools-menu (>=0.1.14)', 'napari-time-slicer (>=0.4.5)', 'napari-workflows (>=0.2.3)', 'vedo (>=2022.4.1)', 'napari-skimage-regionprops (>=0.5.5)', 'pandas', 'imageio (!=2.22.1)', 'stackview (>=0.5.2)']","# napari-process-points-and-surfaces (nppas)

[![License](https://img.shields.io/pypi/l/napari-process-points-and-surfaces.svg?color=green)](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-process-points-and-surfaces.svg?color=green)](https://pypi.org/project/napari-process-points-and-surfaces)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-process-points-and-surfaces.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-process-points-and-surfaces/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-process-points-and-surfaces)
[![Development Status](https://img.shields.io/pypi/status/napari-process-points-and-surfaces.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-process-points-and-surfaces)](https://napari-hub.org/plugins/napari-process-points-and-surfaces)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7654555.svg)](https://doi.org/10.5281/zenodo.7654555)

Process and analyze surfaces using [vedo](https://vedo.embl.es/) in [napari].

![img.png](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/raw/main/docs/graphical_abstract.gif)
The nppas gastruloid example is derived from [AV Luque and JV Veenvliet (2023)](https://zenodo.org/record/7603081) which is licensed [CC-BY](https://creativecommons.org/licenses/by/4.0/legalcode) and can be downloaded from here: https://zenodo.org/record/7603081

## Usage

You find menus for surface generation, smoothing and analysis in the menu `Tools > Surfaces` and `Tools > Points`. 
For detailed explanation of the underlying algorithms, please refer to the [vedo](https://vedo.embl.es/) documentation.

For processing meshes in Python scripts, see the [demo notebook](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/blob/main/docs/demo.ipynb). 
There you also learn how this screenshot is made:

![img.png](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/raw/main/docs/screenshot5.png)

For performing quantitative measurements of surface in Python scripts, see the [demo notebook](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/blob/main/docs/quality_measurements.ipynb). 
There you also learn how this screenshot is made:

![img.png](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/raw/main/docs/screenshot6.png)

### Surface measurements and annotations

Using the menu `Tools > Measurement tables > Surface quality table (vedo, nppas)` you can derive quantiative measurements of
the vertices in a given surface layer. 

![img_1.png](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/raw/main/docs/surface_measurements2.png)

To differentiate regions when analyzing those measurements it is recommended to use the menu `Tools > Surfaces > Annotate surface manually (nppas)`
after measurements have been made. This tool allows you to draw annotation label values on the surface. 
It is recommended to do activate a colorful colormap such as `hsv` before starting to draw annotations. 
Furthermore, set the maximum of the contrast limit range to the number of regions you want to annotate + 1.
Annotations can be drawn as freehand lines and circles.

![img.png](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/raw/main/docs/surface_annotation2.png)

After measurements and annotations were done, you can save the annotation in the same measurement table using the menu
`Tools > Measurement tables > Surface quality/annotation to table (nppas)`

![img.png](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/raw/main/docs/surface_annotation_in_table2.png)

For classifying surface vertices using machine learning, please refer to the [napari APOC](https://www.napari-hub.org/plugins/napari-accelerated-pixel-and-object-classification) documentation.

### Measurement visualization

To visualize measurements on the surface, just double-click on the table column headers.

![img.png](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/raw/main/docs/quality_measurements.gif)

## Installation

You can install `napari-process-points-and-surfaces` via mamba/conda and pip:

```
mamba install vedo vtk libnetcdf=4.7.4 -c conda-forge
pip install napari-process-points-and-surfaces
```

### Troubleshooting: Open3d installation

Since version 0.4.0, `nppas` does no longer depend on [open3d](http://www.open3d.org/). 
Some deprecated functions still use Open3d though. 
Follow the installation instructions in the [open3d documentation](http://www.open3d.org/docs/release/getting_started.htm) to install it and keep using those functions.
Also consider updating code and no longer using these deprecated functions. 
See [release notes](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/releases/tag/0.4.0) for details.

## See also

There are other napari plugins with similar / overlapping functionality
* [morphometrics](https://www.napari-hub.org/plugins/morphometrics)  
* [napari-accelerated-pixel-and-object-classification](https://www.napari-hub.org/plugins/napari-accelerated-pixel-and-object-classification)
* [napari-pymeshlab](https://www.napari-hub.org/plugins/napari-pymeshlab)
* [napari-pyclesperanto-assistant](https://www.napari-hub.org/plugins/napari-pyclesperanto-assistant)
* [napari-stress](https://www.napari-hub.org/plugins/napari-stress)

And there is software for doing similar things:
* [meshlab](https://www.meshlab.net/)
* [paraview](https://www.paraview.org/)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-process-points-and-surfaces"" is free and open source software

## Acknowledgements

Some code snippets and example data were taken from the [vedo](https://vedo.embl.es/) and [open3d](http://www.open3d.org/) 
repositories and documentation. See [thirdparty licenses](https://github.com/haesleinhuepf/napari-process-points-and-surfaces/tree/main/licenses_third_party) for licensing details.
The Standford Bunny example dataset has been taken from [The Stanford 3D Scanning Repository](http://graphics.stanford.edu/data/3Dscanrep/).
The nppas gastruloid example is derived from [AV Luque and JV Veenvliet (2023)](https://zenodo.org/record/7603081) which is licensed [CC-BY](https://creativecommons.org/licenses/by/4.0/legalcode) and can be downloaded from here: https://zenodo.org/record/7603081

## Issues

If you encounter any problems, please create a thread on [image.sc] along with a detailed description and tag [@haesleinhuepf].

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-process-points-and-surfaces/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

[image.sc]: https://image.sc
[@haesleinhuepf]: https://twitter.com/haesleinhuepf
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-process-points-and-surfaces/issues', 'Documentation, https://github.com/haesleinhuepf/napari-process-points-and-surfaces#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-process-points-and-surfaces', 'User Support, https://github.com/haesleinhuepf/napari-process-points-and-surfaces/issues']",,,napari-process-points-and-surfaces.SurfaceAnnotationWidget,napari-process-points-and-surfaces._vedo_stanford_bunny_layerdatatuple,,,
348,napari-properties-plotter,napari-properties-plotter,napari-properties-plotter,0.2.2,2021-05-26,2021-12-01,Lorenzo Gaifas,lorenzo.gaifas@gmail.com,BSD-3,https://github.com/brisvag/napari-properties-plotter/issues,https://pypi.org/project/napari-properties-plotter/,,https://github.com/brisvag/napari-properties-plotter,A napari plugin that automatically generates interactive plots based on layer properties.,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'pandas', 'pyqtgraph', 'qtpy']","# napari-properties-plotter

[![License](https://img.shields.io/pypi/l/napari-properties-plotter.svg?color=green)](https://github.com/brisvag/napari-properties-plotter/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-properties-plotter.svg?color=green)](https://pypi.org/project/napari-properties-plotter)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-properties-plotter.svg?color=green)](https://python.org)
[![tests](https://github.com/brisvag/napari-properties-plotter/workflows/tests/badge.svg)](https://github.com/brisvag/napari-properties-plotter/actions)
[![codecov](https://codecov.io/gh/brisvag/napari-properties-plotter/branch/master/graph/badge.svg)](https://codecov.io/gh/brisvag/napari-properties-plotter)

A napari plugin that automatically generates interactive plots based on layer properties.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-properties-plotter` via [pip]:

    pip install napari-properties-plotter

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-properties-plotter"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/brisvag/napari-properties-plotter/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/brisvag/napari-properties-plotter/issues', 'Documentation, https://github.com/brisvag/napari-properties-plotter#README.md', 'Source Code, https://github.com/brisvag/napari-properties-plotter', 'User Support, https://github.com/brisvag/napari-properties-plotter/issues']",,,napari-properties-plotter.PropertyPlotter,,,,
349,napari-proofread-brainbow,napari-proofread-brainbow,Proofread Brainbow,0.3.1,2022-08-30,2025-06-23,Seongbin Lim,sungbin246@gmail.com,MIT,,https://pypi.org/project/napari-proofread-brainbow/,None,,Proofreading Brainbow images with napari,>=3.10,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'setuptools-scm; extra == ""testing""']","# napari-proofread-brainbow

[![License MIT](https://img.shields.io/pypi/l/napari-proofread-brainbow.svg?color=green)](https://github.com/sbinnee/napari-proofread-brainbow/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-proofread-brainbow.svg?color=green)](https://pypi.org/project/napari-proofread-brainbow)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-proofread-brainbow.svg?color=green)](https://python.org)
[![tests](https://github.com/sbinnee/napari-proofread-brainbow/workflows/tests/badge.svg)](https://github.com/sbinnee/napari-proofread-brainbow/actions)
[![codecov](https://codecov.io/gh/sbinnee/napari-proofread-brainbow/branch/main/graph/badge.svg)](https://codecov.io/gh/sbinnee/napari-proofread-brainbow)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-proofread-brainbow)](https://napari-hub.org/plugins/napari-proofread-brainbow)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

Proofreading Brainbow images with napari

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-proofread-brainbow` via [pip]:

    pip install napari-proofread-brainbow




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-proofread-brainbow"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-proofread-brainbow.make_qwidget,,,,
350,napari-pram,napari-pram,napari PRAM,0.1.3,2022-04-29,2022-05-03,Hieu Hoang,hthieu@illinois.edu,MIT,,https://pypi.org/project/napari-pram/,None,,plugin for PRAM data annotation and processing,>=3.7,"['numpy', 'magicgui', 'qtpy', 'opencv-python', 'scipy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-pram

[![License](https://img.shields.io/pypi/l/napari-pram.svg?color=green)](https://github.com/hthieu166/napari-pram/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-pram.svg?color=green)](https://pypi.org/project/napari-pram)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-pram.svg?color=green)](https://python.org)
[![tests](https://github.com/hthieu166/napari-pram/workflows/tests/badge.svg)](https://github.com/hthieu166/napari-pram/actions)
[![codecov](https://codecov.io/gh/hthieu166/napari-pram/branch/main/graph/badge.svg)](https://codecov.io/gh/hthieu166/napari-pram)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-pram)](https://napari-hub.org/plugins/napari-pram)

Plugin for PRAM data annotation and processing.

![PRAM Demo](https://raw.githubusercontent.com/hthieu166/napari-pram/main/docs/figs/demo.jpg)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Usage

### Open `napari-pram` toolbox:

On the toolbar, select ``[Plugins] > napari-pram: Open PRAM's toolbox``

### Load PRAM image and annotations:

Press <kbd>Command/Control</kbd> + <kbd>O</kbd>: 
- Select `*.json` files for annotations (from either [VGG Annotator](https://www.robots.ox.ac.uk/~vgg/software/via/) or `napari-pram`)
- Select `*.png` files for PRAM image

### Annotate
- Press <kbd>Annotate</kbd>
- Click the plus-in-circle icon on the top-left panel and start editing

### Run PRAM particles detector
- Select a proper threshold between 1 (ultra sensitive) - 10 (less sensitive)
- Press <kbd>Run Detector</kbd>

### Evaluate
- Press <kbd>Evaluate</kbd>
- Hide/Unhide true positive/ false postive/false negative layers

### Load new image
- Press <kbd>Clear All</kbd> to remove all layers

### Export to JSON
- Press <kbd>Save to File</kbd> to export all annotations, predictions from the algorithm to a JSON file
## Installation
Following this [tutorial](https://napari.org/tutorials/fundamentals/quick_start.html) to install `napari`. 

Alternatively, you can follow my instructions as follows:

You will need a python environment. I recommend [Conda](https://docs.conda.io/en/latest/miniconda.html). Create a new environment, for example:
    
    conda create --name napari-env python=3.7 pip 

Activate the new environment:

    conda activate napari-env 

Install [napari](https://napari.org/tutorials/fundamentals/installation) via [pip]:

    pip install napari[all]

Then you can finally install our plugin `napari-pram` via [pip]:

    pip install napari-pram

Alternatively, the plugin can be installed using napari-GUI

``[Plugins] > Install/Uninstall Plugins`` and search for `napari-pram`

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-pram"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']",,napari-pram.get_img_reader,napari-pram.write_multiple,napari-pram.open_panel,napari-pram.make_sample_data,['*.png'],,['.npy']
351,napari-psfgenerator,napari-psfgenerator,PSF Generator,0.3.2,2025-02-05,2025-06-17,"Vasiliki Stergiopoulou, Jonathan Dong, Yan Liu, Daniel Sage","Vasiliki Stergiopoulou <vasiliki.stergiopoulou@epfl.ch>, Jonathan Dong <jonathan.dong@epfl.ch>, Yan Liu <yan.liu@epfl.ch>, Daniel Sage <daniel.sage@epfl.ch>",MIT,https://github.com/VStergiop/napari-psfgenerator/issues,https://pypi.org/project/napari-psfgenerator/,,,Plugin to compute the focal electric field,>=3.9,"['magicgui', 'qtpy', 'psf-generator', 'pyqt5', 'napari', 'napari; extra == ""napari""', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-psfgenerator

[![MIT License](https://img.shields.io/github/license/Biomedical-Imaging-Group/napari-psfgenerator)](https://github.com/Biomedical-Imaging-Group/napari-psfgenerator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-psfgenerator.svg?color=green)](https://pypi.org/project/napari-psfgenerator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-psfgenerator.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-psfgenerator)](https://napari-hub.org/plugins/napari-psfgenerator)

## PSF Generator Napari Plugin

The **PSF Generator Napari Plugin** provides an intuitive, interactive platform for simulating **Point Spread Functions (PSFs)** directly within the Napari ecosystem. Built on **PyTorch**, this plugin supports both **CPU and GPU-accelerated** computations, ensuring fast and efficient simulations for fundamental and advanced optical modeling.

### Key Features:

- **Flexible Propagation Models:** Scalar and vectorial propagators in Cartesian and spherical coordinates.
- **Customizable Parameters:** Configure **physical** (e.g., numerical aperture, wavelength), **numerical** (e.g., pixel size, Z-stacks), and **optical settings** (e.g., Gibson-Lanni corrections, Zernike aberrations).
- **Real-Time Visualization:** Seamless integration with Napari for immediate visual feedback.
- **Versatile API:** Access propagators programmatically for custom workflows.
- **Image Export:** Save computed PSFs in **TIFF format**.

This plugin is a powerful tool for researchers in **optics, computational microscopy, and imaging science**, bridging user-friendly interactivity with the computational capabilities of our Python library.

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

Set up a Python virtual environment and install napari following this [guide].

You can install `napari-psfgenerator` via [pip]:

    pip install napari-psfgenerator

To install latest development version :

    pip install git+https://github.com/Biomedical-Imaging-Group/napari-psfgenerator.git


Now you can try the plugin out! Open napari, click on the menu ""Plugins"" and select ""Propagators (PSF Generator)"".


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-psfgenerator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template
[guide]: https://napari.org/dev/tutorials/fundamentals/installation.html
[file an issue]: https://github.com/VStergiop/napari-psfgenerator/issues
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[psf_generator library]: https://github.com/Biomedical-Imaging-Group/psf_generator
[plugin]: https://github.com/Biomedical-Imaging-Group/napari-psfgenerator
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/VStergiop/napari-psfgenerator/issues', 'Documentation, https://github.com/VStergiop/napari-psfgenerator#README.md', 'Source Code, https://github.com/VStergiop/napari-psfgenerator', 'User Support, https://github.com/VStergiop/napari-psfgenerator/issues']",napari-psfgenerator.get_reader,napari-psfgenerator.write_multiple,napari-psfgenerator.make_function_widget,napari-psfgenerator.make_sample_data,['*.npy'],,['.npy']
352,napari-properties-viewer,napari-properties-viewer,napari-properties-viewer,0.0.2,2021-04-28,2021-06-30,Kevin Yamauchi,kevin.yamauchi@gmail.com,BSD-3,https://github.com/kevinyamauchi/napari-properties-viewer,https://pypi.org/project/napari-properties-viewer/,,https://github.com/kevinyamauchi/napari-properties-viewer,A viewer for napari layer properties,>=3.6,"['napari-plugin-engine (>=0.1.4)', 'numpy']","# napari-properties-viewer

[![License](https://img.shields.io/pypi/l/napari-properties-viewer.svg?color=green)](https://github.com/napari/napari-properties-viewer/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-properties-viewer.svg?color=green)](https://pypi.org/project/napari-properties-viewer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-properties-viewer.svg?color=green)](https://python.org)
[![tests](https://github.com/kevinyamauchi/napari-properties-viewer/workflows/tests/badge.svg)](https://github.com/kevinyamauchi/napari-properties-viewer/actions)
[![codecov](https://codecov.io/gh/kevinyamauchi/napari-properties-viewer/branch/master/graph/badge.svg)](https://codecov.io/gh/kevinyamauchi/napari-properties-viewer)

A viewer for napari layer properties

![image](resources/properties_viewer.gif)
----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-properties-viewer` via [pip]:

    pip install napari-properties-viewer
    
## Using the properties viewer table

1. Open a a napari viewer with a layer with properties (e.g., Points)
2. View the properties by opening the properties viewer plugin from Plugins menu -> Add dock widget -> napari-propertiews-viewer: properties table
3. The layer property values are now displayed in the table widget. You can edit the values by double clicking the cell of interest and entering a new value.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-properties-viewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/kevinyamauchi/napari-properties-viewer/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,napari-properties-viewer.QtPropertiesTable,,,,
353,napari-psf-simulator,napari-psf-simulator,PSF simulator,0.3.1,2022-04-14,2023-10-31,Andrea Bassi,andrea1.bassi@polimi.it,BSD-3-Clause,https://github.com/andreabassi78/napari-psf-simulator/issues,https://pypi.org/project/napari-psf-simulator/,,https://github.com/andreabassi78/napari-psf-simulator,"A plugin for simulations of the Point Spread Function, with aberrations",>=3.8,"['numpy', 'magicgui', 'qtpy', 'PyCustomFocus >=3.3.6', 'matplotlib', 'scikit-image', 'scipy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""qtpy ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""PyCustomFocus >=3.3.6 ; extra == 'testing'"", ""matplotlib ; extra == 'testing'"", ""scikit-image ; extra == 'testing'"", ""scipy ; extra == 'testing'""]","# napari-psf-simulator

[![License](https://img.shields.io/pypi/l/napari-psf-simulator.svg?color=green)](https://github.com/andreabassi78/napari-psf-simulator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-psf-simulator.svg?color=green)](https://pypi.org/project/napari-psf-simulator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-psf-simulator.svg?color=green)](https://python.org)
[![tests](https://github.com/andreabassi78/napari-psf-simulator/workflows/tests/badge.svg)](https://github.com/andreabassi78/napari-psf-simulator/actions)
[![codecov](https://codecov.io/gh/andreabassi78/napari-psf-simulator/branch/main/graph/badge.svg)](https://codecov.io/gh/andreabassi78/napari-psf-simulator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-psf-simulator)](https://napari-hub.org/plugins/napari-psf-simulator)

A plugin for the simulation of the 3D Point Spread Function of an optical systen, particularly a microscope objective.
 
Calculates the PSF using scalar and vectorial models.  
The following aberrations are included:
- phase aberration described by a Zernike polynomials with n-m coefficients.
- aberration induced by a slab, with a refractive index different from the one at the object.  

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-psf-simulator` via [pip]:

    pip install napari-psf-simulator


To install latest development version :

    pip install git+https://github.com/andreabassi78/napari-psf-simulator.git


## Usage

1) Lauch the plugin and select the parameters of the microscope: `NA` (numerical aperture), `wavelenght`, `n` (refractive index at the object),
   `FOV xy` (field of view in the transverse direction), `FOV z` (field of view in the axial direction), `dxy` (pixel size, transverse sampling), `dz` (voxel depth, axial sampling), `lens radius` (physical aperture of the lens, used in vectorial model)

2) Select a propagation model between `scalar` and `vectorial`.  

3) Select an aberration type (if needed).

4) Press `Calculate PSF` to run the simulator. This will create a new image layer with the 3D PSF.
 
   The option `Show Airy disk` creates a circle with radius given by the diffraction limit (Rayleigh criterion).

![raw](https://github.com/andreabassi78/napari-psf-simulator/raw/main/images/figure.png)
**Napari viewer with the psf-simulator widget showing the in-focus plane of an aberrated PSF**

![raw](https://github.com/andreabassi78/napari-psf-simulator/raw/main/images/animation.gif)
**Slicing through a PSF aberrated with Zernike polynomials of order N=3, M=1 (coma)**

3) Click on the `Plot PSF Profile in Console` checkbox to see the x and z profiles of the PSF.
   They will show up in  the viewer console when `Calculate PSF` is executed.

![raw](https://github.com/andreabassi78/napari-psf-simulator/raw/main/images/Plot.png)
**Plot profile of the PSF, shown in the Console**

## Detailed documentation

An exhaustive documentation of the use of the plugin on scalar and vectoral propagation models can be found in [this] presentation.

A detailed explanation of the uses and advantages that simulating a PSF brings can be found [here].

The vectorial propagation model implements a secondary library: [pyfocus](https://github.com/fcaprile/PyFocus). The full documentation of this library can be found at [read the docs](https://pyfocus.readthedocs.io/en/latest/) and in the paper: ""PyFocus: A Python package for vectorial calculations of focused optical fields under realistic conditions. Application to toroidal foci."" https://doi.org/10.1016/j.cpc.2022.108315

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request. 
The plugin has been concived to be modular allowing the insertion of new aberations and pupils. Please contact the developers on github for adding new propagations and aberrations types. 
Any suggestions or contributions are welcome.

## License

Distributed under the terms of the [BSD-3] license,
""napari-psf-simulator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/andreabassi78/napari-psf-simulator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

[this]: https://github.com/andreabassi78/napari-psf-simulator/raw/main/docs/napari_psf_simullator_presentation.pdf

[here]: https://github.com/andreabassi78/napari-psf-simulator/raw/main/docs/pyfocus_seminar.pptx
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/andreabassi78/napari-psf-simulator/issues', 'Documentation, https://github.com/andreabassi78/napari-psf-simulator#README.md', 'Source Code, https://github.com/andreabassi78/napari-psf-simulator', 'User Support, https://github.com/andreabassi78/napari-psf-simulator/issues']",,,napari-psf-simulator.make_widget,,,,
354,napari-pyav,napari-pyav,pyav video plugin,0.0.10,2024-10-05,2025-06-23,jlab.berlin,yourname@example.com,MIT,https://github.com/danionella/napari-pyav/issues,https://pypi.org/project/napari-pyav/,,,Napari plugin for reading videos using PyAV,>=3.9,"['numpy', 'av<14', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""']","# napari-pyav

[![License MIT](https://img.shields.io/pypi/l/napari-pyav.svg?color=green)](https://github.com/danionella/napari-pyav/raw/main/LICENSE)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-pyav.svg?color=green)](https://python.org)
[![PyPI](https://img.shields.io/pypi/v/napari-pyav.svg?color=green)](https://pypi.org/project/napari-pyav)
[![Conda Version](https://img.shields.io/conda/v/danionella/napari_pyav)](https://anaconda.org/danionella/napari_pyav)
[![tests](https://github.com/danionella/napari-pyav/workflows/tests/badge.svg)](https://github.com/danionella/napari-pyav/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-pyav)](https://napari-hub.org/plugins/napari-pyav)

Napari plugin for reading videos using [PyAV](https://github.com/PyAV-Org/PyAV). Inspired by the [napari-video](https://github.com/janclemenslab/napari-video) project, which served us very well for many years. For some long videos, however, its dependency on opencv caused seek glitches, so we implemented this alternative plugin based on PyAV.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-pyav` via [pip]:

    pip install napari-pyav


Or via [conda](https://github.com/conda-forge/miniforge?tab=readme-ov-file#miniforge): 

    conda install danionella::napari_pyav


To install latest development version :

    pip install git+https://github.com/danionella/napari-pyav.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-pyav"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/danionella/napari-pyav/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Homepage, https://github.com/danionella/napari-pyav', 'Bug Tracker, https://github.com/danionella/napari-pyav/issues', 'Documentation, https://github.com/danionella/napari-pyav#README.md', 'Source Code, https://github.com/danionella/napari-pyav', 'User Support, https://github.com/danionella/napari-pyav/issues']",napari-pyav.get_reader,,,,['*.mp4'],,
355,napari-psf-analysis,napari-psf-analysis,napari_psf_analysis,1.1.4,2022-03-30,2024-10-02,Tim-Oliver Buchholz,tim-oliver.buchholz@fmi.ch,BSD-3-Clause,https://github.com/fmi-faim/napari-psf-analysis/issues,https://pypi.org/project/napari-psf-analysis/,,https://github.com/fmi-faim/napari-psf-analysis.git,A plugin to analyse point spread functions (PSFs).,>=3.9,"['bfio', 'matplotlib<3.9', 'matplotlib-scalebar', 'napari', 'numpy', 'pandas', 'scikit-image', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'tox; extra == ""testing""']","# napari-psf-analysis

[![License](https://img.shields.io/badge/License-BSD_3--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)
[![PyPI](https://img.shields.io/pypi/v/napari-psf-analysis.svg?color=green)](https://pypi.org/project/napari-psf-analysis)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-psf-analysis.svg?color=green)](https://python.org)
[![tests](https://github.com/fmi-faim/napari-psf-analysis/workflows/tests/badge.svg)](https://github.com/fmi-faim/napari-psf-analysis/actions)
[![codecov](https://codecov.io/gh/fmi-faim/napari-psf-analysis/branch/main/graph/badge.svg)](https://codecov.io/gh/fmi-faim/napari-psf-analysis)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-psf-analysis)](https://napari-hub.org/plugins/napari-psf-analysis)

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

---
![application_screenshot](figs/napari-psf-analysis_demo.gif)
<!-- start abstract -->
A plugin to analyse point spread functions (PSFs) of optical systems.
<!-- end abstract -->
## Usage
### Starting Point
To run a PSF analysis open an image of acquired beads. Add a point-layer
and indicate the beads you want to measure by adding a point.

### Run Analysis
Open the plugin (Plugins > napari-psf-analysis > PSF Analysis) and ensure
that your bead image and point layers are select in the `Basic` tab under
`Image` and `Points` respectively.
In the `Advanced` tab further information can be provided. Only the filled
in fields of the `Advanced` tab are saved in the output.

After verifying all input fields click `Extract PSFs`.

### Discard and Save Measurement
Once the PSF extraction has finished a new layer (`Analyzed Beads`) appears,
holding a summary
image for every selected bead.
Individual summaries can be discarded by clicking the `Delete Displayed
Measurement` button.

Results are saved to the selected `Save Dir` by clicking the `Save
Measurements` button.

Note: Beads for which the bounding box does not fit within the image are
automatically excluded from the analysis and no output is generated.


### Saved Data
Every image of the `Analyzed Beads` layer is saved as `{source_image_name}_X
{bead-centroid-x}_Y{bead-centroid-y}_Z{bead-centroid-z}.png` file.
Additionally a `PSFMeasurement_{source_image_acquisition_date}_
{source_image_name}_{microscope_name}_{magnification}_{NA}.csv` file is
stored containing the measured values and all filled in fields.

---
<!-- start install -->
## Installation
We recommend installation into a fresh conda environment.

### 1. Install napari
```shell
conda create -y -n psf-analysis -c conda-forge python=3.9

conda activate psf-analysis

conda install -c conda-forge napari pyqt
```

### 2. Install napari-aicsimageio and bioformats
Required if you want to open other files than `.tif` e.g. `.stk. `.

__Note:__ See [napari-aicsimageio](https://www.napari-hub.org/plugins/napari-aicsimageio) for more information about opening images.
```shell
conda install -c conda-forge openjdk bioformats_jar ""aicsimageio[all]"" napari-aicsimageio

conda deactivate
conda activate psf-analysis
```

### 3. Install napari-psf-analysis
You can install `napari-psf-analysis` via [pip]:

```shell
python -m pip install xmlschema
python -m pip install napari-psf-analysis
```

### 4. Optional `Set Config`
You can provide a config yaml file with the available microscope names and a default save directory.
This will change the `Microscope` text field to a drop down menu and change the default save directory.

`example_config.yaml`
```yaml
microscopes:
  - TIRF
  - Zeiss Z1
output_path: ""D:\\psf_analysis\\measurements""
```

To use this config navigate to `Plugins > napari-psf-analysis > Set Config` and select the config file.

__Note:__ The save path is OS specific.

<!-- end install -->
### 5. Desktop Icon for Windows
Follow [these instructions](https://twitter.com/haesleinhuepf/status/1537030855843094529) by Robert Haase.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-psf-analysis"" is free and open source software

## Issues

If you encounter any problems, please [file an issue](https://github.com/fmi-faim/napari-psf-analysis/issues) along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/fmi-faim/napari-psf-analysis/issues', 'Documentation, https://github.com/fmi-faim/napari-psf-analysis#README.md', 'Source Code, https://github.com/fmi-faim/napari-psf-analysis', 'User Support, https://github.com/fmi-faim/napari-psf-analysis/issues']",,,napari_psf_analysis.set_config,,,,
356,napari-pssr,napari-pssr,napari PSSR,0.1,2022-11-18,2022-11-18,William Patton,will.hunter.patton@gmail.com,MIT,https://github.com/pattonw/napari-pssr/issues,https://pypi.org/project/napari-pssr/,,https://github.com/pattonw/napari-pssr,A plugin for training and applying pssr,>=3.7,"['numpy', 'zarr', 'magicgui', 'bioimageio.core', 'gunpowder', 'matplotlib', 'torch', 'napari']","# napari-pssr

[![License](https://img.shields.io/pypi/l/napari-pssr.svg?color=green)](https://github.com/pattonw/napari-pssr/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-pssr.svg?color=green)](https://pypi.org/project/napari-pssr)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-pssr.svg?color=green)](https://python.org)
[![tests](https://github.com/pattonw/napari-pssr/workflows/tests/badge.svg)](https://github.com/pattonw/napari-pssr/actions)
[![codecov](https://codecov.io/gh/pattonw/napari-pssr/branch/main/graph/badge.svg)](https://codecov.io/gh/pattonw/napari-pssr)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-pssr)](https://napari-hub.org/plugins/napari-pssr)

A plugin for training and applying pssr

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-pssr` via [pip]:

    pip install napari-pssr

Some libraries need to be updated to the most recent version to get all features.
These will be updated once they are released on pypi
    
    pip install git+https://github.com/bioimage-io/core-bioimage-io-python"",
    pip install git+https://github.com/funkey/gunpowder.git@patch-1.2.3"",


To install latest development version :

    pip install git+https://github.com/pattonw/napari-pssr.git

## Model download

A sample model can be downloaded from `https://github.com/pattonw/model-specs/tree/main/pssr`. This model comes with some restrictive dependencies. To use follow these steps.
1) install this plugin following the directions provided above
2) install bioimageio.core via `pip install bioimageio.core` or `conda install -c conda-forge bioimageio.core`
3) `pip install fastai==1.0.55 tifffile libtiff czifile scikit-image`
4) `pip uninstall torch torchvision` (may need multiple runs)
5) `conda install pytorch==1.1.0 torchvision==0.3.0 cudatoolkit=10.0 -c pytorch`
6) `pip install pillow==6.1.0`

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-pssr"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/pattonw/napari-pssr/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/pattonw/napari-pssr/issues', 'Documentation, https://github.com/pattonw/napari-pssr#README.md', 'Source Code, https://github.com/pattonw/napari-pssr', 'User Support, https://github.com/pattonw/napari-pssr/issues']",,,napari-pssr.make_pssr_widget,napari-pssr.lr_em,,,
357,napari-qrcode,napari-qrcode,QR-Code,0.0.1,2023-02-21,2023-02-21,Kyle Harrington,czi@kyleharrington.com,BSD-3-Clause,https://github.com/kephale/napari-qrcode/issues,https://pypi.org/project/napari-qrcode/,,https://github.com/kephale/napari-qrcode,A napari plugin to generate QR-Codes,>=3.8,"['numpy', 'magicgui', 'qtpy', 'qrcode', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-qrcode

[![License BSD-3](https://img.shields.io/pypi/l/napari-qrcode.svg?color=green)](https://github.com/kephale/napari-qrcode/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-qrcode.svg?color=green)](https://pypi.org/project/napari-qrcode)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-qrcode.svg?color=green)](https://python.org)
[![tests](https://github.com/kephale/napari-qrcode/workflows/tests/badge.svg)](https://github.com/kephale/napari-qrcode/actions)
[![codecov](https://codecov.io/gh/kephale/napari-qrcode/branch/main/graph/badge.svg)](https://codecov.io/gh/kephale/napari-qrcode)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-qrcode)](https://napari-hub.org/plugins/napari-qrcode)

A napari plugin to generate QR-Codes

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-qrcode` via [pip]:

    pip install napari-qrcode



To install latest development version :

    pip install git+https://github.com/kephale/napari-qrcode.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-qrcode"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kephale/napari-qrcode/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kephale/napari-qrcode/issues', 'Documentation, https://github.com/kephale/napari-qrcode#README.md', 'Source Code, https://github.com/kephale/napari-qrcode', 'User Support, https://github.com/kephale/napari-qrcode/issues']",,,napari-qrcode.qrcode_widget,,,,
358,napari-quoll,napari-quoll,napari Quoll,0.0.1,2022-08-26,2022-08-26,Elaine Ho,Elaine.Ho@rfi.ac.uk,Apache-2.0,https://github.com/rosalindfranklininstitute/napari-quoll/issues,https://pypi.org/project/napari-quoll/,,https://github.com/rosalindfranklininstitute/napari-quoll,Resolution estimation for electron tomography,>=3.7,"['numpy', 'magicgui', 'qtpy', 'quoll', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-quoll

[![License](https://img.shields.io/badge/License-Apache_2.0-green.svg)](https://opensource.org/licenses/Apache-2.0)
[![PyPI](https://img.shields.io/pypi/v/napari-quoll.svg?color=green)](https://pypi.org/project/napari-quoll)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-quoll.svg?color=green)](https://python.org)
[![tests](https://github.com/rosalindfranklininstitute/napari-quoll/workflows/tests/badge.svg)](https://github.com/rosalindfranklininstitute/napari-quoll/actions)
[![codecov](https://codecov.io/gh/rosalindfranklininstitute/napari-quoll/branch/main/graph/badge.svg)](https://codecov.io/gh/rosalindfranklininstitute/napari-quoll)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-quoll)](https://napari-hub.org/plugins/napari-quoll)

Resolution estimation for electron tomography

The Python package which does the resolution estimation is [Quoll](https://github.com/rosalindfranklininstitute/quoll). This repository, `napari-quoll` is just the Napari plugin.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-quoll` via [pip] into a <b>Python 3.7</b> environment, replacing <env_name> with an environment name of your choice:

    conda -n create <env_name> python=3.7
    conda activate <env_name>
    pip install napari-quoll



To install latest development version :

    pip install git+https://github.com/rosalindfranklininstitute/napari-quoll.git

<b>Note:</b> Due to [miplib]() dependencies, this plugin only works on Python 3.7 environments.


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-quoll"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/rosalindfranklininstitute/napari-quoll/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/rosalindfranklininstitute/napari-quoll/issues', 'Documentation, https://github.com/rosalindfranklininstitute/napari-quoll#README.md', 'Source Code, https://github.com/rosalindfranklininstitute/napari-quoll', 'User Support, https://github.com/rosalindfranklininstitute/napari-quoll/issues']",,,napari-quoll.make_quoll_widget,,,,
359,napari-pystackreg,napari-pystackreg,napari pystackreg,0.1.4,2022-07-07,2023-01-15,Gregor Lichtner,gregor.lichtner@med.uni-greifswald.de,Apache-2.0,https://github.com/glichtner/napari-pystackreg/issues,https://pypi.org/project/napari-pystackreg/,,https://github.com/glichtner/napari-pystackreg,Robust image registration for napari,>=3.8,"['magicgui', 'numpy', 'pystackreg (>=0.2.6)', 'qtpy', ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-pystackreg

[![License](https://img.shields.io/pypi/l/napari-pystackreg.svg?color=green)](https://github.com/glichtner/napari-pystackreg/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-pystackreg.svg?color=green)](https://pypi.org/project/napari-pystackreg)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-pystackreg.svg?color=green)](https://python.org)
[![tests](https://github.com/glichtner/napari-pystackreg/workflows/tests/badge.svg)](https://github.com/glichtner/napari-pystackreg/actions)
[![codecov](https://codecov.io/gh/glichtner/napari-pystackreg/branch/main/graph/badge.svg)](https://codecov.io/gh/glichtner/napari-pystackreg)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-pystackreg)](https://napari-hub.org/plugins/napari-pystackreg)

Robust image registration for napari.

## Summary
napari-pystackreg offers the image registration capabilities of the python package
[pystackreg](https://github.com/glichtner/pystackreg) for napari.

![](https://github.com/glichtner/napari-pystackreg/raw/main/docs/napari-pystackreg.gif)

## Description

pyStackReg is used to align (register) one or more images to a common reference image, as is required usually in
time-resolved fluorescence or wide-field microscopy.
It is directly ported from the source code of the ImageJ plugin ``TurboReg`` and provides additionally the
functionality of the ImageJ plugin ``StackReg``, both of which were written by Philippe Thevenaz/EPFL
(available at http://bigwww.epfl.ch/thevenaz/turboreg/).

pyStackReg provides the following five types of distortion:

- Translation
- Rigid body (translation + rotation)
- Scaled rotation (translation + rotation + scaling)
- Affine (translation + rotation + scaling + shearing)
- Bilinear (non-linear transformation; does not preserve straight lines)

pyStackReg supports the full functionality of StackReg plus some additional options, e.g., using different reference
images and having access to the actual transformation matrices (please see the examples below). Note that pyStackReg
uses the high quality (i.e. high accuracy) mode of TurboReg that uses cubic spline interpolation for transformation.

Please note: The bilinear transformation cannot be propagated, as a combination of bilinear transformations does not
generally result in a bilinear transformation. Therefore, stack registration/transform functions won't work with
bilinear transformation when using ""previous"" image as reference image. You can either use another reference (
""first"" or ""mean"" for first or mean image, respectively), or try to register/transform each image of the stack
separately to its respective previous image (and use the already transformed previous image as reference for the
next image).

## Installation

You can install ``napari-pystackreg`` via [pip](https://pypi.org/project/pip/) from [PyPI](https://pypi.org/):

    pip install napari-pystackreg

You can also install ``napari-pystackreg`` via [conda](https://docs.conda.io/en/latest/):

    conda install -c conda-forge napari-pystackreg

Or install it via napari's plugin installer.

    Plugins > Install/Uninstall Plugins... > Filter for ""napari-pystackreg"" > Install

To install latest development version:

    pip install git+https://github.com/glichtner/napari-pystackreg.git

## Usage


### Open Plugin User Interface

Start up napari, e.g. from the command line:

    napari

Then, load an image stack (e.g. via ``File > Open Image...``) that you want to register. You can also use the example
stack provided by the pluging (``File > Open Sample > napari-pystackreg: PC12 moving example``).
Then, select the ``napari-pystackreg`` plugin from the ``Plugins > napari-pystackreg: pystackreg`` menu.

![](https://github.com/glichtner/napari-pystackreg/raw/main/docs/ui-initial.png)

### User Interface Options
A variety of options are available to control the registration process:

* `Image Stack`: The image layer that should be registered/transformed.
* `Transformation`: The type of transformation that should be applied.
  - `Translation`: translation
  - `Rigid body`: translation + rotation
  - `Scaled rotation`: translation + rotation + scaling
  - `Affine`: translation + rotation + scaling + shearing
  - `Bilinear`: non-linear transformation; does not preserve straight lines
* `Reference frame:` The reference image for registration.
  - `Previous frame`: Aligns each frame (image) to its previous frame in the stack
  - `Mean (all frames)`: Aligns each frame (image) to the average of all images in the stack
  - `Mean (first n frames)`: Aligns each frame (image) to the mean of the first n frames in the stack. n is a tuneable parameter.
* `Moving-average stack before register`: Apply a moving average to the stack before registration. This can be useful to
  reduce noise in the stack (if the signal-to-noise ratio is very low). The moving average is applied to the stack only
  for determining the transformation matrices, but not for the actual transforming of the stack.
* `Transformation matrix file`: Transformation matrices can be saved to or loaded from a file for permanent storage.

### Reference frame
The reference frame is the frame to which the other frames are aligned. The default option is to use the
`Previous frame`, which will register each frame to its respective previous frame in the stack. Alternatively, the
reference frame can be set to the mean of all frames in the stack (`Mean (all frames)`) or the mean of the first n
frames in the stack (`Mean (first n frames)`). The latter option can be useful if the first frames in the stack are more
stable than the later frames (e.g. if the first frames are taken before the sample is moved). When selecting the
`Mean (first n frames)` option, the number of frames to use for the mean can be set via the spinbox below the option.

![](https://github.com/glichtner/napari-pystackreg/raw/main/docs/ui-reference-mean-n.png)

### Moving average before registration
To increase registration performance with low signal-to-noise ratio stacks, a moving average can be applied to the
stack before registration. The moving average is applied to the stack only for determining the
transformation matrices, but not for the actual transforming of the stack. That means that the transformed stack will
still contain the original frames (however registered), but not the averaged frames.

When selecting the `Moving-average stack before register` option, the number of frames to use for the moving average can
be set via the spinbox below the option.

![](https://github.com/glichtner/napari-pystackreg/raw/main/docs/ui-moving-average.png)

### Transformation matrix file
The transformation matrices can be saved to or loaded from a file for permanent storage. This can be useful if you want
to apply the same transformation to another stack (e.g. a different channel of the same sample). The transformation
matrices are saved as a numpy array in a binary file (``.npy``). The file can be loaded via the `Load` button and saved
via the `Save` button.

![](https://github.com/glichtner/napari-pystackreg/raw/main/docs/ui-register-tmat.png)

### Register/Transform
To perform the actual registration and transformation steps, click the `Register` and `Transform` buttons, respectively.

The `Register` button will register the stack to the reference by determining the appropriate transformation matrices,
without actually transforming the stack. The transformation matrices can be saved to a file via the `Save` button in the
`Transformation matrix file` section.

![](https://github.com/glichtner/napari-pystackreg/raw/main/docs/ui-registered.png)

The `Transform` button (1) will transform the stack to the reference by applying the transformation matrices that are
currently loaded to the stack selected in `Image Stack`. For the button to become active, either the transformation
matrices have to be loaded from a file via the `Load` button in the `Transformation matrix file` section, or the
`Register` button has to be clicked first to determine the transformation matrices.

The `Transform` button will also add a new image layer to the napari viewer (2) with the transformed stack. The name of the
new layer will be the name of the original stack with the prefix `Registered`.

![](https://github.com/glichtner/napari-pystackreg/raw/main/docs/ui-transformed.png)

Finally, the `Register & Transform` button will perform both the registration and transformation steps in one go.

----------------------------------

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-pystackreg"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

## Acknowledgments

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/glichtner/napari-pystackreg/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/glichtner/napari-pystackreg/issues', 'Documentation, https://github.com/glichtner/napari-pystackreg#README.md', 'Source Code, https://github.com/glichtner/napari-pystackreg', 'User Support, https://github.com/glichtner/napari-pystackreg/issues']",,,napari-pystackreg.pystackreg,napari-pystackreg.load_sample_data,,,
360,napari-pymeshlab,napari-pymeshlab,napari pymeshlab,0.0.6,2022-01-14,2024-07-31,"Zach Marin, Robert Haase",zach.marin@yale.edu,MIT,https://github.com/zacsimile/napari-pymeshlab/issues,https://pypi.org/project/napari-pymeshlab/,,https://github.com/zacsimile/napari-pymeshlab,"Interfaces between napari and pymeshlab library to allow import, export and construction of surfaces.",>=3.8,"['napari', 'npe2', 'numpy', 'pymeshlab']","# napari-pymeshlab

[![License](https://img.shields.io/pypi/l/napari-pymeshlab.svg?color=green)](https://github.com/zacsimile/napari-pymeshlab/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-pymeshlab.svg?color=green)](https://pypi.org/project/napari-pymeshlab)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-pymeshlab.svg?color=green)](https://python.org)
[![tests](https://github.com/zacsimile/napari-pymeshlab/workflows/tests/badge.svg)](https://github.com/zacsimile/napari-pymeshlab/actions)
[![codecov](https://codecov.io/gh/zacsimile/napari-pymeshlab/branch/main/graph/badge.svg)](https://codecov.io/gh/zacsimile/napari-pymeshlab)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-pymeshlab)](https://napari-hub.org/plugins/napari-pymeshlab)

Interfaces between `napari` and the `pymeshlab` library to allow import, export, construction and processing of surfaces. 

This is a WIP and feature requests are welcome. Please check [PyMeshLab](https://pymeshlab.readthedocs.io/en/latest/)
for possible features.

![img.png](https://github.com/zacsimile/napari-pymeshlab/raw/main/docs/screenshot.png)

## Feature list

- Read/write .3ds, .apts, .asc, .bre, .ctm, .dae, .e57, .es, .fbx, .glb, .gltf, .obj, .off, .pdb, .ply,
                  .ptx, .qobj, .stl, .vmi, .wrl, .x3d, .x3dv
- [Screened Poisson Surface Reconstruction](https://www.cs.jhu.edu/~misha/MyPapers/ToG13.pdf)
- [Convex hull of a surface](https://pymeshlab.readthedocs.io/en/0.1.9/tutorials/apply_filter.html)
- [Laplacian smoothing of surfaces](https://pymeshlab.readthedocs.io/en/0.1.9/filter_list.html#laplacian_smooth)
- [Smoothing surfaces using Taubin's method](https://pymeshlab.readthedocs.io/en/0.1.9/filter_list.html#taubin_smooth)
- [Surface simplification using clustering decimation](https://pymeshlab.readthedocs.io/en/0.1.9/filter_list.html#simplification_clustering_decimation)
- [colorize_curvature_apss](https://pymeshlab.readthedocs.io/en/0.1.9/filter_list.html#colorize_curvature_apss)

Some functions are shown in the [demo notebook](docs/demo.ipynb).

----------------------------------

<!--

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation 

You can install `napari-pymeshlab` via [pip]:

    pip install napari-pymeshlab




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-pymeshlab"" is free and open source software

## Issues

If you encounter any problems, please [file an issue](https://github.com/zacsimile/napari-pymeshlab/issues) along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']","['Bug Tracker, https://github.com/zacsimile/napari-pymeshlab/issues', 'Documentation, https://github.com/zacsimile/napari-pymeshlab#README.md', 'Source Code, https://github.com/zacsimile/napari-pymeshlab', 'User Support, https://github.com/zacsimile/napari-pymeshlab/issues']",napari-pymeshlab.get_mesh_reader,napari-pymeshlab.write_single_surface,napari-pymeshlab.screened_poisson_reconstruction,napari-pymeshlab.make_sphere,"['*.3ds', '*.apts', '*.asc', '*.bre', '*.ctm', '*.dae', '*.e57', '*.es', '*.fbx', '*.glb', '*.gltf', '*.obj', '*.off', '*.pdb', '*.ply', '*.ptx', '*.qobj', '*.stl', '*.vmi', '*.wrl', '*.x3d', '.x3dv']","['.3ds', '.apts', '.asc', '.bre', '.ctm', '.dae', '.e57', '.es', '.fbx', '.glb', '.gltf', '.obj', '.off', '.pdb', '.ply', '.ptx', '.qobj', '.stl', '.vmi', '.wrl', '.x3d', '.x3dv']",
361,napari-pyclesperanto-assistant,napari-pyclesperanto-assistant,napari_pyclesperanto_assistant,0.25.0,2020-12-19,2024-10-22,"Robert Haase, Talley Lambert",robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/clEsperanto/napari_pyclesperanto_assistant,https://pypi.org/project/napari-pyclesperanto-assistant/,,https://github.com/clesperanto/napari_pyclesperanto_assistant,GPU-accelerated image processing in napari using OpenCL,>=3.9,"['napari-plugin-engine>=0.1.4', 'pyopencl', 'toolz', 'scikit-image', 'napari>=0.4.15', 'pyclesperanto-prototype>=0.24.5', 'pyclesperanto==0.14.2', 'magicgui', 'numpy!=1.19.4', 'pyperclip', 'loguru', 'jupytext', 'jupyter', 'pandas', 'napari-tools-menu>=0.1.8', 'napari-time-slicer>=0.4.0', 'napari-skimage-regionprops>=0.2.0', 'napari-workflows>=0.1.1', 'napari-assistant>=0.2.0']","# napari-pyclesperanto-assistant
[![Image.sc forum](https://img.shields.io/badge/dynamic/json.svg?label=forum&url=https%3A%2F%2Fforum.image.sc%2Ftag%2Fclesperanto.json&query=%24.topic_list.tags.0.topic_count&colorB=brightgreen&suffix=%20topics&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAOCAYAAAAfSC3RAAABPklEQVR42m3SyyqFURTA8Y2BER0TDyExZ+aSPIKUlPIITFzKeQWXwhBlQrmFgUzMMFLKZeguBu5y+//17dP3nc5vuPdee6299gohUYYaDGOyyACq4JmQVoFujOMR77hNfOAGM+hBOQqB9TjHD36xhAa04RCuuXeKOvwHVWIKL9jCK2bRiV284QgL8MwEjAneeo9VNOEaBhzALGtoRy02cIcWhE34jj5YxgW+E5Z4iTPkMYpPLCNY3hdOYEfNbKYdmNngZ1jyEzw7h7AIb3fRTQ95OAZ6yQpGYHMMtOTgouktYwxuXsHgWLLl+4x++Kx1FJrjLTagA77bTPvYgw1rRqY56e+w7GNYsqX6JfPwi7aR+Y5SA+BXtKIRfkfJAYgj14tpOF6+I46c4/cAM3UhM3JxyKsxiOIhH0IO6SH/A1Kb1WBeUjbkAAAAAElFTkSuQmCC)](https://forum.image.sc/tag/clesperanto)
[![website](https://img.shields.io/website?url=http%3A%2F%2Fclesperanto.net)](http://clesperanto.net)
[![License](https://img.shields.io/pypi/l/napari-pyclesperanto-assistant.svg?color=green)](https://github.com/clesperanto/napari-pyclesperanto-assistant/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-pyclesperanto-assistant.svg?color=green)](https://pypi.org/project/napari-pyclesperanto-assistant)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-pyclesperanto-assistant.svg?color=green)](https://python.org)
[![tests](https://github.com/clesperanto/napari_pyclesperanto_assistant/workflows/tests/badge.svg)](https://github.com/clesperanto/napari_pyclesperanto_assistant/actions)
[![codecov](https://codecov.io/gh/clesperanto/napari_pyclesperanto_assistant/branch/master/graph/badge.svg)](https://codecov.io/gh/clesperanto/napari_pyclesperanto_assistant)
[![Development Status](https://img.shields.io/pypi/status/napari_pyclesperanto_assistant.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-pyclesperanto-assistant)](https://napari-hub.org/plugins/napari-pyclesperanto-assistant)
[![DOI](https://zenodo.org/badge/322312181.svg)](https://zenodo.org/badge/latestdoi/322312181)

The py-clEsperanto-assistant is a yet experimental [napari](https://github.com/napari/napari) plugin for building GPU-accelerated image processing workflows. 
It is part of the [clEsperanto](http://clesperanto.net) project and thus, aims at removing programming language related barriers between image processing ecosystems in the life sciences. 
It uses [pyclesperanto](https://github.com/clEsperanto/pyclesperanto_prototype) and with that [pyopencl](https://documen.tician.de/pyopencl/) as backend for processing images.

This napari plugin adds some menu entries to the Tools menu. You can recognize them with their suffix `(clEsperanto)` in brackets.
Furthermore, it can be used from the [napari-assistant](https://www.napari-hub.org/plugins/napari-assistant) graphical user interface. 
Therefore, just click the menu `Tools > Utilities > Assistant (na)` or run `naparia` from the command line.

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/virtual_4d_support1.gif)

## Usage

### Start up the assistant
Start up napari, e.g. from the command line:
```
napari
```

Load example data, e.g. from the menu `File > Open Samples > clEsperanto > CalibZAPWfixed` and 
start the assistant from the menu `Tools > Utilities > Assistant (na)`.

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/screenshot1.png)

In case of two dimensional timelapse data, an initial conversion step might be necessary depending on your data source. 
Click the menu `Tools > Utilities > Convert to 2d timelapse`. In the dialog, select the dataset and click ok. 
You can delete the original dataset afterwards:

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/screenshot1a.png)

### Set up a workflow

Choose categories of operations in the top right panel, for example start with denoising using a Gaussian Blur with sigma 1 in x and y.

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/screenshot2.png)

Continue with background removal using the top-hat filter with radius 5 in x and y.

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/screenshot2a.png)

For labeling the objects, use [Voronoi-Otsu-Labeling](https://nbviewer.jupyter.org/github/clEsperanto/pyclesperanto_prototype/blob/master/demo/segmentation/voronoi_otsu_labeling.ipynb) with both sigma parameters set to 2.

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/screenshot2b.png)

The labeled objects can be extended using a Voronoi diagram to derive a estimations of cell boundaries.

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/screenshot2c.png)

You can then configure napari to show the label boundaries on top of the original image:

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/screenshot2d.png)

When your workflow is set up, click the play button below your dataset:

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/timelapse_2d.gif)

### Neighbor statistics

When working with 2D or 3D data you can analyze measurements in relationship with their neighbors. 
For example, you can measure the area of blobs as shown in the example shown below using the menu 
`Tools > Measurements > Statistics of labeled pixels (clesperant)` and visualize it as `area` image by double-clicking on the table column (1).
Additionally, you can measure the maximum area of the 6 nearest neighbors using the menu `Tools > Measurments > Neighborhood statistics of measurements`.
The new column will then be called ""max_nn6_area..."" (2). When visualizing such parametric images next by each other, it is recommended to use
[napari-brightness-contrast](https://www.napari-hub.org/plugins/napari-brightness-contrast) and visualize the same intensity range to see differences correctly.

![](https://github.com/clEsperanto/napari_pyclesperanto_assistant/raw/master/docs/images/neighbor_statistics.png)

### Code generation
You can also export your workflow as Python/Jython code or as notebook. See the [napari-assistant documentation](https://www.napari-hub.org/plugins/napari-assistant) for details.

## Features
[pyclesperanto](https://github.com/clEsperanto/pyclesperanto_prototype) offers various possibilities for processing images. It comes from developers who work in life sciences and thus, it may be focused towards processing two- and three-dimensional microscopy image data showing cells and tissues. A selection of pyclesperanto's functionality is available via the assistant user interface. Typical workflows which can be built with this assistant include
* image filtering
  * denoising / noise reduction (mean, median, Gaussian blur)
  * background subtraction for uneven illumination or out-of-focus light (bottom-hat, top-hat, subtract Gaussian background)
  * grey value morphology (local minimum, maximum. variance)
  * gamma correction
  * Laplace operator
  * Sobel operator
* combining images
  * masking
  * image math (adding, subtracting, multiplying, dividing images) 
  * absolute / squared difference
* image transformations
  * translation
  * rotation
  * scale
  * reduce stack  
  * sub-stacks
* image projections
  * minimum / mean / maximum / sum / standard deviation projections
* image segmentation
  * binarization (thresholding, local maxima detection)
  * labeling
  * regionalization
  * instance segmentation
  * semantic segmentation
  * detect label edges
  * label spots
  * connected component labeling
  * Voronoi-Otsu-labeling
* post-processing of binary images
  * dilation
  * erosion
  * binary opening
  * binary closing 
  * binary and / or / xor
* post-processing of label images
  * dilation (expansion) of labels
  * extend labels via Voronoi
  * exclude labels on edges
  * exclude labels within / out of size / value range
  * merge touching labels
* parametric maps
  * proximal / touching neighbor count
  * distance measurements to touching / proximal / n-nearest neighbors
  * pixel count map
  * mean / maximum / extension ratio map
* label measurements / post processing of parametric maps
  * minimum / mean / maximum / standard deviation intensity maps
  * minimum / mean / maximum / standard deviation of touching / n-nearest / neighbors
* neighbor meshes
  * touching neighbors
  * n-nearest neighbors
  * proximal neighbors
  * distance meshes
* measurements based on label images
  * bounding box 2D / 3D
  * minimum / mean / maximum / sum / standard deviation intensity
  * center of mass
  * centroid
  * mean / maximum distance to centroid (and extension ratio shape descriptor)
  * mean / maximum distance to center of mass (and extension ratio shape descriptor)
  * statistics of neighbors (See related [publication](https://www.frontiersin.org/articles/10.3389/fcomp.2021.774396/full))
* code export
  * python / Fiji-compatible jython
  * python jupyter notebooks
* pyclesperanto scripting
  * cell segmentation
  * cell counting
  * cell differentiation
  * tissue classification

## Installation

It is recommended to install the assistant using mamba. If you have never used mamba before, it is recommended to read 
[this blog post](https://biapol.github.io/blog/mara_lampert/getting_started_with_mambaforge_and_python/readme.html) first. 

```shell
mamba create --name cle_39 python=3.9 napari-pyclesperanto-assistant -c conda-forge
mamba activate cle_39
```

Mac-users please also install this:

    mamba install -c conda-forge ocl_icd_wrapper_apple
    
Linux users please also install this:
    
    mamba install -c conda-forge ocl-icd-system

You can then start the napari-assistant using this command:

```
naparia
```


## Feedback and contributions welcome!
clEsperanto is developed in the open because we believe in the open source community. See our [community guidelines](https://clij.github.io/clij2-docs/community_guidelines). Feel free to drop feedback as [github issue](https://github.com/clEsperanto/pyclesperanto_prototype/issues) or via [image.sc](https://image.sc)

## Acknowledgements
This project was supported by the Deutsche Forschungsgemeinschaft under Germanyâs Excellence Strategy â EXC2068 - Cluster of Excellence ""Physics of Life"" of TU Dresden.
This project has been made possible in part by grant number [2021-240341 (Napari plugin accelerator grant)](https://chanzuckerberg.com/science/programs-resources/imaging/napari/improving-image-processing/) from the Chan Zuckerberg Initiative DAF, an advised fund of the Silicon Valley Community Foundation.

[Imprint](https://clesperanto.github.io/imprint)

","['Programming Language :: Python :: 3', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Framework :: napari', 'Intended Audience :: Science/Research', 'Development Status :: 3 - Alpha']","['Bug Tracker, https://github.com/clEsperanto/napari_pyclesperanto_assistant/issues', 'Documentation, https://github.com/clEsperanto/napari_pyclesperanto_assistant/', 'Source Code, https://github.com/clEsperanto/napari_pyclesperanto_assistant', 'User Support, https://forum.image.sc/tag/clij']",,,napari_pyclesperanto_assistant.Assistant,napari_pyclesperanto_assistant._load_Lund,,,
362,napari-rembg,napari-rembg,Napari Select Foreground,0.0.7,2023-09-30,2024-02-17,Mallory Wittwer,mallory.wittwer@epfl.ch,BSD-3-Clause,https://github.com/EPFL-Center-for-Imaging/napari-rembg.git,https://pypi.org/project/napari-rembg/,,https://github.com/EPFL-Center-for-Imaging/napari-rembg.git,AI-based foreground extraction in scientific and natural images.,>=3.8,"['magicgui', 'qtpy', 'napari[all] >=0.4.16', ""rembg ; extra == 'local'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","![EPFL Center for Imaging logo](https://imaging.epfl.ch/resources/logo-for-gitlab.svg)
# napari-rembg

Segment images using a collection of fast and lightweight generalist segmentation models in Napari. This plugin is based on the [rembg](https://github.com/danielgatis/rembg) project.

![demo](./assets/demo.gif)

**Key features**

- Choose among **five generalist segmentation models**, including SAM (Segment Anything Model).
- Quickly annotate individual objects by drawing **bounding boxes** around them.
- Possibility to generate predictions via a remote **web API** and keep the installation lightweight on client machines.
- Compatible with 2D, RGB, 2D+t, and 3D images (slice by slice).

## Installation

You can install `napari-rembg` via [pip]. If you wish to use your local machine for the predictions (most users):

    pip install ""napari-rembg[local]""

If you wish to generate predictions from a [web api](#running-the-segmentation-via-a-web-api), go for a minimal install:

    pip install napari-rembg

## Models

- [u2net](https://github.com/xuebinqin/U-2-Net): A pre-trained model for general use cases.
- [u2netp](https://github.com/xuebinqin/U-2-Net): A lightweight version of u2net.
- [silueta](https://github.com/xuebinqin/U-2-Net/issues/295): Same as u2net with a size reduced to 43 Mb.
- [isnet](https://github.com/xuebinqin/DIS): A pre-trained model for general use cases.
- [sam](https://github.com/facebookresearch/segment-anything): Segment Anything Model pre-trained for any use cases (`vit_b`)

![models](./assets/comparison.png)

The models automatically get downloaded in the user's home folder in the `.u2net` directory the first time inference is run.

## Usage

Start `napari-rembg` from the `Plugins` menu of Napari:

```
Plugins > Napari Select Foreground > Select foreground
```

### Segment an image loaded into Napari

Select your image in the `Image` dropdown and press `Run`. The output segmentation appears in the `Labels` layer selected in the `Mask` field (if no layer is selected, a new one is created).

### Segment individual objects using bounding boxes

- Click on the `Add` button next to the `ROI` field. This adds a `Shapes layer` to the viewer.
- Click and drag bounding boxes around objects in the image. Each time you draw a bounding box a segmentation is generated in the region selected.

![screenshot](./assets/screenshot.gif)

You can choose to auto-increment the label index to distinguish individual objects. Deselect that option to annotate a single foreground class.

## Running the segmentation via a web API

You can run the `rembg` segmentation via a web API running in a `docker` container.

**Advantages**
- The segmentation can be run on a remote machine with optimization (e.g. GPU).
- The segmentation models will be downloaded inside the docker container instead of the user's file system.
- You can minimally install the package with `pip install napari-rembg` on the client's machine. This will *not* install the `rembg` library, which can solve potential dependency conflicts or bugs.

**Setup**

See [these instructions](./src/rembg-api/README.md) on how to set up the docker container and web API.

**Usage**

Start `napari-rembg` from the `Plugins` menu of Napari:

```
Plugins > Napari Select Foreground > Select foreground (Web API)
```

## Related projects

If you are looking for similar generalist segmentation plugins, check out these related projects:

- [napari-sam](https://github.com/MIC-DKFZ/napari-sam)
- [napari-segment-anything](https://github.com/royerlab/napari-segment-anything)

## Contributing

Contributions are very welcome. 

## License

Distributed under the terms of the [BSD-3] license,
""napari-rembg"" is free and open source software.

## Issues

If you encounter any problems, please file an issue along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Source Code, https://github.com/EPFL-Center-for-Imaging/napari-rembg.git']",,,napari-rembg.local,,,,
363,napari-roi-manager,napari-roi-manager,ROI Manager,0.0.5,2024-02-25,2025-05-27,Hanjin Liu,Hanjin Liu <liuhanjin.sc@gmail.com>,Unavailable,https://github.com/hanjinliu/napari-roi-manager/issues,https://pypi.org/project/napari-roi-manager/,,,A ROI Manager Widget with an UI similar to ImageJ,>=3.9,"['numpy', 'qtpy', 'roifile', ""napari; extra == 'testing'"", ""pyqt5; extra == 'testing'"", ""pytest; extra == 'testing'"", ""pytest-cov; extra == 'testing'"", ""pytest-qt; extra == 'testing'"", ""tox; extra == 'testing'""]","# napari-roi-manager

[![License BSD-3](https://img.shields.io/pypi/l/napari-roi-manager.svg?color=green)](https://github.com/hanjinliu/napari-roi-manager/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-roi-manager.svg?color=green)](https://pypi.org/project/napari-roi-manager)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-roi-manager.svg?color=green)](https://python.org)
[![tests](https://github.com/hanjinliu/napari-roi-manager/workflows/tests/badge.svg)](https://github.com/hanjinliu/napari-roi-manager/actions)
[![codecov](https://codecov.io/gh/hanjinliu/napari-roi-manager/branch/main/graph/badge.svg)](https://codecov.io/gh/hanjinliu/napari-roi-manager)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-roi-manager)](https://napari-hub.org/plugins/napari-roi-manager)

A ROI Manager Widget with an UI similar to ImageJ.

![](https://github.com/hanjinliu/napari-roi-manager/blob/main/images/demo.gif)

&check; The layer is just a Shapes layer, so it is compatible with any other plugins.

&check; Supports importing and exporting ImageJ ROI files.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


## Installation

You can install `napari-roi-manager` via [pip]:

    pip install napari-roi-manager



To install latest development version :

    pip install git+https://github.com/hanjinliu/napari-roi-manager.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-roi-manager"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hanjinliu/napari-roi-manager/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hanjinliu/napari-roi-manager/issues', 'Documentation, https://github.com/hanjinliu/napari-roi-manager#README.md', 'Homepage, https://github.com/hanjinliu/napari-roi-manager', 'Source Code, https://github.com/hanjinliu/napari-roi-manager', 'User Support, https://github.com/hanjinliu/napari-roi-manager/issues']",,,napari-roi-manager.make_qwidget,,,,
364,napari-rioxarray,napari-rioxarray,Rioxarray Plugin,0.0.1,2022-09-01,2022-09-01,Dr. Andrew Annex,ama6fy@virginia.edu,BSD-3-Clause,https://github.com/AndrewAnnex/napari-rioxarray/issues,https://pypi.org/project/napari-rioxarray/,,https://github.com/AndrewAnnex/napari-rioxarray,A rioxarray plugin for napari supporting GDAL raster datatypes,>=3.8,"['numpy', 'napari', 'rioxarray', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-rioxarray

[![License BSD-3](https://img.shields.io/pypi/l/napari-rioxarray.svg?color=green)](https://github.com/AndrewAnnex/napari-rioxarray/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-rioxarray.svg?color=green)](https://pypi.org/project/napari-rioxarray)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-rioxarray.svg?color=green)](https://python.org)
[![tests](https://github.com/AndrewAnnex/napari-rioxarray/workflows/tests/badge.svg)](https://github.com/AndrewAnnex/napari-rioxarray/actions)
[![codecov](https://codecov.io/gh/AndrewAnnex/napari-rioxarray/branch/main/graph/badge.svg)](https://codecov.io/gh/AndrewAnnex/napari-rioxarray)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-rioxarray)](https://napari-hub.org/plugins/napari-rioxarray)

A rioxarray plugin for napari supporting GDAL raster datatypes

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-rioxarray` via [pip]:

    pip install napari-rioxarray



To install latest development version :

    pip install git+https://github.com/AndrewAnnex/napari-rioxarray.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-rioxarray"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/AndrewAnnex/napari-rioxarray/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/AndrewAnnex/napari-rioxarray/issues', 'Documentation, https://github.com/AndrewAnnex/napari-rioxarray#README.md', 'Source Code, https://github.com/AndrewAnnex/napari-rioxarray', 'User Support, https://github.com/AndrewAnnex/napari-rioxarray/issues']",napari-rioxarray.get_reader,,,,"['*.vrt', '*.tif', '*.tiff', '*.TIF', '*.TIFF', '*.img', '*.lbl', '*.cub', '*.fits', '*.IMG', '*.LBL', '*.CUB', '*.FITS']",,
365,napari-roxas-ai,napari-roxas-ai,ROXAS AI,0.1.2,2025-05-17,2025-06-19,"Nicola Antonio Santacroce, Marc Katzenmaier, Triyan Bhardwaj, Georg von Arx",The WSL Dendrosciences Group <roxas@wsl.ch>,"GNU GENERAL PUBLIC LICENSE
   ...",https://github.com/roxas-ai/napari-roxas-ai/issues,https://pypi.org/project/napari-roxas-ai/,,,A plugin that integrates the ROXAS AI analysis methods for quantitative wood anatomy in the napari platform,>=3.9,"['magicgui==0.10.0', 'napari[all]==0.5.6', 'numpy<=2.1.3,>=2.0.2', 'opencv-contrib-python-headless==4.11.0.86', 'qtpy==2.4.3', 'rasterio==1.4.3', 'scikit-image<=0.25.2,>=0.24.0', 'matplotlib<=3.10.1,>=3.9.4', 'torch<2.7.0,>=2.2.0; sys_platform == ""linux"" and platform_machine == ""x86_64""', 'torchvision==0.21.0; sys_platform == ""linux"" and platform_machine == ""x86_64""', 'torch<2.7.0,>=2.2.0; sys_platform == ""win32"" and platform_machine == ""AMD64""', 'torchvision==0.21.0; sys_platform == ""win32"" and platform_machine == ""AMD64""', 'torch<2.7.0,>=2.4.0; sys_platform == ""darwin"" or platform_machine == ""arm64""', 'torchvision==0.21.0; sys_platform == ""darwin"" or platform_machine == ""arm64""', 'pytorch-lightning==2.5.1', 'segmentation-models-pytorch==0.4.0', 'albumentations==2.0.5', 'hydra-core==1.3.2', 'tox==4.25.0; extra == ""testing""', 'pytest==8.3.5; extra == ""testing""', 'pytest-cov==6.0.0; extra == ""testing""', 'pytest-qt==4.4.0; extra == ""testing""', 'napari==0.5.6; extra == ""testing""', 'pyqt5==5.15.11; extra == ""testing""']","# napari-roxas-ai

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-roxas-ai.svg?color=green)](https://github.com/roxas-ai/napari-roxas-ai/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-roxas-ai.svg?color=green)](https://pypi.org/project/napari-roxas-ai)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-roxas-ai.svg?color=green)](https://python.org)
[![tests](https://github.com/roxas-ai/napari-roxas-ai/workflows/tests/badge.svg)](https://github.com/roxas-ai/napari-roxas-ai/actions)
[![codecov](https://codecov.io/gh/roxas-ai/napari-roxas-ai/branch/main/graph/badge.svg)](https://codecov.io/gh/roxas-ai/napari-roxas-ai)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-roxas-ai)](https://napari-hub.org/plugins/napari-roxas-ai)

A plugin that integrates the ROXAS AI analysis methods for quantitative wood anatomy in the napari platform

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

### Environment setup
It's recommended to create a dedicated Python environment for napari-roxas-ai:

1. Install Miniconda if you don't have it already: [Miniconda Installation Guide](https://docs.conda.io/en/latest/miniconda.html)

2. Create a new environment:
```bash
conda create -n roxas-ai python=3.12
conda activate roxas-ai
```

### Installation
Install `napari-roxas-ai` via [pip]:

```bash
pip install napari-roxas-ai
```

### Launching the plugin
Once installed, you can launch napari with the roxas-ai plugin:

```bash
napari
```

### Verifying installation
To check if the plugin is working correctly:
1. Go to `File > Open Sample > ROXAS AI` in the napari interface.
2. The first time you open a sample, it may take some time as sample data and model weights are being downloaded. Progress will be logged in the terminal.
3. After the downloads, a sample made of three layers should open in the viewer

### GPU Support
If you want to use GPU acceleration for model inference:

1. Ensure you have the proper GPU drivers and CUDA installed for your system:
   - [NVIDIA CUDA Installation Guide Linux](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/)
   - [NVIDIA CUDA Installation Guide Windows](https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html)

2. Enable GPU support in the napari-roxas-ai settings within the napari interface.

3. You may need to reinstall PyTorch with CUDA support for your specific hardware:
   Visit the [PyTorch Installation Guide](https://pytorch.org/get-started/locally/) to find the appropriate installation command for your setup.

## Contributing

Contributions are very welcome. Tests are automatically run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

### Contributor Installation

In order to contribute to the development of the plugin the installation can be done as follows:
1. Create an environment
```bash
conda create -n roxas-ai python=3.12
conda activate roxas-ai
```
2. In the cloned / forked plugin directory, install the plugin dependencies
```bash
pip install -e .
```

3. Install the testing dependencies, as well as the napari plugin engine
```bash
pip install -e "".[testing]""
pip install npe2
```

4. Install pre-commit for quality checks
```bash
pip install pre-commit
pre-commit install
```

### Documentation: Plugin Template and Development
You can find more information on the plugin template on the [napari-plugin-template repository](https://github.com/napari/napari-plugin-template).
You can find more information on plugin contributions and how to create plugins on the [plugins section of the napari documentation](https://napari.org/dev/plugins/index.html).

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-roxas-ai"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/roxas-ai/napari-roxas-ai/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/roxas-ai/napari-roxas-ai/issues', 'Documentation, https://github.com/roxas-ai/napari-roxas-ai#README.md', 'Source Code, https://github.com/roxas-ai/napari-roxas-ai', 'User Support, https://github.com/roxas-ai/napari-roxas-ai/issues']",napari-roxas-ai.napari_get_reader,napari-roxas-ai.write_single_layer,napari-roxas-ai.open_project_directory_dialog,napari-roxas-ai.load_sample_data,"['*.cells*', '*.scan*', '*.rings*']",,
366,napari-roi,napari-roi,napari-roi,0.1.8,2021-11-19,2023-02-17,Jonas Windhager,jonas@windhager.io,MIT,https://github.com/BodenmillerGroup/napari-roi/issues,https://pypi.org/project/napari-roi/,,https://github.com/BodenmillerGroup/napari-roi,Select regions of interest (ROIs) using napari,>=3.8,"['numpy', 'pandas', 'qtpy']","# napari-roi

[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-roi)](https://napari-hub.org/plugins/napari-roi)
[![PyPI](https://img.shields.io/pypi/v/napari-roi.svg?color=green)](https://pypi.org/project/napari-roi)
[![License](https://img.shields.io/pypi/l/napari-roi.svg?color=green)](https://github.com/BodenmillerGroup/napari-roi/raw/main/LICENSE)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-roi.svg?color=green)](https://python.org)
[![Issues](https://img.shields.io/github/issues/BodenmillerGroup/napari-roi)](https://github.com/BodenmillerGroup/napari-roi/issues)
[![Pull requests](https://img.shields.io/github/issues-pr/BodenmillerGroup/napari-roi)](https://github.com/BodenmillerGroup/napari-roi/pulls)

Select regions of interest (ROIs) using napari

## Installation

You can install napari-roi via [pip](https://pypi.org/project/pip/):

    pip install napari-roi

Alternatively, you can install napari-roi via [conda](https://conda.io/):

    conda install -c conda-forge napari-roi

## Usage

The *napari-roi* plugin can be opened from within napari (`napari -> napari-roi: regions of interest`) and operates on napari *Shapes* layers.

ROIs can be added to any napari *Shapes* layer, either by drawing a standard napari shape (e.g. rectangle), or by adding a rectangular ROI of specified size using the `Add ROI` functionality in the *napari-roi* widget. Each ROI is associated with a name, a position (X/Y origin), and a size (width/height). The location of the X/Y origin of all ROIs can be chosen in the *napari-roi* widget. Note that any shape supported by napari (e.g. ellipse, rectangle, polygon, line, path) can serve as an ROI; for non-rectangular shapes, *napari-roi* computes rectangular bounding boxes aligned with the napari coordinate system to determine their positions and sizes. ROIs can be edited or deleted by modifying the corresponding shapes in napari, or by editing the corresponding row in the *napari-roi* widget.

All ROIs in the current *Shapes* layer can be saved to a comma-separated values (CSV) file using the `Save` functionality in the *napari-roi* widget. When the `Autosave` option is checked, the file is automatically updated on every ROI change. Note that the selected file is specific to the current *Shapes* layer; ROIs from different *Shapes* layers cannot be saved to the same file. ROIs can be loaded from a previously saved file and added to the current *Shapes* layer by opening the file in the *napari-roi* widget.

CSV files saved using *napari-roi* adhere to the following format:

| Columns | Description |
| --- | --- |
| `Name` | ROI name |
| `X`, `Y` | Position (X/Y origin) |
| `W`, `H` | Size (width/height) |

## Authors

Created and maintained by [Jonas Windhager](mailto:jonas@windhager.io) until February 2023.

Maintained by [Milad Adibi](mailto:milad.adibi@uzh.ch) from February 2023.

## Contributing

[Contributing](https://github.com/BodenmillerGroup/napari-roi/blob/main/CONTRIBUTING.md)

## Changelog

[Changelog](https://github.com/BodenmillerGroup/napari-roi/blob/main/CHANGELOG.md)

## License

[MIT](https://github.com/BodenmillerGroup/napari-roi/blob/main/LICENSE)
","['Framework :: napari', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/BodenmillerGroup/napari-roi/issues', 'Documentation, https://github.com/BodenmillerGroup/napari-roi#README.md', 'Source Code, https://github.com/BodenmillerGroup/napari-roi', 'User Support, https://github.com/BodenmillerGroup/napari-roi/issues']",,,napari-roi.ROIWidget,,,,
367,napari-sairyscan,napari-sairyscan,napari sairyscan,0.0.2,2022-06-03,2022-06-07,Sylvain Prigent,meriadec.prigent@gmail.com,BSD-3-Clause,https://github.com/sylvainprigent/napari-sairyscan/issues,https://pypi.org/project/napari-sairyscan/,,https://github.com/sylvainprigent/napari-sairyscan,Airyscan image reconstruction,>=3.8,"['numpy', 'magicgui', 'qtpy', 'sairyscan (>=0.0.2)', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-sairyscan

[![License](https://img.shields.io/pypi/l/napari-sairyscan.svg?color=green)](https://github.com/sylvainprigent/napari-sairyscan/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-sairyscan.svg?color=green)](https://pypi.org/project/napari-sairyscan)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-sairyscan.svg?color=green)](https://python.org)
[![tests](https://github.com/sylvainprigent/napari-sairyscan/workflows/tests/badge.svg)](https://github.com/sylvainprigent/napari-sairyscan/actions)
[![codecov](https://codecov.io/gh/sylvainprigent/napari-sairyscan/branch/main/graph/badge.svg)](https://codecov.io/gh/sylvainprigent/napari-sairyscan)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-sairyscan)](https://napari-hub.org/plugins/napari-sairyscan)

Airyscan image reconstruction

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-sairyscan` via [pip]:

    pip install napari-sairyscan



To install latest development version :

    pip install git+https://github.com/sylvainprigent/napari-sairyscan.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-sairyscan"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/sylvainprigent/napari-sairyscan/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/sylvainprigent/napari-sairyscan/issues', 'Documentation, https://github.com/sylvainprigent/napari-sairyscan#README.md', 'Source Code, https://github.com/sylvainprigent/napari-sairyscan', 'User Support, https://github.com/sylvainprigent/napari-sairyscan/issues']",napari-sairyscan.get_reader,,napari-sairyscan.make_qwidget,napari-sairyscan.make_sample_data,['*.czi'],,
368,napari-roi-registration,napari-roi-registration,Roi Registration,0.1.4,2022-05-04,2023-12-13,Andrea Bassi and Giorgia Tortora,giorgia.tortora@polimi.it,BSD-3-Clause,https://github.com/GiorgiaTortora/napari-roi-registration/issues,https://pypi.org/project/napari-roi-registration/,,https://github.com/GiorgiaTortora/napari-roi-registration,A plugin to perform registration of regions-of-interests in time-lapse data.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'opencv-python', 'matplotlib', 'openpyxl', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""scikit-image ; extra == 'testing'"", ""opencv-python-headless ; extra == 'testing'"", ""matplotlib ; extra == 'testing'"", ""openpyxl ; extra == 'testing'""]","# napari-roi-registration

[![License](https://img.shields.io/pypi/l/napari-roi-registration.svg?color=green)](https://github.com/GiorgiaTortora/napari-roi-registration/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-roi-registration.svg?color=green)](https://pypi.org/project/napari-roi-registration)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-roi-registration.svg?color=green)](https://python.org)
[![tests](https://github.com/GiorgiaTortora/napari-roi-registration/workflows/tests/badge.svg)](https://github.com/GiorgiaTortora/napari-roi-registration/actions)
[![codecov](https://codecov.io/gh/GiorgiaTortora/napari-roi-registration/branch/main/graph/badge.svg)](https://codecov.io/gh/GiorgiaTortora/napari-roi-registration)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-roi-registration)](https://napari-hub.org/plugins/napari-roi-registration)

A Napari plugin for the registration of regions of interests (ROI) in a time lapse acquistion and processing of the intensity of the registered data.

The ROI are defined using a Labels layer. Registration of multiple ROIs is supported.  

The `Registration` widget uses the user-defined labels, constructs a rectangular ROI around each of them and registers the ROIs in each time frame.

The `Processing` widget measures the ROI displacements and extracts the average intensity of the ROI, calculated on the area of the labels.

The `Subtract background` widget subtracts a background on each frame, calculated as the mean intensity on a Labels layer.
Tipically useful when ambient light affects the measurement.  

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

![raw](https://github.com/GiorgiaTortora/napari-roi-registration/raw/main/images/roi_registration.gif)

## Installation

You can install `napari-roi-registration` via [pip]:

    pip install napari-roi-registration



To install latest development version :

    pip install git+https://github.com/GiorgiaTortora/napari-roi-registration.git

## Usage

A detailed guide which shows how to use the widgets of the napari-roi-registration plugin and how to properly choose the parameters can be found [here]. A demo video is available at this [link](https://www.youtube.com/watch?v=oXyAqZdFrSE). [Sample datasets](https://polimi365-my.sharepoint.com/:f:/g/personal/10853110_polimi_it/ErHvu3QXhktGq-NLqFdZXMYBWXaRNIZWlQhWg5EdOgbmWg?e=HeExQl) are available.

### Registration Widget

1. Create a new Labels layer and draw one or more labels where you want to select a ROI (Region Of Interest). Each color in the same Labels layer represents a different label which will correspond to a different ROI.

![raw](https://github.com/GiorgiaTortora/napari-roi-registration/raw/main/images/Picture1.png)

2. Push the `Register ROIs` button: registration of the entire stack will be performed. When the registration is finished two new layers will appear in the viewer. One layer contains the centroids of the drawn labels while the other contains the bounding boxes enclosing the ROIs.
The registration starts from the currently selected frame. If `register entire stack` is selected, the registration will create a new layer for each label, with the registered ROI stacks.

![raw](https://github.com/GiorgiaTortora/napari-roi-registration/raw/main/images/Picture2.png)

### Processing Widget

Pushing the `Process registered ROIs` button, the registered ROIs will be analyzed. The intensity of the registered ROIs (measured on the area of the selected label) and the displacement of the ROIs will be calculated.
If `plot results` is selected the plot of displacement vs time index and mean intensity vs time index will appear in the Console.
Choosing the `save results` option, an excel file containing ROIs positions, displacements and intensities, will be saved. 

![raw](https://github.com/GiorgiaTortora/napari-roi-registration/raw/main/images/Picture3.png)

### Background Widget

1. Create a new Labels layer and draw a label on the area where you want to calculate the background. 

![raw](https://github.com/GiorgiaTortora/napari-roi-registration/raw/main/images/Picture4.png)

2. Push the `Subtract background` button. A new image layer will appear in the viewer. This layer contains the image to which the background was subtracted.

## Contributing 

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-roi-registration"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[here]: https://github.com/GiorgiaTortora/napari-roi-registration/blob/main/docs/index.md

[file an issue]: https://github.com/GiorgiaTortora/napari-roi-registration/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/GiorgiaTortora/napari-roi-registration/issues', 'Documentation, https://github.com/GiorgiaTortora/napari-roi-registration#README.md', 'Source Code, https://github.com/GiorgiaTortora/napari-roi-registration', 'User Support, https://github.com/GiorgiaTortora/napari-roi-registration/issues']",,,napari-roi-registration.make_background_widget,,,,
369,napari-result-stack,napari-result-stack,Result stack,0.0.1,2023-01-27,2023-01-27,Hanjin Liu,liuhanjin-sc@g.ecc.u-tokyo.ac.jp,BSD-3-Clause,https://github.com/hanjinliu/napari-result-stack/issues,https://pypi.org/project/napari-result-stack/,,https://github.com/hanjinliu/napari-result-stack,Widgets and type annotations for storing function results of any types,>=3.8,"['numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-result-stack

[![License BSD-3](https://img.shields.io/pypi/l/napari-result-stack.svg?color=green)](https://github.com/hanjinliu/napari-result-stack/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-result-stack.svg?color=green)](https://pypi.org/project/napari-result-stack)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-result-stack.svg?color=green)](https://python.org)
[![tests](https://github.com/hanjinliu/napari-result-stack/workflows/tests/badge.svg)](https://github.com/hanjinliu/napari-result-stack/actions)
[![codecov](https://codecov.io/gh/hanjinliu/napari-result-stack/branch/main/graph/badge.svg)](https://codecov.io/gh/hanjinliu/napari-result-stack)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-result-stack)](https://napari-hub.org/plugins/napari-result-stack)

Widgets and type annotations for storing function results of any types.

## `Stored` type

Type `Stored[T]` is equivalent to `T` for the type checker, but `magicgui` is aware of this annotation and behaves as a ""storage"" for the `T` instances.

```python
from pathlib import Path
import pandas as pd
from magicgui import magicgui
from napari_result_stack import Stored

# Returned values will be stored in a result stack.
@magicgui
def provide_data(path: Path) -> Stored[pd.DataFrame]:
    return pd.read_csv(path)

# You can choose one of the values stored in the result stack
# for the argument `df` from a ComboBox widget.
@magicgui
def print_data(df: Stored[pd.DataFrame]):
    print(df)
```

![](https://github.com/hanjinliu/napari-result-stack/blob/main/images/demo-0.gif)

- Different types use different storage. e.g. `Stored[int]` and `Stored[str]` do not share the same place.
- Even for the same type, you can specify the second key to split the storage. e.g. `Stored[int]`, `Stored[int, 0]` and `Stored[int, ""my-plugin-name""]` use the distinct storages.

## Manually store variables

`Stored.valuesof[T]` is a `list`-like object that returns a view of the values stored in `Stored[T]`. This value view is useful if you want to store values outside `@magicgui`.

```python
from magicgui.widgets import PushButton
from datetime import datetime
from napari_result_stack import Stored

button = PushButton(text=""Click!"")

@button.changed.connect
def _record_now():
    Stored.valuesof[datetime].append(datetime.now())

```

## Result stack widget

`napari-result-stack` provides a plugin widget that is helpful to inspect all the stored values.

![](https://github.com/hanjinliu/napari-result-stack/blob/main/images/demo-1.gif)


<details><summary>Show code</summary><div>

```python
from napari_result_stack import Stored
from magicgui import magicgui
import numpy as np
import pandas as pd

@magicgui
def f0() -> Stored[pd.DataFrame]:
    return pd.DataFrame(np.random.random((4, 3)))

@magicgui
def f1(x: Stored[pd.DataFrame]) -> Stored[float]:
    return np.mean(np.array(x))

viewer.window.add_dock_widget(f0, name=""returns a DataFrame"")
viewer.window.add_dock_widget(f1, name=""mean of a DataFrame"")
```

---
</div></details>



----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-result-stack` via [pip]:

    pip install napari-result-stack



To install latest development version :

    pip install git+https://github.com/hanjinliu/napari-result-stack.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-result-stack"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hanjinliu/napari-result-stack/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hanjinliu/napari-result-stack/issues', 'Documentation, https://github.com/hanjinliu/napari-result-stack#README.md', 'Source Code, https://github.com/hanjinliu/napari-result-stack', 'User Support, https://github.com/hanjinliu/napari-result-stack/issues']",,,napari-result-stack.make_qwidget,,,,
370,napari-sam2long,napari-sam2long,SAM2Long,1.0.3,2025-04-14,2025-04-22,Mai Hoang,maihan.hoang1208@gmail.com,Attribution-NonCommercial 4.0 ...,https://github.com/maihanhoang/napari-sam2long/issues,https://pypi.org/project/napari-sam2long/,,,A plugin for interactive 3D (volumetric or time-lapse) segmentation using Meta's Segment Anything Model 2 (SAM2).,>=3.10,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'opencv-python', 'pytest', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-sam2long

[![License: CC BY-NC 4.0](https://img.shields.io/badge/License-CC_BY--NC_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc/4.0/)
[![PyPI](https://img.shields.io/pypi/v/napari-sam2long.svg?color=green)](https://pypi.org/project/napari-sam2long)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-sam2long.svg?color=green)](https://python.org)
[![tests](https://github.com/maihanhoang/napari-sam2long/workflows/tests/badge.svg)](https://github.com/maihanhoang/napari-sam2long/actions)
[![codecov](https://codecov.io/gh/maihanhoang/napari-sam2long/branch/main/graph/badge.svg)](https://codecov.io/gh/maihanhoang/napari-sam2long)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-sam2long)](https://napari-hub.org/plugins/napari-sam2long)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

A plugin for interactive 3D (volumetric or time-lapse) segmentation using Meta's Segment Anything Model 2 (SAM2).

Designed for bioimaging researchers working with 3D volumetric or time-lapse images, this plugin supports TIFF files in ZYX or TYX format. Users can provide input and make corrections through point clicks or manually drawn masks.

The tool leverages the [SAM2Long](https://github.com/Mark12Ding/SAM2Long) model, an optimized version of [Meta's SAM 2](https://github.com/facebookresearch/sam2) with enhancements to the memory module for improved performance on long videos. It was built to support long videos, but it remains effective for shorter videos as well.

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<h3 align=""center"">Select object with point prompts</h3>

<p align=""middle"">
  <img src=""https://github.com/maihanhoang/napari-sam2long/raw/main/assets/napari-sam2long-firstLabel.gif"" width=""100%"" />
</p>

<h3 align=""center"">Refine object selection with napari tools </h3>

<p align=""middle"">
  <img src=""https://github.com/maihanhoang/napari-sam2long/raw/main/assets/napari-sam2long-anotherLabel.gif"" width=""100%"" />
</p>


## Installation
Please see the official [SAM 2](https://github.com/facebookresearch/sam2) repo and the [INSTALL.md](https://github.com/facebookresearch/sam2/blob/main/INSTALL.md) for notes and FAQs on potential installation issues.

1. Create a new conda environment with python>=3.10 and install napari:
    ```bash
    conda create -n napari-sam2long python==3.10 pip
    conda activate napari-sam2long
    python -m pip install ""napari[all]""
    ```

2. Install PyTorch and TorchVision. Select preferences [here](https://pytorch.org/get-started/locally/) to find correct installation command.

    Example command can look like this:

    ```bash
    pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
    ```

3. Install SAM2Long:
    ```bash
    git clone git@github.com:maihanhoang/napari-sam2long.git

    cd napari-sam2long/SAM2Long && python -m pip install -e .
    ```
4. Install napari-SAM2Long plugin:
    ```bash
    cd .. && python -m pip install e .
    ```

## Usage

### Segmenting & tracking first object
1. **Open a 3D tiff** in napari, make sure it's in TYX or ZYX format.
2. **Select** the image in the ***Input*** dropdown.
3. **Add a new [labels layer](https://napari.org/0.5.0/howtos/layers/labels.html)** *after* the input image, then select it in the *Labels* dropdown.

    The labels layer must be added after the image to ensure dimension alignment.
4. **Select the *Model***.
5. **Click *Initialize*** to load the image and initialize the inference state.
6. **Define the initial object mask** on any frame:
    - Use the mouse middle-click to prompt the model:
        - *Middle-click* = add region
        - *Ctrl + middle-click* = remove region
    - Or use napari's built-in tools (paintbrush, eraser, etc.) to draw the mask manually.

    If the model doesnât segment the object accurately with point prompts, manual correction using napari tools can be useful.

7. Once satisfied with the initial mask, **click *Propagate from current frame*** to obtain segmentations for all subsequent frames. The result will be added to the labels layer.

    Propagation only affects future frames. It does not recompute previous ones or consider prompts from other frames. Only the current mask is used to propagate forward.

### Making corrections
8. To refine segmentation, add/remove regions use:
    - *(Ctrl+) middle-click* prompts
    - napariâs label tools
9. *Propagate from current frame* to re-run the model's predictions with the new mask.

    The plugin treats this as a new initial mask and discards earlier prompts on that frame.

### Segmenting another object in the same image/video
10. Save the current labels layer (to preserve previous segmentation).
11. Click *Reset*, or add a new labels layer and select it in the *Labels* dropdown.
Then repeat steps from Step 6 for the next object.

###  Segment new image/video
12. *Reset* inference state.
13. Load new image and follow instructions starting from Step 1.
    *Initialize* is necessary to load the new image.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/maihanhoang/napari-sam2long/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

## Bibliography
[1]: Nikhila Ravi, Valentin Gabeur, Yuan-Ting Hu, Ronghang Hu, Chaitanya Ryali, Tengyu Ma, Haitham Khedr, Roman RÃ¤dle, Chloe Rolland, Laura Gustafson, Eric Mintun, Junting Pan, Kalyan Vasudev Alwala, Nicolas Carion, Chao-Yuan Wu, Ross Girshick, Piotr DollÃ¡r, & Christoph Feichtenhofer. (2024). SAM 2: Segment Anything in Images and Videos.

[2]: Ding, S., Qian, R., Dong, X., Zhang, P., Zang, Y., Cao, Y., Guo, Y., Lin, D., & Wang, J. (2024). SAM2Long: Enhancing SAM 2 for Long Video Segmentation with a Training-Free Memory Tree. arXiv preprint arXiv:2410.16268.

## License & Attribution

This project integrates code from:
- [SAM2](https://github.com/facebookresearch/sam2) by Meta ([`Apache 2.0 License`](LICENSE-Apache-2.0))
- [SAM2Long](https://github.com/Mark12Ding/SAM2Long) by Shuangrui Ding et al. ([`CC-BY-NC 4.0 License`](LICENSE-CC-BY-NC-4.0))
- [napari-samv2](https://github.com/Krishvraman/napari-SAMV2) by Krishnan Venkataraman ([`BSD-3 License`](LICENSE-BSD-3))


The following changes were made to SAM2Long:
- integrated SAM2Long into a napari plugin
- modified the video predictor to support the progress bar in the plugin


Since this project includes **SAM2Long**, it inherits the **CC-BY-NC 4.0 license**, meaning **commercial use is not allowed**.
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: Other/Proprietary License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Homepage, https://github.com/maihanhoang/napari-sam2long', 'Bug Tracker, https://github.com/maihanhoang/napari-sam2long/issues', 'Documentation, https://github.com/maihanhoang/napari-sam2long#README.md', 'Source Code, https://github.com/maihanhoang/napari-sam2long', 'User Support, https://github.com/maihanhoang/napari-sam2long/issues']",,,napari-sam2long.make_qwidget,,,,
371,napari-sam,napari-sam,Segment Anything,0.4.13,2023-04-06,2023-08-02,Karol Gotkowski,karol.gotkowski@dkfz.de,Apache-2.0,https://github.com/MIC-DKFZ/napari-sam/issues,https://pypi.org/project/napari-sam/,,https://github.com/MIC-DKFZ/napari-sam,Segment anything with Meta AI's new SAM model!,>=3.8,"['numpy', 'magicgui', 'qtpy', 'napari', 'vispy', 'tqdm', 'napari-nifti', 'superqt', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# Segment Anything Model (SAM) in Napari

[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-sam.svg?color=green)](https://github.com/MIC-DKFZ/napari-sam/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-sam.svg?color=green)](https://pypi.org/project/napari-sam)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-sam.svg?color=green)](https://python.org)
[![tests](https://github.com/MIC-DKFZ/napari-sam/workflows/tests/badge.svg)](https://github.com/MIC-DKFZ/napari-sam/actions)
[![codecov](https://codecov.io/gh/MIC-DKFZ/napari-sam/branch/main/graph/badge.svg)](https://codecov.io/gh/MIC-DKFZ/napari-sam)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-sam)](https://napari-hub.org/plugins/napari-sam)

Segment anything with our **Napari** integration of Meta AI's new **Segment Anything Model (SAM)**!

SAM is the new segmentation system from Meta AI capable of **one-click segmentation of any object**, and now, our plugin neatly integrates this into Napari.

We have already **extended** SAM's click-based foreground separation to full **click-based semantic segmentation and instance segmentation**!

At last, our SAM integration supports both **2D and 3D images**!

----------------------------------

Everything mode             |  Click-based semantic segmentation mode |  Click-based instance segmentation mode
:-------------------------:|:-------------------------:|:-------------------------:
![](https://github.com/MIC-DKFZ/napari-sam/raw/main/cats_everything.png)  |  ![](https://github.com/MIC-DKFZ/napari-sam/raw/main/cats_semantic.png)  |  ![](https://github.com/MIC-DKFZ/napari-sam/raw/main/cats_instance.png)


----------------------------------
<h2 align=""center"">SAM in Napari demo</h2>
<div align=""center"">

https://user-images.githubusercontent.com/3471895/236152620-0de983db-954b-4480-97b9-901ee82f8edd.mp4

</div>

----------------------------------

## Installation

The plugin requires `python>=3.8`, as well as `pytorch>=1.7` and `torchvision>=0.8`. Please follow the instructions here to install both PyTorch and TorchVision dependencies. Installing both PyTorch and TorchVision with CUDA support is strongly recommended.

Install Napari via [pip]:
    
    pip install napari[all]

You can install `napari-sam` via [pip]:

    pip install git+https://github.com/facebookresearch/segment-anything.git
    pip install napari-sam



To install latest development version :

    pip install git+https://github.com/MIC-DKFZ/napari-sam.git

## Usage

Start Napari from the console with:

    napari

Then navigate to `Plugins -> Segment Anything (napari-sam)` and drag & drop an image into Napari. At last create, a labels layer that will be used for the SAM predictions, by clicking in the layer list on the third button.

You can then auto-download one of the available SAM models (this can take 1-2 minutes),  activate one of the annotations & segmentation modes, and you are ready to go!


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-sam"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/MIC-DKFZ/napari-sam/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

# Acknowledgements
<img src=""https://github.com/MIC-DKFZ/napari-sam/raw/main/HI_Logo.png"" height=""100px"" />

<img src=""https://github.com/MIC-DKFZ/napari-sam/raw/main/dkfz_logo.png"" height=""100px"" />

napari-sam is developed and maintained by the Applied Computer Vision Lab (ACVL) of [Helmholtz Imaging](http://helmholtz-imaging.de) 
and the [Division of Medical Image Computing](https://www.dkfz.de/en/mic/index.php) at the 
[German Cancer Research Center (DKFZ)](https://www.dkfz.de/en/index.html).
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/MIC-DKFZ/napari-sam/issues', 'Documentation, https://github.com/MIC-DKFZ/napari-sam#README.md', 'Source Code, https://github.com/MIC-DKFZ/napari-sam', 'User Support, https://github.com/MIC-DKFZ/napari-sam/issues']",,,napari-sam.make_qwidget,,,,
372,napari-samv2,napari-SAMV2,napari-SAMV2,0.1.2,2024-10-08,2025-07-16,Krishnan Venkataraman,krishvraman95@gmail.com,"Copyright (c) 2024, Krishnan V...",https://github.com/Krishvraman/napari-SAMV2/issues,https://pypi.org/project/napari-SAMV2/,,,Napari plugin for segment anything version 2 model from meta. Plugin primarily useful for segmenting 3d volumetric data or 3d time series data. ,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'numpy; extra == ""testing""']","# napari-SAMV2

Napari plugin to use segment anything version 2.1 models from Meta.

Plugin made for segmenting 3d volumetric data or 3d time series data.

----------------------------------

## Installation

The plugin requires the following pre-requisite to be installed :

1. Python and pytorch versions

python>=3.10,torch>=2.5.1 and torchvision>=0.20.1 required

To install pytorch with your respective OS please visit - https://pytorch.org/get-started/locally/

2. SAM v2 installation from meta

Please refer https://github.com/facebookresearch/sam2

3. Install napari

python -m pip install ""napari[all]""

Following is a sample conda environment installation with the above pre-req 

    conda create -n samv2_env python=3.10
    conda activate samv2_env
    pip3 install torch torchvision

    git clone https://github.com/facebookresearch/sam2.git && cd sam2
    pip install -e .

    python -m pip install ""napari[all]""

    pip install napari-SAMV2


## Usage

Middle mouse click - positive point or keyboard shortcut ""a""

Ctrl + Middle mouse click - negative point or keyboard shortcut ""n""

Time Series Segmentation :

![samv2_time_series_demo](https://github.com/user-attachments/assets/078ca2bb-3016-4257-ac7c-c3cde8f9d125)



Volume Segmentation :

![samv2_volume_segmentation](https://github.com/user-attachments/assets/af05fcc4-a60d-44e8-ae05-70764d96e828)



Reference :

Example Data in the demo videos are from,

Cell tracking challenge - https://celltrackingchallenge.net/ 

and

FlyEM project - https://www.janelia.org/project-team/flyem/hemibrain


## License

Distributed under the terms of the [BSD-3] license,
""napari-SAMV2"" is free and open source software



## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/Krishvraman/napari-SAMV2/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/Krishvraman/napari-SAMV2/issues', 'Documentation, https://github.com/Krishvraman/napari-SAMV2#README.md', 'Source Code, https://github.com/Krishvraman/napari-SAMV2', 'User Support, https://github.com/Krishvraman/napari-SAMV2/issues']",,,napari-samv2.make_qwidget,,,,
373,napari-save-transformed,napari-save-transformed,napari-save-transformed,0.0.2,2024-07-02,2024-09-11,Jan Eglinger,Jan Eglinger <jan.eglinger@fmi.ch>,Unavailable,https://github.com/fmi-faim/napari-save-transformed,https://pypi.org/project/napari-save-transformed/,,,Napari plugin to save layers with their transforms applied.,>=3.9,['napari'],"# napari-save-transformed

[![PyPI - Version](https://img.shields.io/pypi/v/napari-save-transformed.svg)](https://pypi.org/project/napari-save-transformed)
[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/napari-save-transformed.svg)](https://pypi.org/project/napari-save-transformed)

-----

## Table of Contents

- [Installation](#installation)
- [License](#license)

## Installation

```console
pip install napari-save-transformed
```

## License

`napari-save-transformed` is distributed under the terms of the [BSD-3-Clause](https://spdx.org/licenses/BSD-3-Clause.html) license.
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: Implementation :: CPython', 'Programming Language :: Python :: Implementation :: PyPy']","['Documentation, https://github.com/fmi-faim/napari-save-transformed#readme', 'Issues, https://github.com/fmi-faim/napari-save-transformed/issues', 'Source, https://github.com/fmi-faim/napari-save-transformed']",,napari-save-transformed.write_transformed_layers,,,,['.tif'],
374,napari-sam4is,napari-SAM4IS,napari-SAM4IS,0.1.1,2023-04-28,2025-07-23,Hiroki Kawai,Hiroki Kawai <h.kawai888@gmail.com>,Apache-2.0,https://github.com/hiroalchem/napari-SAM4IS/issues,https://pypi.org/project/napari-SAM4IS/,,,Create annotations for instance segmentation using Segment Anything models,>=3.8,"['numpy>=1.20.0', 'magicgui>=0.7.0', 'qtpy>=2.0.0', 'torch>=1.12.0', 'torchvision>=0.13.0', 'scikit-image>=0.19.0', 'napari[all]>=0.4.17', 'requests>=2.25.0', 'urllib3>=1.26.0', 'Pillow>=8.0.0', 'tox; extra == ""testing""', 'pytest>=6.0; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'pyqt5; extra == ""testing""', 'black>=22.0; extra == ""dev""', 'ruff>=0.1.0; extra == ""dev""', 'pre-commit; extra == ""dev""']","# napari-SAM4IS

[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-SAM4IS.svg?color=green)](https://github.com/hiroalchem/napari-SAM4IS/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-SAM4IS.svg?color=green)](https://pypi.org/project/napari-SAM4IS)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-SAM4IS.svg?color=green)](https://python.org)
[![tests](https://github.com/hiroalchem/napari-SAM4IS/workflows/tests/badge.svg)](https://github.com/hiroalchem/napari-SAM4IS/actions)
[![codecov](https://codecov.io/gh/hiroalchem/napari-SAM4IS/branch/main/graph/badge.svg)](https://codecov.io/gh/hiroalchem/napari-SAM4IS)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-SAM4IS)](https://napari-hub.org/plugins/napari-SAM4IS)


### napari plugin for instance and semantic segmentation annotation using Segment Anything Model (SAM)

This is a plugin for [napari](https://napari.org/), a multi-dimensional image viewer for Python, that allows for instance and semantic segmentation annotation. This plugin provides an easy-to-use interface for annotating images with the option to output annotations as COCO format.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

### Step 1: Install napari-SAM4IS

You can install `napari-SAM4IS` via [pip]:

```bash
pip install napari-SAM4IS
```

Or via conda

```bash
conda install -c conda-forge napari-SAM4IS
```


### Step 2: Install Segment Anything Model

**IMPORTANT**: You must install the Segment Anything Model separately to use this plugin:

```bash
pip install git+https://github.com/facebookresearch/segment-anything.git
```

### Development Installation

To install the latest development version:

```
pip install git+https://github.com/facebookresearch/segment-anything.git
```

Or you can install from source by cloning the repository:

```
git clone https://github.com/facebookresearch/segment-anything.git
cd segment-anything
pip install -e .
```

For more detailed instructions, please refer to the [SAM installation guide](https://github.com/facebookresearch/segment-anything#installation).

### napari-SAM4IS Installation

You can install `napari-SAM4IS` via [pip]:

    pip install napari-SAM4IS


Or via conda

    conda install -c conda-forge napari-SAM4IS



To install latest development version :

    pip install git+https://github.com/hiroalchem/napari-SAM4IS.git

## Usage
### Preparation
1. Open an image in napari and launch the plugin. (Opening an image after launching the plugin is also possible.)
2. Upon launching the plugin, three layers will be automatically created: SAM-Box, SAM-Predict, and Accepted. The usage of these layers will be explained later.
3. In the widget that appears, select the model you want to use and click the load button. (The default option is recommended.)
4. Next, select the image layer you want to annotate.
5. Then, select whether you want to do instance segmentation or semantic segmentation. (Note that for 3D images, semantic segmentation should be chosen in the current version.)
6. Finally, select the output layer as ""shapes"" for instance segmentation or ""labels"" for semantic segmentation. (For instance segmentation, the ""Accept"" layer can also be used.)

### Annotation
1. Select the SAM-Box layer and use the rectangle tool to enclose the object you want to segment.
2. An automatic segmentation mask will be created and output to the SAM-Predict layer.
3. If you want to make adjustments, do so in the SAM-Predict layer.
4. To accept or reject the annotation, press ""a"" or ""r"" on the keyboard, respectively.
5. If you accept the annotation, it will be output as label 1 for semantic segmentation or converted to a polygon and output to the designated layer for instance segmentation.
6. If you reject the annotation, the segmentation mask in the SAM-Predict layer will be discarded.
7. After accepting or rejecting the annotation, the SAM-Predict layer will automatically reset to blank and return to the SAM-Box layer.

### Saving
1. If you have output to the labels layer, use napari's standard functionality to save the mask.
2. If you have output to the shapes layer, you can save the shapes layer using napari's standard functionality, or you can click the ""save"" button to output a JSON file in COCO format for each image in the folder. (The JSON file will have the same name as the image.)



## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-SAM4IS"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hiroalchem/napari-SAM4IS/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hiroalchem/napari-SAM4IS/issues', 'Documentation, https://github.com/hiroalchem/napari-SAM4IS#README.md', 'Source Code, https://github.com/hiroalchem/napari-SAM4IS', 'User Support, https://github.com/hiroalchem/napari-SAM4IS/issues']",,,napari-SAM4IS.make_sam_widget,,,,
375,napari-sc3d-viewer,napari-sc3D-viewer,sc3D Viewer,1.1.1,2022-06-21,2025-06-17,Leo Guignard,leo.guignard@univ-amu.fr,MIT,https://github.com/GuignardLab/napari-sc3D-viewer/issues,https://pypi.org/project/napari-sc3D-viewer/,,https://github.com/GuignardLab/napari-sc3D-viewer,A plugin to visualize 3D single cell omics,>=3.8,"['numpy', 'magicgui', 'qtpy', 'sc-3D', 'matplotlib', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'pyvista; extra == ""pyvista""']","# napari-sc3D-viewer

[![License](https://img.shields.io/pypi/l/napari-sc3D-viewer.svg?color=green)](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/LICENSE)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-sc3D-viewer.svg?color=green)](https://python.org)
[![PyPI](https://img.shields.io/pypi/v/napari-sc3D-viewer.svg?color=green)](https://pypi.org/project/napari-sc3D-viewer)
[![tests](https://github.com/GuignardLab/napari-sc3D-viewer/workflows/tests/badge.svg)](https://github.com/GuignardLab/napari-sc3D-viewer/actions)
[![codecov](https://codecov.io/gh/GuignardLab/napari-sc3D-viewer/branch/main/graph/badge.svg)](https://codecov.io/gh/GuignardLab/napari-sc3D-viewer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-sc3D-viewer)](https://napari-hub.org/plugins/napari-sc3D-viewer)

A plugin to visualise 3D spatial single cell omics

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Test and atlas datasets

Because the datasets representing the mouse embryo at stages E8.5 and E9.0 are rather large, it is not possible to host them on GitHub. They are instead hosted on figshare at the following links:

- [E8.5 replicate 1](https://figshare.com/s/1c29d867bc8b90d754d2)
- [E8.5 replicate 2](https://doi.org/10.6084/m9.figshare.21695849.v1)
- [E9.0 replicate 1](https://doi.org/10.6084/m9.figshare.21695879.v1)

Once downloaded, one can open them in the viewer as explained below (note that the files for the tissue names are stored in the json file there: `napari-sc3D-viewer/test_data/corresptissues.json`). It can be downloaded by right-clicking on the following [link](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/test_data/corresptissues.json) and then clicking on ""Save link as"".

## Installation

----------------------------------

__Disclaimer:__
While we tried to make the installation and usage as easy as possible, please keep in mind that [napari-sc3d-viewer] is still under development, it has been and is being developed by a single person. We will be happy to answer any question and help in any way.

----------------------------------

There are many ways to install our viewer, but the global idea is that it works in two steps:

- first installing [napari]
- then installing the [napari-sc3d-viewer] plugin.

Installing [napari] and the [napari-sc3d-viewer] plugin can be done either through command line or using an interface.

If you have decided to use command line, as [napari] developers do, we strongly recommend to install the viewer in an environement such as a conda environment `conda` for example:

```shell
conda create -n sc3D python=3.10
conda activate sc3D
```

### Installing napari

The first step is to [install napari](https://napari.org/stable/tutorials/fundamentals/installation.html) on your computer. The previous link should explain how to do so. There you can find either the installation via terminal or directly by [downloading the binary](https://napari.org/stable/tutorials/fundamentals/installation.html#install-as-a-bundled-app).

#### Quick trouble shooting

Installing [napari] can sometimes be difficult. If you try to install [napari] via the command line and it gets stuck ""resolving the environment"" you can try to install it the following way:

```shell
conda create -n sc3D python=3.10
conda activate sc3D
conda install pyqt pip
pip install napari
```

### Installing napari-sc3D-viewer

Once [napari] is installed, you can install `napari-sc3D-viewer`.
As for [napari], [napari-sc3D-viewer] can be installed either through an interface or via the terminal.

#### Installation via graphical interface

To install [napari-sc3D-viewer] with a visual interface, you should use the [napari's plugin manager](https://napari.org/stable/plugins/find_and_install_plugin.html) look for the plugin there and install it as explained in the previous link.

#### Installation via the terminal

Another way is to install `napari-sc3D-viewer` via [pip] or via [conda]:

```shell
conda install napari-sc3d-viewer
```

or

```shell
pip install napari-sc3d-viewer
```

Finally, to install latest development version :

```shell
pip install git+https://github.com/GuignardLab/napari-sc3D-viewer.git
```

#### Installation of the surface computation module

To install the surface computation enabled version it is necessary to use Python 3.9 (until [VTK] is ported to Python 3.10) and you can run one of the following commands:

```shell
pip install '.[pyvista]'
```

from the correct folder or

```shell
pip install 'napari-sc3D-viewer[pyvista]'
```

or

```shell
conda install 'napari-sc3D-viewer[pyvista]'
```

to install directly from pip or

```shell
pip install 'napari-sc3D-viewer[pyvista] @ git+https://github.com/GuignardLab/napari-sc3D-viewer.git'
```

to install the latest version

## Usage

`napari-sc3D-viewer` allows users to easily visualise and navigate 3D spatial single-cell transcriptomics using napari.

### Starting the plugin

First, you need to start [napari], for example, one can start it from a terminal just by typing:

```shell
napari
```

in the correct environment.

Then, one can follow the following steps to browse the dataset.

To open the plugin you can click on the ""Load spatial single cell"" from the `Plugins -> napari-sc3d-viewer` menu:
![loading image](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/0.openplugin.png)

Once opened you should have an interface poping similar to the one showed in the image below (note that it might not be exactly the same depending on the version of the viewer you are using).

### Loading and opening a dataset

The expected dataset is a [scanpy]/[anndata] h5ad file together with an optional json file that maps cluster id numbers to actual tissue/cluster name.

The json file should look like that:

```json
{
    ""1"": ""Endoderm"",
    ""2"": ""Heart"",
    ""10"": ""Anterior neuroectoderm""
}
```

If no json file or a wrong json file is given, the original cluster id numbers are used.

The h5ad file should be informed in (1) and the json file in (2).
![loading image](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/1.loading.png)

Let `data` be your h5ad data structure. To work properly, the viewer is expecting 4 different columns to be present in the h5ad file:

- the cluster id column (by default named 'predicted.id' that can be accessed as `data.obs['predicted.id']`)
- the 3D position column (by default named 'X_spatial_registered' that can be accessed as `data.obsm['X_spatial_registered']`)
- the gene names if not already in the column name (by default named 'feature_name' that can be accessed as `data.var['feature_name']`)
- umap coordinates (by default named 'X_umap' that can be accessed as `data.obsm['X_umap']`)

If the default column names are not consistent with your dataset, they can be changed in the tab `Parameters` (3) next to the tab `Loading files`

Once all the data paths and fields are correctly informed pressing the `Load Atlas` button (4) will load the dataset.

### Exploring a dataset

Once the dataset is loaded there are few options to explore it.

The viewer should look like to the following:
![viewer](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/2.viewer.png)

It is divided in two main parts, the Tissue visualisation (1) part and the Metric visualisation (2) one.
Both of them are themselves split in two and three tabs respectively. All these tabs allow you to visualise and explore the dataset in different fashions.

The Tissues tab (1.1) allows to select the tissues to display, to show the legend and to colour the cells according to their tissue types.

The Surfaces tab (1.2) allows to construct coarse surfaces of tissues and to display them.

The Single metric tab (2.1) allows to display a metric, whether it is a gene intensity or a numerical metric that is embedded in the visualised dataset. This tab also allows to threshold cells according to the viewed metric, to change the contrast and the colour map.

The 2 Genes (2.2) tab allows to display gene coexpression.

The umap tab (2.3) allows to display the umap of the selected cells and to manually select subcategories of cells to be displayed.

![viewer](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/3.description.png)

#### Explanatory ""videos""

The plugin is meant to be easy to use. That means that you should be able to play with it and figure things out by yourself.

That being said, it is not always that easy. You can find below a series of videos showing how to perform some of the main features.

#### Loading data

![Loading data video](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/loading.gif)

#### Selecting tissues

![Selecting tissues video](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/tissue-select.gif)

#### Displaying one gene

![Displaying one gene video](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/gene1.gif)

#### Displaying two genes co-expression

![Displaying genes video](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/gene2.gif)

#### Playing with the umap

![Playing with the umap video](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/umap.gif)

#### Computing and processing the surface

![Computing and processing the surface video](https://raw.githubusercontent.com/GuignardLab/napari-sc3D-viewer/main/images/surfaces.gif)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-sc3D-viewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/GuignardLab/napari-sc3D-viewer/issues
[napari-sc3d-viewer]: https://github.com/GuignardLab/napari-sc3D-viewer

[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[VTK]: https://vtk.org/
[scanpy]: https://scanpy.readthedocs.io/en/latest/index.html
[anndata]: https://anndata.readthedocs.io/en/latest/
[conda]: https://conda.io
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/GuignardLab/napari-sc3D-viewer/issues', 'Documentation, https://github.com/GuignardLab/napari-sc3D-viewer#README.md', 'Source Code, https://github.com/GuignardLab/napari-sc3D-viewer', 'User Support, https://github.com/GuignardLab/napari-sc3D-viewer/issues', 'Twitter, https://twitter.com/guignardlab']",,,napari-sc3D-viewer.load_atlas,,,,
376,napari-sediment,napari-sediment,napari Sediment,0.4.0,2024-09-23,2025-02-26,Guillaume Witz,guillaume.witz@unibe.ch,BSD-3-Clause,https://github.com/guiwitz/napari-sediment/issues,https://pypi.org/project/napari-sediment/,,https://github.com/guiwitz/napari-sediment,A plugin to process hyperspectral images of sediments,>=3.9,"['numpy<2', 'zarr<3', 'magicgui', 'qtpy', 'napari-guitils', 'napari-convpaint>=0.6.0', 'superqt', 'natsort', 'spectral', 'matplotlib', 'scikit-image', 'scikit-learn', 'PyYAML', 'microfilm', 'dask', 'distributed', 'tqdm', 'cmap', 'colour-science', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'torch; extra == ""classifier""', 'torchvision; extra == ""classifier""']","# napari-sediment

[![License BSD-3](https://img.shields.io/pypi/l/napari-sediment.svg?color=green)](https://github.com/guiwitz/napari-sediment/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-sediment.svg?color=green)](https://pypi.org/project/napari-sediment)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-sediment.svg?color=green)](https://python.org)
[![tests](https://github.com/guiwitz/napari-sediment/workflows/tests/badge.svg)](https://github.com/guiwitz/napari-sediment/actions)
[![codecov](https://codecov.io/gh/guiwitz/napari-sediment/branch/main/graph/badge.svg)](https://codecov.io/gh/guiwitz/napari-sediment)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-sediment)](https://napari-hub.org/plugins/napari-sediment)

This napari plugin is designed to hpyerspectral images of sediment cores. It is composed of three interfaces allowing the user to:

- import HDR images
- normalize the images using white and dark references
- mask unwanted regions
- perform spectral dimensionality reduction via minimum noise fraction analysis
- perform spatial dimensionality reduction based on pixel purity indices
- identify representative end-members by clustering pure pixels
- select relevant regions in spectra to compute absorption indices and create absorption maps 

### Pre-processing: Sediment widget

The sediment widget allows the user to import an HDR image and to normalize it using white and dark references. The widget also allows the user to mask unwanted regions of the images.

## Documentation

You can find a detailed documentation [here](https://guiwitz.github.io/napari-sediment).
## Installation

Create a conda environment and activate it. We highly recommend to use the new conda version called mamba to speed up the installation process. You can install it from [here](https://github.com/conda-forge/miniforge#mambaforge). If you don't use mamba, replace the mamba command by conda in the following instructions:

    mamba create -n sediment python=3.9 napari pyqt -c conda-forge
    mamba activate sediment

Then you can install `napari-sediment` use:

    pip install git+https://github.com/guiwitz/napari-sediment.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-sediment"" is free and open source software

## Authors

This plugin has been developed by Guillaume Witz at the Data Science Lab of the University of Bern in collaboration with Petra ZahajskÃ¡, Institue of Geography of the University of Bern. Funding for development was provided by Prof. Martin Grosjean, Institute of Geography of the University of Bern.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/guiwitz/napari-sediment/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/guiwitz/napari-sediment/issues', 'Documentation, https://github.com/guiwitz/napari-sediment#README.md', 'Source Code, https://github.com/guiwitz/napari-sediment', 'User Support, https://github.com/guiwitz/napari-sediment/issues']",napari-sediment.get_reader,,napari-sediment.make_qwidget,,"['*.hdr', '*.zarr']",,
377,napari-script-editor,napari-script-editor,napari-script-editor,0.2.10,2021-11-06,2023-07-08,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-script-editor/issues,https://pypi.org/project/napari-script-editor/,,https://github.com/haesleinhuepf/napari-script-editor,A python script editor for napari,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari', 'haesleinhuepf-pyqode.core (>=2.15.5)', 'haesleinhuepf-pyqode.python (>=2.15.2)', 'napari-tools-menu', 'jedi (>=0.18.0)', 'pyflakes (<=2.4.0)', 'imageio (!=2.22.1)']","# napari-script-editor

[![License](https://img.shields.io/pypi/l/napari-script-editor.svg?color=green)](https://github.com/haesleinhuepf/napari-script-editor/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-script-editor.svg?color=green)](https://pypi.org/project/napari-script-editor)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-script-editor.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-script-editor/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-script-editor/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-script-editor/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-script-editor)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-script-editor)](https://napari-hub.org/plugins/napari-script-editor)

A python script editor for napari based on [haesleinhuepf's fork of PyQode](https://github.com/haesleinhuepf/pyqode.core).

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

![](https://github.com/haesleinhuepf/napari-script-editor/raw/main/docs/screenshot2.png)

## Usage

Start the script editor from the menu `Tools > Scripts > Script Editor`. Use the auto-completion while typing, 
check out the [napari tutorials](https://napari.org/tutorials/) and the
[example scripts](https://github.com/haesleinhuepf/napari-script-editor/tree/main/example_scripts). 
Use the `Run` button to execute a script.

![](https://github.com/haesleinhuepf/napari-script-editor/raw/main/docs/type_and_run_screencast.gif)

If you save the script to the folder "".napari-scripts"" in your home directory, you will find the script in the 
`Tools > Scripts` menu in napari. You can then also start it from there.

![](https://github.com/haesleinhuepf/napari-script-editor/raw/main/docs/run_from_menu_screencast.gif)

Note: If you have scripts, that might be useful to others, please send them as 
[pull-request](https://github.com/haesleinhuepf/napari-script-editor/pulls) to the examples in 
repository or share them in any other way that suits you.

### chatGPT support

In case [openAI API](https://openai.com/blog/openai-api) is installed, you find another button in the script editor to `Ask chatGPT`. 
Enter a prompt in the script editor and click the button. The script editor will send the prompt to
chatGPT and replace it with the answer. For example try entering:
```python
Write Python code for segmenting an image using these steps:
    * Apply a Gaussian blur
    * Threshold the image using Otsu's method
    * Apply connected component labeling
```
and it will replace it with code accordingly. If it doesn't work in the first attempt, try again. ChatGPT's answers are not always the same.

![](https://github.com/haesleinhuepf/napari-script-editor/raw/main/docs/ask_chatgpt.gif)


## Installation
* Get a python environment, e.g. via [mini-conda](https://docs.conda.io/en/latest/miniconda.html). 
  If you never used python/conda environments before, please follow the instructions 
  [here](https://mpicbg-scicomp.github.io/ipf_howtoguides/guides/Python_Conda_Environments) first.
* Install [napari](https://github.com/napari/napari) using conda. 

```
conda install -c conda-forge napari
```

Afterwards, install `napari-script-editor` using pip:

```
pip install napari-script-editor
```

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-script-editor"" is free and open source software

## Known issues

* Sometimes, the script editor thinks, the file has been changed on disk and asks to reload it.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-script-editor/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Text Editors :: Integrated Development Environments (IDE)', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-script-editor/issues', 'Documentation, https://github.com/haesleinhuepf/napari-script-editor#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-script-editor', 'User Support, https://github.com/haesleinhuepf/napari-script-editor/issues']",,,napari-script-editor.ScriptEditor,,,,
378,napari-sdeconv,napari-sdeconv,napari sdeconv,1.0.1,2021-09-02,2022-07-06,Sylvain Prigent,meriadec.prigent@gmail.com,BSD-3-Clause,https://github.com/sylvainprigent/napari-sdeconv/issues,https://pypi.org/project/napari-sdeconv/,,https://github.com/sylvainprigent/napari-sdeconv,2D and 3D deconvolution,>=3.8,"['numpy', 'magicgui', 'qtpy', 'sdeconv (>=1.0.1)', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""sdeconv (>=1.0.1) ; extra == 'testing'""]","# napari-sdeconv

[![License BSD-3](https://img.shields.io/pypi/l/napari-sdeconv.svg?color=green)](https://github.com/sylvainprigent/napari-sdeconv/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-sdeconv.svg?color=green)](https://pypi.org/project/napari-sdeconv)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-sdeconv.svg?color=green)](https://python.org)
[![tests](https://github.com/sylvainprigent/napari-sdeconv/workflows/tests/badge.svg)](https://github.com/sylvainprigent/napari-sdeconv/actions)
[![codecov](https://codecov.io/gh/sylvainprigent/napari-sdeconv/branch/main/graph/badge.svg)](https://codecov.io/gh/sylvainprigent/napari-sdeconv)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-sdeconv)](https://napari-hub.org/plugins/napari-sdeconv)

2D and 3D deconvolution

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-sdeconv` via [pip]:

    pip install napari-sdeconv



To install latest development version :

    pip install git+https://github.com/sylvainprigent/napari-sdeconv.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-sdeconv"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/sylvainprigent/napari-sdeconv/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/sylvainprigent/napari-sdeconv/issues', 'Documentation, https://github.com/sylvainprigent/napari-sdeconv#README.md', 'Source Code, https://github.com/sylvainprigent/napari-sdeconv', 'User Support, https://github.com/sylvainprigent/napari-sdeconv/issues']",,,napari-sdeconv.gaussian_widget,napari-sdeconv.make_sample_data,,,
379,napari-segment-anything-2,napari-segment-anything-2,Segment Anything 2,0.0.1,2024-07-30,2024-07-30,JordÃ£o Bragantini,jordao.bragantini@czbiohub.org,"Copyright (c) 2024, JordÃ£o Bra...",https://github.com/JoOkuma/napari-segment-anything-2/issues,https://pypi.org/project/napari-segment-anything-2/,,,A napari plugin for Meta's Segment Anything 2 in Images and Videos,>=3.9,"['magicgui', 'numpy', 'qtpy', 'scikit-image', ""napari; extra == 'testing'"", ""pyqt5; extra == 'testing'"", ""pytest; extra == 'testing'"", ""pytest-cov; extra == 'testing'"", ""pytest-qt; extra == 'testing'"", ""tox; extra == 'testing'""]","# napari-segment-anything-2

[![License BSD-3](https://img.shields.io/pypi/l/napari-segment-anything-2.svg?color=green)](https://github.com/JoOkuma/napari-segment-anything-2/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-segment-anything-2.svg?color=green)](https://pypi.org/project/napari-segment-anything-2)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-segment-anything-2.svg?color=green)](https://python.org)
[![tests](https://github.com/JoOkuma/napari-segment-anything-2/workflows/tests/badge.svg)](https://github.com/JoOkuma/napari-segment-anything-2/actions)
[![codecov](https://codecov.io/gh/JoOkuma/napari-segment-anything-2/branch/main/graph/badge.svg)](https://codecov.io/gh/JoOkuma/napari-segment-anything-2)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-segment-anything-2)](https://napari-hub.org/plugins/napari-segment-anything-2)

A napari plugin for Meta's Segment Anything 2 in Images and Videos

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-segment-anything-2` via [pip]:

    pip install git+https://github.com/jookuma/segment-anything-2@no-cc
    pip install napari[all] napari-segment-anything-2


To install latest development version :

    pip install git+https://github.com/jookuma/segment-anything-2@no-cc
    pip install napari[all] git+https://github.com/JoOkuma/napari-segment-anything-2.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-segment-anything-2"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/JoOkuma/napari-segment-anything-2/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/JoOkuma/napari-segment-anything-2/issues', 'Documentation, https://github.com/JoOkuma/napari-segment-anything-2#README.md', 'Source Code, https://github.com/JoOkuma/napari-segment-anything-2', 'User Support, https://github.com/JoOkuma/napari-segment-anything-2/issues']",,,napari-segment-anything-2.sam2,,,,
380,napari-seedseg,napari-seedseg,SeedSeg Segmentation,0.0.2,2023-05-09,2023-05-09,Reza Akbarian Bafghi,reza.akb98@gmail.com,BSD-3,https://github.com/rezaakb/napari-seedseg/issues,https://pypi.org/project/napari-seedseg/,,https://github.com/rezaakb/napari-seedseg,A simple plugin for segmentation,>=3.8,"['napari', 'numpy', 'magicgui', 'qtpy', 'opencv-python-headless', 'scikit-image>=0.19.3', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-seedseg

[![License BSD-3](https://img.shields.io/pypi/l/napari-seedseg.svg?color=green)](https://github.com/rezaakb/napari-seedseg/tree/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-seedseg.svg?color=green)](https://pypi.org/project/napari-seedseg)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-seedseg.svg?color=green)](https://python.org)
[![tests](https://github.com/rezaakb/napari-seedseg/workflows/tests/badge.svg)](https://github.com/rezaakb/napari-seedseg/actions)
[![codecov](https://codecov.io/gh/rezaakb/napari-seedseg/branch/main/graph/badge.svg)](https://codecov.io/gh/rezaakb/napari-seedseg)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-seedseg)](https://napari-hub.org/plugins/napari-seedseg)

A simple plugin for 2D medical image segmentation. In this project, we are trying to use Flood method for segmentation. 
Flood segmentation, also known as flood fill or region growing, is an image segmentation technique that starts from a seed point and expands to neighboring pixels with similar properties (e.g., intensity, color). In our project, you only can segment one label at the time. Below is a description of the repository's structure and the purpose of each file:

    .
    âââ setup.cfg              # package metadata
    âââ pyproject.toml         # use setuptools
    âââ src/napari_seedseg     
    â   âââ napari.yaml        # Load and stress tests
    â   âââ __init.py__        # Python package metadata files
    â   âââ _widget.py         # Widget contributions
    â   âââ _layers.py         # Layers contributions
    â   âââ _method.py         # Methods contributions
    âââ ...

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-seedseg` via [pip]:

    pip install napari-seedseg



To install latest development version :

    pip install git+https://github.com/rezaakb/napari-seedseg.git


## Packages
In this project we have used these packages:

    numpy
    magicgui
    qtpy
    opencv-python-headless
    scikit-image>=0.19.3



## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-seedseg"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/rezaakb/napari-seedseg/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/rezaakb/napari-seedseg/issues', 'Documentation, https://github.com/rezaakb/napari-seedseg#README.md', 'Source Code, https://github.com/rezaakb/napari-seedseg', 'User Support, https://github.com/rezaakb/napari-seedseg/issues']",,,napari-seedseg.make_qwidget,,,,
381,napari-segmentation-overlap-filter,napari-segmentation-overlap-filter,Segmentation Filter Overlap,0.0.1,2024-06-24,2024-06-24,Vanessa Dao,vanessadao31@yahoo.co.uk,BSD-3-Clause,https://github.com/FrancisCrickInstitute/PARSEG,https://pypi.org/project/napari-segmentation-overlap-filter/,,https://github.com/FrancisCrickInstitute/PARSEG,A simple plugin to remove overlapping segmentations from images,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# PARSEG

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/FrancisCrickInstitute/CALM_Template/HEAD?labpath=blob%2Fmain%2Fsegment_image.ipynb)
[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/release/python-3115/)
![Commit activity](https://img.shields.io/github/commit-activity/y/FrancisCrickInstitute/CALM_Template?style=plastic)
![GitHub](https://img.shields.io/github/license/FrancisCrickInstitute/CALM_Template?color=green&style=plastic)

PARSEG (PAralellised Refinement of SEGmentations) combines segmentation masks and filters overlapping objects based on colocalization statistics, such as percent overlap. 

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Overview
By leveraging [Dask], PARSEG filters overlapping segmentations masks in a computationally efficient manner by processing individual 2D slices in parallel. 

There are two different ways to interact with PARSEG and use it for different objectives:

* As a napari plugin for graphical user interaction
* As a Python API to allow users to integrate PARSEG tools into their own custom workflows

## Installation

You can install `napari-segmentation-overlap-filter` via [pip]:

    pip install napari-segmentation-overlap-filter

## Getting Started

### Napari Plugin
1. Download the example dataset images
2. Start napari and open both images as separate layers
3. Convert the layers from an `Image Layer` to a `Labels Layer` by right-clicking on the layer
4. Open the plugin with `Plugins > Segmentation Overlap Filter` and the widget will appear on the right
5. Select the two segmentation masks you'd like to combine using the drop down and menu
6. Drag the slider to set percent overlap allowed
7. Click `Run`
8. Optionally, export the overlap dataframe as a csv file

### Python API
This [example notebook] shows how you can integrate the Python API into your own workflow for filtering and combining overlapping segmentation masks

## Issues

If you encounter any problems, please file an issue along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[Dask]: https://www.dask.org/
[pip]: https://pypi.org/project/pip/
[example notebook]: https://github.com/FrancisCrickInstitute/PARSEG/blob/main/Notebooks/Combine_Segmentations_And_Filter_Overlaps.ipynb
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-segmentation-overlap-filter.make_plugin_widget,,,,
382,napari-segment-anything,napari-segment-anything,Segment Anything,0.1.4,2023-04-05,2023-04-19,Jordao Bragantini,jordao.bragantini@czbiohub.org,Apache-2.0,https://github.com/jookuma/napari-segment-anything/issues,https://pypi.org/project/napari-segment-anything/,,https://github.com/jookuma/napari-segment-anything,Napari plugin of Segment Anything Model (SAM),>=3.8,"['numpy', 'torch', 'torchvision', 'segment-anything', 'qtpy', 'magicgui', 'napari', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-segment-anything

[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-segment-anything.svg?color=green)](https://github.com/jookuma/napari-segment-anything/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-segment-anything.svg?color=green)](https://pypi.org/project/napari-segment-anything)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-segment-anything.svg?color=green)](https://python.org)
[![tests](https://github.com/jookuma/napari-segment-anything/workflows/tests/badge.svg)](https://github.com/jookuma/napari-segment-anything/actions)
[![codecov](https://codecov.io/gh/jookuma/napari-segment-anything/branch/main/graph/badge.svg)](https://codecov.io/gh/jookuma/napari-segment-anything)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-segment-anything)](https://napari-hub.org/plugins/napari-segment-anything)

Napari plugin of [Segment Anything Model (SAM)](https://github.com/facebookresearch/segment-anything)

Download the network weights [here](https://github.com/facebookresearch/segment-anything#model-checkpoints)


https://user-images.githubusercontent.com/21022743/230456433-2fa7bc40-a735-4d73-8d87-ecf776bbe2be.mp4


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-segment-anything` via [pip]:

```bash
pip install napari-segment-anything
```

We recommend installing the latest development version because this package is being developed:

```bash
pip install git+https://github.com/jookuma/napari-segment-anything.git
```

**IMPORTANT**: `napari` won't work if you don't have `pyqt5` or `pyside2` installed.

## Instructions

### Opening napari-segment-anything

This software is napari plugin, so once you have napari installed you can open it using the command line:

```bash
napari <your image path> -w napari-segment-anything 'Segment Anything'
```

I noticed that sometimes napari fails to load the plugin widget from the command line, go to step 2 from below to load it.

If you prefer the user interface you need to:

1) Drag and drop your image into napari to load it;
2) Go to the ""Plugins"" file menu in the upper right corner and select the ""Segment Anything"" plugin.
3) Follow the instructions below for usage.

**IMPORTANT**: If you get an error make sure you have `pyqt5` or `pyside2` installed.

### Usage

- Interactions are done on the ""SAM points"" and ""SAM box"" layers using the existing functionalities of napari. Only rectangle shapes trigger the network prediction.
- For points supervision, left clicks are positive cues (object) and right clicks are negative (background).
- Press the ""Confirm Annot."" button (or the ""C"" key) to propagate the current segmentation mask to the label image.
- Use the napari labels layer features to delete or edit already confirmed labels.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-segment-anything"" is a free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/jookuma/napari-segment-anything/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/jookuma/napari-segment-anything/issues', 'Documentation, https://github.com/jookuma/napari-segment-anything#README.md', 'Source Code, https://github.com/jookuma/napari-segment-anything', 'User Support, https://github.com/jookuma/napari-segment-anything/issues']",,,napari-segment-anything.samwidget,,,,
383,napari-segment,napari-segment,Segment organoid,0.3.12,2022-10-05,2023-09-01,Andrey Aristov,aaristov@pasteur.fr,BSD-3-Clause,https://github.com/aaristov/napari-segment/issues,https://pypi.org/project/napari-segment/,,https://github.com/aaristov/napari-segment,Segment organoids and measure intensities,>=3.8,"['dask', 'imageio-ffmpeg', 'matplotlib', 'napari', 'nd2', 'numpy', 'pytest-qt', 'scikit-image', 'zarr']","# napari-segment

[![License](https://img.shields.io/pypi/l/napari-segment.svg?color=green)](https://github.com/aaristov/napari-segment/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-segment.svg?color=green)](https://pypi.org/project/napari-segment)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-segment.svg?color=green)](https://python.org)
[![tests](https://github.com/aaristov/napari-segment/workflows/tests/badge.svg)](https://github.com/aaristov/napari-segment/actions)
[![codecov](https://codecov.io/gh/aaristov/napari-segment/branch/main/graph/badge.svg)](https://codecov.io/gh/aaristov/napari-segment)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-segment)](https://napari-hub.org/plugins/napari-segment)

Interactively segment organoids/spheroids/aggregates in brightfield/fluorescence from nd2 multipositional stack.
----------------------------------

![image](https://user-images.githubusercontent.com/11408456/201948817-255717a6-5f5c-45a2-ae01-2e0cbb1e29e8.png)


## Installation

```pip install napari-segment```

or

From napari plugin

![image](https://user-images.githubusercontent.com/11408456/201949692-33f94eaf-ac43-44dd-8c21-e9f9a460c5b2.png)


## Usage for segmentation

1. Drag your nd2 file into napari (otherwise try the Sample data from File / Open Sample / napari-segment)
2. Lauch Plugins -> napari-segment: Segment multipos
3. Select the brightfield channel
4. The data is lazily loaded from nd2 dataset and dynamically segmented in the viewer.
5. Binning 1-8 allows to skip small features and focus on bigger objects, also makes processing faster.
![image](https://user-images.githubusercontent.com/11408456/201701163-70c4af51-8a3a-42a0-adb9-32f0114eb49d.png)
6. Various preprocessing modes allow segmentation of different objects:
![image](https://user-images.githubusercontent.com/11408456/201701809-f16a23ea-d14a-4b38-8b8c-08a113416509.png)

  - Invert: will use the dark shadow around aggregate - best for very old aggregates , out of focus (File / Open Sample / napari-segment / Old aggregate)
  
  ![image](https://user-images.githubusercontent.com/11408456/201701950-efd86fae-d85b-471c-bb44-a0e328e26adc.png)

  - Gradient: best for very sharp edges, early aggregates, single cells (File / Open Sample / napari-segment / Early aggregate) 
  
  ![image](https://user-images.githubusercontent.com/11408456/201705697-5d0d0643-44b6-4cb9-9208-4a29dd899d8c.png)
  
  
  - Gauss diff: Fluorescence images
  The result of preprocessing will be shown in the ""Preprocessing"" layer.
7. Smooth, Theshold and Erode parameters allow you to adjust the preliminary segmentation -> they all will appear in the ""Detections"" layer as outlines 

  ![image](https://user-images.githubusercontent.com/11408456/201703675-cff6bac1-bb2a-4d45-963f-6e6d00309c77.png)

8. Min/max diameter and eccentricity allow you to filter out unwanted regions -> the good regions will appear in the ""selected labels"" layer as filled areas.

![image](https://user-images.githubusercontent.com/11408456/201703754-2c83a8d6-70c2-444a-8e30-54a39c901cd0.png)
![image](https://user-images.githubusercontent.com/11408456/201707025-9121f0dc-3939-48f0-ae75-884891be8d66.png)


9. Once satisfied, click ""Save the params!"" - it will automatically create file.nd2.params.yml file, so you can recall how the segmentation was done. Next time you open the same dataset, the parameters will be loaded automatically from this file. 

10. Next section is for quantifying the sizes. Pixel size will be retrieved automatically from metadata. If not: update it manually and click Update plots to see the correct sizes. Click on any suspected value to see the corresponding frame and try to adjust the above parameters. 

![image](https://user-images.githubusercontent.com/11408456/201704881-b2303b9a-50c6-49c7-80ff-a6099cc2a151.png)

11. If impossible to get good results with automatic pipeline, click Clone for manual correction: this will create an editable ""Manual"" layer which you can edin with built-in tools in napari. Click ""Update plots"" to see the updated values. 

12. ""Save csv!"" will generate a csv file with regionprops. 


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-segment"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/aaristov/napari-segment/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/aaristov/napari-segment/issues', 'Documentation, https://github.com/aaristov/napari-segment#README.md', 'Source Code, https://github.com/aaristov/napari-segment', 'User Support, https://github.com/aaristov/napari-segment/issues']",napari-segment.get_reader,napari-segment.write_multiple,napari-segment.make_qwidget,napari-segment.make_late_aggregate,"['*.npy', '*.nd2', '*.tif']",,['.npy']
384,napari-segment-everything,napari-segment-everything,Napari Segment Everything,0.1.6,2024-04-01,2024-05-17,"Brian Northan, Ian Coccimiglio",bnorthan@gmail.com,BSD-3-Clause,https://github.com/True-North-Intelligent-Algorithms/napari-segment-everything,https://pypi.org/project/napari-segment-everything/,,https://github.com/True-North-Intelligent-Algorithms/napari-segment-everything,A Napari SAM plugin to segment everything in your image (not just some things),>=3.9,"['numpy', 'torch', 'torchvision', 'segment-anything', 'magicgui', 'qtpy', 'scikit-image', 'napari', 'gdown', 'opencv-python', 'timm', 'torchpack', 'onnx', 'onnxsim', 'matplotlib', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-segment-everything

[![License BSD-3](https://img.shields.io/pypi/l/napari-segment-everything.svg?color=green)](https://github.com/True-North-Intelligent-Algorithms/napari-segment-everything/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-segment-everything.svg?color=green)](https://pypi.org/project/napari-segment-everything)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-segment-everything.svg?color=green)](https://python.org)
[![tests](https://github.com/True-North-Intelligent-Algorithms/napari-segment-everything/workflows/tests/badge.svg)](https://github.com/True-North-Intelligent-Algorithms/napari-segment-everything/actions)
[![codecov](https://codecov.io/gh/True-North-Intelligent-Algorithms/napari-segment-everything/branch/main/graph/badge.svg)](https://codecov.io/gh/True-North-Intelligent-Algorithms/napari-segment-everything)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-segment-everything)](https://napari-hub.org/plugins/napari-segment-everything)

A Napari SAM plugin to segment everything in your image (not just some things)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

https://github.com/True-North-Intelligent-Algorithms/napari-segment-everything/assets/4366342/1f451e4a-bf66-4b77-a91d-4fa283270160

## Instructions

### 0. Select recipe (implementation)

Use the 'select recipe' combo box to choose the implementation.   Currently 'Mobile SAM v2', 'Mobile SAM finetuned' and 'SAM Automatic Mask Generator' are available.  Not that the sub-options will change slightly depending on which recipe you choose.  'Mobile SAM v2' and 'Mobile SAM finetuned' (finetuned using Cellpose training data) first use a bounding box detector to locate objects then feed the bounding boxes to SAM.  'SAM Automatic Mask Generator' uses a grid of points as the prompt for SAM.  Our experiments indicate that the 'Mobile SAM' recipes work well in most cases.  'SAM Automatic Mask Generator' may be useful for cases where bounding box detection was sub-optimal.  

### 1. Generate 3D labels

In the first step adjust SAM settings and generate a 3D representation of your labels.  The 3D view is needed to represent overlapping labels (labels that overlap in xy can be represented at different z).  After tweaking settings press 'Generate 3D labels'.  Be patient.  SAM with permissive settings can potentially find thousands of labels in a complicated image.  At least 6G of GPU memory is recommended to run SAM and to render to 3D label map (which can be large). 

### 2. Filter 3D labels

In the next step select a stat (solidity, hue, IOE, stability and other stats are available) then use the sliders and number boxes to filter out labels that do not represent structure of interest.  If you double click on a label a popup will appear containing the stats for that label.  Inpect stats for labels you want to keep, and labels you want to eliminate to help determine the filter settings. 

### 3. Generate 2D labels

In this step the 3D labels are projected to a 2D label map, use the dropdown to choose between projecting big labels in front or small labels in front.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-segment-everything"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-segment-everything.napari_segment_everything,,,,
385,napari-segselect,napari-segselect,SegSelect,0.1.3,2025-01-31,2025-02-06,Benedikt Wimmer,b.wimmer@bioc.uzh.ch,"Copyright (c) 2025, Benedikt W...",https://github.com/bwmr/napari-segselect/issues,https://pypi.org/project/napari-segselect/,,,Select a connected component from a membrain-seg segmentation.,>=3.9,"['numpy', 'magicgui', 'mrcfile', 'scipy', 'napari; extra == ""testing""', 'ruff; extra == ""testing""']","# napari-segselect

[![License BSD-3](https://img.shields.io/pypi/l/napari-segselect.svg?color=green)](https://github.com/bwmr/napari-segselect/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-segselect.svg?color=green)](https://pypi.org/project/napari-segselect)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-segselect.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-segselect)](https://napari-hub.org/plugins/napari-segselect)

Select a connected component from a [membrain-seg](https://github.com/teamtomo/membrain-seg) segmentation.

## Usage

1. Run `membrain-seg` with the `--store-connected-components` flag (optional, otherwise connected components will be calculated while opening)
2. Open the segmentation in Napari, find out which component numbers correspond to your feature.
    ![Label Layer](images/image2.png)
3. Enter these numbers and a feature name in the widget, press run. 
    ![Widget](images/image3.png)
4. Save the resulting layer using naparis built-in dialog. 
5. Now you have a standalone binary segmentation of your feature of interest.
    ![Output](images/image4.png)


## Installation

You can install `napari-segselect` via [pip]:

    pip install napari-segselect
   
Or directly from GitHub:

    pip install git+https://github.com/bwmr/napari-segselect.git


## License

Distributed under the terms of the [BSD-3] license,
""napari-segselect"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

This [napari] plugin was generated with [copier] using the [napari-plugin-template].


[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/bwmr/napari-segselect/issues

[napari]: https://github.com/napari/napari
[pip]: https://pypi.org/project/pip/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/bwmr/napari-segselect/issues', 'Documentation, https://github.com/bwmr/napari-segselect#README.md', 'Source Code, https://github.com/bwmr/napari-segselect', 'User Support, https://github.com/bwmr/napari-segselect/issues']",napari-segselect.read_mrc,napari-segselect.write_segmentation,napari-segselect.select_label,,['*.mrc'],['.mrc'],
386,napari-segment-blobs-and-things-with-membranes,napari-segment-blobs-and-things-with-membranes,napari-segment-blobs-and-things-with-membranes,0.3.12,2021-09-25,2024-10-25,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/issues,https://pypi.org/project/napari-segment-blobs-and-things-with-membranes/,,https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes,A plugin based on scikit-image for segmenting nuclei and cells based on fluorescent microscopy images with high intensity in nuclei and/or membranes,>=3.8,"['napari-plugin-engine>=0.1.4', 'numpy', 'scikit-image', 'scipy', 'napari-tools-menu>=0.1.17', 'napari-time-slicer>=0.4.8', 'napari-assistant', 'stackview>=0.9.1']","# napari-segment-blobs-and-things-with-membranes (nsbatwm)

[![License](https://img.shields.io/pypi/l/napari-segment-blobs-and-things-with-membranes.svg?color=green)](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-segment-blobs-and-things-with-membranes.svg?color=green)](https://pypi.org/project/napari-segment-blobs-and-things-with-membranes)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-segment-blobs-and-things-with-membranes.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-segment-blobs-and-things-with-membranes)
[![Development Status](https://img.shields.io/pypi/status/napari-segment-blobs-and-things-with-membranes.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-segment-blobs-and-things-with-membranes)](https://napari-hub.org/plugins/napari-segment-blobs-and-things-with-membranes)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.7027634.svg)](https://doi.org/10.5281/zenodo.7027634)

This napari-plugin is based on scikit-image and allows segmenting nuclei and cells based on fluorescence microscopy images with high intensity in nuclei and/or membranes.

## Usage

This plugin populates image processing operations to the `Tools` menu in napari.
You can recognize them with their suffix `(nsbatwm)` in brackets.
Furthermore, it can be used from the [napari-assistant](https://www.napari-hub.org/plugins/napari-assistant) graphical user interface. 
Therefore, just click the menu `Tools > Utilities > Assistant (na)` or run `naparia` from the command line.

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/tools_menu_screenshot.png)

You can also call these functions as shown in [the demo notebook](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/blob/main/docs/demo.ipynb).

### Voronoi-Otsu-Labeling

This algorithm uses [Otsu's thresholding method](https://ieeexplore.ieee.org/document/4310076) in combination with 
[Gaussian blur](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.gaussian) and a 
[Voronoi-Tesselation](https://en.wikipedia.org/wiki/Voronoi_diagram) 
approach to label bright objects such as nuclei in an intensity image. The alogrithm has two sigma parameters which allow
you to fine-tune where objects should be cut (`spot_sigma`) and how smooth outlines should be (`outline_sigma`).
This implementation aims to be similar to [Voronoi-Otsu-Labeling in clesperanto](https://github.com/clEsperanto/pyclesperanto_prototype/blob/master/demo/segmentation/voronoi_otsu_labeling.ipynb).

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/voronoi_otsu_labeling.png)

### Seeded Watershed

Starting from an image showing high-intensity membranes and a seed-image where objects have been labeled (e.g. using Voronoi-Otsu-Labeling),
objects are labeled that are constrained by the membranes.

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/seeded_watershed.png)

### Seeded Watershed with mask

If there is additionally a mask image available, one can use the `Seeded Watershed with mask`, to constraint the flooding 
on a membrane image (1), starting from nuclei (2), limited by a mask image (3) to produce a cell segmentation within the mask (4).

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/seeded_watershed_with_mask.png)

### Seeded Watershed using local minima as starting points

Similar to the Seeded Watershed and Voronoi-Otsu-Labeling explained above, you can use this tool to segment an image
showing membranes without an additional image showing nuclei. The two sigma parameters allow to fine tune how close 
objects can be and how precise their boundaries are detected.

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/local_minima_seeded_watershed.png)

### Gaussian blur

Applies a [Gaussian blur](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.gaussian) to an
image. This might be useful for denoising, e.g. before applying the Threshold-Otsu method.

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/gaussian_blur.png)

### Subtract background

Subtracts background using [scikit-image's rolling-ball algorithm](https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_rolling_ball.html). 
This might be useful, for example to make intensity of membranes more similar in different regions of an image.

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/subtract_background.png)

### Threshold Otsu

Binarizes an image using [scikit-image's threshold Otsu algorithm](https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_thresholding.html), also known as 
[Otsu's method](https://ieeexplore.ieee.org/document/4310076).

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/threshold_otsu.png)

### Split touching objects (formerly known as binary watershed).

In case objects stick together after thresholding, this tool might help.
It aims to deliver similar results as [ImageJ's watershed implementation](https://imagej.nih.gov/ij/docs/menus/process.html#watershed).

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/binary_watershed.png)

### Connected component labeling

Takes a binary image and produces a label image with all separated objects labeled differently. Under the hood, it uses
[scikit-image's label function](https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_label.html).

![img.png](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/connected_component_labeling.png)

### Manual split and merge labels

Split and merge labels in napari manually via the `Tools > Utilities menu`:

![](https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/raw/main/docs/split_and_merge_demo.gif)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

This plugin is part of devbio-napari. To install it, please follow its [installation instructions](https://github.com/haesleinhuepf/devbio-napari#installation).

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-segment-blobs-and-things-with-membranes"" is free and open source software

## Issues

If you encounter any problems, please create a thread on [image.sc] along with a detailed description and tag [@haesleinhuepf].

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

[image.sc]: https://image.sc
[@haesleinhuepf]: https://twitter.com/haesleinhuepf
","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/issues', 'Documentation, https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes', 'User Support, https://github.com/haesleinhuepf/napari-segment-blobs-and-things-with-membranes/issues']",,,napari-segment-blobs-and-things-with-membranes.napari_experimental_provide_function,,,,
387,napari-shape-odyssey,napari-shape-odyssey,shape odyssey,0.1.1,2023-08-31,2024-01-02,Johannes Soltwedel,johannes_richard.soltwedel@tu-dresden.de,BSD-3-Clause,https://github.com/jo-mueller/napari-shape-odyssey/issues,https://pypi.org/project/napari-shape-odyssey/,,,Analyze shapes of meshes,>=3.8,"['numpy', 'vedo', 'pandas', 'napari', 'napari-stress', 'napari-process-points-and-surfaces', 'pyfmaps', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""PyQt5 ; extra == 'testing'""]","# napari-shape-odyssey

[![License BSD-3](https://img.shields.io/pypi/l/napari-shape-odyssey.svg?color=green)](https://github.com/jo-mueller/napari-shape-odyssey/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-shape-odyssey.svg?color=green)](https://pypi.org/project/napari-shape-odyssey)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-shape-odyssey.svg?color=green)](https://python.org)
[![tests](https://github.com/jo-mueller/napari-shape-odyssey/workflows/tests/badge.svg)](https://github.com/jo-mueller/napari-shape-odyssey/actions)
[![codecov](https://codecov.io/gh/jo-mueller/napari-shape-odyssey/branch/main/graph/badge.svg)](https://codecov.io/gh/jo-mueller/napari-shape-odyssey)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-shape-odyssey)](https://napari-hub.org/plugins/napari-shape-odyssey)

Analyze shapes of meshes: This plugin provides advanced measures of shape for meshes. It is based largely on the following libraries and tools:

* [PyFM](https:/github.com/robinmagnet/pyfm)
* [boundary-first-flattening](https://github.com/GeometryCollective/boundary-first-flattening)

## Shape analysis

This plugin provides Laplace spectra ([Reuter, Wolter, Peinecke (2005)](https://dl.acm.org/doi/abs/10.1145/1060244.1060256)), heat kernel signatures ([Bronstein & Kokkinos (2010)](https://ieeexplore.ieee.org/abstract/document/5539838/)) & wave kernel signatures ([Audrey, Schlickewei, Cremers et al.](https://ieeexplore.ieee.org/abstract/document/6130444)).

**Laplace spectra** can be imagined to be the equivalent of resonance modes on the surface of a mesh. The resonance and the resonance modes can, for typical objects, look like this:

![](https://github.com/jo-mueller/napari-shape-odyssey/raw/main/docs/imgs/Eigenvalues.gif)

**Heat kernel signatures**: Heat dissipation on a mesh depends on local geometry. You can use the heat kernel signature to easily generate a large number of local features of shape

![](https://github.com/jo-mueller/napari-shape-odyssey/raw/main/docs/imgs/heat_kernel_signature.gif)

## Unwrapping

This plugin provides a number of methods to unwrap a mesh into basic shapes such as spheres or disks. The method relies on [boundary-first flattening](https://github.com/GeometryCollective/boundary-first-flattening) - currently it's only available on Windows.

![](https://github.com/jo-mueller/napari-shape-odyssey/raw/main/docs/imgs/unwrap_to_sphere.png)



----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-shape-odyssey` via [pip]:

Â´Â´Â´bash
    pip install napari-shape-odyssey
    napari-skimage-regionprops @ git+https://github.com/jo-mueller/napari-skimage-regionprops.git
    pyFM @ git+https://github.com/RobinMagnet/pyFM.git
Â´Â´Â´




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-shape-odyssey"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/jo-mueller/napari-shape-odyssey/issues', 'Documentation, https://jo-mueller.github.io/napari-shape-odyssey/intro.html', 'Source Code, https://github.com/jo-mueller/napari-shape-odyssey', 'User Support, https://github.com/jo-mueller/napari-shape-odyssey/issues']",napari-shape-odyssey.get_reader,napari-shape-odyssey.write_multiple,napari-shape-odyssey.shape_fingerprint_spectral,,"['*.obj', '*.stl', '*.off', '*.ply', '*.vtk', '*.vtp']",,['.npy']
388,napari-serialcellpose,napari-serialcellpose,serialcellpose,0.3.0,2022-07-28,2025-07-22,Guillaume Witz,guillaume.witz@unibe.ch,BSD-3-Clause,https://github.com/guiwitz/napari-serialcellpose/issues,https://pypi.org/project/napari-serialcellpose/,,https://github.com/guiwitz/napari-serialcellpose,A simple plugin to batch segment cells with cellpose,>=3.10,"['cellpose<4', 'numpy', 'magicgui', 'qtpy', 'matplotlib', 'napari-skimage-regionprops', 'bioio', 'bioio-tifffile', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-serialcellpose

[![License](https://img.shields.io/pypi/l/napari-serialcellpose.svg?color=green)](https://github.com/guiwitz/napari-serialcellpose/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-serialcellpose.svg?color=green)](https://pypi.org/project/napari-serialcellpose)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-serialcellpose.svg?color=green)](https://python.org)
[![tests](https://github.com/guiwitz/napari-serialcellpose/workflows/tests/badge.svg)](https://github.com/guiwitz/napari-serialcellpose/actions)
[![codecov](https://codecov.io/gh/guiwitz/napari-serialcellpose/branch/main/graph/badge.svg)](https://codecov.io/gh/guiwitz/napari-serialcellpose)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-serialcellpose)](https://napari-hub.org/plugins/napari-serialcellpose)

This napari plugin allows you to segment single images or series of images using built-in or custom Cellpose models as well as to analyze the properties of these segmented regions (""region properties""). Properties can be visualized for a single image or a complete experiment in the form of histograms that can also be filtered (e.g. based on area size, mean intensity etc.) Thanks to the [napari-skimage-regionprops](https://github.com/haesleinhuepf/napari-skimage-regionprops) plugin, properties of segmented objects can be interactively explored at a single object level.

## Main goal

The main goal of this plugin is to simplify the classical image processing pipeline of image segmentation followed by region analysis via Cellpose. It allows to quickly get a quantification of a set of images without the need for any scripting.

## Installation

In order to use this plugin, whe highly recommend to create a specific environment and to install the required software in it. You can create a conda environment using:

    conda create -n serialcellpose python=3.8.5 napari -c conda-forge

Then activate it and install the plugin:
    
    conda activate serialcellpose
    pip install napari-serialcellpose

### Potential issue with PyTorch

Cellpose and therefore the plugin and napari can crash without warning in some cases with ```torch==1.12.0```. This can be fixed by reverting to an earlier version using:
    
    pip install torch==1.11.0

### GPU

In order to use a GPU:

1. Uninstall the PyTorch version that gets installed by default with Cellpose:

        pip uninstall torch

2. Make sure your have up-to-date drivers for your NVIDIA card installed.

3. Re-install a GPU version of PyTorch via conda using a command that you can find [here](https://pytorch.org/get-started/locally/) (this takes care of the cuda toolkit, cudnn etc. so **no need to install manually anything more than the driver**). The command will look like this:

        conda install pytorch torchvision cudatoolkit=11.3 -c pytorch

### Plugin Updates

To update the plugin, you only need to activate the existing environment and install the new version:

    conda activate serialcellpose
    pip install napari-serialcellpose -U

## Usage: segmentation

The main interface is shown below. The sequence of events should be the following:

1. Select a folder containing images. The list of files within that folder will appear in the area above. You can also just drag and drop a folder or an image in that area. When selecting an image, it gets displayed in the viewer. Images are opened via [aicsimageio](https://allencellmodeling.github.io/aicsimageio/). You can use grayscale images, RGB images or multi-channel images. In the latter case, **make sure each channel opens as a separate layer when you open them using the napari-aicsimagio importer**.
2. If you want to save the segmentation and tables with properties, select a folder that will contain the output.
3. Select the type of cellpose model.
4. If you use a custom model, select its location.
5. Run the analysis on the currently selected image or on all files in the folder.
### Options

6. Select if you want to use a GPU or not.
7. If you are using multi-channel images, you can specify which channel to segment and optionally which to use as ""nuclei"" channel to help cell segmentation.
8. In case you are using one of the built-in models, you can set the estimated diameter of your objects.
9. In the Options tab you will find a few more options for segmentation, including the two thresholds ```flow_threshold``` and ```cellprob_threshold```. You can also decide to discard objects touching the border. Using the ```Select options yml file``` you can select a ```.yml``` file which contains a list of additional options to pass to the ```eval``` method of the Cellpose model. **Note that options specified in the yml file will override options set in the GUI**. The file [my_options.yml](https://raw.githubusercontent.com/guiwitz/napari-serialcellpose/main/src/napari_serialcellpose/_tests/my_options.yml) is an example of such a file where for example the ```diameter``` (also available in the GUI) and ```resample``` (not available in the GUI) options are set. 

<img src=""https://github.com/guiwitz/napari-serialcellpose/raw/main/illustrations/napari_serialcellpose_gui1.png"" alt=""image"" width=""500"">
<img src=""https://github.com/guiwitz/napari-serialcellpose/raw/main/illustrations/napari_serialcellpose_gui1b.png"" alt=""image"" width=""500"">

### Properties

10. After segmentation, properties of the objects can automatically be computed. You can select which properties should be computed in the Options tab. As defined in ```napari-skimage-regionprops``` properties are grouped by types. If you want to measure intensity properties such as mean intensity, you have to specify which channel (```Analysis channel```) you want to perform the measurement on.

### Output

The results of the analysis are saved in the folder chosen in #2. The segmentation mask is saved with the same name as the original image with the suffix ```_mask.tif```. A table with properties is saved in the subfolder ```tables``` also with the same name as the image with the suffix ```props.csv```. If you run the plugin on multiple files in a folder, a ```summary.csv``` file is also generated which compiles all the data.
## Usage: post-processing

After the analysis is done, when you select an image, the corresponding segmentation mask is shown on top of the image as shown below. This also works for saved segmentations: in that case you just select a folder with data and the corresponding output folder.

<img src=""https://github.com/guiwitz/napari-serialcellpose/raw/main/illustrations/napari_serialcellpose_gui2.png"" alt=""image"" width=""500"">

### Properties

If you head to the **Properties** tab, you will find there two histograms showing the distribution of two properties that you can choose from a list at the top of the window. Below the plot you find the table containing information for each cell (each line is a cell).

As shown below, if you select the box ```show selected```, you can select items in the properties table and it will highlight the corresponding cell in the viewer. If you select the pipet tool, you can also select a cell and see the corresponding line in the table highlighted.

<img src=""https://github.com/guiwitz/napari-serialcellpose/raw/main/illustrations/napari_serialcellpose_gui3.png"" alt=""image"" width=""500"">

### Summary

Finally if you select the **Summary** tab, and click on ```Load summary```, it will load all data of the current output folder and create histograms of two properties that can be selected. An additional property can be used for filtering the data. Using the sliders, one can set a minimum and maximum threshold on the ""filtering property"", which will create a sub-selection of the data.

<img src=""https://github.com/guiwitz/napari-serialcellpose/raw/main/illustrations/napari_serialcellpose_gui4.png"" alt=""image"" width=""500"">

## Data

Sample data were acquired by Fabian Blank at the DBMR, University of Bern.

## License

Distributed under the terms of the [BSD-3] license,
""napari-serialcellpose"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/guiwitz/napari-serialcellpose/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/guiwitz/napari-serialcellpose/issues', 'Documentation, https://github.com/guiwitz/napari-serialcellpose#README.md', 'Source Code, https://github.com/guiwitz/napari-serialcellpose', 'User Support, https://github.com/guiwitz/napari-serialcellpose/issues']",,,napari-serialcellpose.make_qwidget,,,,
389,napari-sif-reader,napari-sif-reader,napari sif file reader,0.0.2,2022-11-03,2023-10-31,Ruben Lopez,rjlopez2@gmail.com,BSD-3-Clause,https://github.com/rjlopez2/napari-sif-reader/issues,https://pypi.org/project/napari-sif-reader/,,https://github.com/rjlopez2/napari-sif-reader,This is a simple wraper to read .sif format files from Andor Technology.,>=3.8,"['numpy', 'sif-parser', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pillow ; extra == 'testing'""]","# napari-sif-reader

[![License BSD-3](https://img.shields.io/pypi/l/napari-sif-reader.svg?color=green)](https://github.com/rjlopez2/napari-sif-reader/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-sif-reader.svg?color=green)](https://pypi.org/project/napari-sif-reader)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-sif-reader.svg?color=green)](https://python.org)
[![tests](https://github.com/rjlopez2/napari-sif-reader/workflows/tests/badge.svg)](https://github.com/rjlopez2/napari-sif-reader/actions)
[![codecov](https://codecov.io/gh/rjlopez2/napari-sif-reader/branch/main/graph/badge.svg)](https://codecov.io/gh/rjlopez2/napari-sif-reader)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-sif-reader)](https://napari-hub.org/plugins/napari-sif-reader)

This is a simple wraper to read .sif format files from Andor Technology.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-sif-reader` via [pip]:

    pip install napari-sif-reader



To install latest development version :

    pip install git+https://github.com/rjlopez2/napari-sif-reader.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-sif-reader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/rjlopez2/napari-sif-reader/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/rjlopez2/napari-sif-reader/issues', 'Documentation, https://github.com/rjlopez2/napari-sif-reader#README.md', 'Source Code, https://github.com/rjlopez2/napari-sif-reader', 'User Support, https://github.com/rjlopez2/napari-sif-reader/issues']",napari-sif-reader.get_reader,,,napari-sif-reader.make_sample_data,['*.sif'],,
390,napari-simple-orthoviewer,napari-simple-orthoviewer,Orthogonal Viewer,0.0.5,2024-10-08,2024-10-28,Krishnan Venkataraman,krishvraman95@gmail.com,"Copyright (c) 2024, Krishnan V...",https://github.com/Krishvraman/napari-simple-orthoviewer/issues,https://pypi.org/project/napari-simple-orthoviewer/,,,A simple orthogonal viewer in napari,>=3.9,"['numpy', 'magicgui', 'qtpy', 'matplotlib', 'tifffile', 'napari', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-simple-orthoviewer

A simple orthogonal viewer in napari

----------------------------------
## Installation

You can install `napari-simple-orthoviewer` via [pip]:

    pip install napari-simple-orthoviewer



To install latest development version :

    pip install git+https://github.com/Krishvraman/napari-simple-orthoviewer.git


## Usage

![ortho_views_with_overlay](https://github.com/user-attachments/assets/33c00852-13b8-42ca-aa37-cbd28743297c)




## License

Distributed under the terms of the [BSD-3] license,
""napari-simple-orthoviewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.


[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/Krishvraman/napari-simple-orthoviewer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/Krishvraman/napari-simple-orthoviewer/issues', 'Documentation, https://github.com/Krishvraman/napari-simple-orthoviewer#README.md', 'Source Code, https://github.com/Krishvraman/napari-simple-orthoviewer', 'User Support, https://github.com/Krishvraman/napari-simple-orthoviewer/issues']",,,napari-simple-orthoviewer.make_qwidget,,,,
391,napari-sift-registration,napari-sift-registration,SIFTReg,0.1.2,2022-07-27,2022-07-27,John Fozard,john.fozard@gmail.com,BSD-3-Clause,https://github.com/jfozard/napari-sift-registration/issues,https://pypi.org/project/napari-sift-registration/,,https://github.com/jfozard/napari-sift-registration,"Simple plugin for SIFT keypoint detection, and affine registration with RANSAC, based on scikit-image",>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# skimage-sift-registration

[![License BSD-3](https://img.shields.io/pypi/l/napari-sift-registration.svg?color=green)](https://github.com/jfozard/napari-sift-registration/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-sift-registration.svg?color=green)](https://pypi.org/project/napari-sift-registration)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-sift-registration.svg?color=green)](https://python.org)
[![tests](https://github.com/jfozard/napari-sift-registration/workflows/tests/badge.svg)](https://github.com/jfozard/napari-sift-registration/actions)
[![codecov](https://codecov.io/gh/jfozard/napari-sift-registration/branch/main/graph/badge.svg)](https://codecov.io/gh/jfozard/napari-sift-registration)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-sift-registration)](https://napari-hub.org/plugins/napari-sift-registration)

Simple plugin for 2D keypoint detection and affine registration with RANSAC.

----------------------------------

![moving image](test_data/test1.png)
![fixed image](test_data/test2.png)

Artificial data 

![moving image with inlier keypoints](doc/moving_keypoints.png)
![fixed image with inlier keypoints](doc/fixed_keypoints.png)

Moving and fixed images showing inlier keypoints after RANSAC


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.
It uses the [scikit-image] SIFT keypoint detection routines to find distinctive image points and generate local descriptions of the image around them.
Correspondences between the two images are then found by looking for pairs of keypoints, one in each of the two images, with closely matching descriptors.



For typical images, many of these correspondences will be wrong. To reduce these false correspondences, the plugin applies the RANSAC algorithm. This randomly selects a small subset of the matching pairs of keypoints, estimates the affine transformation between this subset of keypoints, and then evaluates how many of the other pairs of keypoints also closely agree with this affine transformation (""inliers""). A large number of random samples are tested, and the transformation with the most inliers retained.

The plugin outputs two points layers, one for each image, containing all the corresponding (inlier) SIFT keypoints. It also uses the estimated affine transformation between the two images to deform the ""moving"" image layer onto the ""fixed"" image layer.

This approach is an attempt to provide similar functionality to the Stephan Saalfeld's Fiji ""Extract SIFT Correspondences"" plugin [extract], and more-or-less
just provides a napari interface to the existing routines in scikit-image. There are great examples in the scikit-image documentation (e.g. [SIFT-example] and [RANSAC-example]) that can be used if you would like to use these routines in your own analysis scripts.


## Installation

You can install `napari-sift-registration` via [pip]:

    pip install napari-sift-registration

To install the latest development version :

    pip install git+https://github.com/jfozard/napari-sift-registration.git

## Usage

### Basic usage

- Load two 2D single channel images in Napari.
- Select the menu item Plugins > napari-sift-registration
- Select these two images as the ""Moving image layer"" and the ""Fixed image layer"". The moving image will be deformed by the transformation to look like the fixed image.
- The remaining parameters are the default settings from scikit-image; try these default values first.

### Advanced usage

The parameter values for SIFT feature detection, keypoint matching and RANSAC are accessible from the plugin gui. For further information about their use, see the appropriate scikit-image documentation:

Upsampling before feature detection, maximum number of octaves, maximum number of scales in every octave, blur level of seed image, feature descriptor size, feature descriptor orientation bins: see [scikit-image-SIFT].

Closest/next closest ratio: see [scikit-image-match_descriptors]

Minimum number of points sampled for each RANSAC model, distance for points to be inliers in RANSAC model, maximum number of trials in RANSAC model: see [scikit-image-RANSAC]

Only show inlier keypoints: If checked, only show corresponding keypoints that are inliers after RANSAC. If unchecked, show all corresponding keypoints.

### Limitations

Only 2D, single channel images (for now).

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-sift-registration"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[extract]: https://imagej.net/plugins/feature-extraction
[scikit-image]: https://scikit-image.org/
[SIFT-example]: https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_sift.html
[RANSAC-example]: https://scikit-image.org/docs/stable/auto_examples/transform/plot_matching.html
[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[scikit-image-SIFT]: https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.SIFT
[scikit-image-match_descriptors]: https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.match_descriptors
[scikit-image-RANSAC]: https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.ransac

[file an issue]: https://github.com/jfozard/napari-sift-registration/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/jfozard/napari-sift-registration/issues', 'Documentation, https://github.com/jfozard/napari-sift-registration#README.md', 'Source Code, https://github.com/jfozard/napari-sift-registration', 'User Support, https://github.com/jfozard/napari-sift-registration/issues']",,,napari-sift-registration.make_magic_widget,,,,
392,napari-signal-selector,napari-signal-selector,Napari Signal Selector,0.0.6,2023-10-17,2024-10-29,Marcelo Leomil Zoccoler,marzoccoler@gmail.com,BSD-3-Clause,https://github.com/zoccoler/napari-signal-selector/issues,https://pypi.org/project/napari-signal-selector/,,https://github.com/zoccoler/napari-signal-selector,"An interactive signal selector for napari, based on matplotlib.",>=3.8,"['numpy', 'magicgui', 'qtpy', 'cmap', 'nap-plot-tools>=0.1.2', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari>=0.4.19; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-signal-selector

[![License BSD-3](https://img.shields.io/pypi/l/napari-signal-selector.svg?color=green)](https://github.com/zoccoler/napari-signal-selector/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-signal-selector.svg?color=green)](https://pypi.org/project/napari-signal-selector)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-signal-selector.svg?color=green)](https://python.org)
[![tests](https://github.com/zoccoler/napari-signal-selector/workflows/tests/badge.svg)](https://github.com/zoccoler/napari-signal-selector/actions)
[![codecov](https://codecov.io/gh/zoccoler/napari-signal-selector/branch/main/graph/badge.svg)](https://codecov.io/gh/zoccoler/napari-signal-selector)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-signal-selector)](https://napari-hub.org/plugins/napari-signal-selector)
[![DOI](https://zenodo.org/badge/661588266.svg)](https://zenodo.org/doi/10.5281/zenodo.10041219)

An interactive signal selector and annotator for napari, based on [matplotlib](https://matplotlib.org/stable/).

[Jump to Intallation](#installation)

----------------------------------

## Usage

This plugin opens an embedded plotter in napari capable of plotting and interacting (selecting/annotating) with individual object signals (typically temporal features).

![plotting](https://github.com/zoccoler/napari-signal-selector/raw/main/images/plotting.gif)

### Input Data

napari-signal-selector works with a [Labels layer](https://napari.org/stable/howtos/layers/labels.html) containing segmented objects and whose `features` attribute contains a table that follows the example structure shown below:

| `label` | `frame` | `feature` | ...  |
|-------|-------|---------|---|
| 1     | 0     | 1.0     | ...  |
| 2     | 0     | 1.0     | ...  |
| 3     | 0     | 0.5     | ...  |
| 4     | 0     | 0.5     | ...  |
| 1     | 1     | 2.0     | ...  |
| 2     | 1     | 1.0     | ...  |
| 3     | 1     | 1.0     | ...  |
| 4     | 1     | 1.0     | ...  |
| 1     | 2     | 3.0     | ...  |
| 2     | 2     | 1.0     | ...  |
| 3     | 2     | 0.5     | ...  |
| 4     | 2     | 1.5     | ...  |
| â®     | â®     | â®     |   |

Basically, it needs an object identifier (in this case, the `label` column) that matches the labels in the Labels layer, and other columns containing x- and y-axis numbers to plot. Typically, x-axis is some temporal-related property.

Here is how one could add such a layer to a napari viewer via code (check [this example notebook](./examples/synthetic_example.ipynb) for more details):

```python
viewer.add_labels(labels_image, features = table)
```

If a layer like this is selected, you can choose what to plot by means of dropdown fields in the bottom of the plotter.

Below is a basic example using the ""Flashing Polygons"" synthetic data:

![intro](https://github.com/zoccoler/napari-signal-selector/raw/main/images/intro.gif)

## Tools

### Selection Tool

The selection tool (arrowhead icon) is a toggle button which enables you to select individual signals. Once activated, the icon gets highlighted and you can click over individual signals to select them. Right-clicking unselects everything.

![select](https://github.com/zoccoler/napari-signal-selector/raw/main/images/select.gif)

If the region you want to click is too crowded, consider zooming in first and then selecting.

![zoom-select](https://github.com/zoccoler/napari-signal-selector/raw/main/images/zoom_select.gif)

And if you know which label you want to select, you can enable `'show selected'` from the Labels layer options to solely display one label at a time. The Lables layer picker tool may help you get the right label.

![show-selected](https://github.com/zoccoler/napari-signal-selector/raw/main/images/show_selected.gif)

### Annotation Tool

Once one or multiple signals are selected, you can annotate them with the annotation tool (brush with a 'plus' icon). You need to choose a signal class first.
*Remember to right-click to remove previous selections when annotating different signal classes!*

![annotation](https://github.com/zoccoler/napari-signal-selector/raw/main/images/annotation.gif)

Annotations are saved back in the table in a new column called 'Annotations'.
*Currently multiple annotations is not possible, i.e., more than one class assigned to the same part of the signal.*

### Span-Selection Tool

You can use the span-selection tool (bounded horizontal arrows icon) to sub-select one or multiple parts of signals. Right-click to unselect regions. Hold 'SHIFT' while dragging the mouse to select multiple sub-regions.

![span-select](https://github.com/zoccoler/napari-signal-selector/raw/main/images/span_select.gif)

You can use this in conjunction with the annotation tool to have sub-regions from the same signal with different annotations.

![](https://github.com/zoccoler/napari-signal-selector/raw/main/images/span_annotation.gif)

### Deletion Tool

If you made a mistake, you can remove previous annotations by selecting signal(s) and clicking on the trash icon at the right of the toolbar (or just annotate them with class 0).

![delete](https://github.com/zoccoler/napari-signal-selector/raw/main/images/delete.gif)

Also, with the selection tool enbaled, by holding 'SHIFT' and left-clicking, you can select all signals. This may be useful to delete all previous annotations.

![select-delete-all](https://github.com/zoccoler/napari-signal-selector/raw/main/images/select_delete_all.gif)

### Exporting Annotations

The table with annotations can be displayed in napari using the 'Show table' widget from [napari-skimage-regionprops plugin](https://github.com/haesleinhuepf/napari-skimage-regionprops#napari-skimage-regionprops-nsr), which is available under `Tools > Measurements > Show Table (nsr)`. This plugin may require a specific napari version, so check its documentation for more details.

![](https://github.com/zoccoler/napari-signal-selector/raw/main/images/table_view.gif)

By the way, with `'show selected'` checked, you can click on a label row in the table and see the corresponding label in the image **...and** in the plotter!

To export the table, click on `'Save as csv...'`.

Another option is to run the following code in the napari console (replace `'Labels'` with the name of your Labels layer and `'annotations.csv'` with the desired file name or file path):

```python
import pandas as pd
df = viewer.layers['Labels'].data.features
df.to_csv('annotations.csv')
```

## Installation

You can install `napari-signal-selector` via [pip]. Follow these steps from a terminal.

We recommend using `mamba-forge` whenever possible. Click [here](https://github.com/conda-forge/miniforge#mambaforge) to choose the right download option for your OS.
**If you do not use `mamba-forge`, replace the `mamba` term whenever you see it below with `conda`.**

Create a conda environment :

    mamba create -n napari-ss-env napari pyqt python=3.9
    
Activate the environment :

    mamba activate napari-ss-env

Install `napari-signal-selector` via [pip] :

    pip install napari-signal-selector

Alternatively, install latest development version with :

    pip install git+https://github.com/zoccoler/napari-signal-selector.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-signal-selector"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/zoccoler/napari-signal-selector/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/zoccoler/napari-signal-selector/issues', 'Documentation, https://github.com/zoccoler/napari-signal-selector#README.md', 'Source Code, https://github.com/zoccoler/napari-signal-selector', 'User Support, https://github.com/zoccoler/napari-signal-selector/issues']",,,napari-signal-selector.make_inter_features_line_widget,napari-signal-selector.load_flashing_polygons_data,,,
393,napari-simpleannotate,napari-simpleannotate,SimpleAnnotate,0.1.2,2023-10-29,2025-07-23,Hiroki Kawai,Hiroki Kawai <h.kawai888@gmail.com>,BSD-3-Clause,https://github.com/hiroalchem/napari-simpleannotate/issues,https://pypi.org/project/napari-simpleannotate/,,,A napari plugin for simple image and video annotation,>=3.8,"['numpy', 'magicgui', 'pyyaml', 'qtpy', 'scikit-image', 'pandas', 'napari_video', 'zarr', 'numcodecs', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-simpleannotate

[![License BSD-3](https://img.shields.io/pypi/l/napari-simpleannotate.svg?color=green)](https://github.com/hiroalchem/napari-simpleannotate/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-simpleannotate.svg?color=green)](https://pypi.org/project/napari-simpleannotate)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-simpleannotate.svg?color=green)](https://python.org)
[![tests](https://github.com/hiroalchem/napari-simpleannotate/workflows/tests/badge.svg)](https://github.com/hiroalchem/napari-simpleannotate/actions)
[![codecov](https://codecov.io/gh/hiroalchem/napari-simpleannotate/branch/main/graph/badge.svg)](https://codecov.io/gh/hiroalchem/napari-simpleannotate)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-simpleannotate)](https://napari-hub.org/plugins/napari-simpleannotate)

A napari plugin for simple image and video annotation that provides three main annotation workflows:

1. **Bounding Box Annotation (YOLO format)**: For object detection training data on images
2. **Video Bounding Box Annotation**: For object detection training data on video files
3. **Image Classification Labeling**: For image classification training data

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

![overview](https://github.com/hiroalchem/napari-simpleannotate/raw/main/images/dog_and_cat.jpg)


## Installation

You can install `napari-simpleannotate` via [pip]:

    pip install napari-simpleannotate



To install latest development version :

    pip install git+https://github.com/hiroalchem/napari-simpleannotate.git


## How to use

### Getting Started

After installing napari-simpleannotate, launch napari and navigate to `Plugins > Add dock widget` to find three annotation widgets:

- **Bbox annotation**: For bounding box annotation on images
- **Bbox video annotation**: For bounding box annotation on video files  
- **Label image classification**: For image classification labeling

### Bounding Box Annotation (Images)

**Prerequisites**: None required

1. **Opening Files**:
   - Single file: Click `Open File` to select an image file
   - Directory: Click `Open Directory` to select a folder containing images
   - If a `class.yaml` file exists in the directory, you'll be prompted to load existing classes

2. **Class Management**:
   - Enter class names in the text box and click `Add class`
   - Classes are automatically assigned sequential IDs (0, 1, 2, ...)
   - Select a class and click `Delete selected class` to remove it
   - Classes are saved to `class.yaml` alongside annotations

3. **Creating Annotations**:
   - Select a class from the list (becomes your active class)
   - Use napari's rectangle tool (shortcut: R) to draw bounding boxes
   - New rectangles automatically inherit the selected class
   - Change existing rectangles: select the shape, then click a different class

4. **Saving Work**:
   - Click `Save Annotations` to export in YOLO format
   - Files saved: `image_name.txt` (YOLO coordinates) + `class.yaml` (class definitions)
   - YOLO format: `class_id x_center y_center width height` (normalized 0-1)

### Video Bounding Box Annotation

**Prerequisites**: Install PyAV for video support: `pip install av`

1. **Opening Videos**:
   - Click `Open Video` to select video files
   - Supported formats: MP4, AVI, MOV, MKV, WMV, FLV, WebM
   - Video loads with frame-by-frame navigation

2. **Navigation**:
   - Use napari's time slider to navigate frames
   - Frame counter shows current position: ""Frame: X/Y""
   - **Keyboard shortcuts**: Q (previous annotation), W (next annotation)
   - Click navigation buttons to jump to nearest annotations
   - Video performance optimized with LRU cache and parallel prefetching

3. **Frame-Aware Annotation**:
   - Navigate to target frame before annotating
   - Create bounding boxes with napari's rectangle tool
   - Each annotation automatically records the current frame number
   - Annotations only visible on their respective frames

4. **Class and Export**:
   - Class management identical to image annotation
   - Extended YOLO format: `class_id frame x_center y_center width height`
   - Saves to `video_name.txt` + `class.yaml` in video directory

### Image Classification Labeling

**Prerequisites**: None required

1. **Opening Directory**:
   - Click `Open Directory` to select image folder
   - Recursively finds all images (PNG, TIF, JPG, JPEG, TIFF)
   - Automatically loads existing `labels.csv` and `class.txt` if present

2. **Display Options**:
   - **Split Channels**: Check to display multi-channel images as separate layers
   - Contrast settings preserved when switching between images
   - Navigate images using the file list on the left

3. **Labeling Workflow**:
   - Add classes: Type in text box and press Enter (or click `Add class`)
   - Remove classes: Type existing class name and press Enter
   - Assign labels: Select image â Click class name to label it
   - Real-time auto-save to `labels.csv` and `class.txt`

4. **Resume Sessions**:
   - Previous work automatically loaded when reopening directories
   - Continue labeling from where you left off

## Performance Notes

- **Video annotation**: Optimized with frame caching and parallel prefetching for smooth playback
- **Large datasets**: Classification widget handles thousands of images efficiently  
- **Memory management**: LRU cache prevents memory overflow during long annotation sessions

## Output Formats

| Widget | Annotation File | Class File | Format |
|--------|----------------|------------|---------|
| Bbox (Images) | `image.txt` | `class.yaml` | YOLO standard |
| Bbox (Video) | `video.txt` | `class.yaml` | Extended YOLO with frame |
| Classification | `labels.csv` | `class.txt` | CSV with image-label pairs |


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-simpleannotate"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hiroalchem/napari-simpleannotate/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['homepage, https://github.com/hiroalchem/napari-simpleannotate', 'repository, https://github.com/hiroalchem/napari-simpleannotate', 'documentation, https://github.com/hiroalchem/napari-simpleannotate#README.md', 'Bug Tracker, https://github.com/hiroalchem/napari-simpleannotate/issues', 'User Support, https://github.com/hiroalchem/napari-simpleannotate/issues']",,,napari-simpleannotate.make_bboxwidget,,,,
394,napari-sketchpose,napari-sketchpose,Sketchpose,0.1.8,2023-11-07,2023-12-08,ClÃ©ment Cazorla,clement.cazorla31@gmail.com,GPL-3.0-only,,https://pypi.org/project/napari-sketchpose/,,,A segmentation plugin to adapt Omnipose implementation to partial labelling.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'cellpose-omni ==0.9.1', 'omnipose ==0.4.4', 'pyqtgraph ==0.13.3', 'matplotlib', 'light-the-torch', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-sketchpose

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-sketchpose.svg?color=green)](https://github.com/koopa31/napari-sketchpose/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-sketchpose.svg?color=green)](https://pypi.org/project/napari-sketchpose)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-sketchpose.svg?color=green)](https://python.org)
[![tests](https://github.com/koopa31/napari-sketchpose/workflows/tests/badge.svg)](https://github.com/koopa31/napari-sketchpose/actions)
[![codecov](https://codecov.io/gh/koopa31/napari-sketchpose/branch/main/graph/badge.svg)](https://codecov.io/gh/koopa31/napari-sketchpose)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-sketchpose)](https://napari-hub.org/plugins/napari-sketchpose)

A plugin to adapt the Omnipose implementation to frugal labeling. It aims to facilitate the training from scratch or the 
use of transfer learning with little data, by not needing to draw entire cells, but a few squiggles instead (see GIF below).


If you use this plugin please cite the [paper](https://hal.science/hal-04330824): 

ClÃ©ment Cazorla, NathanaÃ«l Munier, Renaud Morin, Pierre Weiss. Sketchpose: Learning to Segment
Cells with Partial Annotations. 2023. ffhal-04330824f

```bibtex
@unpublished{cazorla:hal-04330824,
      TITLE = {{Sketchpose: Learning to Segment Cells with Partial Annotations}},
      AUTHOR = {Cazorla, Cl{\'e}ment and Munier, Nathana{\""e}l and Morin, Renaud and Weiss, Pierre},
      URL = {https://hal.science/hal-04330824},
      NOTE = {working paper or preprint},
      YEAR = {2023},
      MONTH = Dec,
      KEYWORDS = {Cellpose -Segmentation -Frugal learning -Napari -Deep learning -Distance map},
      PDF = {https://hal.science/hal-04330824/file/sketchpose_hal.pdf},
      HAL_ID = {hal-04330824},
      HAL_VERSION = {v1},
    }

```


![](https://bitbucket.org/koopa31/napari-sketchpose/raw/b691817e9e20a3c1c2bc69277579f6fb9b26354e/images/frugalpose.gif)
Image Credit: Eduard Muzhevskyi
----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation



First, we advise you to create a conda environment in Python 3.10, in which you will run Napari:

    conda create -n sketchpose_env python=3.10
    conda activate sketchpose_env
    conda install pip
    python -m pip install ""napari[all]"" --upgrade

You can install `napari_sketchpose` via [pip]:

    pip install napari_sketchpose

WARNING:

For Windows users, CUDA version of PyTorch may not be installed properly. When the plugin starts for the first time, it checks whether
CUDA version is installed. If not, it tries to install it using light-the-torch library. If this does not work, you should re-install 
CUDA torch and torchvision versions manually, otherwise the plugin will not work properly.

## Tutorial

We strongly recommend reading the [documentation] to get the most out of the plugin.
A step-by-step tutorial illustrated with GIFs will guide you through the various stages.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-sketchpose"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[documentation]: https://sketchpose-doc.readthedocs.io/en/latest/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://bitbucket.org/koopa31/napari-sketchpose/issues?status=new&status=open&status=submitted&is_spam=!spam', 'Documentation, https://sketchpose-doc.readthedocs.io/en/latest/', 'Source Code, https://bitbucket.org/koopa31/napari-sketchpose/src/master', 'User Support, https://bitbucket.org/koopa31/napari-sketchpose/issues?status=new&status=open&status=submitted&is_spam=!spam']",napari-sketchpose.get_reader,napari-sketchpose.write_multiple,napari-sketchpose.make_qwidget,napari-sketchpose.make_sample_data,['*.npy'],,['.npy']
395,napari-simpleitk-image-processing,napari-simpleitk-image-processing,napari-simpleitk-image-processing,0.4.9,2021-11-28,2024-10-10,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-simpleitk-image-processing/issues,https://pypi.org/project/napari-simpleitk-image-processing/,,https://github.com/haesleinhuepf/napari-simpleitk-image-processing,Process and analyze images using SimpleITK in napari,>=3.8,"['napari-plugin-engine>=0.1.4', 'numpy', 'simpleitk', 'napari-tools-menu>=0.1.17', 'napari-time-slicer', 'napari-skimage-regionprops>=0.5.1', 'napari-assistant>=0.3.10', 'pandas', 'stackview>=0.3.2']","# napari-simpleitk-image-processing (n-SimpleITK)

[![License](https://img.shields.io/pypi/l/napari-simpleitk-image-processing.svg?color=green)](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-simpleitk-image-processing.svg?color=green)](https://pypi.org/project/napari-simpleitk-image-processing)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-simpleitk-image-processing.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-simpleitk-image-processing/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-simpleitk-image-processing)
[![Development Status](https://img.shields.io/pypi/status/napari-simpleitk-image-processing.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-simpleitk-image-processing)](https://napari-hub.org/plugins/napari-simpleitk-image-processing)
[![DOI](https://zenodo.org/badge/432729955.svg)](https://zenodo.org/badge/latestdoi/432729955)

Process images using [SimpleITK](https://simpleitk.org/) in [napari]

## Usage

Filters, segmentation algorithms and measurements provided by this napari plugin can be found in the `Tools` menu. 
You can recognize them with their suffix `(n-SimpleITK)` in brackets.
Furthermore, it can be used from the [napari-assistant](https://www.napari-hub.org/plugins/napari-assistant) graphical user interface. 
Therefore, just click the menu `Tools > Utilities > Assistant (na)` or run `naparia` from the command line.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/screenshot_with_assistant.png)

All filters implemented in this napari plugin are also demonstrated in [this notebook](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/blob/main/docs/demo.ipynb).

### Gaussian blur

Applies a [Gaussian blur](https://en.wikipedia.org/wiki/Gaussian_blur)
to an image. This might be useful for denoising, e.g. before applying the Threshold-Otsu method.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/gaussian_blur.png)

### Median filter

Applies a [median filter](https://en.wikipedia.org/wiki/Median_filter) to an image. 
Compared to the Gaussian blur this method preserves edges in the image better. 
It also performs slower.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/median_filter.png)

### Bilateral filter

The [bilateral filter](https://en.wikipedia.org/wiki/Bilateral_filter) allows denoising an image
while preserving edges.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/bilateral.png)

### Threshold Otsu

Binarizes an image using [Otsu's method](https://ieeexplore.ieee.org/document/4310076).

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/threshold_otsu.png)

### Connected Component Labeling

Takes a binary image and labels all objects with individual numbers to produce a label image.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/connected_component_labeling.png)

### Measurements

This function allows determining intensity and shape statistics from labeled images. I can be found in the `Tools > Measurement tables` menu.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/measurements.png)

### Signed Maurer distance map

A distance map (more precise: [Signed Maurer Distance Map](https://itk.org/ITKExamples/src/Filtering/DistanceMap/MaurerDistanceMapOfBinary/Documentation.html)) can be useful for visualizing distances within binary images between black/white borders. 
Positive values in this image correspond to a white (value=1) pixel's distance to the next black pixel.
Black pixel's (value=0) distance to the next white pixel are represented in this map with negative values.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/signed_maured_distance_map.png)

### Binary fill holes

Fills holes in a binary image.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/binary_fill_holes.png)

### Touching objects labeling

Starting from a binary image, touching objects can be splits into multiple regions, similar to the [Watershed segmentation in ImageJ](https://imagej.net/plugins/classic-watershed).

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/Touching_object_labeling.png)

### Morphological Watershed

The [morhological watershed](http://insightsoftwareconsortium.github.io/SimpleITK-Notebooks/Python_html/32_Watersheds_Segmentation.html)
allows to segment images showing membranes. Before segmentation, a filter such as the Gaussian blur or a median filter
should be used to eliminate noise. It also makes sense to increase the thickness of membranes using a maximum filter. 
See [this notebook](https://github.com/clEsperanto/pyclesperanto_prototype/blob/master/demo/segmentation/segmentation_2d_membranes.ipynb) for details.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/morphological_watershed.png)

### Watershed-Otsu-Labeling

This algorithm uses [Otsu's thresholding method](https://ieeexplore.ieee.org/document/4310076) in combination with 
[Gaussian blur](https://en.wikipedia.org/wiki/Gaussian_blur) and the 
[Watershed-algorithm](https://en.wikipedia.org/wiki/Watershed_(image_processing)) 
approach to label bright objects such as nuclei in an intensity image. The alogrithm has two sigma parameters and a 
level parameter which allow you to fine-tune where objects should be cut (`spot_sigma`) and how smooth outlines 
should be (`outline_sigma`). The `watershed_level` parameter determines how deep an intensity valley between two maxima 
has to be to differentiate the two maxima. 
This implementation is similar to [Voronoi-Otsu-Labeling in clesperanto](https://github.com/clEsperanto/pyclesperanto_prototype/blob/master/demo/segmentation/voronoi_otsu_labeling.ipynb).


![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/watershed_otsu_labeling.png)

### Richardson-Lucy Deconvolution

[Richardson-Lucy deconvolution](https://en.wikipedia.org/wiki/Richardson%E2%80%93Lucy_deconvolution)
allows to restore image quality if the point-spread-function of the optical system used 
for acquisition is known or can be approximated.

![img.png](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/docs/Richardson-Lucy-Deconvolution.png)


## Installation

You can install `napari-simpleitk-image-processing` via using `conda` and `pip`.
If you have never used `conda` before, please go through [this tutorial](https://biapol.github.io/blog/johannes_mueller/anaconda_getting_started/) first.

    conda install -c conda-forge napari
    pip install napari-simpleitk-image-processing

## Features

The user can select categories of features for feature extraction in the user interface. These categories contain the following measurements:
* size:
    * equivalent_ellipsoid_diameter
    * equivalent_spherical_perimeter
    * equivalent_spherical_radius
    * number_of_pixels
    * number_of_pixels_on_border
* intensity:
   * maximum 
   * mean 
   * median
   * minimum 
   * sigma
   * sum
   * variance
* perimeter:
   * perimeter
   * perimeter_on_border
   * perimeter_on_border_ratio
* shape:
   * elongation
   * feret_diameter
   * flatness
   * roundness
* position:
   * centroid 
   * bbox
* moments:
   * principal_axes
   * principal_moments

## See also

There are other napari plugins with similar functionality for processing images and extracting features:
* [morphometrics](https://www.napari-hub.org/plugins/morphometrics)
* [PartSeg](https://www.napari-hub.org/plugins/PartSeg)
* [napari-skimage-regionprops](https://www.napari-hub.org/plugins/napari-skimage-regionprops)
* [napari-cupy-image-processing](https://www.napari-hub.org/plugins/napari-cupy-image-processing)
* [napari-pyclesperanto-assistant](https://www.napari-hub.org/plugins/napari-pyclesperanto-assistant)
* [napari-allencell-segmenter](https://napari-hub.org/plugins/napari-allencell-segmenter)
* [RedLionfish](https://www.napari-hub.org/plugins/RedLionfish)
* [bbii-decon](https://www.napari-hub.org/plugins/bbii-decon)  
* [napari-segment-blobs-and-things-with-membranes](https://www.napari-hub.org/plugins/napari-segment-blobs-and-things-with-membranes)

Furthermore, there are plugins for postprocessing extracted measurements
* [napari-feature-classifier](https://www.napari-hub.org/plugins/napari-feature-classifier)
* [napari-clusters-plotter](https://www.napari-hub.org/plugins/napari-clusters-plotter)

## Contributing

Contributions are very welcome. There are many useful algorithms available in 
[SimpleITK](https://simpleitk.org/). If you want another one available here in this napari
plugin, don't hesitate to send a [pull-request](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/pulls).
This repository just holds wrappers for SimpleITK-functions, see [this file](https://github.com/haesleinhuepf/napari-simpleitk-image-processing/raw/main/src/napari_simpleitk_image_processing/_simpleitk_image_processing.py#L51) for how those wrappers
can be written.

## License

Distributed under the terms of the [BSD-3] license,
""napari-simpleitk-image-processing"" is free and open source software

## Citation

For implementing this napari plugin, the 
[SimpleITK python notebooks](https://insightsoftwareconsortium.github.io/SimpleITK-Notebooks/) were very helpful. 
Thus, if you find the plugin useful, consider citing the SimpleITK notebooks:

Z. Yaniv, B. C. Lowekamp, H. J. Johnson, R. Beare, 
""SimpleITK Image-Analysis Notebooks: a Collaborative Environment for Education and Reproducible Research"", \
J Digit Imaging., 31(3): 290-303, 2018, [https://doi.org/10.1007/s10278-017-0037-8](https://doi.org/10.1007/s10278-017-0037-8).

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-simpleitk-image-processing/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-simpleitk-image-processing/issues', 'Documentation, https://github.com/haesleinhuepf/napari-simpleitk-image-processing#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-simpleitk-image-processing', 'User Support, https://github.com/haesleinhuepf/napari-simpleitk-image-processing/issues']",,,napari-simpleitk-image-processing.napari_experimental_provide_function,,,,
396,napari-smlmlab,napari-SMLMLAB,BP04 Practical,0.1.4,2024-04-25,2024-11-13,Piers Turner,Piers Turner <piers.turner@physics.ox.ac.uk>,"Copyright (c) 2024, Piers Turn...",https://github.com/piedrro/napari-bacseg/issues,https://pypi.org/project/napari-SMLMLAB/,,https://github.com/piedrro/napari-SMLMLAB,Napari widget for BP04 Practical.,>=3.9,"['napari[all]==0.5.0', 'numpy', 'magicgui', 'qtpy', 'scipy', 'pyqtgraph', 'picassosr==0.7.3', 'matplotlib', 'tqdm', 'pyqt5-tools', 'trackpy', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-SMLMLAB

[![License BSD-3](https://img.shields.io/pypi/l/napari-SMLMLAB.svg?color=green)](https://github.com/piedrro/napari-SMLMLAB/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-SMLMLAB.svg?color=green)](https://pypi.org/project/napari-SMLMLAB)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-SMLMLAB.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-SMLMLAB)](https://napari-hub.org/plugins/napari-SMLMLAB)

Napari widget for BP04 Practical

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-SMLMLAB` via [pip]:

    pip install napari-SMLMLAB

To upgrade to the latest version of `napari-SMLMLAB` from [pip]:

    pip install napari-SMLMLAB --upgrade

To install latest development version :

    conda create â-name napari-SMLMLAB python==3.9
    conda activate napari-SMLMLAB
    conda install -c anaconda git
    conda update --all

    pip install napari[all]

    pip install git+https://github.com/piedrro/napari-SMLMLAB.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-SMLMLAB"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/piedrro/napari-SMLMLAB/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Framework :: napari', 'Environment :: Plugins', 'License :: OSI Approved :: BSD License', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent']","['Homepage, https://github.com/piedrro/napari-bacseg', 'Bug Tracker, https://github.com/piedrro/napari-bacseg/issues']",,,napari-SMLMLAB.make_qwidget,,,,
397,napari-skimage,napari-skimage,napari skimage,0.5.0,2024-05-29,2025-04-29,Guillaume Witz,guillaume.witz@unibe.ch,"Copyright (c) 2024, Guillaume ...",https://github.com/guiwitz/napari-skimage/issues,https://pypi.org/project/napari-skimage/,,,A plugin to apply scikit-image operations,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-skimage

[![License BSD-3](https://img.shields.io/pypi/l/napari-skimage.svg?color=green)](https://github.com/guiwitz/napari-skimage/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-skimage.svg?color=green)](https://pypi.org/project/napari-skimage)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-skimage.svg?color=green)](https://python.org)
[![tests](https://github.com/guiwitz/napari-skimage/workflows/tests/badge.svg)](https://github.com/guiwitz/napari-skimage/actions)
[![codecov](https://codecov.io/gh/guiwitz/napari-skimage/branch/main/graph/badge.svg)](https://codecov.io/gh/guiwitz/napari-skimage)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-skimage)](https://napari-hub.org/plugins/napari-skimage)
[![launch - renku](https://renkulab.io/renku-badge.svg)](https://renkulab.io/projects/guillaume.witz1/napari-skimage/sessions/new?autostart=1)

napari-skimage gives easy access to scikit-image functions in napari. The main goal of the plugin is to allow new users of napari, especially without coding experience, to easily explore basic image processing, in a similar way to what is possible in Fiji.

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Philosophy

The plugin is still in early development and does not cover all functions of scikit-image. If you are interested in a specific function, please open an issue or a pull request. scikit-image functions are turned into interactive widgets mostly via magicgui, a tool that allows to create GUIs from functions in a simple way (in particular not requiring Qt knowledge). The code avoids on purpose complex approaches, e.g. to automate the creation of widgets, in order to keep the code simple and easy to understand for beginners.

## Installation

You can install `napari-skimage` via [pip]:

    pip install napari-skimage



To install latest development version :

    pip install git+https://github.com/guiwitz/napari-skimage.git

## Usage

The plugin function can be accessed under ```Plugins -> napari-skimage```. Each function will appear as a widget on the right of the napari window. Some functions such as ```Gaussian Filter``` give access to a single operation and its options. Some functions such as ```Thresholding``` give access to variants of the same operation via a dropdown menu. Currently the plugin does not support multi-channel processing and will consider those as stacks. At the moment, the plugin offers access to the following operation types.

### Filtering

A set of classical filters: Gaussian, Prewitt, Laplace etc. as well as rank filters such as median, minimum, maximum etc.

![Gaussian filter](docs/gaussian.png)

### Thresholding
A set of thresholding methods: Otsu, Li, Yen etc.
![Thresholding](docs/thresholding.png)

### Binary morphological operations
A set of binary morphology operations: binary erosion, binary dilation etc.
![Binary morphological operations](docs/binary_morphology.png)

### Morphological operations
A set of morphological operations: erosion, dilation, opening, closing etc.
![Morphological operations](docs/morphology.png)

### Restoration
A set of restoration operations such as rolling ball, or non-local means denoising.
![Restoration](docs/denoise_nl.png)

### Mathematics 
In addition the plugin provides a set of simple mathematical operators to:
- operate on single images e.g. square, square root, log etc.
- operate on two images e.g. add, subtract, multiply etc.
![Mathematics](docs/simple_maths.png)

## Code structure

Each set of functions is grouped in a separate module. For example all filtering operations are grouped in ```src/napari_skimge/skimage_filter_widget.py```. A set of test in ```src/_tests/test_basic_widgets.py``` simply check that each widget can be created and generated an output of the correct size using the default settings.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-skimage"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/guiwitz/napari-skimage/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/guiwitz/napari-skimage/issues', 'Documentation, https://github.com/guiwitz/napari-skimage#README.md', 'Source Code, https://github.com/guiwitz/napari-skimage', 'User Support, https://github.com/guiwitz/napari-skimage/issues']",,,napari-skimage.make_farid_widget,,,,
398,napari-skimage-regionprops,napari-skimage-regionprops,napari-skimage-regionprops,0.10.1,2021-06-07,2023-05-19,"Marcelo Zoccoler, Robert Haase",robert.haase@tu-dresden.de,BSD-3,https://github.com/haesleinhuepf/napari-skimage-regionprops,https://pypi.org/project/napari-skimage-regionprops/,,https://github.com/haesleinhuepf/napari-skimage-regionprops,A regionprops table widget plugin for napari,>=3.8,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'scikit-image', 'napari', 'pandas', 'napari-tools-menu (>=0.1.19)', 'napari-workflows', 'imageio (!=2.22.1)', 'Deprecated']","# napari-skimage-regionprops (nsr)



[![License](https://img.shields.io/pypi/l/napari-skimage-regionprops.svg?color=green)](https://github.com/haesleinhuepf/napari-skimage-regionprops/raw/master/LICENSE)

[![PyPI](https://img.shields.io/pypi/v/napari-skimage-regionprops.svg?color=green)](https://pypi.org/project/napari-skimage-regionprops)

[![Python Version](https://img.shields.io/pypi/pyversions/napari-skimage-regionprops.svg?color=green)](https://python.org)

[![tests](https://github.com/haesleinhuepf/napari-skimage-regionprops/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-skimage-regionprops/actions)

[![codecov](https://codecov.io/gh/haesleinhuepf/napari-skimage-regionprops/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-skimage-regionprops)

[![Development Status](https://img.shields.io/pypi/status/napari-skimage-regionprops.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)

[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-skimage-regionprops)](https://napari-hub.org/plugins/napari-skimage-regionprops)



 

A [napari] plugin for measuring properties of labeled objects based on [scikit-image]



![](https://github.com/haesleinhuepf/napari-skimage-regionprops/raw/master/images/interactive.gif)



## Usage: measure region properties



From the menu `Tools > Measurement > Regionprops (nsr)` you can open a dialog where you can choose an intensity image, a corresponding label image and the features you want to measure:



![img.png](https://github.com/haesleinhuepf/napari-skimage-regionprops/raw/master/images/dialog.png)



If you want to interface with the labels and see which table row corresponds to which labeled object, use the label picker and

activate the `show selected` checkbox.



![](https://github.com/haesleinhuepf/napari-skimage-regionprops/raw/master/images/interactive.png)



If you closed a table and want to reopen it, you can use the menu `Tools > Measurements > Show table (nsr)` to reopen it. 

You just need to select the labels layer the properties are associated with.



For visualizing measurements with different grey values, as parametric images, you can double-click table headers.



![img.png](https://github.com/haesleinhuepf/napari-skimage-regionprops/raw/master/images/label_value_visualization.gif)



## Usage: measure point intensities



Analogously, also the intensity and coordinates of point layers can be measured using the menu `Tools > Measurement > Measure intensity at point coordinates (nsr)`. 

Also these measurements can be visualized by double-clicking table headers:



![img.png](measure_point_intensity.png)



![img_1.png](measure_point_coordinate.png)



## Working with time-lapse and tracking data



Note that tables for time-lapse data should include a column named ""frame"", which indicates which slice in

time the given row refers to. If you want to import your own csv files for time-lapse data make sure to include this column.

If you have tracking data where each column specifies measurements for a track instead of a label at a specific time point,

this column must not be added.



In case you have 2D time-lapse data you need to convert it into a suitable shape using the function: `Tools > Utilities > Convert 3D stack to 2D time-lapse (time-slicer)`,

which can be found in the [napari time slicer](https://www.napari-hub.org/plugins/napari-time-slicer).



Last but not least, make sure that in case of time-lapse data the label image has labels that are subsquently labeled per timepoint.

E.g. a dataset where label 5 is missing at timepoint 4 may be visualized incorrectly.



## Usage: multichannel or multi-label data



If you want to relate objects from one channels to objects from another channel, you can use `Tools > Measurement tables > Object Features/Properties (scikit-image, nsr)`. 

This plugin module allos you to answer questions like:

  - how many objects I have inside other objects?

  - what is the average intensity of the objects inside other objects?

For that, you need at least two labeled images in napari. You can relate objects along with their features. 

If intensity features are also wanted, then you also need to provide two intensity images. 

Below, there is a small example on how to use it. 

Also, take a look at [this example notebook](https://github.com/haesleinhuepf/napari-skimage-regionprops/blob/master/demo/measure_relationship_to_other_channels_plugin.ipynb).

 

 ![](https://github.com/haesleinhuepf/napari-skimage-regionprops/raw/master/images/things_inside_things_demo.gif)



## Usage, programmatically



You can also control the tables programmatically. See this 

[example notebook](https://github.com/haesleinhuepf/napari-skimage-regionprops/blob/master/demo/tables.ipynb) for details on regionprops and

[this example notebook](https://github.com/haesleinhuepf/napari-skimage-regionprops/blob/master/demo/measure_points.ipynb) for details on measuring intensity at point coordinates. For creating parametric map images, see [this notebook](https://github.com/haesleinhuepf/napari-skimage-regionprops/blob/master/demo/map_measurements.ipynb).





## Features

The user can select categories of features for feature extraction in the user interface. These categories contain measurements from the scikit-image [regionprops list of measurements](https://scikit-image.org/docs/dev/api/skimage.measure.html#skimage.measure.regionprops) library:

* size:

  * area

  * bbox_area

  * convex_area

  * equivalent_diameter

* intensity:

  * max_intensity 

  * mean_intensity

  * min_intensity

  * standard_deviation_intensity (`extra_properties` implementation using numpy)

* perimeter:

  * perimeter

  * perimeter_crofton

* shape

  * major_axis_length

  * minor_axis_length

  * orientation

  * solidity

  * eccentricity

  * extent

  * feret_diameter_max

  * local_centroid

  * roundness as defined for 2D labels [by ImageJ](https://imagej.nih.gov/ij/docs/menus/analyze.html#set)

  * circularity as defined for 2D labels  [by ImageJ](https://imagej.nih.gov/ij/docs/menus/analyze.html#set)

  * aspect_ratio as defined for 2D labels [by ImageJ](https://imagej.nih.gov/ij/docs/menus/analyze.html#set)

* position:

  * centroid

  * bbox

  * weighted_centroid

* moments:

  * moments

  * moments_central

  * moments_hu

  * moments_normalized



 



This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.



## See also



There are other napari plugins with similar functionality for extracting features:

* [morphometrics](https://www.napari-hub.org/plugins/morphometrics)

* [PartSeg](https://www.napari-hub.org/plugins/PartSeg)

* [napari-simpleitk-image-processing](https://www.napari-hub.org/plugins/napari-simpleitk-image-processing)

* [napari-cupy-image-processing](https://www.napari-hub.org/plugins/napari-cupy-image-processing)

* [napari-pyclesperanto-assistant](https://www.napari-hub.org/plugins/napari-pyclesperanto-assistant)



Furthermore, there are plugins for postprocessing extracted measurements

* [napari-feature-classifier](https://www.napari-hub.org/plugins/napari-feature-classifier)

* [napari-clusters-plotter](https://www.napari-hub.org/plugins/napari-clusters-plotter)

* [napari-accelerated-pixel-and-object-classification](https://www.napari-hub.org/plugins/napari-accelerated-pixel-and-object-classification)



## Installation



You can install `napari-skimage-regionprops` via [pip]:



    pip install napari-skimage-regionprops



Or if you plan to develop it:



    git clone https://github.com/haesleinhuepf/napari-skimage-regionprops

    cd napari-skimage-regionprops

    pip install -e .



If there is an error message suggesting that git is not installed, run `conda install git`.



## Contributing



Contributions are very welcome. Tests can be run with [tox], please ensure

the coverage at least stays the same before you submit a pull request.



## License



Distributed under the terms of the [BSD-3] license,

""napari-skimage-regionprops"" is free and open source software



## Issues



If you encounter any problems, please create a thread on [image.sc] along with a detailed description and tag [@haesleinhuepf].



[napari]: https://github.com/napari/napari

[Cookiecutter]: https://github.com/audreyr/cookiecutter

[@napari]: https://github.com/napari

[BSD-3]: http://opensource.org/licenses/BSD-3-Clause

[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[image.sc]: https://image.sc

[napari]: https://github.com/napari/napari

[tox]: https://tox.readthedocs.io/en/latest/

[pip]: https://pypi.org/project/pip/

[PyPI]: https://pypi.org/

[scikit-image]: https://scikit-image.org/

[@haesleinhuepf]: https://twitter.com/haesleinhuepf

","['Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,napari-skimage-regionprops.napari_experimental_provide_function,,,,
399,napari-spatial-correlation-plotter,napari-spatial-correlation-plotter,Spatial Correlation Plotter,0.0.3,2024-08-13,2024-09-26,Jules Vanaret,jules.vanaret@univ-amu.fr,MIT,https://github.com/jules-vanaret/napari-spatial-correlation-plotter/issues,https://pypi.org/project/napari-spatial-correlation-plotter/,,https://github.com/jules-vanaret/napari-spatial-correlation-plotter,A plugin to compute and display spatial correlation histograms in Napari,>=3.8,"['numpy', 'magicgui', 'matplotlib', 'scikit-image', 'qtpy', 'pyclesperanto-prototype', 'tapenade', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# :herb: napari-spatial-correlation-plotter

[![License MIT](https://img.shields.io/pypi/l/napari-spatial-correlation-plotter.svg?color=green)](https://github.com/jules-vanaret/napari-spatial-correlation-plotter/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-spatial-correlation-plotter.svg?color=green)](https://pypi.org/project/napari-spatial-correlation-plotter)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-spatial-correlation-plotter.svg?color=green)](https://python.org)
[![tests](https://github.com/jules-vanaret/napari-spatial-correlation-plotter/workflows/tests/badge.svg)](https://github.com/jules-vanaret/napari-spatial-correlation-plotter/actions)
[![codecov](https://codecov.io/gh/jules-vanaret/napari-spatial-correlation-plotter/branch/main/graph/badge.svg)](https://codecov.io/gh/jules-vanaret/napari-spatial-correlation-plotter)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-spatial-correlation-plotter)](https://napari-hub.org/plugins/napari-spatial-correlation-plotter)

<img src=""https://github.com/GuignardLab/tapenade/blob/Packaging/imgs/tapenade3.png"" width=""100"">

A plugin to dynamically interact with the spatial correlation heatmap obtained by comparing two continuous fields of biophysical properties in 3D tissues.

If you use this plugin for your research, please [cite us](https://github.com/GuignardLab/tapenade/blob/main/README.md#how-to-cite).

`napari-spatial-correlation-plotter` is a [napari] plugin that is part of the [Tapenade](https://github.com/GuignardLab/tapenade) project. Tapenade is a tool for the analysis of dense 3D tissues acquired with deep imaging microscopy. It is designed to be user-friendly and to provide a comprehensive analysis of the data.

## Overview

While working with large and dense 3D and 3D+time gastruloid datasets, we found that being able to visualise and interact with the data dynamically greatly helped processing it.
During the pre-processing stage, dynamical exploration and interaction led to faster tuning of the parameters by allowing direct visual feedback, and gave key biophysical insight during the analysis stage.

This plugins allows the user to analyse the spatial correlations of two 3D fields loaded in Napari (e.g two fluorescent markers). The user can dynamically vary the analysis length scale, which corresponds to the standard deviation of the Gaussian kernel used for smoothing the 3D fields. 
If a layer of segmented nuclei instances is additionally specified, the histogram is constructed by binning values at the nuclei level (each point corresponds to an individual nucleus). Otherwise, individual voxel values are used.
The user can dynamically interact with the correlation heatmap by manually selecting a region in the plot. The corresponding cells (or voxels) that contributed to the region's statistics will be displayed in 3D on an independant Napari layer for the user to interact with and gain biological insight.

<img src=""imgs/Fig_Napari_correlation.png"">

## Installation

The plugin obviously requires [napari] to run. If you don't have it yet, follow the instructions [here](https://napari.org/stable/tutorials/fundamentals/installation.html).

The simplest way to install `napari-spatial-correlation-plotter` is via the [napari] plugin manager. Open Napari, go to `Plugins > Install/Uninstall Packages...` and search for `napari-spatial-correlation-plotter`. Click on the install button and you are ready to go!

You can also install `napari-spatial-correlation-plotter` via [pip]:

    pip install napari-spatial-correlation-plotter

To install latest development version :

    pip install git+https://github.com/jules-vanaret/napari-spatial-correlation-plotter.git

## Usage

<img src=""imgs/corr_0.png"">

Steps:
1. First, load your images (and optionally mask and labels) in Napari. You can drag and drop them from your file explorer to the Napari viewer, or open them using the `File > Open files...` menu.
2. Click on the `Plugins > Spatial Correlation Plotter` menu to open the plugin.
3. Select the first layer you want to study from the combo box `Quantity X`.
4. Select the second layer you want to study from the combo box `Quantity Y`. In this example, labels have loaded in step 1. Labels layers can be chosen as `Quantity X` or `Quantity Y` so that the quantity to study is the object instance density (in this example, the labels come from nuclei segmentation, so this leads to studying the nuclei density, or equivalently the cell density) or instance volume fraction.
5. Optionally, a mask layer (with boolean values, 0 for outside, 1 for inside) can be selected to restrict the analysis to a specific region of the image.
6. Optionally, a labels layer can be selected so that the histogram is constructed by binning values obtained by averaging the two fields in the segegmented instances (in this case, the quantitites will be averaged inside nuclei).
7. Use the `Blur sigma` slider to vary the length scale of the analysis. This corresponds to the standard deviation of the Gaussian kernel used for masked gaussian smoothing the 3D fields. If set to 0, no smoothing is applied, which can be useful to study the raw data or if the quantities are already coming from smoothed data.
8. Click on the `Compute correlation heatmap` button to compute and plot the correlation heatmap.
9. If the image does not properly fit in the window (e.g if the borders are cut), you can use the `Configure subplots > Tight layout` button to adjust the plot size.
10. You can adjust the histogram binning by changing the `Heatmap bins` sliders. If the histogram range is too large (e.g due to outliers), you can adjust the `Percentiles` sliders to focus on the most relevant part of the histogram. You can also check options to (i) `Show individual cells` to display the individual points that compose the histogram as an additional scatter, (ii) `Show linear fit` to display the linear fit of the histogram, (iii) `Display quadrants` to display vertical and horizontal lines that divide the histogram in 4 quadrants. The lines are placed at the median of the histogram values in X and Y. For instance, once checked, these options lead to the following plot:

<img src=""imgs/corr_1.png"" width=280>

11. You can click on the `Save the figure` button to save the current plot (many formats are available, including .png, .svg, .jpeg).
12. You can interact with the plot by manually drawing a region of interest directly on the plot to automatically select and display the corresponding cells in 3D on an independant Napari Labels layer `clustered labels`. By using a left click, you can draw an arbitrary shape. By using a right click, you can draw a rectangle. If `Shift` is pressed while drawing, several groups of cells can appear on the `clustered labels` layer, each with a different color.
13. To trigger the grid view like in the example image, you can click on the `Toggle grid mode` button. This will display all layers in a grid view. By right clicking the button, you can parametrize the grid view (e.g number of columns, number of rows, etc).
14. You can switch between 2D and 3D view at all time by clicking on the `Toggle 2D/3D view` button (it resembles a square when in 2D mode, or a cube when in 3D mode).

## Acknowledgements

The ""napari-clusters-plotter"" plugin [1] heavily inspired this plugin, most notably the `SelectFromCollection`, `MplCanvas` and `FigureToolbar` classes. The `PlotterWidget` class has been modified for the specific use case of this plugin, but the core functionalites have been adapted directly.
napari-clusters-plotter source code is available [here](https://github.com/BiAPoL/napari-clusters-plotter/tree/main).


[1] Zigutyte, L., Savill, R., MÃ¼ller, J., Zoccoler, M., Wagner, T., & Haase, R. (2023). napari-clusters-plotter. Zenodo. https://doi.org/10.5281/zenodo.5884657

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-spatial-correlation-plotter"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/jules-vanaret/napari-spatial-correlation-plotter/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/jules-vanaret/napari-spatial-correlation-plotter/issues', 'Documentation, https://github.com/jules-vanaret/napari-spatial-correlation-plotter#README.md', 'Source Code, https://github.com/jules-vanaret/napari-spatial-correlation-plotter', 'User Support, https://github.com/jules-vanaret/napari-spatial-correlation-plotter/issues']",,,napari-spatial-correlation-plotter.make_widget,,,,
400,napari-solarized,napari-solarized,Napari Solarized,0.1.1,2023-01-23,2023-01-23,Ashley Anderson,aandersoniii@chanzuckerberg.com,MIT,https://github.com/aganders3/napari-solarized/issues,https://pypi.org/project/napari-solarized/,,https://github.com/aganders3/napari-solarized,Solarized themes for napari,>=3.8,"[""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""npe2 ; extra == 'testing'"", ""typer ; extra == 'testing'"", ""importlib-resources ; extra == 'testing'""]","# napari-solarized

Solarized (-ish) themes for napari, based on [solarized](https://ethanschoonover.com/solarized/).

![solarized dark screenshot](https://raw.githubusercontent.com/aganders3/napari-solarized/main/screenshot_dark.png)
![solarized light screenshot](https://raw.githubusercontent.com/aganders3/napari-solarized/main/screenshot_light.png)

[![License MIT](https://img.shields.io/pypi/l/napari-solarized.svg?color=green)](https://github.com/aganders3/napari-solarized/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-solarized.svg?color=green)](https://pypi.org/project/napari-solarized)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-solarized.svg?color=green)](https://python.org)
[![tests](https://github.com/aganders3/napari-solarized/workflows/tests/badge.svg)](https://github.com/aganders3/napari-solarized/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-solarized)](https://napari-hub.org/plugins/napari-solarized)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-solarized` via [pip]:

    pip install napari-solarized



To install latest development version :

    pip install git+https://github.com/aganders3/napari-solarized.git


## Contributing

Contributions are very welcome.

## License

Distributed under the terms of the [MIT] license,
""napari-solarized"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/aganders3/napari-solarized/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/aganders3/napari-solarized/issues', 'Documentation, https://github.com/aganders3/napari-solarized#README.md', 'Source Code, https://github.com/aganders3/napari-solarized', 'User Support, https://github.com/aganders3/napari-solarized/issues']",,,,,,,
401,napari-spacetx-explorer,napari-spacetx-explorer,napari-spacetx-explorer,0.1.8,2021-09-28,2021-12-10,Sebastian Gonzalez-Tirado,sebastian.gonzalez@embl.de,BSD-3,https://github.com/sebgoti/napari-spacetx-explorer/issues,https://pypi.org/project/napari-spacetx-explorer/,,https://github.com/sebgoti/napari-spacetx-explorer,visualizer for spatial omic data,>=3.7,"['napari', 'napari-plugin-engine (>=0.1.4)', 'numpy', 'pandas']","# napari-spacetx-explorer

[![License](https://img.shields.io/pypi/l/napari-spacetx-explorer.svg?color=green)](https://github.com/sebgoti/napari-spacetx-explorer/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-spacetx-explorer.svg?color=green)](https://pypi.org/project/napari-spacetx-explorer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-spacetx-explorer.svg?color=green)](https://python.org)
[![tests](https://github.com/sebgoti/napari-spacetx-explorer/workflows/tests/badge.svg)](https://github.com/sebgoti/napari-spacetx-explorer/actions)
[![codecov](https://codecov.io/gh/sebgoti/napari-spacetx-explorer/branch/master/graph/badge.svg)](https://codecov.io/gh/sebgoti/napari-spacetx-explorer)

A napari plugin for interactive visualization of decoded spots from spatial transcriptomic data stored as CSV

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

The plugin code was written by Sebastian Gonzalez-Tirado.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->
## Reader hookspec

`napari-spacetx-explorer` allows the user to open and visualize CSV files that
have point-data stored in a given format. The main target is for users who
want to analyze decoded spot maps from spatial omics experiments but it can
used as well for any other type of coordinate data where each point has assigned
a label (e. g. a gene) as a string and the x and y-coordinates of the point's center.
The header for these data must be 'target', 'xc', and 'yc', respectively.

![img.png](https://github.com/sebgoti/napari-spacetx-explorer/raw/main/docs/Read_Hookspec.png)

## Selecting genes

After loading the gene/target maps it is possible to select specific groups for better visualization.
This creates a new ""Points"" layer in napari with the selected groups displayed in different colors.

![img.png](https://github.com/sebgoti/napari-spacetx-explorer/raw/main/docs/_function_hookspec.png)

## Loading data in OME.ZARR format

The plugin napari-ome-zarr can be used to display whole-tissue images in addition to the spot maps produced with the 
`napari-spacetx-explorer` plugin.

![img.png](https://github.com/sebgoti/napari-spacetx-explorer/raw/main/docs/_ome_zarr_napari_spacetx_explorer.png)

## Installation

The easiest installation is via the ""Install/Uninstall Plugins..."" under the Plugins menu in napari.  
Another way is through [pip] 

    pip install napari-spacetx-explorer

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-spacetx-explorer"" is free and open source software

## Issues

If you encounter any problems or would like some support, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/sebgoti/napari-spacetx-explorer/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/sebgoti/napari-spacetx-explorer/issues', 'Documentation, https://github.com/sebgoti/napari-spacetx-explorer#README.md', 'Source Code, https://github.com/sebgoti/napari-spacetx-explorer', 'User Support, https://github.com/sebgoti/napari-spacetx-explorer/issues']",napari-spacetx-explorer.napari_get_reader,,napari-spacetx-explorer.napari_experimental_provide_function,,['*'],,
402,napari-sim-processor,napari-sim-processor,napari SIM processor,0.1.1,2022-05-04,2023-11-01,Andrea Bassi and Mark Neil,andrea1.bassi@polimi.it,BSD-3-Clause,https://github.com/andreabassi78/napari-sim-processor/issues,https://pypi.org/project/napari-sim-processor/,,https://github.com/andreabassi78/napari-sim-processor,A plugin to process Structured Illumination Microscopy data with gpu acceleration,>=3.8,"['numpy', 'scipy', 'magicgui', 'qtpy', 'matplotlib', 'superqt >=0.3.2', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""matplotlib ; extra == 'testing'"", ""numpy ; extra == 'testing'"", ""scipy ; extra == 'testing'"", ""superqt ; extra == 'testing'""]","# napari-sim-processor

[![License](https://img.shields.io/pypi/l/napari-sim-processor.svg?color=green)](https://github.com/andreabassi78/napari-sim-processor/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-sim-processor.svg?color=green)](https://pypi.org/project/napari-sim-processor)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-sim-processor.svg?color=green)](https://python.org)
[![tests](https://github.com/andreabassi78/napari-sim-processor/workflows/tests/badge.svg)](https://github.com/andreabassi78/napari-sim-processor/actions)
[![codecov](https://codecov.io/gh/andreabassi78/napari-sim-processor/branch/main/graph/badge.svg)](https://codecov.io/gh/andreabassi78/napari-sim-processor)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-sim-processor)](https://napari-hub.org/plugins/napari-sim-processor)

A Napari plugin for the reconstruction of Structured Illumination Microscopy (SIM) with GPU acceleration (pytorch/cupy if installed).
Currently supports:    
   - conventional SIM data with a generic number of angles and phases (typically, 3 angles and 3 phases are used for resolution improvement in 2D, but any combination can be processed by the widget)
   - hexagonal SIM data with 7 phases, as used in [this] publication.
   - 3D SIM, for resolution enhancement in three dimensions. This is available in the [3dSIM] branch  

The SIM processing widget accepts image stacks organized in 5D (`angle`,`phase`,`z`,`y`,`x`).

The reshape widget can be used to easily reshape the data if they are not organized as 5D (angle,phase,z,y,x).

For 3D stacks (raw images) with multiple z-frames, a batch reconstruction method is available, as described [here].

Syntetic raw-image stacks of Structured Illumination Microscopy can be easily simulated using the napari [SIMulator] pluging.
	 
----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-sim-processor` via [pip]:

    pip install napari-sim-processor


To install latest development version :

    pip install git+https://github.com/andreabassi78/napari-sim-processor.git


## Usage

1) Open napari. 

2) Launch the reshape and sim-processor widgets.

3) Open your raw image stack (using the napari built-in or your own file opener).

![raw](https://github.com/andreabassi78/napari-sim-processor/raw/main/images/Picture1.png)

4) If your image is ordered as a 5D stack (angle, phase, z-frame, y, x) go to point 6. 

5) In the reshape widget, select the actual number of acquired angles, phases, and frames (red arrow) and press `Reshape Stack`.
 Note that the label axis of the viewer will be updated (green arrow).

![raw](https://github.com/andreabassi78/napari-sim-processor/raw/main/images/Picture1b.png)

6) In the sim-reconstruction widget press the Select image layer button. Note that the number of phases and angles will be updated (blue arrow). 

7) Choose the correct parameters of the SIM acquisition (`NA`, `pixelsize`, `M`, etc.) and processing parameters (`alpha`, `beta`, w, `eta`, `group`):
   - `w`: parameter of the Weiner filter.
   - `eta`: constant used for calibration. It should be slightly smaller than the carrier frequency (in pupil radius units).
   - `group`: for stacks with multiple z-frames, it is the number of frames that are used together for the calibration process.
	
For details on the other parameters see [here].

8) Calibrate the SIM processor, pressing the `Calibrate` button. This will find the carrier frequencies (red circles if the `Show Carrier` checkbox is selected), the modulation amplitude and the phase, using cross correlation analysis.

9) Click on the checkboxes to show the power spectrum of the raw image (`Show power spectrum`) or the cross-correlation (`Show Xcorr`), to see if the found carrier frequency is correct.

![raw](https://github.com/andreabassi78/napari-sim-processor/raw/main/images/Picture2b.png)
**Napari viewer showing the power spectrum of the raw stack. The pupil circle is in blue. A circle corresponding to `eta` is shown in green.**

![raw](https://github.com/andreabassi78/napari-sim-processor/raw/main/images/Picture2.png)
**Napari viewer showing the cross-correlation of the raw stack. The red circles indicate the found carrier frequencies**

10) Run the reconstruction of a single plane (`SIM reconstruction`) or of a stack (`Stack reconstruction`). After execution, a new image_layer will be added to the napari viewer. Click on the `Batch reconstruction` checkbox in order to process an entire stack in one shot. Click on the pytorch checkbox for gpu acceleration.

![raw](https://github.com/andreabassi78/napari-sim-processor/raw/main/images/Picture3b.png)
**Napari viewer with widgets showing a pseudo-widefield reconstruction**

![raw](https://github.com/andreabassi78/napari-sim-processor/raw/main/images/Picture3.png)
**Napari viewer with widgets showing a SIM reconstruction**

## GPU processing

The underlying processing classes will use numpy (and FFTW if available) for 
its calculations. For GPU accelerated processing you need to have either the 
PyTorch (tested with torch v1.11.0+cu113) or the CuPy (tested with cupy-cuda113 
v10.4.0) package installed.  Make sure to match the package cuda version to the CUDA library 
installed on your system otherwise PyTorch will default to CPU and CuPy will not work at all.  

Both packages give significant speedup on even relatively modest CUDA GPUs compared 
to Numpy, and PyTorch running on the CPU only can show improvements relative to numpy 
and FFTW. Selection of which processing package to use is via a ComboBox in the 
napari_sim_processor widget.  Only available packages are shown. 

Other than requiring a CUDA GPU it is advisable to have significant GPU memory 
available, particularly when processing large datasets.  Batch processing is the 
most memory hungry of the methods, but can process 280x512x512 datasets on a 4GB GPU.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-sim-processor"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/andreabassi78/napari-sim-processor/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

[here]: https://doi.org/10.1098/rsta.2020.0162
[this]: https://doi.org/10.1364/OE.466225
[3dSIM]: https://github.com/andreabassi78/napari-sim-processor/tree/3dSIM
[SIMulator]: https://www.napari-hub.org/plugins/napari-generic-SIMulator
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/andreabassi78/napari-sim-processor/issues', 'Documentation, https://github.com/andreabassi78/napari-sim-processor#README.md', 'Source Code, https://github.com/andreabassi78/napari-sim-processor', 'User Support, https://github.com/andreabassi78/napari-sim-processor/issues']",,,napari-sim-processor.make_sim_widget,,,,
403,napari-spatial-omics,napari-spatial-omics,napari-spatial-omics,0.0.8,2021-12-10,2021-12-12,Sebastian Gonzalez-Tirado,sebgoti8@gmail.com,BSD-3-Clause,https://github.com/sebgoti/napari-spatial-omics/issues,https://pypi.org/project/napari-spatial-omics/,,https://github.com/sebgoti/napari-spatial-omics,A simple plugin to visualize spatial omic data stored in CSV format,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'pandas']","# napari-spatial-omics

[![License](https://img.shields.io/pypi/l/napari-spatial-omics.svg?color=green)](https://github.com/sebgoti/napari-spatial-omics/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-spatial-omics.svg?color=green)](https://pypi.org/project/napari-spatial-omics)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-spatial-omics.svg?color=green)](https://python.org)
[![tests](https://github.com/sebgoti/napari-spatial-omics/workflows/tests/badge.svg)](https://github.com/sebgoti/napari-spatial-omics/actions)
[![codecov](https://codecov.io/gh/sebgoti/napari-spatial-omics/branch/main/graph/badge.svg)](https://codecov.io/gh/sebgoti/napari-spatial-omics)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-spatial-omics)](https://napari-hub.org/plugins/napari-spatial-omics)

A simple plugin to visualize spatial omic data stored in CSV format

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-spatial-omics` via [pip]:

    pip install napari-spatial-omics



To install latest development version :

    pip install git+https://github.com/sebgoti/napari-spatial-omics.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-spatial-omics"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/sebgoti/napari-spatial-omics/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/sebgoti/napari-spatial-omics/issues', 'Documentation, https://github.com/sebgoti/napari-spatial-omics#README.md', 'Source Code, https://github.com/sebgoti/napari-spatial-omics', 'User Support, https://github.com/sebgoti/napari-spatial-omics/issues']",napari-spatial-omics.napari_get_reader,,napari-spatial-omics.example_magic_widget,,['*'],,
404,napari-spfluo,napari-spfluo,single particle,0.1.0,2024-10-04,2024-11-26,Jean Plumail,Jean Plumail <jplumail@unistra.fr>,MIT,https://github.com/jplumail/napari-spfluo/issues,https://pypi.org/project/napari-spfluo/,,,A plugin to use spfluo within napari,>=3.8,"['magicgui', 'numpy', 'qtpy', 'scikit-image', 'spfluo[ab-initio-reconstruction]']","# napari-spfluo

[![License MIT](https://img.shields.io/pypi/l/napari-spfluo.svg?color=green)](https://github.com/jplumail/napari-spfluo/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-spfluo.svg?color=green)](https://pypi.org/project/napari-spfluo)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-spfluo.svg?color=green)](https://python.org)
[![tests](https://github.com/jplumail/napari-spfluo/workflows/tests/badge.svg)](https://github.com/jplumail/napari-spfluo/actions)
[![codecov](https://codecov.io/gh/jplumail/napari-spfluo/branch/main/graph/badge.svg)](https://codecov.io/gh/jplumail/napari-spfluo)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-spfluo)](https://napari-hub.org/plugins/napari-spfluo)

A plugin to use spfluo within napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-spfluo` via [pip]:

    pip install napari-spfluo



To install latest development version :

    pip install git+https://github.com/jplumail/napari-spfluo.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-spfluo"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/jplumail/napari-spfluo/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/jplumail/napari-spfluo/issues', 'Documentation, https://github.com/jplumail/napari-spfluo#README.md', 'Homepage, https://github.com/jplumail/napari-spfluo', 'Source Code, https://github.com/jplumail/napari-spfluo', 'User Support, https://github.com/jplumail/napari-spfluo/issues']",,,napari-spfluo.make_ab_initio_widget,napari-spfluo.make_generated_anisotropic,,,
405,napari-spatialdata,napari-spatialdata,napari spatialdata,0.5.6,2022-07-06,2025-04-21,giovanni palla,giov.pll@gmail.com,BSD-3-Clause,https://github.com/scverse/napari-spatialdata/issues,https://pypi.org/project/napari-spatialdata/,,https://github.com/scverse/napari-spatialdata.git,Interactive visualization of spatial omics data with napari,>=3.10,"['anndata', 'click', 'cycler', 'dask>=2024.4.1', 'geopandas', 'loguru', 'matplotlib', 'napari<0.5.6,>=0.4.19.post1', 'napari-matplotlib', 'numba', 'numpy', 'packaging', 'pandas', 'pillow', 'pyqtgraph', 'qtpy', 'scanpy', 'scipy', 'shapely', 'scikit-learn', 'spatialdata>=0.2.6', 'superqt', 'typing_extensions>=4.8.0', 'vispy', 'xarray', 'xarray-datatree', 'loguru; extra == ""test""', 'pytest; extra == ""test""', 'pytest-cov; extra == ""test""', 'pytest-mock; extra == ""test""', 'pytest-qt; extra == ""test""', 'pre-commit>=2.9.0; extra == ""test""', 'sphinx>=4.5; extra == ""doc""', 'sphinx-book-theme>=1.0.0; extra == ""doc""', 'myst-parser; extra == ""doc""', 'sphinxcontrib-bibtex>=1.0.0; extra == ""doc""', 'sphinx-autodoc-typehints>=1.11.0; extra == ""doc""', 'sphinx-autobuild; extra == ""doc""', 'scanpydoc; extra == ""doc""', 'ipykernel; extra == ""doc""', 'ipython; extra == ""doc""', 'sphinx-copybutton; extra == ""doc""', 'sphinx-qt-documentation; extra == ""doc""', 'myst-nb; extra == ""doc""', 'squidpy; extra == ""doc""', 'pydantic<2; extra == ""readthedocs""', 'spatialdata>=0.1.0-pre0; extra == ""pre""', 'napari[pyqt5]; extra == ""all""']","![SpatialData banner](https://github.com/scverse/spatialdata/blob/main/docs/_static/img/spatialdata_horizontal.png?raw=true)

# napari-spatialdata: interactive exploration and annotation of spatial omics data

[![License](https://img.shields.io/pypi/l/napari-spatialdata.svg?color=green)](https://github.com/scverse/napari-spatialdata/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-spatialdata.svg?color=green)](https://pypi.org/project/napari-spatialdata)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-spatialdata.svg?color=green)](https://python.org)
[![tests](https://github.com/scverse/napari-spatialdata/workflows/tests/badge.svg)](https://github.com/scverse/napari-spatialdata/actions)
[![codecov](https://codecov.io/gh/scverse/napari-spatialdata/branch/main/graph/badge.svg?token=ASqlOKnOj7)](https://codecov.io/gh/scverse/napari-spatialdata)
[![pre-commit.ci status](https://results.pre-commit.ci/badge/github/scverse/napari-spatialdata/main.svg)](https://results.pre-commit.ci/latest/github/scverse/napari-spatialdata/main)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-spatialdata)](https://napari-hub.org/plugins/napari-spatialdata)
[![DOI](https://zenodo.org/badge/477021400.svg)](https://zenodo.org/badge/latestdoi/477021400)

This repository contains a napari plugin for interactively exploring and annotating
SpatialData objects. Here you can find the [napari-spatialdata documentation]
(https://spatialdata.scverse.org/projects/napari/en/stable/notebooks/spatialdata.html). `napari-spatialdata` is part of the `SpatialData` ecosystem. To learn more about SpatialData, please see the [spatialdata documentation](https://spatialdata.scverse.org/).

## Installation

You can install `napari-spatialdata` via [pip]:

    pip install napari-spatialdata[all]

The `all` command will install the qt bindings `PyQt5`.

You can find more details on this in the [installation instructions](https://spatialdata.scverse.org/en/stable/installation.html).

## Using napari-spatialdata as default zarr reader

If you would like to use the plugin as the default zarr reader, in napari please go to `File` -> `Preferences`
-> `Plugins` and follow the instructions under `File extension readers`.

## Development Version

You can install `napari-spatialdata` from Github with:

    pip install git+https://github.com/scverse/napari-spatialdata

Or, you can also install in editable mode after cloning the repo by:

    git clone https://github.com/scverse/napari-spatialdata
    cd napari-spatialdata
    pip install -e .

Note: when performing an editable install of `napari-spatialdata`, `spatialdata`
will be reinstalled from `pip`. So, if you previously also made an editable install
of `spatialdata`, you need to re-run `pip install -e .` on the `spatialdata`
repository. Please find more details on this in the [installation instructions](https://spatialdata.scverse.org/en/stable/installation.html).

## Getting started

To learn how to use the `napari-spatialdata` plugin, please see the [documentation](https://spatialdata.scverse.org/projects/napari/en/stable/notebooks/spatialdata.html).
To learn how to integrate napari-spatialdata into your analysis workflows, please
see the [SpatialData tutorials](https://spatialdata.scverse.org/en/stable/tutorials/notebooks/notebooks.html). In particular:

- [Annotating regions of interest with napari](https://spatialdata.scverse.org/en/stable/tutorials/notebooks/notebooks/examples/napari_rois.html)
- [Use landmark annotations to align multiple -omics layers](https://spatialdata.scverse.org/en/stable/tutorials/notebooks/notebooks/examples/alignment_using_landmarks.html)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-spatialdata"" is free and open source software

## Issues

If you encounter any problems, please file an [issue] along with a detailed description.

## Citation

Marconato, L., Palla, G., Yamauchi, K.A. et al. SpatialData: an open and universal data framework for spatial omics. Nat Methods (2024). https://doi.org/10.1038/s41592-024-02212-x

[napari]: https://github.com/napari/napari
[cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[mit]: http://opensource.org/licenses/MIT
[bsd-3]: http://opensource.org/licenses/BSD-3-Clause
[gnu gpl v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[gnu lgpl v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[apache software license 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[mozilla public license 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[pypi]: https://pypi.org/
[issue]: https://github.com/scverse/napari-spatialdata/issues
[//]: # ""numfocus-fiscal-sponsor-attribution""

napari-spatialdata is part of the scverseÂ® project ([website](https://scverse.org), [governance](https://scverse.org/about/roles)) and is fiscally sponsored by [NumFOCUS](https://numfocus.org/).
If you like scverseÂ® and want to support our mission, please consider making a tax-deductible [donation](https://numfocus.org/donate-to-scverse) to help the project pay for developer time, professional services, travel, workshops, and a variety of other needs.

<div align=""center"">
<a href=""https://numfocus.org/project/scverse"">
  <img
    src=""https://raw.githubusercontent.com/numfocus/templates/master/images/numfocus-logo.png""
    width=""200""
  >
</a>
</div>
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/scverse/napari-spatialdata/issues', 'Documentation, https://spatialdata.scverse.org/projects/napari/en/latest/notebooks/spatialdata.html', 'Source Code, https://github.com/scverse/napari-spatialdata', 'User Support, https://github.com/scverse/napari-spatialdata/issues']",napari-spatialdata.get_reader,,napari-spatialdata.QtAdataScatterWidget,,['*.zarr'],,
406,napari-splinebox,napari-splinebox,splinebox,0.0.4a0,2024-10-01,2025-04-09,Florian Aymanns,florian.aymanns@epfl.ch,"Copyright (c) 2024, Florian Ay...",https://github.com/EPFL-Center-for-Imaging/napari-splinebox/issues,https://pypi.org/project/napari-splinebox/,,,A plugin to create splines with napari.,>=3.9,"['numpy', 'magicgui', 'qtpy', 'splinebox', 'pandas', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-splinebox

[![License BSD-3](https://img.shields.io/pypi/l/napari-splinebox.svg?color=green)](https://github.com/EPFL-Center-for-Imaging/napari-splinebox/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-splinebox.svg?color=green)](https://pypi.org/project/napari-splinebox)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-splinebox.svg?color=green)](https://python.org)
[![tests](https://github.com/EPFL-Center-for-Imaging/napari-splinebox/workflows/tests/badge.svg)](https://github.com/EPFL-Center-for-Imaging/napari-splinebox/actions)
[![codecov](https://codecov.io/gh/EPFL-Center-for-Imaging/napari-splinebox/branch/main/graph/badge.svg)](https://codecov.io/gh/EPFL-Center-for-Imaging/napari-splinebox)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-splinebox)](https://napari-hub.org/plugins/napari-splinebox)

A plugin to create splines with napari.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-splinebox` via [pip]:

    pip install napari-splinebox



To install latest development version :

    pip install git+https://github.com/EPFL-Center-for-Imaging/napari-splinebox.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-splinebox"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/EPFL-Center-for-Imaging/napari-splinebox/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/EPFL-Center-for-Imaging/napari-splinebox/issues', 'Documentation, https://github.com/EPFL-Center-for-Imaging/napari-splinebox#README.md', 'Source Code, https://github.com/EPFL-Center-for-Imaging/napari-splinebox', 'User Support, https://github.com/EPFL-Center-for-Imaging/napari-splinebox/issues']",napari-splinebox.get_reader,napari-splinebox.write_multiple_layers,napari-splinebox.make_container_widget,,['*.json'],,['.json']
407,napari-spofi,napari-spofi,Spot Finder,0.0.1,2024-02-07,2024-02-09,Christian Schulze,drchrisch@gmail.com,BSD-3-Clause,https://github.com/drchrisch/napari-spofi/issues,https://pypi.org/project/napari-spofi/,,,napari plugin to interactively train and test a StarDist model,>=3.8,"['numpy', 'pandas', 'magicgui', 'qtpy', 'scikit-image', 'pyclesperanto', 'tensorflow', 'stardist', ""tox ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-spofi

[![License BSD-3](https://img.shields.io/pypi/l/napari-spofi.svg?color=green)](https://github.com/githubuser/napari-spofi/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-spofi.svg?color=green)](https://pypi.org/project/napari-spofi)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-spofi.svg?color=green)](https://python.org)
[![tests](https://github.com/githubuser/napari-spofi/workflows/tests/badge.svg)](https://github.com/githubuser/napari-spofi/actions)
[![codecov](https://codecov.io/gh/githubuser/napari-spofi/branch/main/graph/badge.svg)](https://codecov.io/gh/githubuser/napari-spofi)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-spofi)](https://napari-hub.org/plugins/napari-spofi)

napari plugin to interactively train and test a StarDist model

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started


and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Description

This plugin provides tools for annotating spots in a 3D two-channel image (hdf5 type input file),
submitting tiles for StarDist model generation or model re-training, and refining initial annotations
based on predictions (kind of human-in-the-loop approach).

The objects of interest in the image are sphere-like spots with a diameter of just a
few pixels and are thus well suited for StarDist instance segmentation. The image 
dimensions are typically 1024x1024 pixels in xy and â¥ 64 sections in z.


## Installation

With python and pip installed (e.g., via miniconda or miniforge),
it is recommended to create a new environment and install `napari-spofi` using pip.

    pip install napari napari-spofi

## Starting `napari-spofi`

Start `napari` and select ""spot finder (napari-spofi)"" from the ""plugin"" menu.

### Annotate image
Go to the 'annotation' section of the widget and create a new directory for annotations. Add an image
folder containing at least one h5 file (foreground and background, e.g., 'ch1' & 'ch2'). Select an image file, foreground and background
channels. Load the image file.

Inspect the image for distinct regions. To help locate relevant tile positions, make
the 'checkerboard' layer visible. While the 'tiles' layer is active, double-click a tile
to add it to the list of tiles. This list will be used to generate a set of 
images and masks for training purposes.

Switch to napari's 2D view. Navigate to the centre section of each spot in the active tile
and annotate by adding points (one point per spot) using the 'true' points layer. The
built-in heuristic will automatically annotate pixels that belong to individual spots.
Some image enhancement step before loading images may be beneficial. 

Annotate tiles in one or a multiple images.
To prepare training data, use the 'extract spots' button.

### Train a StarDist model
Go to the 'training' section of the widget. Adjust the ""number of epochs"". For a first
check, 100 epochs is a good start. The plugin uses a simplified setup for StarDist
configurations (please see [StarDist](https://github.com/stardist/stardist/) for a full discussion).

Start training and watch the 'loss' and 'val_loss' values, which should decrease
steadily while their ratio should roughly remain at 1 as training progresses.

The retrain option allows the selection of an existing model for retraining.

### Predict instances
Go to the 'prediction' section of the widget to start spot prediction for the
currently loaded image. Select the appropriate model from the given annotation
directory. The 'threshold' value is calculated from the validation data and can be
adjusted. Start a new prediction and load the predicted spots when the process has
finished. (It is possible to load an existing prediction).

### Polish annotation
Predicted spots will be loaded into two new layers: 'predicted' and 'edited'. The
'predicted' layer is not editable and gives an overview of the spots found. Check
your annotation in the active tiles ('true' layer) and compare it carefully with
the spots in the 'edited' layer.
Adjust the positions of the spots or remove any incorrect spots from the 'edited'
layer. Extract the spots and train a new model or retrain the model.



## Contributing

Contributions are very welcome.

## License

Distributed under the terms of the [BSD-3] license,
""napari-spofi"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Visualization']","['Bug Tracker, https://github.com/drchrisch/napari-spofi/issues', 'Documentation, https://github.com/drchrisch/napari-spofi#README.md', 'Source Code, https://github.com/drchrisch/napari-spofi', 'User Support, https://github.com/drchrisch/napari-spofi/issues']",,,napari-spofi.widget,,,,
408,napari-spotiflow,napari-spotiflow,napari-spotiflow,0.4.3,2024-02-02,2025-06-16,"Albert Dominguez Mantes, Martin Weigert","Albert Dominguez Mantes <albert.dominguezmantes@epfl.ch>, Martin Weigert <martin.weigert@epfl.ch>",BSD 3-Clause,https://github.com/weigertlab/napari-spotiflow/issues,https://pypi.org/project/napari-spotiflow/,,,Napari plugin for Spotiflow,"<3.13,>=3.9","['spotiflow', 'npe2', 'napari>=0.5']","[![License: BSD-3](https://img.shields.io/badge/License-BSD3-blue.svg)](https://www.gnu.org/licenses/bsd3)
[![PyPI](https://img.shields.io/pypi/v/napari-spotiflow.svg?color=green)](https://pypi.org/project/napari-spotiflow)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-spotiflow.svg?color=green)](https://python.org)
[![tests](https://github.com/weigertlab/napari-spotiflow/workflows/tests/badge.svg)](https://github.com/weigertlab/napari-spotiflow/actions)
[![PyPI - Downloads](https://img.shields.io/pypi/dm/napari-spotiflow)](https://pypistats.org/packages/napari-spotiflow)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-spotiflow)](https://napari-hub.org/plugins/napari-spotiflow)

![Logo](https://github.com/weigertlab/napari-spotiflow/raw/main/artwork/spotiflow_logo.png)
---

# Spotiflow: napari plugin

Napari plugin for *Spotiflow*, a deep learning-based, threshold-agnostic, and subpixel-accurate spot detection method for 2D and 3D fluorescence microscopy images. The plugin allows using several pre-trained models as well as user-trained ones. For the main repository, see [here](https://github.com/weigertlab/spotiflow). 

https://github.com/weigertlab/napari-spotiflow/assets/11042162/02940480-daa9-4a21-8cf5-ad73c26c9838

If you use this plugin for your research, please [cite us](https://github.com/weigertlab/spotiflow#how-to-cite) as well as [napari](https://github.com/napari/napari?tab=readme-ov-file#citing-napari).

----------------------------------

## Installation

The plugin can be installed directly from PyPi (make sure you use a conda environment with `napari` and `spotiflow` installed):

```
pip install napari-spotiflow
```

## Usage 

1. Open the image (or open one of our samples, _e.g._ `File > Open Sample > napari-spotiflow > HybISS`)
2. Start the plugin `Plugins > napari-spotiflow`
3. Select model (pre-trained or custom trained) and optionally adjust any other parameters
4. Click `Detect spots`

## Supported input formats
- 2D (YX, YXC or CYX)
- 2D+t (TYX, TYXC or TCYX)
- 3D (ZYX, ZYXC or CZYX)
- 3D+t (TZYX, TZYXC or TCZYX)

## How to cite
See the [main repository's _How to cite_ section](https://github.com/weigertlab/spotiflow?tab=readme-ov-file#how-to-cite) as well as napari's [_citing napari_ section](https://github.com/napari/napari?tab=readme-ov-file#citing-napari).
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/weigertlab/napari-spotiflow/issues', 'Documentation, https://github.com/weigertlab/napari-spotiflow#README.md', 'Source Code, https://github.com/weigertlab/napari-spotiflow', 'User Support, https://github.com/weigertlab/napari-spotiflow/issues']",napari-spotiflow.reader,,napari-spotiflow.widget,napari-spotiflow.data.hybiss_2d,['*.csv'],,
409,napari-splineit,napari-splineit,Napari SplineIt2,0.3.0,2022-07-05,2022-10-24,Thorsten Beier,derthorstenbeier@gmail.com,BSD-3-Clause,https://github.com/uhlmanngroup/napari-splineit/issues,https://pypi.org/project/napari-splineit/,,https://github.com/uhlmanngroup/napari-splineit,A napari plugin for spline manipulation,>=3.7,"['numpy', 'qtpy', 'scikit-image', 'scipy', ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-splineit

[![License](https://img.shields.io/pypi/l/napari-splineit.svg?color=green)](https://github.com/uhlmanngroup/napari-splineit/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-splineit.svg?color=green)](https://pypi.org/project/napari-splineit)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-splineit.svg?color=green)](https://python.org)
[![tests](https://github.com/uhlmanngroup/napari-splineit/workflows/tests/badge.svg)](https://github.com/uhlmanngroup/napari-splineit/actions)
[![codecov](https://codecov.io/gh/uhlmanngroup/napari-splineit/branch/main/graph/badge.svg)](https://codecov.io/gh/uhlmanngroup/napari-splineit)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-splineit)](https://napari-hub.org/plugins/napari-splineit)

A napari plugin for the interactive manipulation of spline-interpolation based geometrical models

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `napari-splineit` via [pip]:

    pip install napari-splineit



To install latest development version :

    pip install git+https://github.com/uhlmanngroup/napari-splineit.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-splineit"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/uhlmanngroup/napari-splineit/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/uhlmanngroup/napari-splineit/issues', 'Documentation, https://github.com/uhlmanngroup/napari-splineit#README.md', 'Source Code, https://github.com/uhlmanngroup/napari-splineit', 'User Support, https://github.com/uhlmanngroup/napari-splineit/issues']",napari-splineit.read_splineit,napari-splineit.write_splineit_json,napari-splineit.make_qwidget,napari-splineit.make_sample_data_coins,['*.splineit'],['.splineit'],
410,napari-splinedist,napari-splinedist,SplineDist,0.3.1,2022-10-18,2022-10-31,Dr. Thorsten Beier,derthorstebeier@gmail.com,MIT,https://github.com/DerThorsten/napari-splinedist/issues,https://pypi.org/project/napari-splinedist/,,https://github.com/DerThorsten/napari-splinedist,A napari SplineDist plugin,>=3.8,"['pydantic', 'numpy', 'magicgui', 'qtpy', 'stardist (>=0.8.3)', 'splinedist (>=0.1.2)', 'napari-splineit (>=0.3.0)', 'requests', 'tensorflow', 'opencv-python-headless', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-splinedist

[![License MIT](https://img.shields.io/pypi/l/napari-splinedist.svg?color=green)](https://github.com/DerThorsten/napari-splinedist/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-splinedist.svg?color=green)](https://pypi.org/project/napari-splinedist)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-splinedist.svg?color=green)](https://python.org)
[![tests](https://github.com/DerThorsten/napari-splinedist/workflows/tests/badge.svg)](https://github.com/DerThorsten/napari-splinedist/actions)
[![codecov](https://codecov.io/gh/DerThorsten/napari-splinedist/branch/main/graph/badge.svg)](https://codecov.io/gh/DerThorsten/napari-splinedist)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-splinedist)](https://napari-hub.org/plugins/napari-splinedist)

A napari SplineDist plugin

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-splinedist` via [pip]:

    pip install napari-splinedist



To install latest development version :

    pip install git+https://github.com/DerThorsten/napari-splinedist.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-splinedist"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/DerThorsten/napari-splinedist/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/DerThorsten/napari-splinedist/issues', 'Documentation, https://github.com/DerThorsten/napari-splinedist#README.md', 'Source Code, https://github.com/DerThorsten/napari-splinedist', 'User Support, https://github.com/DerThorsten/napari-splinedist/issues']",,,napari-splinedist.make_qwidget,napari-splinedist.sample_data_bbbc038,,,
411,napari-stitcher,napari-stitcher,napari-stitcher,0.1.2,2024-10-18,2025-04-07,Marvin Albert,marvin.albert@gmail.com,BSD-3-Clause,https://github.com/multiview-stitcher/napari-stitcher/issues,https://pypi.org/project/napari-stitcher/,,,Stitch napari image layers in 2-3D+t,>=3.10,"['dask', 'magicgui', 'multiscale_spatial_image', 'multiview-stitcher>=0.1.24', 'napari', 'numpy>=1.18', 'qtpy', 'spatial_image', 'tifffile>=2022.7.28', 'tqdm', 'xarray', 'tox; extra == ""testing-no-gui""', 'multiview-stitcher[czi]>=0.1.24; extra == ""testing-no-gui""', 'pytest; extra == ""testing-no-gui""', 'pytest-cov; extra == ""testing-no-gui""', 'pytest-qt; extra == ""testing-no-gui""', 'tox; extra == ""testing""', 'multiview-stitcher[czi]>=0.1.24; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-stitcher)](https://napari-hub.org/plugins/napari-stitcher)
[![License {{cookiecutter.license}}](https://img.shields.io/pypi/l/napari-stitcher.svg?color=green)](https://github.com/multiview-stitcher/napari-stitcher/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-stitcher.svg?color=green)](https://pypi.org/project/napari-stitcher)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-stitcher.svg?color=green)](https://python.org)
[![tests](https://github.com/multiview-stitcher/napari-stitcher/actions/workflows/test_and_deploy.yml/badge.svg)](https://github.com/multiview-stitcher/napari-stitcher/actions)
[![codecov](https://codecov.io/gh/multiview-stitcher/napari-stitcher/branch/main/graph/badge.svg)](https://codecov.io/gh/multiview-stitcher/napari-stitcher)
[![DOI](https://zenodo.org/badge/697999800.svg)](https://zenodo.org/doi/10.5281/zenodo.14176362)


# napari-stitcher

A napari plugin for stitching large multi-positioning datasets in 2/3D+t using [`multiview-stitcher`](https://github.com/multiview-stitcher/multiview-stitcher).

![](docs/images/napari-stitcher-loaded-mosaic-annotated.png)
<small>Image data by Arthur Michaut @ JÃ©rÃ´me Gros Lab @ Institut Pasteur.</small>

#### Quick guide:

1. Directly stitch napari layers: Use napari to load, visualize and [preposition](prearrangement.md) the tiles to be stitched.
2. When working with multi-channel data, stick to the following [naming convention](naming_convention.md): `{tile} :: {channel}`.
3. Load either all or just a subset of the layers into the plugin.
4. Choose registration options: registration channel, binning and more.
5. Stitching = registration (refining the positions, optional) + fusion (joining the tiles into a single image).
6. The registration result is shown in the viewer and the fused channels are added as new layers.

## Demo

https://github.com/user-attachments/assets/8773e49f-af18-4ff3-ab2f-2a5f1b1cadf2

<small>This demo uses the awesome [`napari-threedee`](https://github.com/napari-threedee/napari-threedee) for prepositioning the tiles. Image data: [BigStitcher](https://imagej.net/plugins/bigstitcher/).</small>

## Documentation

Head over to the [user guide](https://multiview-stitcher.github.io/napari-stitcher/main/) for more details.

## Installation

You can install `napari-stitcher` via `pip`:

```bash
pip install napari-stitcher
```

For more installation options, see the [installation docs](https://multiview-stitcher.github.io/napari-stitcher/main/installation/).

## Contributing

Contributions are very welcome. Tests can be run with `tox`.

## License

Distributed under the terms of the [BSD-3] license, ""napari-stitcher"" is free and open source software

## Issues

If you encounter any problems, please [file an issue](https://github.com/multiview-stitcher/napari-stitcher/issues) along with a detailed description.
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/multiview-stitcher/napari-stitcher/issues', 'Documentation, https://multiview-stitcher.github.io/napari-stitcher/', 'Source Code, https://github.com/multiview-stitcher/napari-stitcher', 'User Support, https://github.com/multiview-stitcher/napari-stitcher/issues']",napari-stitcher.get_reader,napari-stitcher.write_multiple,napari-stitcher.make_qwidget,napari-stitcher.make_sample_data,['*.czi'],['.tif'],
412,napari-spreadsheet,napari-spreadsheet,Spreadsheet,0.0.4,2022-08-28,2023-04-16,Hanjin Liu,liuhanjin-sc@g.ecc.u-tokyo.ac.jp,BSD-3-Clause,https://github.com/hanjinliu/napari-spreadsheet/issues,https://pypi.org/project/napari-spreadsheet/,,https://github.com/hanjinliu/napari-spreadsheet,A spreadsheet widget for napari,>=3.8,"['magicgui', 'napari', 'numpy', 'pandas', 'qtpy', 'tabulous (>=0.5.0)', ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# napari-spreadsheet

[![License BSD-3](https://img.shields.io/pypi/l/napari-spreadsheet.svg?color=green)](https://github.com/hanjinliu/napari-spreadsheet/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-spreadsheet.svg?color=green)](https://pypi.org/project/napari-spreadsheet)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-spreadsheet.svg?color=green)](https://python.org)
[![tests](https://github.com/hanjinliu/napari-spreadsheet/workflows/tests/badge.svg)](https://github.com/hanjinliu/napari-spreadsheet/actions)
[![codecov](https://codecov.io/gh/hanjinliu/napari-spreadsheet/branch/main/graph/badge.svg)](https://codecov.io/gh/hanjinliu/napari-spreadsheet)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-spreadsheet)](https://napari-hub.org/plugins/napari-spreadsheet)

Let's replace Microsoft Excel or Google Spreadsheet with `napari-spreadsheet` for your daily image analysis.

### Highlights

- Convert layer features to a spreadsheet.
- Update layer features from a spreadsheet.
- Send spreadsheet data to the namespace of napari's console directly.

![](https://github.com/hanjinliu/napari-spreadsheet/blob/main/images/image.png)

This plugin is largely dependent on [tabulous](https://github.com/hanjinliu/tabulous). To know more about the user interface, please see the [documentation](https://hanjinliu.github.io/tabulous/main/user_interface.html).

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-spreadsheet` via [pip]:

    pip install napari-spreadsheet



To install latest development version :

    pip install git+https://github.com/hanjinliu/napari-spreadsheet.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-spreadsheet"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hanjinliu/napari-spreadsheet/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hanjinliu/napari-spreadsheet/issues', 'Documentation, https://github.com/hanjinliu/napari-spreadsheet#README.md', 'Source Code, https://github.com/hanjinliu/napari-spreadsheet', 'User Support, https://github.com/hanjinliu/napari-spreadsheet/issues']",napari-spreadsheet.read_table_data,,napari-spreadsheet.make_qwidget,,"['*.txt', '*.dat', '*.csv', '*.xlsx']",,
413,napari-stable-diffusion,napari-stable-diffusion,Stable Diffusion,0.1.1,2022-10-27,2023-07-03,Kyle Harrington,napari@kyleharrington.com,BSD-3-Clause,https://github.com/kephale/napari-stable-diffusion/issues,https://pypi.org/project/napari-stable-diffusion/,,https://github.com/kephale/napari-stable-diffusion,A demo of stable diffusion in napari,>=3.8,"['napari', 'napari-plugin-engine (>=0.1.4)', 'numpy', 'magicgui', 'qtpy', 'diffusers', 'transformers', 'torch', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-stable-diffusion

[![License BSD-3](https://img.shields.io/pypi/l/napari-stable-diffusion.svg?color=green)](https://github.com/kephale/napari-stable-diffusion/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-stable-diffusion.svg?color=green)](https://pypi.org/project/napari-stable-diffusion)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-stable-diffusion.svg?color=green)](https://python.org)
[![tests](https://github.com/kephale/napari-stable-diffusion/workflows/tests/badge.svg)](https://github.com/kephale/napari-stable-diffusion/actions)
[![codecov](https://codecov.io/gh/kephale/napari-stable-diffusion/branch/main/graph/badge.svg)](https://codecov.io/gh/kephale/napari-stable-diffusion)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-stable-diffusion)](https://napari-hub.org/plugins/napari-stable-diffusion)

A demo of stable diffusion in napari.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

![demo image of napari-stable-diffusion of the prompt ""a unicorn and a dinosaur eating cookies and drinking tea""](https://github.com/kephale/napari-stable-diffusion/raw/main/napari_stable_diffusion_demo.png)

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-stable-diffusion` via [pip]:

    pip install napari-stable-diffusion

To install latest development version :

    pip install git+https://github.com/kephale/napari-stable-diffusion.git

You will also need to sign up with HuggingFace and [generate an access
token](https://huggingface.co/docs/hub/security-tokens) to get access to the
Stable Diffusion model we use.

When you have generated your access token you can either permanently
set the `HF_TOKEN_SD` environment variable in your `.bashrc` or whichever file
your OS uses, or you can include it on the command line

```
HF_TOKEN_SD=""hf_aaaAaaaasdadsadsaoaoaoasoidijo"" napari
```

For more information on the Stable Diffusion model itself, please see https://huggingface.co/CompVis/stable-diffusion-v1-4.

### Apple M1 specific instructions

To utilize the M1 GPU, the nightly version of PyTorch needs to be
installed. Consider using `conda` or `mamba` like this:

```
mamba create -c pytorch-nightly -n napari-stable-diffusion python=3.9 pip pyqt pytorch torchvision
pip install git+https://github.com/kephale/napari-stable-diffusion.git
```

## Next steps

- Image 2 Image support
- Inpainting support

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-stable-diffusion"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kephale/napari-stable-diffusion/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kephale/napari-stable-diffusion/issues', 'Documentation, https://github.com/kephale/napari-stable-diffusion#README.md', 'Source Code, https://github.com/kephale/napari-stable-diffusion', 'User Support, https://github.com/kephale/napari-stable-diffusion/issues']",,,napari-stable-diffusion.make_qwidget,,,,
414,napari-steinpose,napari-steinpose,napari Steinpose,0.1.0,2022-11-17,2022-11-17,Guillaume Witz,guillaume.witz@unibe.ch,BSD-3-Clause,https://github.com/guiwitz/napari-steinpose/issues,https://pypi.org/project/napari-steinpose/,,https://github.com/guiwitz/napari-steinpose,A plugin to process Imaging Mass Cytometry data with cellpose and steinbock,>=3.8,"['torch (==1.11.0)', 'cellpose', 'numpy', 'magicgui', 'qtpy', 'matplotlib', 'readimc', 'steinbock', 'pandas', 'aicsimageio', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest-order ; extra == 'testing'""]","# napari-steinpose

[![License BSD-3](https://img.shields.io/pypi/l/napari-steinpose.svg?color=green)](https://github.com/guiwitz/napari-steinpose/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-steinpose.svg?color=green)](https://pypi.org/project/napari-steinpose)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-steinpose.svg?color=green)](https://python.org)
[![tests](https://github.com/guiwitz/napari-steinpose/workflows/tests/badge.svg)](https://github.com/guiwitz/napari-steinpose/actions)
[![codecov](https://codecov.io/gh/guiwitz/napari-steinpose/branch/main/graph/badge.svg)](https://codecov.io/gh/guiwitz/napari-steinpose)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-steinpose)](https://napari-hub.org/plugins/napari-steinpose)

This napari plugin allows to segment and extract information from Imaging Mass Cytometry data by combining the [cellpose](http://www.cellpose.org/) and [steinbock](https://bodenmillergroup.github.io/steinbock/v0.14.2/) tools.

## Installation

In order to use this plugin, whe highly recommend to create a specific environment and to install the required software in it. You can create a conda environment using:

    conda create -n steinpose python=3.8.5 napari -c conda-forge

Then activate it and install the plugin:
    
    conda activate steinpose
    pip install napari-steinpose

### Potential issue with PyTorch

Cellpose and therefore the plugin and napari can crash without warning in some cases with ```torch==1.12.0```. This can be fixed by reverting to an earlier version using:
    
    pip install torch==1.11.0

### GPU

In order to use a GPU:

1. Uninstall the PyTorch version that gets installed by default with Cellpose:

        pip uninstall torch

2. Make sure your have up-to-date drivers for your NVIDIA card installed.

3. Re-install a GPU version of PyTorch via conda using a command that you can find [here](https://pytorch.org/get-started/locally/) (this takes care of the cuda toolkit, cudnn etc. so **no need to install manually anything more than the driver**). The command will look like this:

        conda install pytorch torchvision cudatoolkit=11.3 -c pytorch

### Plugin Updates

To update the plugin, you only need to activate the existing environment and install the new version:

    conda activate steinpose
    pip install git+https://github.com/guiwitz/napari-steinpose.git -U

## Usage

Here is a short summary on how to proceed to use the plugin. For more detailed information, please visit [this page](https://guiwitz.github.io/napari-steinpose).

### Load data

Using the ""Select data folder"" button, select a folder containing your .mcd files. The contents of the folder will appear in the List of images box. When you select one of the files it is loaded in the viewer. Using the ROI spinpox, you can change the roi (or acquisition) to be visualized.
### Segmentation

1. In the channels tab, choose the combination of channels to use to define images to segment. You can choose what type of projection (mean, min etc.) is used to combine channels. You can either select channels defining both cells and nuclei or just a single channel. **Note that if you want to just segment nuclei, you need to select them as ""cell channel"".**

2. To save the output, select a folder using the ""Select output folder"" button.

3. In the segmentation tab, pick a cellpose model to use. If you use one of the built-in models, you can specify the average diameter of objects to detect.

4. In the Options tab, you can set a few more options:
   - cellpose options: you can adjust the flow threshold and cell probabilities. If cells are missing try to use higher values of flow threshold (close to 1) and lower values for the cell probabilities (around -6)
   - segmentation options: you can decide to remove segmentation touching the image border, and you can also decide to expand the segmented objects by a fixed number of pixels. If a segmentation is displayed in the viewer, adjusting this parameter will live-adjust the mask.

5. You can first test the segmentation using the ""Run on current image"" button. Once segmentation is done, the corresponding mask is displayed. You can then run the segmentation over all ROIs of **all .mcd files** present in the folder by using the ""Run on folder"" button.

### Post-processing

In the Segmentation tab, if you tick the box ""Run steinbock post-processing"", information will directly be extracted from images and masks at the end of segmentation. Processing is done via steinbock and generates files compatible with further downstream processing.

In the Export tab, you can select what type of information to export: object intensities, geometric properties and object neighbourhood. Note that if you have performed a segmentation without post-processing, you can still run post-processing using the ""Run steinbock postproc"" button.

### Saving settings

To avoid having to re-type the same settings repeatedly, you can export a give configuration using the ""Export config"" button in the Options tab. This generates a human readable .yml file with:
- segmentation options
- channels selected for projections

The file is saved in the output folder. You can just copy the file in a new empty output folder to use it for an other analysis run. Once you select that folder containing a configuration file, you can import it with the ""Import config"" button. **Note that you need to have an image opened so that channels can be selected properly.**
## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-steinpose"" is free and open source software

## Authors

The author of this plugin is Guillaume Witz, Data Science Lab and Microscopy Imaging Center, University of Bern. This plugin is the result of a collaboration with the Imaging Mass Cytometry and Mass Cytometry Platform, University of Bern.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/guiwitz/napari-steinpose/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/guiwitz/napari-steinpose/issues', 'Documentation, https://github.com/guiwitz/napari-steinpose#README.md', 'Source Code, https://github.com/guiwitz/napari-steinpose', 'User Support, https://github.com/guiwitz/napari-steinpose/issues']",napari-steinpose.get_reader,,napari-steinpose.make_qwidget,,['*.mcd'],,
415,napari-stl-exporter,napari-stl-exporter,napari-stl-exporter,0.1.5,2021-10-06,2023-07-04,Johannes Soltwedel,johannes_richard.soltwedel@tu-dresden.de,BSD-3-Clause,https://github.com/jo-mueller/napari-stl-exporter/issues,https://pypi.org/project/napari-stl-exporter/,,https://github.com/jo-mueller/napari-stl-exporter.git,Exports label images to 3D-printable stl files.,>=3.7,"['napari', 'scikit-image', 'vedo (>=2023.4.6)', 'npe2', 'numpy']","# napari-stl-exporter

[![License](https://img.shields.io/pypi/l/napari-stl-exporter.svg?color=green)](https://github.com/jo-mueller/napari-stl-exporter/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-stl-exporter.svg?color=green)](https://pypi.org/project/napari-stl-exporter)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-stl-exporter.svg?color=green)](https://python.org)
[![tests](https://github.com/jo-mueller/napari-stl-exporter/workflows/tests/badge.svg)](https://github.com/jo-mueller/napari-stl-exporter/actions)
[![codecov](https://codecov.io/gh/jo-mueller/napari-stl-exporter/branch/main/graph/badge.svg?token=9zctLzazD9)](https://codecov.io/gh/jo-mueller/napari-stl-exporter)

This plugin allows to import and export surface data in Napari to common file formats. The generated file formats can be read by other common applications, and - in particular - allow *3D-printing*.

![](https://github.com/jo-mueller/napari-stl-exporter/raw/main/doc/model_and_printed_model.png)


### Supported file formats:
Currently supported file formats for export include and rely on the [vedo io API](https://vedo.embl.es/autodocs/content/vedo/io.html#vedo.io).
* *.stl*: [Standard triangle language](https://en.wikipedia.org/wiki/STL_%28file_format%29)
* *.ply*: [Polygon file format](https://en.wikipedia.org/wiki/PLY_(file_format))
* *.obj*: [Wavefront object](https://en.wikipedia.org/wiki/Wavefront_.obj_file)

### Supported Napari layers:

Currently supported Napari layer types are:
* [Surface layers](https://napari.org/howtos/layers/surface.html)
* [Label layers](https://napari.org/howtos/layers/labels.html): The label data is converted to surface data under the hood using the [marching cubes algorithm](https://scikit-image.org/docs/dev/api/skimage.measure.html#skimage.measure.marching_cubes) implemented in [scikit-image](https://scikit-image.org/) and is then exported using [Vedo](https://vedo.embl.es/). Warning: This can be slow for large image data!

### Import/export

**Interactively:** To export the data, simply save the selected layer with `File > Save Selected Layer(s)` and specify the file ending to be `some_file.[file_ending]`, for supported file types, see above. Similarly, supported file types can be imported into Napari with `File > `

**From code**: A [Napari Label layer](https://napari.org/api/napari.layers.Labels.html) can be added to the viewer as described in the [napari reference](https://napari.org/gallery/add_labels.html?highlight=add_labels) with this code snippet:

```python
import napari
import numpy as np

# Load and binarize image
label_image = np.zeros((100, 100, 100), dtype=int)
label_image[25:75, 25:75, 25:75] = 1

# Add data to viewer
viewer = napari.Viewer()
label_layer = viewer.add_labels(data, name='3D object')

# save the layer as 3D printable file to disc
napari.save_layers(r'/some/path/test.stl', [label_layer])
```

### Sample data
You can create sample label/surface data for export using the built-in functions as shown here:

![](https://github.com/jo-mueller/napari-stl-exporter/raw/main/doc/1_sample_data.png)

...or from code with

```Python
import napari_stl_exporter

pyramid = napari_stl_exporter.make_pyramid_surface()

```

### 3D-printing
To actually send your object to a 3D-printer, it has to be further converted to the *.gcode* format with a Slicer program. The latter convert the 3D object to machine-relevant parameters (printing detail, motor trajectories, etc). Popular slicers are:

* [Slic3r](https://slic3r.org/): Documentation [here](https://manual.slic3r.org/intro/overview)
* [Prusa Slicer](https://www.prusa3d.com/prusaslicer/): Tutorial [here](https://help.prusa3d.com/en/article/first-print-with-prusaslicer_1753)

*Note*: You can also upload the STL file to [github.com](https://github.com) and interact with it in the browser:

![](https://github.com/jo-mueller/napari-stl-exporter/raw/main/doc/pyramid_browser_screenshot.png)

#### Digital elevation models

DIgital elevation models (DEMs) can be printed with the napari-stl-exporter following these steps:

1. Go to the [open topography repository](https://portal.opentopography.org/raster?opentopoID=OTSDEM.032021.4326.2) and select a region of your choice, then download it as a GeoTiff file (`.tif`, intensity encodes elevation)
2. Open the downloaded tif image use the image conversion plugin (Â´Plugins > napari-stl-exporter > 2D image to surfaceÂ´) to convert the downloaded image to a surface. CHeck the `solidify` option to make it readily 3D-printable.

![](https://github.com/jo-mueller/napari-stl-exporter/raw/main/doc/landscape_to_surface.png)

3. Export the created surface layer as `.stl` or `.ply` file. Open it in your Slicer of choice (you may have to scale it according to the size limitations of your printer) and off you go!

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-stl-exporter` via [pip]:

    pip install napari-stl-exporter

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-stl-exporter"" is free and open source software

## Issues

If you encounter any problems, please [file an issue](https://github.com/jo-mueller/napari-stl-exporter/issues) along with a detailed description or post to image.sc and tag ```El_Pollo_Diablo```

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Project Site, https://github.com/jo-mueller/napari-stl-exporter', 'Report Issues, https://github.com/jo-mueller/napari-stl-exporter/issues', 'Documentation, https://pypi.org/project/napari-stl-exporter/', 'User Support, https://github.com/jo-mueller/napari-stl-exporter/issues', 'Twitter, https://twitter.com/jm_mightypirate']",napari-stl-exporter.import_surface,napari-stl-exporter.write_labels,napari-stl-exporter.convert_image_to_surface,napari-stl-exporter.make_pyramid_label,"['*.stl', '*.ply', '*.obj']","['.stl', '.ply', '.obj']","['.stl', '.ply', '.obj']"
416,napari-stracking,napari-stracking,napari-stracking,0.1.10,2021-08-11,2024-06-05,Sylvain Prigent,sylvain.prigent@inria.fr,BSD 3-Clause,https://github.com/sylvainprigent/napari-stracking/issues,https://pypi.org/project/napari-stracking/,,https://github.com/sylvainprigent/napari-stracking,Linking and tracks analysis,>=3.8,"['napari', 'napari-plugin-engine >=0.1.4', 'numpy', 'stracking >=0.1.10']","# napari-stracking

[![License](https://img.shields.io/pypi/l/napari-stracking.svg?color=green)](https://github.com/sylvainprigent/napari-stracking/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-stracking.svg?color=green)](https://pypi.org/project/napari-stracking)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-stracking.svg?color=green)](https://python.org)
[![tests](https://github.com/sylvainprigent/napari-stracking/workflows/tests/badge.svg)](https://github.com/sylvainprigent/napari-stracking/actions)
[![codecov](https://codecov.io/gh/sylvainprigent/napari-stracking/branch/master/graph/badge.svg)](https://codecov.io/gh/sylvainprigent/napari-stracking)

`napari-stracking` is a suite of **Napari** plugins for the [stracking library](
https://sylvainprigent.github.io/stracking/) dedicated to particles tracking in 2D+t and 3D+t images. Each step of
the tracking process is separated in independent plugins to ease the creation of pipelines.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-stracking` via [pip]:

    pip install napari-stracking

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-stracking"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/sylvainprigent/napari-stracking/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/sylvainprigent/napari-stracking/issues', 'Documentation, https://github.com/sylvainprigent/napari-stracking#README.md', 'Source Code, https://github.com/sylvainprigent/napari-stracking', 'User Support, https://github.com/sylvainprigent/napari-stracking/issues']",,,napari-stracking.SParticlesProperties,,,,
417,napari-stress,napari-stress,napari STRESS,0.4.2,2022-06-02,2025-06-13,"Johannes Soltwedel, Ben J. Gross, Elijah Shelton, Carlos Gomez, Otger Campas",johannes_richard.mueller@tu-dresden.de,"Copyright (c) 2022, Johannes M...",https://github.com/campaslab/napari-stress/issues,https://pypi.org/project/napari-stress/,,,Interactive surface analysis in napari for measuring mechanical stresses in biological tissues,>=3.9,"['dask', 'distributed', 'joblib', 'mpmath', 'napari', 'napari-tools-menu>=0.1.15', 'numpy<2.0.0', 'pandas', 'scikit-image', 'scipy>=1.9.0', 'seaborn', 'tqdm', 'napari-vedo-bridge>=0.2.2', 'vedo>=2023.5.0', 'vispy', 'deprecation', 'gdist', 'pygeodesic', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'pyqt5; extra == ""testing""']","[![License](https://img.shields.io/pypi/l/napari-stress.svg?color=green)](https://github.com/campaslab/napari-stress/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-stress.svg?color=green)](https://pypi.org/project/napari-stress)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-stress.svg?color=green)](https://python.org)
[![tests](https://github.com/campaslab/napari-stress/actions/workflows/test_and_deploy.yml/badge.svg)](https://github.com/campaslab/napari-stress/actions/workflows/test_and_deploy.yml)
[![codecov](https://codecov.io/gh/campaslab/napari-stress/branch/main/graph/badge.svg?token=ZXQGREJAT9)](https://codecov.io/gh/campaslab/napari-stress)
[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)
[![PyPI - Downloads](https://img.shields.io/pypi/dm/napari-stress.svg)](https://pypistats.org/packages/napari-stress)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-stress)](https://www.napari-hub.org/plugins/napari-stress)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.6607329.svg)](https://doi.org/10.5281/zenodo.6607329)

# napari-stress

This plugin provides tools for the analysis of surfaces in Napari, such as utilities to determine and refine the surface-representation of objects using a ray-casting approach and calculate the curvature of surfaces.
It re-implements code in Napari that was written for [Gross et al. (2021): STRESS, an automated geometrical characterization of deformable particles for in vivo measurements of cell and tissue mechanical stresses](https://www.biorxiv.org/content/10.1101/2021.03.26.437148v1)
and has been made open source in [this repository](https://github.com/campaslab/STRESS).

![](https://github.com/campaslab/napari-stress/raw/main/docs/imgs/function_gifs/spherical_harmonics.gif)

## Usage

For documentation on how to use napari-stress both interactively from the napari-viewer or from code, please visit the [**documentation**](https://campaslab.github.io/napari-stress/intro.html)


## Installation

Create a new conda environment with the following command.
If you have never used conda before, please [read this guide first](https://biapol.github.io/blog/mara_lampert/getting_started_with_mambaforge_and_python/readme.html).

```
conda create -n napari-stress Python=3.9 napari jupyterlab -c conda-forge
conda activate napari-stress
```

You can then install napari-stress using pip:

```
pip install napari-stress
```

## Issues

To report bugs, request new features or get in touch, please [open an issue](https://github.com/campaslab/napari-stress/issues) or tag `@EL_Pollo_Diablo` on [image.sc](https://forum.image.sc/).

## See also

There are other napari plugins with similar / overlapping functionality

* [morphometrics](https://www.napari-hub.org/plugins/morphometrics)
* [napari-pymeshlab](https://www.napari-hub.org/plugins/napari-pymeshlab)
* [napari-process-points-and-surfaces](https://www.napari-hub.org/plugins/napari-process-points-and-surfaces)

## Contributing

Contributions are very welcome. Tests can be run with [pytest], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-stress"" is free and open source software

## Acknowledgements
This project was supported by the Deutsche Forschungsgemeinschaft under Germanyâs Excellence Strategy â EXC2068 - Cluster of Excellence ""Physics of Life"" of TU Dresden.

[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[pytest]: https://docs.pytest.org/en/7.0.x/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/campaslab/napari-stress/issues', 'Documentation, https://campaslab.github.io/napari-stress', 'Source Code, https://github.com/campaslab/napari-stress', 'User Support, https://github.com/campaslab/napari-stress/issues']",,,napari-stress.rescale,napari-stress.get_pointcloud_sample_data,,,
418,napari-svetlana,napari-svetlana,Svetlana,1.6.1,2022-11-22,2025-04-07,ClÃ©ment Cazorla,clement.cazorla31@gmail.com,GPL-3.0-only,,https://pypi.org/project/napari-svetlana/,,,"A classification plugin for the ROIs of a segmentation mask. If you face problems opening the Napari-hub page, try replacing napari-svetlana by napari_svetlana in the URL.",>=3.9,"['napari-plugin-engine>=0.1.4', 'numpy', 'albumentations==1.0.3', 'joblib==1.2.0', 'light-the-torch', 'matplotlib', 'opencv-python==4.8.1.78', 'pyqtgraph==0.13.3', 'PyQt5', 'cucim==23.10.0; platform_system == ""Linux""', 'cupy-cuda115==10.6.0', 'xlsxwriter', 'pandas', 'npe2', 'pooch']","    # napari-svetlana

[![License](https://img.shields.io/pypi/l/napari_svetlana.svg?color=green)](https://bitbucket.org/koopa31/napari_svetlana/src/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari_svetlana.svg?color=green)](https://pypi.org/project/napari_svetlana)
[![Python Version](https://img.shields.io/pypi/pyversions/napari_svetlana.svg?color=green)](https://python.org)
[![tests](https://bitbucket.org/koopa31/napari_svetlana/workflows/tests/badge.svg)](https://bitbucket.org/koopa31/napari_svetlana/actions)
[![codecov](https://codecov.io/gh/koopa31/napari_svetlana/branch/main/graph/badge.svg)](https://codecov.io/gh/koopa31/napari_svetlana)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-svetlana)](https://napari-hub.org/plugins/napari-svetlana)
[![Documentation](https://readthedocs.org/projects/svetlana-documentation/badge/?version=latest)](https://svetlana-documentation.readthedocs.io/en/latest/)

The aim of this plugin is to classify the output of a segmentation algorithm.
The inputs are :
<ul>
  <li>A folder of raw images</li>
  <li>Their segmentation masks where each ROI has its own label.</li>
</ul>

Svetlana can process 2D, 3D and multichannel image. If you want to use it to work on cell images, we strongly
recommend the use of [Cellpose](https://www.cellpose.org) for the segmentation part, as it provides excellent quality results and a standard output format
accepted by Svetlana (labels masks). 

If you use this plugin please cite the [paper](https://www.nature.com/articles/s41598-024-60916-8): 

Cazorla, C., Weiss, P., & Morin, R. (2024). Svetlana: a Supervised Segmentation Classifier for Napari.

```bibtex
@article{cazorla2024svetlana,
  title={Svetlana a supervised segmentation classifier for Napari},
  author={Cazorla, Cl{\'e}ment and Morin, Renaud and Weiss, Pierre},
  journal={Scientific Reports},
  volume={14},
  number={1},
  pages={11604},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

```


![](https://bitbucket.org/koopa31/napari_svetlana/raw/bca8788111b38d97bd172c7caac87cc488ace699/images/Videogif.gif)


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

First install Napari in a Python 3.9 Conda environment following these instructions :

```bash
conda create -n svetlana_env python=3.9
conda activate svetlana_env
conda install pip
python -m pip install ""napari[all]""==0.4.17
```

Then, you can install `napari_svetlana` via [pip](https://pypi.org/project/napari-svetlana/), or directly from the Napari plugin manager (see Napari documentation):
```bash
pip install napari_svetlana
```
WARNING:

If you have a Cuda compatible GPU on your computer, some computations may be accelerated
using [Cupy](https://pypi.org/project/cupy/). Unfortunately, Cupy needs Cudatoolkit to be installed. This library can only be installed via 
Conda while the plugin is a pip plugin, so it must be installed manually for the moment:
```bash
conda install cudatoolkit=11.5 
```
Also note that the library ([Cucim](https://pypi.org/project/cucim/)) that we use to improve these performances, computing morphological operations on GPU
is unfortunately only available for Linux systems. Hence, if you are a Windows user, this installation is not necessary.

## Tutorial

Many advanced features are available in Svetlana, such as data augmentation or contextual information reduction, to optimize the performance of your classifier. Thus, we strongly encourage you to
check our [Youtube tutorial](https://www.youtube.com/watch?v=u_FKuHta-RE) and
our [documentation](https://svetlana-documentation.readthedocs.io/en/latest/).
A button called **TRY ON DEMO IMAGE** is available in the annotation plugin and enables you to apply the YouTube
tutorial to the same test images to learn how to use the plugin. Feel free to try it to test all the features
that Svetlana offers.

## Similar Napari plugins

Joel Luethi developed a similar method for objects classification called [napari feature classifier](https://www.napari-hub.org/plugins/napari-feature-classifier).
Also, [apoc](https://www.napari-hub.org/plugins/napari-accelerated-pixel-and-object-classification) by Robert Haase is available in Napari for pixels and objects classification.

## Contributing

Contributions are very welcome.

## License

Distributed under the terms of the [BSD-3] license,
""napari_svetlana"" is free and open source software

## Acknowledgements

The method was developed by [ClÃ©ment Cazorla](https://koopa31.github.io/), [Renaud Morin](https://www.linkedin.com/in/renaud-morin-6a42665b/?originalSubdomain=fr) and [Pierre Weiss](https://www.math.univ-toulouse.fr/~weiss/). And the plugin was written by
ClÃ©ment Cazorla. The project is co-funded by [Imactiv-3D](https://www.imactiv-3d.com/) and [CNRS](https://www.cnrs.fr/fr).

## Issues

If you encounter any problems, please [file an issue](https://bitbucket.org/koopa31/napari_svetlana/issues?status=new&status=open) along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']","['Bug Tracker, https://bitbucket.org/koopa31/napari_svetlana/issues?status=new&status=open', 'Documentation, https://svetlana-documentation.readthedocs.io/en/latest/', 'Source Code, https://bitbucket.org/koopa31/napari_svetlana/src/main/', 'User Support, https://bitbucket.org/koopa31/napari_svetlana/issues?status=new&status=open']",napari-svetlana.get_reader,napari-svetlana.write_image,napari-svetlana.Annotation,,['*.npy'],,
419,napari-subboxer,napari-subboxer,napari-subboxer,0.0.1,2021-11-22,2021-11-22,Alister Burt,alisterburt@gmail.com,BSD-3-Clause,https://github.com/alisterburt/napari-subboxer/issues,https://pypi.org/project/napari-subboxer/,,https://github.com/alisterburt/napari-subboxer,A napari plugin for interacting with electron cryotomograms,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari[pyqt5] (==0.4.12)', 'mrcfile', 'typer', 'eulerangles', 'starfile', 'einops', 'pydantic']","# napari-subboxer

[![License](https://img.shields.io/pypi/l/napari-subboxer.svg?color=green)](https://github.com/alisterburt/napari-subboxer/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-subboxer.svg?color=green)](https://pypi.org/project/napari-subboxer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-subboxer.svg?color=green)](https://python.org)
[![tests](https://github.com/alisterburt/napari-subboxer/workflows/tests/badge.svg)](https://github.com/alisterburt/napari-subboxer/actions)
[![codecov](https://codecov.io/gh/alisterburt/napari-subboxer/branch/master/graph/badge.svg)](https://codecov.io/gh/alisterburt/napari-subboxer)

A napari plugin for visualising and interacting with electron cryotomograms.


## Installation

You can install `napari-subboxer` via [pip]:

    pip install napari-subboxer

## Usage

This plugin provides a user interface for opening electron cryotomograms in 
napari as both volumes and slices through volumes.

![demo](https://user-images.githubusercontent.com/7307488/138575305-b05c4735-9c03-4629-bfb0-9612ea8f26fd.gif)

The plugin can be opened from the `plugins` menu in napari, or with 
`napari-subboxer` at the command line.

![plugins-menu](https://user-images.githubusercontent.com/7307488/138575015-00ea78d9-02c1-44bc-9034-0c0a7fa8d973.png)

```yaml
Usage: napari-subboxer [TOMOGRAM_FILE]

  An interactive tool for defining and applying relative transforms
  on sets of particles in napari.

Arguments:
  [TOMOGRAM_FILE]

Options:
  --help                          Show this message and exit.

```

## Contributing

Contributions are very welcome. 

## License

Distributed under the terms of the [BSD-3] license,
""napari-subboxer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/alisterburt/napari-subboxer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/alisterburt/napari-subboxer/issues', 'Documentation, https://github.com/alisterburt/napari-subboxer#README.md', 'Source Code, https://github.com/alisterburt/napari-subboxer', 'User Support, https://github.com/alisterburt/napari-subboxer/issues']",,,napari-subboxer.SubboxingWidget,,,,
420,napari-superres,napari-superres,superres,0.1.1,2023-06-29,2023-08-08,rocco.dantuono@hotmail.it,rocco.dantuono@hotmail.it,BSD-3-Clause,https://github.com/RoccoDAnt/napari-superres/issues,https://pypi.org/project/napari-superres/,,https://github.com/RoccoDAnt/napari-superres,Fluorescence Fluctuation-based Super Resolution (FF-SRM) Methods,>=3.8,"['matplotlib', 'magicgui', 'qtpy', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-superres

[![License BSD-3](https://img.shields.io/pypi/l/napari-superres.svg?color=green)](https://github.com/RoccoDAnt/napari-superres/blob/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-superres.svg?color=green)](https://pypi.org/project/napari-superres)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-superres.svg?color=green)](https://python.org)
[![tests](https://github.com/RoccoDAnt/napari-superres/workflows/tests/badge.svg)](https://github.com/RoccoDAnt/napari-superres/actions)
[![codecov](https://codecov.io/gh/RoccoDAnt/napari-superres/branch/main/graph/badge.svg)](https://codecov.io/gh/RoccoDAnt/napari-superres)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/RoccoDAnt/napari-superres)](https://napari-hub.org/plugins/napari-superres)


A collection of super-resolution microscopy FF-SRM methods.

Open-source implementation of methods for Fluorescence Fluctuation based Super Resolution Microscopy (FF-SRM):

Review: [Alva et al., 2022. âFluorescence Fluctuation-Based Super-Resolution Microscopy: Basic Concepts for an Easy Start.â Journal of Microscopy, August.](https://onlinelibrary.wiley.com/doi/10.1111/jmi.13135)

MSSR article: [Torres-GarcÃ­a, E., Pinto-CÃ¡mara, R., Linares, A. et al. Extending resolution within a single imaging frame. Nat Commun 13, 7452 (2022).](https://doi.org/10.1038/s41467-022-34693-9)

ESI article: [Idir Yahiatene, Simon Hennig, Marcel MÃ¼ller, Thomas Huser (2015/2016). ""Entropy-based Super-resolution Imaging (ESI): From Disorder to Fine Detail"" ACS Photonics 8, 2 (2015)](https://doi.org/10.1021/acsphotonics.5b00307)

SOFI article: [T. Dertinger, R. Colyer, G. Iyer, and J. Enderlein. Fast, background-free, 3D super-resolution optical fluctuation imaging (SOFI). PNAS 52, 106 (2009) ](https://doi.org/10.1073/pnas.0907866106)

SRRF article: [Gustafsson, N., Culley, S., Ashdown, G., D. M. Owen, P. Matos Pereira, and R. Henriques. Fast live-cell conventional fluorophore nanoscopy with ImageJ through super-resolution radial fluctuations. Nat Commun 7, 12471 (2016)](https://www.nature.com/articles/ncomms12471)

MUSICAL article: [K. Agarwal and R. Machan, Multiple Signal Classification Algorithm for super-resolution fluorescence microscopy, Nature Communications, vol. 7, article id. 13752, (2016)](https://www.nature.com/articles/ncomms13752)



Methods implemented:
- MSSR
- ESI
- SOFI
- SRRF
- MUSICAL
- Split channels


| **Super Resolution Radial Fluctuations (SRRF)**  | **Mean-Shift Super Resolution (MSSR)** | **Entropy-based Super-resolution Imaging (ESI)** |
| --- | --- | --- |
| ![](https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/Fig_7_SRRF_Alva_2022.png) | ![](https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/Fig_2a_MSSR_Garcia_2021.png) | ![](https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/Fig_6_ESI_Alva_2022.png) |
from Fig. 7 of [Alva et al., 2022](https://onlinelibrary.wiley.com/doi/10.1111/jmi.13135) | from Fig. 2 of [GarcÃ­a et al., 2021](https://www.biorxiv.org/content/10.1101/2021.10.17.464398v2.full)|  from Fig. 6 of [Alva et al., 2022](https://onlinelibrary.wiley.com/doi/10.1111/jmi.13135)|


Repositories available:
- [ESI](https://github.com/biophotonics-bielefeld/ESI) GitHub repository
- [PySOFI](https://github.com/xiyuyi-at-LLNL/pysofi) GitHub repository
- [MUSICAL](https://sites.google.com/site/uthkrishth/musical) Google site

----------------------------------


This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->


## Installation
First install napari viewer (if you haven't):

    conda create -y -n napari-env -c conda-forge python=3.9
    conda activate napari-env
    pip install ""napari[all]""

For details check: https://napari.org/stable/




You can install the plugin [graphically](https://github.com/LIBREhub/napari-LatAm-Workshop-2023/blob/napari-superres/docs/day3/napari-superres/napari-superres_installation_guide.pdf).

or install latest development version :

    pip install git+https://github.com/RoccoDAnt/napari-superres.git

You might need to install [git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git) first.

----------------------------------
Examples of use:

| **Original**  | **tMSSR** |
| --- | --- |
| <p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/single-frame-good-exposure.png"" width=100% height=100%> </p>| <p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/tmssr-mean-mag2.png"" width=48% height=48%> </p>|
| Parameters: | Amplification: 2, Order: 0, PSF FWHM: 6, <br> Interpolation: Bicubic, Statistical integration: CV*sigma |

| **Original**  | **ESI** |
| --- | --- |
| <p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/synt.png"" width=40% height=40%> </p> | <p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/ESI.png"" width=50% height=50%> </p> |
| Parameters: | image in output: 2, bins: 2, Order: 2 |

| **Original**  | **SOFI** |
| --- | --- |
|<p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/noSOFI.png"" width=100% height=100%> </p> | <p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/SOFI.png"" width=100% height=100%> </p> |
| Parameters: | Amplification factor: 2, Moment Order: 4, lambda parameter: 1.5, No. Iterations: 20, Window size: 100|

| **Original**  | **SRRF** |
| --- | --- |
|<p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/synt.png"" width=50% height=50%> </p> | <p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/SRRF.png"" width=50% height=50%> </p>|
| Parameters: | Amplification: 2, Spatial radius: 5, Symmetry Axis: 6, Start frame: 0, End frame: 48|

| **Original**  | **MUSICAL** |
| --- | --- |
| <p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/musical_mean.png"" width=70% height=100%> </p> | <p align=""center""> <img src=""https://raw.githubusercontent.com/RoccoDAnt/napari-superres/main/docs/MUSICAL-CardioMyoblast_Mitochondria.png"" width=70% height=100%> </p>|
| Parameters: | Emission [nm]: 510 NA: 1.4, Mag: 100, Pizel size: 8000, Threshold: -0.5, Alpha: 4, Subpixels per pixel: 20|
----------------------------------



## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-superres"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/RoccoDAnt/napari-superres/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/RoccoDAnt/napari-superres/issues', 'Documentation, https://github.com/RoccoDAnt/napari-superres#README.md', 'Source Code, https://github.com/RoccoDAnt/napari-superres', 'User Support, https://github.com/RoccoDAnt/napari-superres/issues']",napari-superres.get_reader,napari-superres.write_multiple,napari-superres.make_mssr_caller,,['*.npy'],,['.npy']
421,napari-swc-editor,napari-swc-editor,napari-swc-editor,0.0.5,2024-12-03,2025-01-05,ClÃ©ment Caporal,caporal.clement@gmail.com,"Copyright (c) 2024, ClÃ©ment Ca...",https://github.com/LaboratoryOpticsBiosciences/napari-swc-editor/issues,https://pypi.org/project/napari-swc-editor/,,,Use point and shape layer to edit swc format in napari,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'pandas', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-swc-editor

[![License BSD-3](https://img.shields.io/pypi/l/napari-swc-editor.svg?color=green)](https://github.com/LaboratoryOpticsBiosciences/napari-swc-editor/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-swc-editor.svg?color=green)](https://pypi.org/project/napari-swc-editor)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-swc-editor.svg?color=green)](https://python.org)
[![tests](https://github.com/LaboratoryOpticsBiosciences/napari-swc-editor/workflows/tests/badge.svg)](https://github.com/LaboratoryOpticsBiosciences/napari-swc-editor/actions)
[![codecov](https://codecov.io/gh/LaboratoryOpticsBiosciences/napari-swc-editor/branch/main/graph/badge.svg)](https://codecov.io/gh/LaboratoryOpticsBiosciences/napari-swc-editor)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-swc-editor)](https://napari-hub.org/plugins/napari-swc-editor)

Use point and shape layer to edit swc format in napari.

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Features


https://github.com/user-attachments/assets/cba1820f-d0b5-436c-a981-62bae0e1a6ba




### IO
#### READER
- Your .swc should follow the following specs: http://www.neuronland.org/NLMorphologyConverter/MorphologyFormats/SWC/Spec.html
- the reader will create 2 napari layer: `point_layer` and `shape_layer`. Only `point_layer` is interactive, `shape_layer` is used to render path between swc points.
- The raw swc can be accessed in the point layer metadata. Such as `point_layer.metadata[""raw_swc""]`
- A `pd.DataFrame` object is also saved in the metadata: `point_layer.metadata[""swc_data""]`
#### WRITER
- With the `point_layer` selected, you can use napari interface to save with `.swc` extension name.
- You can also do it in command line: `napari.save_layers('test.swc', [point_layer])`
### Napari Interface
#### Structure ID and point symbol
In swc, structure id allow to label the type of neuron structure the point belongs to. In this plugin by default, the points will follow this symbol mapping:
```python
SWC_SYMBOL = {
    0: ""clobber"",  # undefined
    1: ""star"",  # soma
    2: ""disc"",  # axon
    3: ""triangle_down"",  # basal dendrite
    4: ""triangle_up"",  # apical dendrite
}
```
![image](https://github.com/user-attachments/assets/618aa000-370d-43f9-8645-8a3b7e9b9739)

You can also visualize the swc data in a table using the widget under `Plugin > SWC Editor Widget`

![image](https://github.com/user-attachments/assets/ed43f4c2-582b-4bc1-bbb1-54e8d9487f1d)

When using the ""Show swc table"" you will have an interactive table widget:
- left-click on table: highlight + center on the corresponding point
- **double**-left-click on table: highlight + center on the correspongind point **+ zoom**
- selection on the point layer: highlight the corresponding row on the table

#### SWC Edition
**ALL INTERACTIONS ARE ONLY BOUND TO THE `point_layer`**
**THERE IS NO CTRL-Z (please save your progress)**
- **Add point**: You can edit the ""r"" and the ""structure_id"" using the `point_size` and `symbol` ![image](https://github.com/user-attachments/assets/44255691-ffa0-4f63-8368-499b0c8ff6a4)
- **Remove point**: (Select the point and press `1` or `suppr` or `delete`) All the link pointing to this point will be removed
- **Add edge**: Select 2 or more point(s) and press on your keyboard `l` (aka: link).
- **Remove edge**: Select 1 or more point(s) and press on your keyboard `u` (aka: unlink).

If you want to link point as you are adding them you have two solutions:
- press ""CTRL"" while you add points, this will create a link with the previously selected point
- use the `Plugin > SWC Editor Widget` Checkbox (""link previous node with new node (same as using CTRL+Click)""): when selected, all new points will be selected with the previously selected point

https://github.com/user-attachments/assets/273f1221-2882-4a7c-ab7f-6d3ecb7f3fa6

## Installation

You can install `napari-swc-editor` via [pip]:

    pip install napari-swc-editor







To install latest development version :

    pip install git+https://github.com/LaboratoryOpticsBiosciences/napari-swc-editor.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-swc-editor"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/LaboratoryOpticsBiosciences/napari-swc-editor/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/LaboratoryOpticsBiosciences/napari-swc-editor/issues', 'Documentation, https://github.com/LaboratoryOpticsBiosciences/napari-swc-editor#README.md', 'Source Code, https://github.com/LaboratoryOpticsBiosciences/napari-swc-editor', 'User Support, https://github.com/LaboratoryOpticsBiosciences/napari-swc-editor/issues']",napari-swc-editor.get_reader,napari-swc-editor.write_multiple,napari-swc-editor.swc_editor_widget,napari-swc-editor.make_sample_data,['*.swc'],,['.swc']
422,napari-swc-reader,napari-swc-reader,napari-swc-reader,0.1.3,2024-11-14,2024-11-14,ClÃ©ment Caporal,caporal.clement@gmail.com,"Copyright (c) 2024, ClÃ©ment Ca...",https://github.com/LaboratoryOpticsBiosciences/napari-swc-reader/issues,https://pypi.org/project/napari-swc-reader/,,,A simple napari plugin to load swc file to napari viewer,>=3.9,"['numpy', 'pandas', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""']","# napari-swc-reader

[![License BSD-3](https://img.shields.io/pypi/l/napari-swc-reader.svg?color=green)](https://github.com/LaboratoryOpticsBiosciences/napari-swc-reader/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-swc-reader.svg?color=green)](https://pypi.org/project/napari-swc-reader)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-swc-reader.svg?color=green)](https://python.org)
[![tests](https://github.com/LaboratoryOpticsBiosciences/napari-swc-reader/workflows/tests/badge.svg)](https://github.com/LaboratoryOpticsBiosciences/napari-swc-reader/actions)
[![codecov](https://codecov.io/gh/LaboratoryOpticsBiosciences/napari-swc-reader/branch/main/graph/badge.svg)](https://codecov.io/gh/LaboratoryOpticsBiosciences/napari-swc-reader)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-swc-reader)](https://napari-hub.org/plugins/napari-swc-reader)

A minimal napari plugin to load swc file to napari viewer.

![image](https://github.com/user-attachments/assets/1c9e5788-0e74-48ab-be0b-0fb74b35192c)


----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

## Features

- Load swc file(s) to napari viewer
- Display swc file(s) in napari viewer as points layers and lines layers
- Size of points and lines are using the radius of the swc file
- You can load an example swc from https://neuromorpho.org/dableFiles/jacobs/CNG%20version/204-2-6nj.CNG.swc or load it under `File` -> `Open Sample` -> `napari-swc-reader`

**Limitations:**
- Only support swc file(s) following specs http://www.neuronland.org/NLMorphologyConverter/MorphologyFormats/SWC/Spec.html 7 columns
- Cannot write swc file(s) to disk but you can access the raw swc data from the napari layers from `metadata` attribute with key `raw_swc`

**Roadmap:**
- Switch to use `napari.layers.Graph` [when it is available](https://github.com/napari/napari/issues/4274)

## Installation

You can install `napari-swc-reader` via [pip]:

    pip install napari-swc-reader


To install latest development version :

    pip install git+https://github.com/LaboratoryOpticsBiosciences/napari-swc-reader.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-swc-reader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/LaboratoryOpticsBiosciences/napari-swc-reader/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/LaboratoryOpticsBiosciences/napari-swc-reader/issues', 'Documentation, https://github.com/LaboratoryOpticsBiosciences/napari-swc-reader#README.md', 'Source Code, https://github.com/LaboratoryOpticsBiosciences/napari-swc-reader', 'User Support, https://github.com/LaboratoryOpticsBiosciences/napari-swc-reader/issues']",napari-swc-reader.get_reader,,,napari-swc-reader.make_sample_data,['*.swc'],,
423,napari-svg,napari-svg,napari SVG,0.2.1,2021-05-01,2025-01-14,"Nicholas Sofroniew, napari core devs","Nicholas Sofroniew <sofroniewn@gmail.com>, napari core devs <napari-core-devs@googlegroups.com>",BSD-3,https://github.com/napari/napari-svg/issues,https://pypi.org/project/napari-svg/,,,A plugin for writing svg files with napari,>=3.9,"['imageio>=2.5.0', 'numpy>=1.16.0', 'vispy>=0.6.4', 'napari>=0.4; extra == ""testing""', 'pyqt5; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""']","# napari-svg

[![License](https://img.shields.io/pypi/l/napari-svg.svg?color=green)](https://github.com/napari/napari-svg/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-svg.svg?color=green)](https://pypi.org/project/napari-svg)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-svg.svg?color=green)](https://python.org)
[![tests](https://github.com/napari/napari-svg/workflows/tests/badge.svg)](https://github.com/napari/napari-svg/actions)
[![codecov](https://codecov.io/gh/napari/napari-svg/branch/master/graph/badge.svg)](https://codecov.io/gh/napari/napari-svg)

A plugin for writing svg files with napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-svg` via [pip]:

    pip install napari-svg

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-svg"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/napari/napari-svg/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Source, https://github.com/napari/napari-svg', 'Bug Tracker, https://github.com/napari/napari-svg/issues']",,napari-svg.svg_writer,,,,['.svg'],
424,napari-tabu,napari-tabu,napari-tabu,0.1.5,2021-10-14,2022-01-01,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-tabu/issues,https://pypi.org/project/napari-tabu/,,https://github.com/haesleinhuepf/napari-tabu,A plugin for handling multiple napari windows,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari', 'napari-tools-menu']","# napari-tabu

[![License](https://img.shields.io/pypi/l/napari-tabu.svg?color=green)](https://github.com/haesleinhuepf/napari-tabu/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tabu.svg?color=green)](https://pypi.org/project/napari-tabu)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tabu.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-tabu/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-tabu/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-tabu/branch/master/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-tabu)

A plugin for handling multiple napari windows
![](https://github.com/haesleinhuepf/napari-tabu/raw/main/docs/napari-tabu-screencast.gif)

----------------------------------

## Usage

To open a new window, first click the menu `Plugins > napari-tabu: open new window`
![](https://github.com/haesleinhuepf/napari-tabu/raw/main/docs/new_window_menu.png)

Afterwards, select the layer which should be opened in the new window and click on `Run`:
![](https://github.com/haesleinhuepf/napari-tabu/raw/main/docs/new_window_dialog.png)

When you're done with working with the new window, you can send back the result of your work using the `Send current layer back to main napari` butoon:
![](https://github.com/haesleinhuepf/napari-tabu/raw/main/docs/send_back.png)

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-tabu` via [pip]:

    pip install napari-tabu

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-tabu"" is free and open source software

## Issues

If you encounter any problems, please open a thread on [image.sc](https://image.sc) along with a detailed description and tag [@haesleinhuepf](https://github.com/haesleinhuepf).

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-tabu/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-tabu/issues', 'Documentation, https://github.com/haesleinhuepf/napari-tabu#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-tabu', 'User Support, https://github.com/haesleinhuepf/napari-tabu/issues']",,,napari-tabu.napari_experimental_provide_function,,,,
425,napari-tapenade-processing,napari-tapenade-processing,Tapenade Processing,0.0.14,2024-08-13,2025-06-13,Jules Vanaret,jules.vanaret@univ-amu.fr,MIT,https://github.com/jules-vanaret/napari-tapenade-processing/issues,https://pypi.org/project/napari-tapenade-processing/,,https://github.com/jules-vanaret/napari-tapenade-processing,A visual pipeline to process images with Tapenade in Napari,>=3.8,"['numpy', 'magicgui', 'qtpy', 'tifffile', 'natsort', 'tapenade>=0.0.18', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# :herb: napari-tapenade-processing

[![License MIT](https://img.shields.io/pypi/l/napari-tapenade-processing.svg?color=green)](https://github.com/jules-vanaret/napari-tapenade-processing/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tapenade-processing.svg?color=green)](https://pypi.org/project/napari-tapenade-processing)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tapenade-processing.svg?color=green)](https://python.org)
[![tests](https://github.com/jules-vanaret/napari-tapenade-processing/workflows/tests/badge.svg)](https://github.com/jules-vanaret/napari-tapenade-processing/actions)
[![codecov](https://codecov.io/gh/jules-vanaret/napari-tapenade-processing/branch/main/graph/badge.svg)](https://codecov.io/gh/jules-vanaret/napari-tapenade-processing)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-tapenade-processing)](https://napari-hub.org/plugins/napari-tapenade-processing)

<img src=""https://github.com/GuignardLab/tapenade/blob/main/imgs/tapenade3.png"" width=""100"">

A collection of methods to process images of deep 3D/3D+time tissues in Napari.

`napari-tapenade-processing` is a [napari] plugin that is part of the [Tapenade](https://github.com/GuignardLab/tapenade) project. Tapenade is a tool for the analysis of dense 3D tissues acquired with deep imaging microscopy. It is designed to be user-friendly and to provide a comprehensive analysis of the data.

If you use this plugin for your research, please [cite us](https://github.com/GuignardLab/tapenade/blob/main/README.md#how-to-cite).

## Overview

<img src=""imgs/napari_preproc_demo.gif""/>

While working with large and dense 3D and 3D+time gastruloid datasets, we found that being able to visualise and interact with the data dynamically greatly helped processing it.
During the pre-processing stage, dynamical exploration and interaction led to faster tuning of the parameters by allowing direct visual feedback, and gave key biophysical insight during the analysis stage.

From a given set of raw images, segmented object instances, and object mask, the plugin allows the user to quickly run all pre-processing functions from our main pipeline with custom parameters while being able to see and interact with the result of each step. For large datasets that are cumbersome to manipulate or cannot be loaded in Napari, the plugin provides a macro recording feature: the users can experiment and design their own pipeline on a smaller subset of the dataset, then run it on the full dataset without having to load it in Napari.

<img src=""imgs/Fig_Napari_preprocessing.png"">

## Installation

The plugin obviously requires [napari] to run. If you don't have it yet, follow the instructions [here](https://napari.org/stable/tutorials/fundamentals/installation.html).

The simplest way to install `napari-tapenade-processing` is via the [napari] plugin manager. Open Napari, go to `Plugins > Install/Uninstall Packages...` and search for `napari-tapenade-processing`. Click on the install button and you are ready to go!

You can also install `napari-tapenade-processing` via [pip]:

    pip install napari-tapenade-processing

To install latest development version :

    pip install git+https://github.com/jules-vanaret/napari-tapenade-processing.git

## Usage

### General overview of the plugin within Napari

<img src=""imgs/proc_0.png"">

To start a pre-processing pipeline, follow these steps:

1. First, load your images in Napari. You can drag and drop them from your file explorer to the Napari viewer, or open them using the `File > Open files...` menu.
2. Click on the `Plugins > Tapenade Processing` menu to open the plugin.
3. The image you have loaded will be displayed as individual layers in the Layer List. They can be clicked-on to reveal a set of visual parameters (see 4) that can be adjusted. By double-clicking on a layer name, you can change it. Right-clicking a layer will give you several options. The little eye icon next to the layer name can be clicked to hide the layer.
4. You can adjust visual parameters for each layer, like the contrast limits, the colormap, the opacity, the blending mode, etc.
5. If you want to switch between 2D and 3D views, click on the `Toggle 2D/3D view` button (it resembles a square when in 2D mode, or a cube when in 3D mode).
6. You can toggle the grid view (as shown in the example image) by clicking on the `Toggle grid mode` button. By right-clicking the button, you can parametrize the grid view (e.g number of columns, number of rows, etc).
7. The plugin is composed of three tabs. The first tab is dedicated to pre-processing functions, the second tab is dedicated to the macro recording feature, and the third tab is dedicated to advanced parameters.

### Tab 1: The pre-processing functions

<img src=""imgs/proc_1.png"" width=300>

The pre-processing tab is composed of the following elements:

1. A combo box to select the pre-processing function to apply from a list.
2. A set of comboxes that allow you to select the layers to apply the function on. If a function does not require a specific layer, the combo box will be greyed out. `Image` layers correspond to integer or float data, `Labels` layers correspond to integer data and represent segmented object instances, `Mask` layers correspond to boolean data and usually represent the sample's large scale mask (inside/outside). All layers must have data of the same shape (same number of dimensions and same dimensions). Layers can be 3D or 3D+time, respectively with the ZYX or TZYX order.
(2') If a layer does not appear in a combo box, but is present in the Layer List, you can click on the `Refresh` button to update the list of layers.
3. A set of parameters that you can tune to adjust the function's behaviour. The parameters are specific to each function. In case of doubt, you can click on the little `[?]` button next to the widget to get a tooltip with a description.
4. A `Run function` button to apply the function with the current parameters to the previously selected layers.


### Tab 2: The macro recording feature

#### A. Recording a macro

<img src=""imgs/proc_macro_1.png"" width=300>

To record a macro, click on the `Macro recording` tab and follow these steps:

1. Click on `Choose directory` to select a folder where the macro file will be saved.
2. Click on `Start recording macro` to start recording the functions you will apply. At this point, you can start applying sequences of functions to images/segementations/masks that you have already loaded in Napari or that you load in the middle of the recording. 

<img src=""imgs/proc_macro_2.png"" width=300>

3. When you are finished, click `Stop recording and save macro`. It will be saved in the JSON (`.json`) format, and the name will follow the pattern `recorder_parameters_YYYY-MM-DD_HH-MM-SS.json`.

#### B. Running a macro

Macros allow you to run a sequence of functions in batch on folders of input TIFF images (either different frames of the same 3D+t image, or several 3D images). The input images should be in the same folder, and the output will be saved in a folder of your choice. The output of each function will be saved in a separate folder, and the name of the folder will be linked to the name of the function.

<img src=""imgs/proc_macro_3.png"" width=300>

To run a macro, click on the `Macro recording` tab and follow these steps:

1. Click on `Select file` to choose the macro file you want to run.
2. After specifying the path to the macro file, several path entries with names like `Path to folder ([...]) N` (e.g `Path to folder (['Image'] 1`) will appear. Click on the `Choose directory` button to select the folder where the input images (TIFF files) are located.
3. Click on `Choose directory` under `Path to save outputs folders of tifs` to select the folder where the results of the pipeline will be saved. Each function call will generate a folder whose name will be linked to the name of the function.
4. You can click the `Compress when saving` checkbox to save the output TIFF images in a compressed format using ZLIB compression. 
5. Choose the number of workers to use for parallel processing. The default value is 1, which means that the functions will be run sequentially on the images. If you have a multi-core CPU, you can increase this value to speed up the processing. Be careful that setting this value too high can lead to memory issues.
6. Click on `Run macro` to start the processing. You will see as many folders as there are steps in your pipeline, containing the results on each frame.


### Tab 3: Advanced parameters

<img src=""imgs/proc_2.png"" width=300>

The advanced parameters tab is composed of the following elements:

1. A checkbox `New layers overwrite previous ones`: whether the output of the pre-processing functions should be saved as new layers or overwrite the previous ones that were used as input. This can be useful to save memory when you don't need to compare the input and output of a function.

## Demo dataset

A demo dataset is available [here](https://amubox.univ-amu.fr/s/MRdFy3KqQNjpyHa).

### Content

This test dataset is composed of a folder `folder_raw_data` which contains 5 separate frames (3D images), and a macro Json file `recorder_parameters.json`.  

### How to use

 - Download the folder `folder_raw_data`. 
 - Load one of the image from the folder (either drag and drop, or `File>Open file(s)`) and start creating your own pipeline.
 - To try batch processing through the macro feature, click on the `Macro recording tab`, choose a path to save the macro Json file, click on `Start recording macro`, and perform a sequence of function runs of your choice. When you are finished, click `Stop recording and save macro`. Then specify the path to your macro file below (alternatively, a valid Json file is also made available), the folder where the rest of the frames are located, and the folder where the results of the pipeline will be saved. Click on run macro. You should see as many folders as there are steps in your pipeline, containing the results on each frame.


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-tapenade-processing"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.


----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/jules-vanaret/napari-tapenade-processing/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/jules-vanaret/napari-tapenade-processing/issues', 'Documentation, https://github.com/jules-vanaret/napari-tapenade-processing#README.md', 'Source Code, https://github.com/jules-vanaret/napari-tapenade-processing', 'User Support, https://github.com/jules-vanaret/napari-tapenade-processing/issues']",,,napari-tapenade-processing.tapenade_processing,,,,
426,napari-tardis-em,napari-tardis-em,TARDIS-em napari plugin,0.3.18,2024-07-22,2025-08-01,Robert Kiewisz,rkiewisz@nysbc.org,MIT,,https://pypi.org/project/napari-tardis-em/,None,,Tomogram and micrograph segmentation with TARDIS-em,>=3.10,"['setuptools>=70.3.0', 'napari>=0.5.0', 'torch>=2.2.2', 'tardis_em[nd2]>=0.3.18', 'numpy>=2.0.0', 'matplotlib>=3.9.1', 'qtpy>=2.4.1', 'pyqt5>=5.15.10', 'opencv-python', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# Napari plugin for TARDIS-em

Napari [gen2] plugin for Cry-EM and Cryo-ET micrograph segmentation with TARDIS-em.
","['Development Status :: 5 - Production/Stable', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-tardis-em.import_data,,napari-tardis-em.viewer_train,,"['*.mrc', '*.rec', '*.tif', '*.tiff', '*.nd2', '*.csv', '*.am']",,
427,napari-text-layer,napari-text-layer,napari-text-layer,0.1.2,2021-12-04,2021-12-13,Hanjin Liu,liuhanjin-sc@g.ecc.u-tokyo.ac.jp,BSD 3-Clause,,https://pypi.org/project/napari-text-layer/,UNKNOWN,UNKNOWN,Text layer for bio-image annotation.,>=3.7,,"# napari-text-layer

Napari text layer for bio-image annotation.

![](https://github.com/hanjinliu/napari-text-layer/raw/main/GIFs/annot.gif)

![](https://github.com/hanjinliu/napari-text-layer/raw/main/GIFs/age.gif)

### Installation

You can install using pip:

```
pip install napari-text-layer
```

### Keybindings and mouse callbacks

- ""&rarr;"", ""&larr;"", ""&uarr;"", ""&darr;"" ... Move selected shapes by 1 pixel.
- ""F2"" ... Enter edit mode at the selected shape (or the last one if no shape is selected).
- ""Enter"" ... Finish edit mode or add a new shape at the same interval.
- ""Ctrl"" + ""Shift"" + ""<"" or "">"" ... Change font size.
- double click ... Enter edit mode at the clicked shape.


","['Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9']",,,,napari-text-layer.TextLayerOverview,,,,
428,napari-tiff,napari-tiff,napari-tiff,0.1.4,2024-02-14,2025-05-27,"Genevieve Buckley, napari-tiff contributors",napari core developers <napari-core-devs@googlegroups.com>,"Copyright (c) 2020, Genevieve ...",https://github.com/napari/napari-tiff/issues,https://pypi.org/project/napari-tiff/,,,official napari tiff reader and writer.,>=3.10,"['numpy', 'tifffile[codecs,zarr]>=2024.7.21', 'build; extra == ""testing""', 'pytest; extra == ""testing""', 'tox; extra == ""testing""']","# napari-tiff

[![License](https://img.shields.io/pypi/l/napari-tiff.svg?color=green)](https://github.com/napari/napari-tiff/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tiff.svg?color=green)](https://pypi.org/project/napari-tiff)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tiff.svg?color=green)](https://python.org)
[![tests](https://github.com/napari/napari-tiff/workflows/test-and-deploy/badge.svg)](https://github.com/napari/napari-tiff/actions)
[![codecov](https://codecov.io/gh/napari/napari-tiff/branch/main/graph/badge.svg)](https://codecov.io/gh/napari/napari-tiff)

A napari plugin for tiff images.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-tiff` via [pip]:

    pip install napari-tiff

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-tiff"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/napari/napari-tiff/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Intended Audience :: Education', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Software Development :: Libraries', 'Topic :: Scientific/Engineering', 'Programming Language :: Python :: Implementation :: CPython', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['source, https://github.com/napari/napari-tiff', 'tracker, https://github.com/napari/napari-tiff/issues']",napari-tiff.get_reader,,,,"['*.zip', '*.tiff', '*.tif', '*.ome.tif', '*.lsm', '*.stk', '*.qpi', '*.pcoraw', '*.qptiff', '*.ptiff', '*.ptif', '*.gel', '*.seq', '*.svs', '*.scn', '*.zif', '*.ndpi', '*.bif', '*.tf8', '*.tf2', '*.btf', '*.eer']",,
429,napari-threedee,napari-threedee,napari-threedee,0.0.29,2022-06-10,2025-07-08,napari team,napari team <napari-steering-council@googlegroups.com>,BSD-3-Clause,https://github.com/napari-threedee/napari-threedee/issues,https://pypi.org/project/napari-threedee/,,,A suite of useful tools based on 3D interactivity in napari,>=3.10,"['einops', 'imageio!=2.11.0,!=2.22.1,>=2.5.0', 'libigl', 'magicgui', 'morphosamplers', 'mrcfile', 'napari>=0.5.0', 'numpy', 'pandas', 'pooch', 'psygnal', 'pydantic', 'qtpy', 'scipy', 'superqt', 'vispy', 'zarr<3', ""lxml[html-clean]>5; extra == 'dev'"", ""mkdocs; extra == 'dev'"", ""mkdocs-gallery>0.7.6; extra == 'dev'"", ""mkdocs-material; extra == 'dev'"", ""mkdocs-video; extra == 'dev'"", ""mkdocstrings[python]; extra == 'dev'"", ""pytest; extra == 'dev'"", ""pytest-qt; extra == 'dev'"", ""qtgallery; extra == 'dev'"", ""scikit-image[data]; extra == 'dev'""]","# napari-threedee

[![License](https://img.shields.io/pypi/l/napari-threedee.svg?color=green)](https://github.com/alisterburt/napari-threedee/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-threedee.svg?color=green)](https://pypi.org/project/napari-threedee)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-threedee.svg?color=green)](https://python.org)
[![tests](https://github.com/napari-threedee/napari-threedee/workflows/tests/badge.svg)](https://github.com/napari-threedee/napari-threedee/actions)
[![codecov](https://codecov.io/gh/napari-threedee/napari-threedee/branch/main/graph/badge.svg)](https://codecov.io/gh/napari-threedee/napari-threedee)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-threedee)](https://napari-hub.org/plugins/napari-threedee)

A suite of useful tools based on 3D interactivity in napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-threedee` via [pip]:

    pip install napari-threedee



To install latest development version :

    pip install git+https://github.com/alisterburt/napari-threedee.git

## Example applications

See the full list of [example gallery scripts here on our website](https://napari-threedee.github.io/generated/gallery/).

<table border=""0"">
<tr><td>


<img src=""https://user-images.githubusercontent.com/1120672/173021751-9206de7d-5675-4aac-aa9e-8585457a7799.gif""
width=""300""/>

</td><td>

[mesh lighting control](https://github.com/napari-threedee/napari-threedee/blob/main/docs/examples/plugin/mesh_headlight_plugin.py)

</td></tr><tr><td>

<img src=""https://user-images.githubusercontent.com/1120672/173022286-2473b6b2-a20e-4514-88a4-8295e001f099.gif""
width=""300""/>

</td><td>

[annotate points on planes](https://github.com/napari-threedee/napari-threedee/blob/main/docs/examples/plugin/point_annotator_plugin.py)

</td></tr><tr><td>

<img src=""https://user-images.githubusercontent.com/1120672/173023185-b6936d1d-590c-4b9b-816a-3779dfe774da.gif""
width=""300""/>

</td><td>

[render plane manipulator](https://github.com/napari-threedee/napari-threedee/blob/main/docs/examples/plugin/render_plane_manipulator_plugin.py)

</td></tr><tr><td>

<img src=""https://user-images.githubusercontent.com/1120672/173023795-7150d3c2-d3d1-4913-981d-1092c1b59f21.gif""
width=""300""/>

</td><td>

[layer manipulator](https://github.com/napari-threedee/napari-threedee/blob/main/docs/examples/plugin/layer_manipulator_plugin.py)

</td></tr><tr><td>

<img src=""https://user-images.githubusercontent.com/1120672/173024361-2f05c68b-e94d-4734-9f5e-1606391e6463.gif""
width=""300""/>

</td><td>

[point manipulator](https://github.com/napari-threedee/napari-threedee/blob/main/docs/examples/plugin/points_manipulator_plugin.py)


</td></tr></table>


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-threedee"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/alisterburt/napari-threedee/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Software Development :: Testing']","['homepage, https://github.com/alisterburt/napari-threedee', 'repository, https://github.com/napari-threedee/napari-threedee', 'Bug Tracker, https://github.com/napari-threedee/napari-threedee/issues', 'Documentation, https://github.com/napari-threedee/napari-threedee#README.md', 'Source Code, https://github.com/napari-threedee/napari-threedee', 'User Support, https://github.com/napari-threedee/napari-threedee/issues']",,,napari-threedee.QtPointAnnotatorWidget,napari-threedee.hiv_particles,,,
430,napari-tiledb-bioimg,napari-tiledb-bioimg,napari TileDB bioimaging,0.0.1,2023-05-12,2023-05-12,"TileDB, Inc.",help@tiledb.io,MIT,https://github.com/TileDB-Inc/napari-tiledb-bioimg,https://pypi.org/project/napari-tiledb-bioimg/,,https://github.com/TileDB-Inc/napari-tiledb-bioimg,Support reading and writing TileDB-Bioimaging image arrays within Napari,>=3.8,"['dask', 'tiledb-bioimg (>=0.2.1)', ""tiledb-cloud ; extra == 'cloud'"", ""napari ; extra == 'testing'"", ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# napari-tiledb-bioimg

[![License MIT](https://img.shields.io/pypi/l/napari-tiledb-bioimg.svg?color=green)](https://github.com/TileDB-Inc/napari-tiledb-bioimg/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tiledb-bioimg.svg?color=green)](https://pypi.org/project/napari-tiledb-bioimg)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tiledb-bioimg.svg?color=green)](https://python.org)
[![tests](https://github.com/TileDB-Inc/napari-tiledb-bioimg/workflows/tests/badge.svg)](https://github.com/TileDB-Inc/napari-tiledb-bioimg/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-tiledb-bioimg)](https://napari-hub.org/plugins/napari-tiledb-bioimg)

This plugin supports reading and writing TileDB-BioImaging multi-resolution arrays within Napari.

----------------------------------

## Demo

https://github.com/TileDB-Inc/napari-tiledb-bioimg/assets/327706/b408d634-6ad0-4160-8571-18cf8e37b4cc

## Installation

[pending PyPI release!] You can install `napari-tiledb-bioimg` via [pip]:

    pip install napari-tiledb-bioimg

## Quickstart

After [ingesting data using `tiledb-bioimg`](https://github.com/TileDB-Inc/TileDB-BioImaging#examples), then:

- Local images can be loaded using Napari's `File -> Open Folder`, and selecting the TileDB array folder. Choose the `napari-tiledb-bioimg` plugin, if prompted.

- Remote arrays (S3, TileDB Cloud) may be loaded using either the `napari` CLI command:

```
napari --plugin napari-tiledb-bioimg s3://<bucket>/<path/to/tiledb_array>
```

- ... or the Napari viewer load command within the Python prompt:

```
# Within a Napari-enabled Python/IPython prompt, run:
import napari
viewer = napari.Viewer()

viewer.open(""tiledb://<namespace>/<array name or UUID>"", plugin=""napari-tiledb-bioimg"")
```


## Contributing

Contributions are very welcome. Tests can be run with tox or pytest.

### Installation from git:

```
pip install git+https://github.com/TileDB-Inc/napari-tiledb-bioimg.git
```

## License

Distributed under the terms of the [MIT] license,
""napari-tiledb-bioimg"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue](https://github.com/TileDB-Inc/napari-tiledb-bioimg/issues/new) along with a detailed description.
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,napari-tiledb-bioimg.get_reader,napari-tiledb-bioimg.write_image_lossless,napari-tiledb-bioimg.make_qwidget,,"['tiledb://*', 's3://*', '*.tdb', '*.tiledb']",,
431,napari-tiler,napari-tiler,napari-tiler,0.0.9,2021-12-13,2021-12-29,Tim Morello,tdmorello@gmail.com,LICENCE,https://github.com/tdmorello/napari-tiler/issues,https://pypi.org/project/napari-tiler/,,,N-dimensional tiling and merging support for napari,">=3.7,<3.11","['importlib-metadata (<4.3); python_version < ""3.8""', 'napari-plugin-engine (>=0.2.0,<0.3.0)', 'napari-tools-menu (>=0.1.7,<0.2.0)', 'numpy (>=1.21.4,<2.0.0)', 'tiler (>=0.4.1,<0.5.0)']","# napari-tiler

[![License](https://img.shields.io/pypi/l/napari-tiler.svg?color=green)](https://github.com/tdmorello/napari-tiler/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tiler.svg?color=green)](https://pypi.org/project/napari-tiler)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tiler.svg?color=green)](https://python.org)
[![tests](https://github.com/tdmorello/napari-tiler/workflows/tests/badge.svg)](https://github.com/tdmorello/napari-tiler/actions)
[![codecov](https://codecov.io/gh/tdmorello/napari-tiler/branch/main/graph/badge.svg)](https://codecov.io/gh/tdmorello/napari-tiler)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-tiler)](https://napari-hub.org/plugins/napari-tiler)
[![PyPI - Downloads](https://img.shields.io/pypi/dm/napari-tiler.svg)](https://pypistats.org/packages/napari-tiler)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/python/black)
[![Development Status](https://img.shields.io/pypi/status/napari-tiler.svg)](https://github.com/tdmorello/napari-tiler)

N-dimensional tiling and merging support for napari

This plugin allows the user to split an image into a stack of tiles and subsequently merge the tiles to reconstruct the orignal image.
See [Tiler](https://pypi.org/project/tiler/) by [@thelay](https://github.com/the-lay) for more details.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

### Option 1 (recommended)

You can install `napari-tiler` from the napari plugin manager. Go to `Plugins -> Install/Uninstall Package(s)`, then search for `napari-tiler`. Click `Install`.

### Option 2

You can also install `napari-tiler` via [pip]:

    pip install napari-tiler

To install latest development version:

    pip install git+https://github.com/tdmorello/napari-tiler.git

## Quick Start

1. Open a file in napari. The file may have any number of dimensions (e.g. z-stack, time series, ...)
2. Start the plugin ( `Plugins -> napari-tiler: make_tiles` )
3. Select the input layer from the dropdown box
4. Select parameters for tiling
5. Click `Run`

## Contributing

This project uses [Poetry](https://github.com/python-poetry/poetry) for dependency management.
To set up the development environment, it is recommended to use:

    conda env create -f environment.yaml

Contributions are very welcome. Tests can be run with [tox], please ensure the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-tiler"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/tdmorello/napari-tiler/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/

","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'License :: Other/Proprietary License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/tdmorello/napari-tiler/issues', 'Documentation, https://github.com/tdmorello/napari-tiler#README.md', 'Source Code, https://github.com/tdmorello/napari-tiler', 'User Support, https://github.com/tdmorello/napari-tiler/issues']",,,napari-tiler.TilerWidget,,,,
432,napari-timelapse-processor,napari-timelapse-processor,Timelapse Processor,0.1.1,2024-07-15,2025-06-16,Johannes Soltwedel,johannes_richard.soltwedel@tu-dresden.de,"Copyright (c) 2024, Johannes S...",https://github.com/jo-mueller/napari-timelapse-processor.git,https://pypi.org/project/napari-timelapse-processor/,,,meta plugin to ease processing timelapse image data,>=3.9,"['numpy', 'tqdm', 'napari', 'dask', 'distributed', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""']","# napari-timelapse-processor

[![License BSD-3](https://img.shields.io/pypi/l/napari-timelapse-processor.svg?color=green)](https://github.com/jo-mueller/napari-timelapse-processor/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-timelapse-processor.svg?color=green)](https://pypi.org/project/napari-timelapse-processor)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-timelapse-processor.svg?color=green)](https://python.org)
[![tests](https://github.com/jo-mueller/napari-timelapse-processor/workflows/tests/badge.svg)](https://github.com/jo-mueller/napari-timelapse-processor/actions)
[![codecov](https://codecov.io/gh/jo-mueller/napari-timelapse-processor/branch/main/graph/badge.svg)](https://codecov.io/gh/jo-mueller/napari-timelapse-processor)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-timelapse-processor)](https://napari-hub.org/plugins/napari-timelapse-processor)

meta plugin to ease processing timelapse image data

## API

This plugin exposes two principal funcionalities:

### TimelapseConverter

The `TimelapseConverter` class allows you to stack or unstack any of the supported napari layers from 4D data into a list of 3D layers or vice versa. Currently supported layers are:

- `napari.layers.Image`
- `napari.layers.Labels`
- `napari.layers.Points`
- `napari.layers.Vectors`
- `napari.layers.Surface`

`napari.layers.Tracks` are intrinsically 4D and thus not supported.

**Unstacking example usage:**

```python
from napari_timelapse_processor import TimelapseConverter
import numpy as np

image_4d = np.random.rand(10, 32, 32, 32)  # 10 timepoints of 32x32x32 data
converter = TimelapseConverter()
list_of_images = converter.unstack(image_4d, layertype='napari.types.ImageData')
```

**Stacking example usage:**

```python
from napari_timelapse_processor import TimelapseConverter
import numpy as np

random_points = [np.random.rand(10, 3)  for _ in range(10)]  # 10 timepoints of 10 random 3D points
converter = TimelapseConverter()

# stack the points into a single 4D layer
stacked_points = converter.stack(random_points, layertype='napari.types.PointsData')
```

The `TimeLapseConverter` class also supports (un)stacking the `napari.layers.Layer` type (and its above-listed subclasses). Importantly, `features` that are associated with the respective layer are also (un)stacked.

**Layer example usage**

```python
from napari_timelapse_processor import TimelapseConverter
import numpy as np
from napari.layers import Points
import pandas as pd

random_points = [np.random.rand(10, 3)  for _ in range(10)]  # 10 timepoints of 10 random 3D points
random_features = [pd.DataFrame(np.random.rand(10)) for _ in range(10)]  # 10 timepoints of 10 random feature values

# create a list of 10 Points layers
points = [Points(random_points[i], properties=random_features[i]) for i in range(10)]

converter = TimelapseConverter()
stacked_points = converter.stack(points, layertype='napari.layers.Points')
```

## frame_by_frame

The frame-by-frame functionality provides a decorator that will inspect the decorated function for `TimelapseConverter`-compatible arguments and, if a 4D value is passed as argument, will automatically (un)stack the data before and after the function call. This allows for a more intuitive API when working with timelapse data. Currently supported type annotations are:

- `napari.types.ImageData`
- `napari.types.LabelsData`
- `napari.types.PointsData`
- `napari.types.VectorsData`
- `napari.types.SurfaceData`
- `napari.layers.Layer`
- `napari.layers.Image`
- `napari.layers.Labels`
- `napari.layers.Points`
- `napari.layers.Vectors`
- `napari.layers.Surface`

Additionally, the `frame_by_frame` supports parallelization with [dask.distributed](https://distributed.dask.org/en/latest/). To use it, simply pass the `use_dask=True` argument to the decorated function, even if the function itself does not require this argument. The decorater will then automatically parallelize the function call over the time-axis and remove the `use_dask` argument when calling the function.

**Example interactive code usage:** If you want to use the `frame_by_frame` functionality in, say, a Jupyter notebook, use it like this:

```python

from napari_timelapse_processor import frame_by_frame
import numpy as np

def my_function(image: 'napari.types.ImageData') -> 'napari.types.ImageData':
    return 2 * image

image_4d = np.random.rand(10, 32, 32, 32)  # 10 timepoints of 32x32x32 data

image_4d_processed = frame_by_frame(my_function)(image_4d)  # without dask
image_4d_processed = frame_by_frame(my_function)(image_4d, use_dask=True)  # with dask
```

**Example napari code** If you want to use the `frame_by_frame` functionality in a napari plugin, use it like this:

```python
from napari_timelapse_processor import frame_by_frame

@frame_by_frame
def my_function(image: 'napari.types.ImageData') -> 'napari.types.ImageData':
    return 2 * image
```

**Hint:** The `frame_by_frame` functionality runs under the assumption that input napari-data (e.g., an Image, a Surface, Points, etc) are *always* arguments and any other parameters are *always* keyword arguments. If this is not the case, the decorator will not work as intended.

```python

# This works
frame_by_frame(my_function)(image_4d, some_parameter=2, use_dask=True)

# This does not work
frame_by_frame(my_function)(image=image_4d, some_parameter=2, use_dask=True)
```

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-timelapse-processor` via [pip]:

    pip install napari-timelapse-processor




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-timelapse-processor"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Repository, https://github.com/jo-mueller/napari-timelapse-processor.git']",,,,,,,
433,napari-timeseries-opener-plugin,napari-timeseries-opener-plugin,napari-timeseries-opener-plugin,0.1.8,2022-02-28,2022-10-04,Niklas Netter,niknett@gmail.com,BSD-3-Clause,https://github.com/gatoniel/napari-timeseries-opener-plugin/issues,https://pypi.org/project/napari-timeseries-opener-plugin/,,https://github.com/gatoniel/napari-timeseries-opener-plugin,Simple plugin that opens separate .tif files as a 3-dimensional layer.,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'qtpy', 'magicgui', 'tifffile', 'stardist', 'tensorflow']","# napari-timeseries-opener-plugin

[![License](https://img.shields.io/pypi/l/napari-timeseries-opener-plugin.svg?color=green)](https://github.com/gatoniel/napari-timeseries-opener-plugin/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-timeseries-opener-plugin.svg?color=green)](https://pypi.org/project/napari-timeseries-opener-plugin)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-timeseries-opener-plugin.svg?color=green)](https://python.org)
[![tests](https://github.com/gatoniel/napari-timeseries-opener-plugin/workflows/tests/badge.svg)](https://github.com/gatoniel/napari-timeseries-opener-plugin/actions)
[![codecov](https://codecov.io/gh/gatoniel/napari-timeseries-opener-plugin/branch/main/graph/badge.svg)](https://codecov.io/gh/gatoniel/napari-timeseries-opener-plugin)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-timeseries-opener-plugin)](https://napari-hub.org/plugins/napari-timeseries-opener-plugin)

Simple plugin that opens separate .tif files as a 3-dimensional layer.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Run

In powershell run when you do not have sufficient GPU support in your environment
```
$env:CUDA_VISIBLE_DEVICES=-1; napari
```

## Installation

You can install `napari-timeseries-opener-plugin` via [pip]:

    pip install napari-timeseries-opener-plugin



To install latest development version :

    pip install git+https://github.com/gatoniel/napari-timeseries-opener-plugin.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-timeseries-opener-plugin"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/gatoniel/napari-timeseries-opener-plugin/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/gatoniel/napari-timeseries-opener-plugin/issues', 'Documentation, https://github.com/gatoniel/napari-timeseries-opener-plugin#README.md', 'Source Code, https://github.com/gatoniel/napari-timeseries-opener-plugin', 'User Support, https://github.com/gatoniel/napari-timeseries-opener-plugin/issues']",,,napari-timeseries-opener-plugin.LoadWidget,,,,
434,napari-time-series-plotter,napari-time-series-plotter,TSP,0.0.6,2021-12-01,2023-07-25,Christopher Nauroth-Kress,nauroth_C@ukw.de,BSD-3-Clause,https://github.com/ch-n/napari-time_series_plotter/issues,https://pypi.org/project/napari-time-series-plotter/,,https://github.com/ch-n/napari-time_series_plotter,"A Plugin for napari to visualize pixel values over the first dimension (time -> t+3D, t+2D) as graphs.",>=3.8,"['napari-matplotlib (<1.0)', 'numpy', 'pandas', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-time_series_plotter

[![License](https://img.shields.io/pypi/l/napari-time_series_plotter.svg?color=green)](https://github.com/ch-n/napari-time_series_plotter/raw/main/LICENSE)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-time_series_plotter.svg?color=green)](https://python.org)
[![PyPI](https://img.shields.io/pypi/v/napari-time_series_plotter.svg?color=blue)](https://pypi.org/project/napari-time_series_plotter)
[![Anaconda-Server Badge](https://anaconda.org/conda-forge/napari-time-series-plotter/badges/version.svg)](https://anaconda.org/conda-forge/napari-time-series-plotter)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-time-series-plotter)](https://napari-hub.org/plugins/napari-time-series-plotter)
[![tests](https://github.com/ch-n/napari-time_series_plotter/workflows/tests/badge.svg)](https://github.com/ch-n/napari-time_series_plotter/actions)
[![codecov](https://codecov.io/gh/ch-n/napari-time_series_plotter/branch/main/graph/badge.svg)](https://codecov.io/gh/ch-n/napari-time_series_plotter)


## Description
Napari-time_series_plotter (TSP) is a plugin for the `napari` ndimensional image viewer. 

**TSP** adds live plotting of time-resolved images to napari. You can select and visualize pixel/voxel or ROI mean values from one or multiple image layers as intensity-over-time line plots (The first image dimension is handled as time) and save the figures or the underlying time series data as CSV file. TSP supports 3D to nD images (3D: t+2D, nD: t+nD).

**Plotting** is handeled by the `Explorer` widget, it offers three different plotting modes: Voxel, Shapes, Points
<br>--> Voxel mode offers live plotting while moving the cursor over an image layer
<br>--> Shapes mode offers shape-based ROI plotting the ROI combination method can be one of [Mean, Median, STD, Sum, Min, Max]; multiple ROIs can be plotted simultaneously
<br>--> Points mode offers simultaneous, point-based plotting of multiple voxels
<br>You can modify and save the plots through the canvas toolbar.
<br>Plotting powered by `napari-matplotlib`.

**Viewing** the time series as a table is handled by the `Inspector` widget. You can load the data you've plotted and inspect the single time point values of each selection. The columns are named like the plots in the `Explorer`. You can copy the whole tabe or a selection to the clipboard or directly expot it to a CSV file to save the time series.

----------------------------------

## Installation
You can either install the latest version via pip or conda.

**pip:**

    pip install napari-time-series-plotter

or download the packaged `tar.gz` file from the release assets and install it with 
    
    pip install /path/to/file.tar.gz

**conda:**

    conda install -c conda-forge napari-time-series-plotter


Alternatively, you can install the plugin directly in the `napari` viewer plugin manager, the napari hub, or the release assets.

<br>

To install the latest development version install directly from the relevant GitHub branch.

## Usage
### Basics and Live plotting

[![basic_demo](./demo_videos/TSP_basic_and_voxel_plotting_demo.jpg)](./demo_videos/TSP_basic_and_voxel_plotting_demo.webm)
    
1. Select the `TSPExplorer` widget in the `Plugins` tab of the napari viewer
2. Use the `LayerSelector` to choose the image layers you want to source for plotting
3. Move the corsor over the layer while holding ""Shift""

The `Options` tab offers multiple options to customize your plot. 
- Set custom title or axe labels
- Switch between autoscaling and manually defined max and min values of the axes
- Switch to label truncation in the options tab if your layer names are too long for the figure legend (set max length manually)
- Set a scaling factor for the X-axis

The plot can be modified and saved through its toolbar above.

### Plotting ROIs

[![roi_demo](./demo_videos/TSP_ROI_plotting_demo.jpg)](./demo_videos//TSP_ROI_plotting_demo.webm)

1. Select the Shapes plotting mode via the `Options` tab (Voxel mode is the default).
2. Use the `LayerSelector` to choose the image layers you want to source for plotting.
2. Add one ore more shapes to the ""ROI Selection"" layer.
   <br>The ""ROI Selection"" shapes are 2D only, effecting the currently displayed slice.
   <br>(newly added shapes might have to be moved before they are correctly plottet)
3. Reposition or remove shapes if needed.
4. Change the ROI mode in the `Options` tab (Default: mean).

### Plotting multiple Points

[![points_demo](./demo_videos/TSP_Points_plotting_demo.jpg)](./demo_videos/TSP_Points_plotting_demo.webm)

1. Select the Shapes plotting mode via the `Options` tab (Voxel mode is the default).
2. Use the `LayerSelector` to choose the image layers you want to source for plotting.
3. Add one or more points to the ""Point selection"" layer.
   <br>The points can be on different slices (3D and 4D support only) or images (grid mode)
4. Reposition or remove points if needed.

### View time series as table

[![points_demo](./demo_videos/TSP_Inspector_demo.jpg)](./demo_videos/TSP_Inspector_demo.webm)

1. Select the `TSPInspector` widget in the `Plugins` tab of the napari viewer
2. Press the load from plot button to load the currently displayed plots into the `Inspector`

You can copy the whole table or a selection to your clipboard or export it to CSV file through the buttons above.

## ToDo (help welcome)
- [ ] Add Sphinx documentation

## Version 0.1.0 Milestones
- [X] Update to napari-plugin-engine2 [#5](https://github.com/ch-n/napari-time_series_plotter/issues/5)
- [X] Update widget GUI [#6](https://github.com/ch-n/napari-time_series_plotter/issues/6)
- [x] Add widget to save pixel/voxel time series to file [#7](https://github.com/ch-n/napari-time_series_plotter/issues/7)
- [X] Add ROI and multi-voxel plotting [#14](https://github.com/ch-n/napari-time_series_plotter/issues/14)
- [ ] Evaluate and close remaining issues ([#22](https://github.com/ch-n/napari-time_series_plotter/issues/22), [#25](https://github.com/ch-n/napari-time_series_plotter/issues/25),)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-time_series_plotter"" is free and open-source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

--------------

## References
This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

Images used in the demo gif were taken from [The Cancer Imaging Archive] <br>

    DOI: https://doi.org/10.7937/K9/TCIA.2015.VOSN3HN1
    Images: 1.3.6.1.4.1.9328.50.16.281868838636204210586871132130856898223
            1.3.6.1.4.1.9328.50.16.254461916058189583774506642993503110733

[The Cancer Imaging Archive]: https://www.cancerimagingarchive.net/
[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/ch-n/napari-time_series_plotter/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/ch-n/napari-time_series_plotter/issues', 'Documentation, https://github.com/ch-n/napari-time_series_plotter#README.md', 'Source Code, https://github.com/ch-n/napari-time_series_plotter', 'User Support, https://github.com/ch-n/napari-time_series_plotter/issues']",,,napari-time-series-plotter.Explorer,,,,
435,napari-tmidas,napari-tmidas,T-MIDAS,0.2.2,2025-03-05,2025-06-03,Marco Meer,marco.meer@pm.me,"Copyright (c) 2025, Marco Meer...",https://github.com/macromeer/napari-tmidas/issues,https://pypi.org/project/napari-tmidas/,,,A plugin for batch processing of confocal and whole-slide microscopy images of biological tissues,>=3.9,"['numpy', 'magicgui', 'tqdm', 'qtpy', 'scikit-image', 'pyqt5', 'tqdm', 'scikit-image', 'ome-zarr', 'napari-ome-zarr', 'torch', 'torchvision', 'timm', 'opencv-python', 'cmake', 'nd2', 'pylibCZIrw', 'readlif', 'tiffslide', 'hydra-core', 'eva-decord', 'acquifer-napari', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-tmidas

[![License BSD-3](https://img.shields.io/pypi/l/napari-tmidas.svg?color=green)](https://github.com/macromeer/napari-tmidas/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tmidas.svg?color=green)](https://pypi.org/project/napari-tmidas)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tmidas.svg?color=green)](https://python.org)
[![tests](https://github.com/macromeer/napari-tmidas/workflows/tests/badge.svg)](https://github.com/macromeer/napari-tmidas/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-tmidas)](https://napari-hub.org/plugins/napari-tmidas)
<!-- [![codecov](https://codecov.io/gh/macromeer/napari-tmidas/branch/main/graph/badge.svg)](https://codecov.io/gh/macromeer/napari-tmidas) -->
The `napari-tmidas` plugin consists of a growing collection of pipelines for fast batch processing of confocal and whole slide microscopy images of biological tissues. This is a WIP and based on the CLI version of [T-MIDAS](https://github.com/MercaderLabAnatomy/T-MIDAS).

## Features
Currently, napari-tmidas provides pipelines as widgets for batch image conversion / cropping / processing, ROI colocalization and label inspection (cf. [Usage](#usage) below).

## Installation

(Video installation guides: https://www.youtube.com/@macromeer/videos)

First, install Napari in a virtual environment:

    mamba create -y -n napari-tmidas -c conda-forge python=3.11
    mamba activate napari-tmidas
    python -m pip install ""napari[all]""

Now you can install `napari-tmidas` via [pip]:

    pip install napari-tmidas

It is recommended though to install the **latest development version**. Please also execute this command from time to time in the activated environment to benefit from newly added features:

    pip install git+https://github.com/macromeer/napari-tmidas.git

To use the Batch Crop Anything pipeline, we need to install **Segment Anything 2** (2D/3D):

    cd /opt # if the folder does not exist: mkdir /opt && cd /opt
    git clone https://github.com/facebookresearch/sam2.git && cd sam2
    pip install -e .
    curl -L https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt -o checkpoints/sam2.1_hiera_large.pt
    mamba install -c conda-forge ffmpeg # we also need ffmpeg

If you want to batch compress image data using [Zstandard](https://github.com/facebook/zstd), use the package manager of your operating system to install it:

   ~~sudo apt-get install zstd~~    # Pre-installed on Linux :man_shrugging:

    brew install zstd            # for macOS (requires [Homebrew](https://brew.sh/)
    pip install zstandard        # Windows with Python >= 3.7



And you are done! 

## Usage

To use the plugin, start napari in the activated virtual environment with this terminal command:

    mamba run -n napari-tmidas napari

You can then find the installed plugin in the Plugins tab.

### Microscopy Image Conversion

You can start this pipeline via `Plugins > T-MIDAS > Batch Microscopy Image Conversion`. Currently, this pipeline supports the conversion of `.nd2, .lif, .ndpi, .czi` and acquifer data. After scanning a folder of your choice for microscopy image data, select a file in the first column of the table and preview and export any image data it contains.


<img src=""https://github.com/user-attachments/assets/e377ca71-2f30-447d-825e-d2feebf7061b"" alt=""Microscopy Image Conversion Widget"" style=""width:75%; height:auto;"">


### Image Processing

1. After opening `Plugins > T-MIDAS > Batch Image Processing`, enter the path to the folder containing the images to be processed (currently supports TIF, later also ZARR). You can also filter for filename suffix.

![image](https://github.com/user-attachments/assets/41ecb689-9abe-4371-83b5-9c5eb37069f9)

2. As a result, a table appears with the found images. You can click on them to inspect them in the viewer.

![image](https://github.com/user-attachments/assets/8360942a-be8f-49ec-bc25-385ee43bd601)

3. Next, select a processing function, set parameters if applicable and `Start Batch Processing`.

![image](https://github.com/user-attachments/assets/05929660-6672-4f76-89da-4f17749ccfad)

4. You can click on the images in the table to show them in the viewer. For example first click on one of the `Original Files`, and then the corresponding `Processed File` to see an overlay.

<img src=""https://github.com/user-attachments/assets/cfe84828-c1cc-4196-9a53-5dfb82d5bfce"" alt=""Image Processing Widget"" style=""width:75%; height:auto;"">


Note that whenever you click on an `Original File` or `Processed File` in the table, it will replace the one that is currently shown in the viewer. So naturally, you'd first select the original image, and then the processed image to correctly see the image pair that you want to inspect.


#### Processing Function Credits

The image processing capabilities are powered by several excellent open-source tools:
- [Cellpose 4](https://github.com/MouseLand/cellpose): Advanced cell segmentation
- [Trackastra](https://github.com/weigertlab/trackastra): Cell tracking and analysis
- [CAREamics](https://github.com/CAREamics/careamics): Content-aware image restoration and enhancement

### Batch Label Inspection
If you have already segmented a folder full of images and now you want to maybe inspect and edit each label image, you can use the `Plugins > T-MIDAS > Batch Label Inspection`, which automatically saves your changes to the existing label image once you click the `Save Changes and Continue` button (bottom right).

<img src=""https://github.com/user-attachments/assets/0bf8c6ae-4212-449d-8183-e91b23ba740e"" alt=""Batch Label Inspection Widget"" style=""width:75%; height:auto;"">

### Crop Anything
This pipeline combines the Segment Anything Model (SAM) for automatic object detection with an interactive interface for selecting and cropping multiple objects from images. To launch the widget, open `Plugins > T-MIDAS > Batch Crop Anything`. Cropping works like this: Enter 2D view and go to the first z slice where the object to be cropped is appearing. Activate/select the points layer and click on the object. Terminal shows progress. You can then proceed to select another object (always do this in 2D mode)

<img src=""https://github.com/user-attachments/assets/6d72c2a2-1064-4a27-b398-a9b86fcbc443"" alt=""Crop Anything Widget"" style=""width:75%; height:auto;"">




### ROI Colocalization
This pipeline quantifies colocalization between labeled regions of interest (ROIs) across multiple image channels. It determines the extent of overlap between ROIs in a reference channel and those in one or two other channels. The output is a table of colocalization counts. Optionally, the size of reference channel ROIs, as well as the total or median size of colocalizing ROIs in the other channels, can be included. Colocalization is determined using Boolean masking. The number of colocalizing instances is determined by counting unique label IDs within the overlapping regions. Typically, the reference channel contains larger structures, while other channels contain smaller, potentially nested, structures. For example, the reference channel might contain cell bodies, with the second and third channels containing nuclei and sub-nuclear objects, respectively.

<img src=""https://github.com/user-attachments/assets/2f9022a0-7b88-4588-a448-250f07a634d7"" alt=""ROI Colocalization Widget"" style=""width:75%; height:auto;"">

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-tmidas"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/macromeer/napari-tmidas/issues

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/macromeer/napari-tmidas/issues', 'Documentation, https://github.com/macromeer/napari-tmidas#README.md', 'Source Code, https://github.com/macromeer/napari-tmidas', 'User Support, https://github.com/macromeer/napari-tmidas/issues']",napari-tmidas.get_reader,napari-tmidas.write_multiple,napari-tmidas.file_selector,napari-tmidas.make_sample_data,['*.npy'],,['.npy']
436,napari-tomodl,napari-tomodl,ToMoDL Reconstruction,0.1.17,2023-03-15,2024-05-20,"Marcos Antonio Obando, GermÃ¡n Mato, Teresa Correia",marcos.obando@ib.edu.ar,MIT,,https://pypi.org/project/napari-tomodl/,None,,A plugin for optical projection tomography reconstruction with model-based neural networks.,<=3.9,"['magicgui', 'qtpy', 'napari[all]', 'pyqt5', 'phantominator', 'opencv-python', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-tomodl

[![License MIT](https://img.shields.io/pypi/l/napari-tomodl.svg?color=green)](https://github.com/marcoso96/napari-tomodl/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tomodl.svg?color=green)](https://pypi.org/project/napari-tomodl)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tomodl.svg?color=green)](https://python.org)
[![tests](https://github.com/marcoso96/napari-tomodl/workflows/tests/badge.svg)](https://github.com/marcoso96/napari-tomodl/actions)
[![codecov](https://codecov.io/gh/marcoso96/napari-tomodl/branch/main/graph/badge.svg)](https://codecov.io/gh/marcoso96/napari-tomodl)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-tomodl)](https://napari-hub.org/plugins/napari-tomodl)

A plugin for optical projection tomography reconstruction with model-based neural networks.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->
## Introduction and usage

ToMoDL allows users to reconstruct tomography images from its raw projections juts from uploading them as an ordered stack of files into the napari viewer.

1 - Load ordered stack: Click File -> Open Files as Stack... and load the angular projections for parallel beam optical tomography reconstruction.

![plot](https://raw.githubusercontent.com/marcoso96/ToMoDL/main/napari-tomodl/figures/fig3.png)

2 - Select the current volume in the dropdown menu with the button 'Select image layer'. Notice that the projections should be in grayscale and more than one slide in the stack.

![plot](https://raw.githubusercontent.com/marcoso96/ToMoDL/main/napari-tomodl/figures/fig4.png)

3 - If the axis is not correctly aligned in acquisition time, we provide an algorithm to do so by clicking on 'Align axis'. This will align the sinogram respect to the center of the detector in order to maximise the variance of the reconstructions. See Walls et al. 

4 - Reshape the reconstructed volume to a desired size. This can be useful to prevent exhausting your computing capabilities.

5 - Clip to circle should be False by default.

6 - Choose if filtering should be used. By the moment we only allow using ramp filtering for FBP only (both CPU and GPU).

7 - Choose the correct order of the axis of the projections (T -> Theta axis, Q -> Detector axis)

8 - Reconstruct! A new Layer should be created on top of the projections stack containing the reconstructed volume.

![plot](https://raw.githubusercontent.com/marcoso96/ToMoDL/main/napari-tomodl/figures/fig2.png)

## Installation

This package requires [torch-radon] for optimized GPU tomographic reconstruction:

    pip install 'torch-radon @ https://rosh-public.s3-eu-west-1.amazonaws.com/radon-v2/cuda-11.1/torch-1.8/torch_radon-2.0.0-cp38-cp38-linux_x86_64.whl'

and `PyTorch == 1.8.0` via wheel, which can be downloaded and installed with: 

    pip install 'torch @ https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp38-cp38-linux_x86_64.whl'

You can install `napari-tomodl` via [pip]:

    pip install napari-tomodl




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-tomodl"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[torch-radon]: https://github.com/matteo-ronchetti/torch-radon
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-tomodl.make_reconstruct_widget,,,,
437,napari-time-slicer,napari-time-slicer,napari-time-slicer,0.5.0,2021-11-12,2023-11-12,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-time-slicer/issues,https://pypi.org/project/napari-time-slicer/,,https://github.com/haesleinhuepf/napari-time-slicer,A meta plugin for processing timelapse data in napari timepoint by timepoint,>=3.8,"['napari-plugin-engine >=0.1.4', 'numpy', 'toolz', 'napari-tools-menu', 'napari-workflows']","# napari-time-slicer

[![License](https://img.shields.io/pypi/l/napari-time-slicer.svg?color=green)](https://github.com/haesleinhuepf/napari-time-slicer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-time-slicer.svg?color=green)](https://pypi.org/project/napari-time-slicer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-time-slicer.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-time-slicer/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-time-slicer/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-time-slicer/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-time-slicer)
[![Development Status](https://img.shields.io/pypi/status/napari-time-slicer.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-time-slicer)](https://napari-hub.org/plugins/napari-time-slicer)

A meta plugin for processing timelapse data timepoint by timepoint. It 
enables a list of napari plugins to process 2D+t or 3D+t data step by step when the user goes 
through the timelapse. Currently, these plugins are using `napari-time-slicer`:
* [napari-segment-blobs-and-things-with-membranes](https://www.napari-hub.org/plugins/napari-segment-blobs-and-things-with-membranes)
* [napari-cupy-image-processing](https://www.napari-hub.org/plugins/napari-cupy-image-processing)
* [napari-pyclesperanto-assistant](https://www.napari-hub.org/plugins/napari-pyclesperanto-assistant)
* [napari-accelerated-pixel-and-object-classification](https://www.napari-hub.org/plugins/napari-accelerated-pixel-and-object-classification)
* [napari-simpleitk-image-processing](https://www.napari-hub.org/plugins/napari-simpleitk-image-processing)
* [napari-stress](https://www.napari-hub.org/plugins/napari-stress)
* [napari-process-points-and-surfaces](https://www.napari-hub.org/plugins/napari-process-points-and-surfaces)

`napari-time-slicer` enables inter-plugin communication, e.g. allowing to combine the plugins listed above in 
one image processing workflow for segmenting a timelapse dataset:

![](https://github.com/haesleinhuepf/napari-time-slicer/raw/main/images/screencast1.gif)

The workflow can then also be exported as a script. The 'Generate Code' button can be found in the [Workflow Inspector](https://www.napari-hub.org/plugins/napari-workflow-inspector)


If you want to convert a 3D dataset into a 2D + time dataset, use the 
menu `Tools > Utilities > Convert 3D stack to 2D timelapse (time-slicer)`. It will turn the 3D dataset to a 4D datset
where the Z-dimension (index 1) has only 1 element, which will in napari be displayed with a time-slider. Note: It is 
recommended to remove the original 3D dataset after this conversion.

## Working with large on-the-fly processed datasets

Using the [napari-assistant](https://www.napari-hub.org/plugins/napari-assistant) complex image processing workflows on timelapse datasets can be setup. 
In combination with the time-slicer it is possible to process time-lapse data that is larger than available computer memory.
In case the workflow only consists of images and label-images and out-of-memory issues arise, consider storing intermediate results on disk following this procedure: 
After setting up the workflow and testing it on a couple of selected frames, store the entire processed timelapse dataset to disk 
using the menu `Tools > Utilities > Convert to file-backed timelapse data (time-slicer)`. It will open this dialog, where you can select 
![img.png](https://github.com/haesleinhuepf/napari-time-slicer/raw/main/images/convert_to_file_backed_timelapse.png)

It is recommended to enter a folder location in the text field. 
If not provided, a temporary folder will be created, typically in the User's temp folder in the home directory. 
The user is responsible for emptying this folder from time to time.
The data stored in this folder can also be loaded into napari using its `File > Open Folder...` menu.

Executing this operation can take time as every timepoint of the timelapse is computed. 
Afterwards, there will be another layer available in napari, which is typically faster to navigate through. 
Consider removing the layer(s) that were only needed to determine the new file-backed layer.

![img.png](https://github.com/haesleinhuepf/napari-time-slicer/raw/main/images/new_file_backed_layer.png)

## Usage for plugin developers

Plugins which implement the `napari_experimental_provide_function` hook can make use of the `@time_slicer`. At the moment,
only functions which take `napari.types.ImageData`, `napari.types.LabelsData` and basic python types such as `int` 
and `float` are supported. If you annotate such a function with `@time_slicer` it will internally convert any 4D dataset
to a 3D dataset according to the timepoint currently selected in napari. Furthermore, when the napari user changes the
current timepoint or the input data of the function changes, a re-computation is invoked. Thus, it is recommended to 
only use the `time_slicer` for functions which can provide [almost] real-time performance. Another constraint is that 
these annotated functions have to have a `viewer` parameter. This is necessary to read the current timepoint from the 
viewer when invoking the re-computions.

Example
```python
import napari
from napari_time_slicer import time_slicer

@time_slicer
def threshold_otsu(image:napari.types.ImageData, viewer: napari.Viewer = None) -> napari.types.LabelsData:
    # ...
```

You can see a full implementations of this concept in the napari plugins listed above.

If you want to combine slicing in time and processing z-stack images slice-by-slice, you can use the `@slice_by_slice` annotation.
Make sure, to insert it after `@time_slicer` as shown below and implemented in [napari-pillow-image-processing](https://github.com/haesleinhuepf/napari-pillow-image-processing/blob/4d846b226739843124953f16059241d917cde8e1/src/napari_pillow_image_processing/__init__.py#L151)

```python
from napari_time_slicer import slice_by_slice

@time_slicer
@slice_by_slice
def blur_2d(image:napari.types.ImageData, sigma:float = 1, viewer: napari.Viewer = None) -> napari.types.LabelsData:
    # ...
```

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `napari-time-slicer` via [pip]:

    pip install napari-time-slicer



To install latest development version :

    pip install git+https://github.com/haesleinhuepf/napari-time-slicer.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-time-slicer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-time-slicer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-time-slicer/issues', 'Documentation, https://github.com/haesleinhuepf/napari-time-slicer#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-time-slicer', 'User Support, https://github.com/haesleinhuepf/napari-time-slicer/issues']",,,napari-time-slicer.napari_experimental_provide_function,,,,
438,napari-tissuumaps,napari-tissuumaps,Napari TissUUmaps,1.1.2,2021-09-02,2022-08-05,Nicolas Pielawski,nicolas@pielawski.fr,MIT,,https://pypi.org/project/napari-tissuumaps/,None,,A plugin to export Napari projects to TissUUmaps.,>=3.8,"['numpy', ""napari ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# ð napari-tissuumaps ð§«

[![License MIT](https://img.shields.io/pypi/l/napari-tissuumaps.svg?color=green)](https://github.com/npielawski/napari-tissuumaps/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tissuumaps.svg?color=green)](https://pypi.org/project/napari-tissuumaps)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tissuumaps.svg?color=green)](https://python.org)
[![tests](https://github.com/npielawski/napari-tissuumaps/workflows/tests/badge.svg)](https://github.com/npielawski/napari-tissuumaps/actions)
[![codecov](https://codecov.io/gh/npielawski/napari-tissuumaps/branch/main/graph/badge.svg)](https://codecov.io/gh/npielawski/napari-tissuumaps)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-tissuumaps)](https://napari-hub.org/plugins/napari-tissuumaps)

A plugin to export Napari projects to [TissUUmaps](https://tissuumaps.research.it.uu.se/).

----------------------------------

This plugins adds a new writer to [Napari] to export projects to [TissUUmaps](https://github.com/TissUUmaps/TissUUmaps). Exported projects can then be open on the browser or on a standalone GUI with [TissUUmaps](https://github.com/TissUUmaps/TissUUmaps). More information and demonstrations are available on the [TissUUmaps webpage](https://tissuumaps.research.it.uu.se/).

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## ð Features

<p align=""center"">
  <img src=""images/screenshot.jpg"" alt=""Demonstration of a project exported from Napari to TissUUmaps."" width=""500"" />
</p>

The plugin now supports:

* Exporting images
* Exporting labels
* Exporting points
* Exporting shapes, including:
    * Polygons
    * Rectangles
    * Lines
    * Paths
    * Ellipses

The plugin exports the right color for the points, shapes and labels and also saves the visibility/opacity of each layers. The shapes are exported in the GeoJSON format, the points in CSV files, and images as TIFFs.

## ðº Installation

You can install `napari-tissuumaps` via [pip]:

    pip install napari-tissuumaps

You can also install `napari-tissumaps` via [napari]:

In Napari, access the menubar, Plugins > Install/Uninstall Plugins.
Search for napari-tissuumaps in the list and choose install, or type
`napari-tissuumaps` in the ""install by name/url, or drop file..."" text area and choose
install.

## â Usage

To export a project for TissUUmaps, access the menubar, File > Save All Layers... and
type in a filename. Choose the `.tmap` extension in the dropdown and click on the Save
button, It will create a folder containing all the necessary files for TissUUmaps.

## ð©âð» Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## âï¸ License

Distributed under the terms of the [MIT] license,
""napari-tissuumaps"" is free and open source software

## ð Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Topic :: Scientific/Engineering :: Image Processing']",,,napari-tissuumaps.write_layers,,,,['.tmap'],
439,napari-tomocube-data-viewer,napari-tomocube-data-viewer,Tomocube data viewer,2024.10.0,2023-03-06,2024-10-15,Dohyeon Lee,Dohyeon Lee <dleh428@kaist.ac.kr>,MIT,https://github.com/ehgus/napari-tomocube-data-viewer/issues,https://pypi.org/project/napari-tomocube-data-viewer/,,,A plugin to visualize three-dimensional data from Tomocube's microscopy,>=3.8,"['numpy', 'TCFile>=2024.10.1', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""']","# napari-tomocube-data-viewer

[![License MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://github.com/ehgus/napari-tomocube-data-viewer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tomocube-data-viewer.svg?color=green)](https://pypi.org/project/napari-tomocube-data-viewer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tomocube-data-viewer.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-tomocube-data-viewer)](https://napari-hub.org/plugins/napari-tomocube-data-viewer)

A plugin to visualize three-dimensional data from [Tomocube](https://www.tomocube.com/)'s holotomography

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-tomocube-data-viewer` via [pip] or [conda]:

    pip install napari-tomocube-data-viewer
    conda install napari-tomocube-data-viewer

To install latest development version :

    pip install git+https://github.com/ehgus/napari-tomocube-data-viewer.git

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-tomocube-data-viewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[conda]: https://docs.anaconda.com/free/miniconda/index.html
[file an issue]: https://github.com/ehgus/napari-tomocube-data-viewer/issues
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/ehgus/napari-tomocube-data-viewer/issues', 'Documentation, https://github.com/ehgus/napari-tomocube-data-viewer', 'Source Code, https://github.com/ehgus/napari-tomocube-data-viewer', 'User Support, https://github.com/ehgus/napari-tomocube-data-viewer/issues']",napari-tomocube-data-viewer.get_reader,,,,['*.TCF'],,
440,napari-tracing,napari-tracing,Napari Tracer Plugin,1.0.2,2023-04-23,2024-02-13,Vasudha Jha,reachvasudha27@gmail.com,GPL-3.0-only,https://github.com/mapmanager/napari-tracing/issues,https://pypi.org/project/napari-tracing/,,https://github.com/mapmanager/napari-tracing,A plugin to trace the brightest path between two points in an image,>=3.8,"['numpy', 'qtpy', 'brightest-path-lib', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-tracing

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/napari-tracing.svg?color=green)](https://github.com/mapmanager/napari-tracing/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tracing.svg?color=green)](https://pypi.org/project/napari-tracing)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tracing.svg?color=green)](https://python.org)
<!-- [![tests](https://github.com/mapmanager/napari-tracing/workflows/tests/badge.svg)](https://github.com/mapmanager/napari-tracing/actions) -->
<!-- [![codecov](https://codecov.io/gh/mapmanager/napari-tracing/branch/main/graph/badge.svg)](https://codecov.io/gh/mapmanager/napari-tracing) -->
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-tracing)](https://napari-hub.org/plugins/napari-tracing)

## Napari Tracer Plugin

The `Napari Tracer Plugin` provides an intuitive interface for users to load images, perform brightest path tracing, and visualize the results. This plugin, which is built on top of the Napari viewer, enables users to explore and annotate complex images, and take advantage of the viewer's built-in features such as zooming, panning, and adjusting contrast while viewing their tracings. The `Napari Tracer Plugin` uses the brightest path tracing algorithms from [brightest-path-lib](https://github.com/mapmanager/brightest-path-lib) to provide an interactive path building process for users to create traced segments in 2D and 3D images.

## Examples

<video loop muted autoplay controls >
  <source src=""sample-2d-tracing.mp4"" type=""video/mp4"">
</video>

You can download our [2D](data/sample-2d.tif) and [3D](sample-3d.tif) example tif files.

## Features

1. Load images and trace paths in 2D and 3D.
1. Offloads computations to a background thread to ensure a responsive user interface.
1. Two tracing modes: disjoint and continuous. Disjoint segments refer to paths that do not share any points, while continuous segments start from the endpoint of a previously traced path.
1. Verify traced segments and cancel tracing if necessary.
1. Save traced paths in SWC format commonly used in biology to represent neuronal morphology.
1. Load previously saved tracings in SWC format.

## Installation

You can install `napari-tracing` via pip:

    pip install napari-tracing

To install latest development version :

    pip install git+https://github.com/mapmanager/napari-tracing.git

## Usage

Once installed, the Napari Tracer Plugin can be accessed from the Napari menu under ""Plugins"" > ""napari tracing: Tracer Widget"". This will open the plugin interface, where you can load your image and start tracing.

## Tracing

1. To trace a path, select the ""Trace"" mode and the image layer that you want to trace from their respective dropdowns.
2. Once you select the image, a points layer called the terminal points layer will be created on the Napari viewer where you can add the start and end point.
3. Click the ""Start Tracing"" button to perform brightest path tracing between the points.
4. The traced path will appear in a new points layer called the tracing result result layer in the Napari viewer as a line overlay.
5. Each new traced segment is verified, so you can either accept the tracing or reject it. If you choose to reject the tracing, you can try again with a different set of points if necessary.
6. You can click on the ""Cancel Tracing"" button to cancel a tracing that is in progress.

## Saving and loading tracings

1. To save a tracing, click on the ""Save Trace"" button from the plugin menu. This will save the traced path in SWC format to a file of your choosing.
1. To load a previously saved tracing, click on the ""Load Trace"" button and choose the SWC file you want to load. The traced path will appear in the Napari viewer.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-tracing"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[file an issue]: https://github.com/mapmanager/napari-tracing/issues
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/mapmanager/napari-tracing/issues', 'Documentation, https://github.com/mapmanager/napari-tracing#README.md', 'Source Code, https://github.com/mapmanager/napari-tracing', 'User Support, https://github.com/mapmanager/napari-tracing/issues']",,,napari-tracing.make_qwidget,,,,
441,napari-toska,napari-toska,Napari Topological Skeleton Analysis,0.2.2,2024-07-08,2025-06-11,"Allyson Quinn Ryan, Johannes Soltwedel","Allyson Quinn Ryan <allyson_quinn.ryan@tu-dresden.de>, Johannes Soltwedel <johannes_richard.soltwedel@tu-dresden.de>","Copyright (c) 2023, Allyson Qu...",https://github.com/allysonryan/napari-toska/issues,https://pypi.org/project/napari-toska/,,,Extracts and analyses topological skeletons as undirected graphs,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image>=0.21.0', 'napari-skimage-regionprops', 'networkx', 'scipy', 'magicgui>=0.4.0', 'tqdm>=4.65.0', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-toska

[![License BSD-3](https://img.shields.io/pypi/l/napari-toska.svg?color=green)](https://github.com/allysonryan/napari-toska/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-toska.svg?color=green)](https://pypi.org/project/napari-toska)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-toska.svg?color=green)](https://python.org)
[![tests](https://github.com/allysonryan/napari-toska/workflows/tests/badge.svg)](https://github.com/allysonryan/napari-toska/actions)
[![codecov](https://codecov.io/gh/allysonryan/napari-toska/branch/main/graph/badge.svg)](https://codecov.io/gh/allysonryan/napari-toska)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-toska)](https://napari-hub.org/plugins/napari-toska)

Extracts and analyses topological skeletons as undirected graphs. For usage instructions and API reference, please refer to the documentation:

## [Documentation](https://allysonryan.github.io/napari-toska/).

![](https://github.com/allysonryan/napari-toska/raw/main/docs/imgs/3d_skeleton_analysis.gif)

The functionality of the plugin comprises the following:

- Extracting the topological skeleton of a binary image using the medial axis transform.
- Extracting the netowrk of the skeleton as an undirected `networkx` graph.
- Computing features of individual skeleton components as well as the entire skeleton network.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-toska` via [pip]:

    pip install napari-toska




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-toska"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/allysonryan/napari-toska/issues', 'Documentation, https://github.com/allysonryan/napari-toska', 'Source Code, https://github.com/allysonryan/napari-toska', 'User Support, https://github.com/allysonryan/napari-toska/issues']",,,napari-toska.analyze_skeleton,,,,
442,napari-tomotwin,napari-tomotwin,TomoTwin,0.4.1,2023-03-24,2024-10-02,Thorsten Wagner,twa1@posteo.de,MPL-2.0,https://github.com/MPI-Dortmund/napari-tomotwin,https://pypi.org/project/napari-tomotwin/,,https://github.com/MPI-Dortmund/napari-tomotwin,Several tools for the work with TomoTwin,>=3.10,"['numpy', 'pandas', 'matplotlib', 'scipy', 'napari-clusters-plotter>=0.7.2', 'magicgui', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""']","# napari-tomotwin

[![License Mozilla Public License 2.0](https://img.shields.io/pypi/l/napari-tomotwin.svg?color=green)](https://github.com/MPI-Dortmund/napari-tomotwin/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tomotwin.svg?color=green)](https://pypi.org/project/napari-tomotwin)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tomotwin.svg?color=green)](https://python.org)

Several tools for the work with TomoTwin :-)


## Installation

You can install `napari-tomotwin` via [pip]:

    pip install napari-tomotwin


## License

Distributed under the terms of the [Mozilla Public License 2.0] license,
""napari-tomotwin"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-tomotwin.UmapTool,,,,
443,napari-trackastra,napari-trackastra,trackastra,0.1.6,2024-05-30,2024-10-22,"Benjamin Gallusser, Martin Weigert","benjamin.gallusser@epfl.ch, martin.weigert@epfl.ch","Copyright (c) 2024, Martin Wei...",https://github.com/weigertlab/napari-trackastra/issues,https://pypi.org/project/napari-trackastra/,,,Napari plugin for cell tracking with trackastra.,>=3.10,"['numpy', 'scikit-image', 'trackastra', 'napari-ctc-io', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-trackastra

[![PyPI](https://img.shields.io/pypi/v/napari-trackastra.svg?color=green)](https://pypi.org/project/napari-trackastra)
[![tests](https://github.com/weigertlab/napari-trackastra/workflows/tests/badge.svg)](https://github.com/weigertlab/napari-trackastra/actions)
[![codecov](https://codecov.io/gh/weigertlab/napari-trackastra/branch/main/graph/badge.svg)](https://codecov.io/gh/weigertlab/napari-trackastra)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-trackastra)](https://napari-hub.org/plugins/napari-trackastra)

A napari plugin for cell tracking with [`trackastra`](https://github.com/weigertlab/trackastra).

![demo](https://github.com/weigertlab/napari-trackastra/assets/8866751/097eb82d-0fef-423e-9275-3fb528c20f7d)


## Installation
1. Please install napari as outlined [here](https://napari.org/stable/tutorials/fundamentals/installation.html).

2. After that, install the latest version of this plugin from PyPI with:
    ```
    pip install napari-trackastra
    ```

Notes:
- For tracking with an integer linear program (ILP, which is optional), follow the [installation instructions of the main `trackastra` package](https://github.com/weigertlab/trackastra/blob/main/README.md#installation).
- On Windows currently only supported for Python 3.10.

## Usage

- `trackastra` expects a timeseries of raw images and corresponding segmentations masks as input.
- We provide some demo data at `File > Open Sample > trackastra`.
- Tracked cells can be directly saved to [Cell Tracking Challenge format](https://celltrackingchallenge.net/datasets/).
- Results can be drag-and-dropped back into napari for inspection.

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/weigertlab/napari-trackastra/issues', 'Documentation, https://github.com/weigertlab/napari-trackastra#README.md', 'Source Code, https://github.com/weigertlab/napari-trackastra', 'User Support, https://github.com/weigertlab/napari-trackastra/issues']",,,napari-trackastra.track,napari-trackastra.example_data_bacteria,,,
444,napari-toothfairy-annotator,napari-toothfairy-annotator,ToothFairy Annotator,0.0.18,2024-03-28,2025-05-28,Luca Lumetti,lumetti.luca@gmail.com,MIT,https://github.com/LucaLumetti/napari-toothfairy-annotator/issues,https://pypi.org/project/napari-toothfairy-annotator/,,https://github.com/LucaLumetti/napari-toothfairy-annotator,The plugin employed to annotate volumes employed in the ToothFairy Challenges,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-toothfairy-annotator

[![License MIT](https://img.shields.io/pypi/l/napari-toothfairy-annotator.svg?color=green)](https://github.com/LucaLumetti/napari-toothfairy-annotator/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-toothfairy-annotator.svg?color=green)](https://pypi.org/project/napari-toothfairy-annotator)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-toothfairy-annotator.svg?color=green)](https://python.org)
[![tests](https://github.com/LucaLumetti/napari-toothfairy-annotator/workflows/tests/badge.svg)](https://github.com/LucaLumetti/napari-toothfairy-annotator/actions)
[![codecov](https://codecov.io/gh/LucaLumetti/napari-toothfairy-annotator/branch/main/graph/badge.svg)](https://codecov.io/gh/LucaLumetti/napari-toothfairy-annotator)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-toothfairy-annotator)](https://napari-hub.org/plugins/napari-toothfairy-annotator)

The plugin employed to annotate volumes employed in the ToothFairy 2 Challenge

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-toothfairy-annotator` via [pip]:

    pip install napari-toothfairy-annotator



To install latest development version :

    pip install git+https://github.com/LucaLumetti/napari-toothfairy-annotator.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-toothfairy-annotator"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/LucaLumetti/napari-toothfairy-annotator/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/LucaLumetti/napari-toothfairy-annotator/issues', 'Documentation, https://github.com/LucaLumetti/napari-toothfairy-annotator#README.md', 'Source Code, https://github.com/LucaLumetti/napari-toothfairy-annotator', 'User Support, https://github.com/LucaLumetti/napari-toothfairy-annotator/issues']",napari-toothfairy-annotator.get_reader,napari-toothfairy-annotator.write_multiple,napari-toothfairy-annotator.annotator,,['*'],,['.npy']
445,napari-trackpy,napari-trackpy,Particle tracking,0.3.0,2023-11-07,2023-11-09,Roy Hoitink,L.D.Hoitink@uu.nl,MIT,https://github.com/rhoitink/napari-trackpy/issues,https://pypi.org/project/napari-trackpy/,,https://github.com/rhoitink/napari-trackpy,Plugin to do trackpy particle tracking on microscopy data within napari,>=3.8,"['numpy', 'magicgui', 'qtpy', 'napari', 'napari-aicsimageio', 'readlif', 'trackpy', 'matplotlib', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-trackpy

[![License MIT](https://img.shields.io/pypi/l/napari-trackpy.svg?color=green)](https://github.com/rhoitink/napari-trackpy/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-trackpy.svg?color=green)](https://pypi.org/project/napari-trackpy)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-trackpy.svg?color=green)](https://python.org)
[![tests](https://github.com/rhoitink/napari-trackpy/workflows/tests/badge.svg)](https://github.com/rhoitink/napari-trackpy/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-trackpy)](https://napari-hub.org/plugins/napari-trackpy)

Plugin to do [trackpy] particle tracking on 3D microscopy data within [napari]. Currently only tracking of XYZ data is implemented.

## Installation

You can install `napari-trackpy` via [pip]:

    pip install napari-trackpy

To install latest development version :

    pip install git+https://github.com/rhoitink/napari-trackpy.git

## How to use this plugin?
* Load your XYZ data (using [napari-aicsimageio])
* Make sure to split channels into different layers, such that the layer only contains 3D (XYZ) data
* Open the widget for the tracking plugin via `Plugins` > `XYZ particle tracking`
* Optimize the tracking settings for your dataset, for an extensive description of the settings, visit [this tutorial](http://soft-matter.github.io/trackpy/dev/tutorial/tracking-3d.html)
* Save your tracking data into the `.xyz` file format using `Ctrl`+`S` (on the points layer) or via the menu `File` > `Save Selected Layer(s)...`

## Contributing

Contributions are very welcome. Tests can be run with [tox].

## License

Distributed under the terms of the [MIT] license,
""napari-trackpy"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[trackpy]: https://github.com/soft-matter/trackpy
[napari-aicsimageio]: https://github.com/AllenCellModeling/napari-aicsimageio
[MIT]: http://opensource.org/licenses/MIT

[file an issue]: https://github.com/rhoitink/napari-trackpy/issues

[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/rhoitink/napari-trackpy/issues', 'Documentation, https://github.com/rhoitink/napari-trackpy#README.md', 'Source Code, https://github.com/rhoitink/napari-trackpy', 'User Support, https://github.com/rhoitink/napari-trackpy/issues']",,napari-trackpy.write_points_xyzfile,napari-trackpy.xyz_tracking,,,['.xyz'],
446,napari-tracks-reader,napari-tracks-reader,napari-tracks-reader,0.1.3,2021-05-11,2021-05-26,Sylvain Prigent,sylvain.prigent@inria.fr,GNU GPL v3.0,https://github.com/sylvainprigent/napari-tracks-reader,https://pypi.org/project/napari-tracks-reader/,,https://github.com/sylvainprigent/napari-tracks-reader,"Read tracks from txt (xml, csv) files to napari",>=3.6,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'pandas (>=1.2.4)']","# napari-tracks-reader

[![License](https://img.shields.io/pypi/l/napari-tracks-reader.svg?color=green)](https://github.com/sylvainprigent/napari-tracks-reader/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tracks-reader.svg?color=green)](https://pypi.org/project/napari-tracks-reader)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tracks-reader.svg?color=green)](https://python.org)
[![tests](https://github.com/sylvainprigent/napari-tracks-reader/workflows/tests/badge.svg)](https://github.com/sylvainprigent/napari-tracks-reader/actions)
[![codecov](https://codecov.io/gh/sylvainprigent/napari-tracks-reader/branch/master/graph/badge.svg)](https://codecov.io/gh/sylvainprigent/napari-tracks-reader)

Read tracks from various tracking softwares output files to napari tracks layer.
Supported formats are:
- Trakmate model (xml)
- Icy (xml)
- TrackContestISBI2012 (xml) 

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `napari-tracks-reader` via [pip]:

    pip install napari-tracks-reader

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-tracks-reader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/sylvainprigent/napari-tracks-reader/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']",,napari-tracks-reader.napari_get_reader,,,,['*'],,
447,napari-trait2d,napari-trait2d,napari TRAIT2D,0.1.4,2022-07-09,2022-07-21,Jacopo Abramo,jacopo.abramo@gmail.com,BSD-3-Clause,https://github.com/jacopoabramo/napari-trait2d/issues,https://pypi.org/project/napari-trait2d/,,https://github.com/jacopoabramo/napari-trait2d,"A napari plugin for TRAIT2D, a software for quantitative analysis of single particle diffusion data",>=3.8,"['numpy', 'qtpy', 'napari[pyqt5]', 'dacite', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'""]","# napari-trait2d

[![License BSD-3](https://img.shields.io/pypi/l/napari-trait2d.svg?color=green)](https://github.com/jacopoabramo/napari-trait2d/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-trait2d.svg?color=green)](https://pypi.org/project/napari-trait2d)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-trait2d.svg?color=green)](https://python.org)
[![tests](https://github.com/jacopoabramo/napari-trait2d/workflows/tests/badge.svg)](https://github.com/jacopoabramo/napari-trait2d/actions)
[![codecov](https://codecov.io/gh/jacopoabramo/napari-trait2d/branch/main/graph/badge.svg)](https://codecov.io/gh/jacopoabramo/napari-trait2d)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-trait2d)](https://napari-hub.org/plugins/napari-trait2d)

A napari plugin for TRAIT2D, a software for quantitative analysis of single particle diffusion data

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-trait2d` via [pip]:

    pip install napari-trait2d



To install latest development version :

    pip install git+https://github.com/jacopoabramo/napari-trait2d.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-trait2d"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/jacopoabramo/napari-trait2d/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10']","['Bug Tracker, https://github.com/jacopoabramo/napari-trait2d/issues', 'Documentation, https://github.com/jacopoabramo/napari-trait2d#README.md', 'Source Code, https://github.com/jacopoabramo/napari-trait2d', 'User Support, https://github.com/jacopoabramo/napari-trait2d/issues']",,,napari-trait2d.trait2d_widget,,,,
448,napari-turing,napari-turing,Turing Patterns,0.3.2,2022-08-08,2022-10-27,LÃ©o Guignard,leo.guignard@univ-amu.fr,MIT,https://github.com/leoguignard/napari-turing/issues,https://pypi.org/project/napari-turing/,,https://github.com/leoguignard/napari-turing,A plugin to run simmple simulations of Turing patterns,>=3.8,"['numpy', 'scipy', 'scikit-image', 'magicgui', 'qtpy', 'napari', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-turing

[![License MIT](https://img.shields.io/pypi/l/napari-turing.svg?color=green)](https://github.com/leoguignard/napari-turing/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-turing.svg?color=green)](https://pypi.org/project/napari-turing)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-turing.svg?color=green)](https://python.org)
[![tests](https://github.com/leoguignard/napari-turing/workflows/tests/badge.svg)](https://github.com/leoguignard/napari-turing/actions)
[![codecov](https://codecov.io/gh/leoguignard/napari-turing/branch/main/graph/badge.svg)](https://codecov.io/gh/leoguignard/napari-turing)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-turing)](https://napari-hub.org/plugins/napari-turing)

A plugin to run simple simulations of Turing patterns

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->
![example 1](img/turing_patterns.gif)
![example 2](img/turing_patterns2.gif)

## Installation

You can install `napari-turing` via [pip] after downloading the content of

    pip install napari-turing


To install latest version :

    pip install git+https://github.com/leoguignard/napari-turing.git

## Troubleshooting

If the installation does not work just with the previous command, it might be useful to first install [napari] for example that way:

    conda install napari

## Creating a new model

To create your own model, you can use the template for models [here](src/napari_turing/Models/ModelTemplate.py).

Note that a bit of knowledge in Python is probably necessary and it might not be completely trivial at first but you'll manage :)

First you need to name the concentrations that you will use with the following [line](src/napari_turing/Models/ModelTemplate.py#L40):
```python
    _concentration_names = [""A"", ""I""]
```

Then, you need to declare its variables. For example you can create a parameter named `mu_a` the following way ([here in the code](src/napari_turing/Models/ModelTemplate.py#L53-L60)):
```python
    mu_a = ModelParameter(
        name=""mu_a"",  # Name of the parameter
        description=""Activator diffusion coefficient (10^-4)"",  # Description of the parameter for napari
        value=2.8,  # Initial and default value
        min=1,  # Minimum value the parameter can take
        max=5,  # Maximum value the parameter can take
        exponent=1e-4,  # All values given to this instance of the class will but multiplied by this value
    )
```

Then you need to list the parameters that are necessary to run the model (usually all the paramaters declared previously) and the parameters that you will allow the user to tune (for example, sometimes some of the parameters are co-dependent and there is no point in being able to tune both of them). That should be done the following way ([here in the code](src/napari_turing/Models/ModelTemplate.py#L86-89)):
```python
    # These are the parameters that are necessary to run the equations.
    _necessary_parameters = [tau, k, mu_a, mu_i]
    # These are the parameters that can be modified via napari
    _tunable_parameters = _necessary_parameters
```

If you want, you can specify what the method will return as a string, it will be displayed in the napari viewer ([here in the code](src/napari_turing/Models/ModelTemplate.py#L90-L98)):
```python
    # This function allows to display some information about the model
    # in napari
    def __str__(self) -> str:
        return (
            ""Equations (FitzHugh-Nagumo model):\n""
            ""  Concentration of Activator (a) and Inhibitor (i)\n""
            ""    - da/dt = mu_a * diffusion(a) + a - a^3 - i + k\n""
            ""    - tau * di/dt = mu_i * diffusion(i) + a - i""
        )
```

Now that the basics are declared, you will need to declare how to initialize your concentrations the following way ([here in the code](src/napari_turing/Models/ModelTemplate.py#L100-L116)):
```python
    # The following allows to reset the values of the concentrations.
    # The function takes the name of the concentration to initialize.
    # If no name is given or if it is None all the concentrations are
    # reinitialized.
    #
    # The reason why this function is useful is that some models 
    # require specific initialisations for them to work correctly
    # In the following example the concentrations are reintinalized
    # to a random value between -1 and 1.
    # This is the default behavior, so if you don't need to change
    # it you don't have to implement the function.
    def init_concentrations(self, C: Optional[str] = None) -> None:
        if C is None:
            for ci in self.concentration_names():
                self[ci] = np.random.random((self.size, self.size)) * 2 - 1
        else:
            self[C] = np.random.random((self.size, self.size)) * 2 - 1
```
In the previous example, the all concentrations are initialized the same way. If you need to have different initializations, you can do it the following way for example ([from the GrayScott model](src/napari_turing/Models/GrayScott.py#L68-L76)):
```python
    def init_concentrations(self, C: Optional[str] = None) -> None:
        if C == ""X"" or C is None:
            self[""X""] = np.ones((self.size, self.size))
        if C == ""Y"" or C is None:
            Y = np.zeros((self.size, self.size))
            nb_pos = 20
            pos = (np.random.random((2, nb_pos)) * self.size).astype(int)
            Y[pos[0], pos[1]] = 1
            self[""Y""] = Y
```
In this model, there are two concentrations, `X` and `Y` which are initialized differenty. Note that they can be accessed using `self[""X""]` or `self.X`.

Finally, you of course have to define the reaction equations and the diffusion equations. The way it is defined is with two functions, one for the reaction and one for the diffusion, that take as an input the name of the concentration to apply the function to and returns the new values. Then for each of your concentrations, their new values will be computed as followed:
```python
new_concentration = current_concentration + dt*(reaction + diffusion)
```

Here is an example for the reaction function ([here in the code](src/napari_turing/Models/ModelTemplate.py#L127-L136)):
```python 
    # This function defines the equations of the reactions.
    # It takes as an input which concentration to compute
    # (in this example we have to define how to compute A and I)
    def _reaction(self, c: str) -> np.ndarray:
        if c == ""A"":
            # Below is the reaction part of the equation (1)
            return self.A - self.A**3 - self.I + self.k 
        elif c == ""I"":
            # Below is the reaction part of the equation (2)
            return (self.A - self.I) / self.tau
```
Of course, if you have more concentrations, you will need to define more equations.

Here is an example for the reaction function ([here in the code](src/napari_turing/Models/ModelTemplate.py#L138-L166)):
```python
    # This function defines the equations of the diffusion.
    # It takes as an input which concentration to compute
    # (in this example we have to define how to compute A and I)
    # Here we compute the diffusion as follow:
    # A cell gives an equal fraction mu of its concentration to its neighbors
    # A cell recieves an equal fraction mu of concentration from its neighbors
    # Neighbors = (left, right, above, below)
    # In the case of oriented diffusion the amount recieved and given to the neighbors
    # is imbalanced according to the position of the neighbor.
    def _diffusion(self, c: str) -> np.ndarray:
        if c == ""A"":
            arr = self.A # Define the array of concentrations to diffuse for the reageant A
            mu = self.mu_a # Define the diffusion coefficient for the reageant A
        elif c == ""I"":
            arr = self.I # Define the array of concentrations to diffuse for the reageant I
            mu = self.mu_i # Define the diffusion coefficient for the reageant I
        
        # Computes what is recieved from neighboring cells
        from_cell = convolve(arr, self.kernel.value, mode=""constant"", cval=0)
        # Computes what is given to neighboring cells
        to_cell = self.nb_neighbs * arr

        # Computes the diffusion
        out = mu * (from_cell - to_cell) / (self.dx * self.dy)

        # In our case, the equation (2), for I specify that it has to be divided by tau
        if c == ""I"":
            out /= self.tau
        return out
```
The diffusion function is usually a standard one so it might not be necessary to overly change it.

You can find other model examples:
- [Brusselator](src/napari_turing/Models/Brusselator.py)
- [GrayScott](src/napari_turing/Models/GrayScott.py)
- [GameOfLife](src/napari_turing/Models/GameOfLife.py)

Once all that is done, let say you've saved your new model in the folder [Models](src/napari_turing/Models) under the name `NewModel.py` and the model class created is name `NewModel`. Then you need to declare you model in the [`_model_list.py`](src/napari_turing/Models/_model_list.py) file. To do so you need to add the following lines in the file:
```python
from enum import Enum
from .FitzHughNagumo import FitzHughNagumo
from .Brusselator import Brusselator
from .GrayScott import GrayScott
from .GameOfLife import GameOfLife
from .NewModel import NewModel ## THAT LINE HERE

class AvailableModels(Enum):
    FitzHughNagumo = FitzHughNagumo
    Brusselator = Brusselator
    GrayScott = GrayScott
    GameOfLife = GameOfLife
    NewModel = NewModel ## AND THAT OTHER LINE HERE
```

## Contributing

Contributions are very welcome.

## License

Distributed under the terms of the [MIT] license,
""napari-turing"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/leoguignard/napari-turing/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/leoguignard/napari-turing/issues', 'Documentation, https://github.com/leoguignard/napari-turing#README.md', 'Source Code, https://github.com/leoguignard/napari-turing', 'User Support, https://github.com/leoguignard/napari-turing/issues']",,,napari-turing.TuringViewer,,,,
449,napari-tyssue,napari-tyssue,napari tyssue,0.1.2,2022-10-20,2023-02-17,Kyle Harrington,czi@kyleharrington.com,BSD-3-Clause,https://github.com/kephale/napari-tyssue/issues,https://pypi.org/project/napari-tyssue/,,https://github.com/kephale/napari-tyssue,A napari plugin for use with the tyssue library,>=3.8,"['numpy', 'magicgui', 'qtpy', 'tyssue', 'quantities', 'pooch', 'tables', 'imageio-ffmpeg', 'invagination (==0.0.2)', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-tyssue

[![License BSD-3](https://img.shields.io/pypi/l/napari-tyssue.svg?color=green)](https://github.com/kephale/napari-tyssue/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-tyssue.svg?color=green)](https://pypi.org/project/napari-tyssue)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-tyssue.svg?color=green)](https://python.org)
[![tests](https://github.com/kephale/napari-tyssue/workflows/tests/badge.svg)](https://github.com/kephale/napari-tyssue/actions)
[![codecov](https://codecov.io/gh/kephale/napari-tyssue/branch/main/graph/badge.svg)](https://codecov.io/gh/kephale/napari-tyssue)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-tyssue)](https://napari-hub.org/plugins/napari-tyssue)

A napari plugin for use with the tyssue library

![napari-tyssue demo of apoptosis model](https://github.com/kephale/napari-tyssue/raw/main/assets/napari_tyssue_apoptosis.gif)


Example video of apoptosis demo simulation created based on the
apoptosis demo from
[tyssue-demo](https://github.com/DamCB/tyssue-demo).

![napari-tyssue demo of invagination model](https://github.com/kephale/napari-tyssue/raw/main/assets/napari_tyssue_invagination_3x.gif)


Example video of apoptosis demo simulation created based on work under
revision by Suzanne group at U Toulouse entitled
""Epithelio-mesenchymal transition generates an apico-basal driving
force required for tissue remodeling"" [available here](https://github.com/DamCB/invagination).

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You are better off using conda. You will need pytables, and ideally CGAL.

You can install `napari-tyssue` via [pip]:

    pip install napari-tyssue



To install latest development version :

    pip install git+https://github.com/kephale/napari-tyssue.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-tyssue"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kephale/napari-tyssue/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kephale/napari-tyssue/issues', 'Documentation, https://github.com/kephale/napari-tyssue#README.md', 'Source Code, https://github.com/kephale/napari-tyssue', 'User Support, https://github.com/kephale/napari-tyssue/issues']",,,napari-tyssue.make_apoptosis_widget,,,,
450,napari-umap,napari-umap,UMAP,0.0.1,2022-11-01,2022-11-01,Jordao Bragantini,jordao.bragantini@czbiohub.org,BSD-3-Clause,https://github.com/royerlab/napari-umap/issues,https://pypi.org/project/napari-umap/,,https://github.com/royerlab/napari-umap,A simple plugin to use with napari,>=3.8,"['numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-umap

[![License BSD-3](https://img.shields.io/pypi/l/napari-umap.svg?color=green)](https://github.com/royerlab/napari-umap/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-umap.svg?color=green)](https://pypi.org/project/napari-umap)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-umap.svg?color=green)](https://python.org)
[![tests](https://github.com/royerlab/napari-umap/workflows/tests/badge.svg)](https://github.com/royerlab/napari-umap/actions)
[![codecov](https://codecov.io/gh/royerlab/napari-umap/branch/main/graph/badge.svg)](https://codecov.io/gh/royerlab/napari-umap)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-umap)](https://napari-hub.org/plugins/napari-umap)

A simple plugin to use with napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-umap` via [pip]:

    pip install napari-umap



To install latest development version :

    pip install git+https://github.com/royerlab/napari-umap.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-umap"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/royerlab/napari-umap/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/royerlab/napari-umap/issues', 'Documentation, https://github.com/royerlab/napari-umap#README.md', 'Source Code, https://github.com/royerlab/napari-umap', 'User Support, https://github.com/royerlab/napari-umap/issues']",,,napari-umap.make_qwidget,,,,
451,napari-ufish,napari-ufish,U-FISH,0.0.1,2023-09-30,2023-09-30,Weize Xu,vet.xwz@gmail.com,MIT,,https://pypi.org/project/napari-ufish/,None,,Deep learning-based FISH spot calling method.,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'ufish', 'napari', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-ufish

[![License MIT](https://img.shields.io/pypi/l/napari-ufish.svg?color=green)](https://github.com/UFISH-Team/napari-ufish/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-ufish.svg?color=green)](https://pypi.org/project/napari-ufish)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-ufish.svg?color=green)](https://python.org)
[![tests](https://github.com/UFISH-Team/napari-ufish/workflows/tests/badge.svg)](https://github.com/UFISH-Team/napari-ufish/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-ufish)](https://napari-hub.org/plugins/napari-ufish)

Deep learning-based FISH spot calling method.
The napari plugin for [U-FISH](https://github.com/UFISH-Team/U-FISH).

## Links

+ [U-FISH](https://github.com/UFISH-Team/U-FISH)
+ [U-FISH models](https://huggingface.co/GangCaoLab/U-FISH)
+ [FISH_spots dataset](https://huggingface.co/datasets/GangCaoLab/FISH_spots)

## TODO List

- [x] Sample image
- [x] Inference interface
    - [x] Inference parameters
    - [x] Load model from path
    - [x] Help information dialog
- [x] Training interface

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-ufish` via [pip]:

    pip install napari-ufish


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-ufish"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-ufish.make_inference_widget,napari-ufish.make_sample_data,,,
452,napari-ui-tracer,napari-ui-tracer,Napari UI tracer,0.1.2,2023-03-14,2023-04-13,Daniel Althviz,dalthviz@gmail.com,MIT,https://github.com/dalthviz/napari-ui-tracer/issues,https://pypi.org/project/napari-ui-tracer/,,https://github.com/dalthviz/napari-ui-tracer,A plugin to help understand Napari UI components and check their source code definition,>=3.8,"['qtpy (>=2.3.0)', ""pre-commit ; extra == 'pre-commit'"", ""pyqt5 ; extra == 'pyqt5'"", ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'""]","# napari-ui-tracer

[![License MIT](https://img.shields.io/pypi/l/napari-ui-tracer.svg?color=green)](https://github.com/dalthviz/napari-ui-tracer/raw/main/LICENSE)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-ui-tracer.svg?color=green)](https://python.org)
[![PyPI](https://img.shields.io/pypi/v/napari-ui-tracer.svg?color=green)](https://pypi.org/project/napari-ui-tracer)
[![PyPI download month](https://img.shields.io/pypi/dm/napari-ui-tracer.svg?color=green)](https://pypi.org/project/napari-ui-tracer/)
[![conda version](https://img.shields.io/conda/vn/conda-forge/napari-ui-tracer.svg?color=blue)](https://anaconda.org/conda-forge/napari-ui-tracer)
[![conda download count](https://img.shields.io/conda/d/conda-forge/napari-ui-tracer.svg?color=blue)](https://anaconda.org/conda-forge/napari-ui-tracer)
[![tests](https://github.com/dalthviz/napari-ui-tracer/workflows/tests/badge.svg)](https://github.com/dalthviz/napari-ui-tracer/actions)
[![codecov](https://codecov.io/gh/dalthviz/napari-ui-tracer/branch/main/graph/badge.svg?token=E6je6vXOSA)](https://codecov.io/gh/dalthviz/napari-ui-tracer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-ui-tracer)](https://napari-hub.org/plugins/napari-ui-tracer)

A plugin to help understand Napari UI components and locate their code definition

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

![GIF showing Napari UI tracer's functionality](https://raw.githubusercontent.com/dalthviz/napari-ui-tracer/main/images/napari-ui-tracer.gif)

## Installation

You can install `napari-ui-tracer` via [pip]:

    pip install napari-ui-tracer

Or via [conda]:

    conda install -c conda-forge napari-ui-tracer

To install latest development version :

    pip install git+https://github.com/dalthviz/napari-ui-tracer.git

## Usage

1. Show the plugin inside the napari interface:

    * You can launch napari with the plugin visible running:

            napari -w napari-ui-tracer

    * Or select it from `Plugins > Napari UI tracer widget`

2. Check the `Enable Qt event filter` checkbox:
    * Use `Ctrl/Cmd + Mouse button right click` to see the information available about any widget inside napari
    * An option to show objects documentation (object class docstring) can be used by checking the `Show object documentation` checkbox

3. Check the `Enable application events logging` checkbox:
    * A log like information with the events generated when interacting with the application will appear
    * Some configuration options are available:
        * `Stack depth`: Stack depth to show. Default to 20
        * `Allowed nested events`: How many sub-emit nesting levels to show (i.e. events that get triggered by other events). Default to 0

4. If you want to explore the related widget or event module source file, click the link in the output section of the plugin (the module file will open if you have a registered program to open such kind of file)

## Contributing

Contributions are very welcome. Pre-commit is used for formatting. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-ui-tracer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/dalthviz/napari-ui-tracer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[conda]: https://docs.conda.io/projects/conda/en/stable/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/dalthviz/napari-ui-tracer/issues', 'Documentation, https://github.com/dalthviz/napari-ui-tracer#README.md', 'Source Code, https://github.com/dalthviz/napari-ui-tracer', 'User Support, https://github.com/dalthviz/napari-ui-tracer/issues']",,,napari-ui-tracer.make_qwidget,,,,
453,napari-unispac,napari-UniSPAC,napari-UniSPAC,1.0.6,2025-02-07,2025-07-11,,,Unavailable,https://github.com/ddd9898/UniSPAC,https://pypi.org/project/napari-UniSPAC/,,https://github.com/ddd9898/UniSPAC,A Unified Segmentation framework for Proofreading and Annotation in Connectomics (UniSPAC)!,,['napari'],"# napari-UniSPAC
The napari plugin for UniSPAC [A Unified Segmentation framework for Proofreading and Annotation in Connectomics]. UniSPAC provides interactive 3D neuron segmentation. Neuron segmentation, proofreading and tracking can be done with just mouse clicks, which is much more efficient than existing tools.

## Requirements

A system with enough GPU memory and pytorch installed. The size of the GPU memory is related to the size of the vEM image that can be processed. For  `test_roi1_sub_z0-100.tiff` with a shape of 800x800x100, the recommended minimum GPU memory is 12GB.

## Installation

Step 1: install napari via pip:

```shell
pip install -U 'napari[all]'
```

Step 2: install `napari-UniSPAC`

```shell
git clone https://github.com/ddd9898/napari-UniSPAC.git
cd napari-UniSPAC
pip install -e .
```

Step 3: run napari:

```shell
napari
```

You can familiarise yourself with how UniSPAC's napari plugin operates by labeling  `test_roi1_sub_z0-100.tiff`, which is an example of Drosophila vEM images.
",['Framework :: napari'],,,,napari-UniSPAC.seg,,,,
454,napari-utrack-loader,napari-utrack-loader,Utrack Loader,0.0.1,2024-05-31,2024-05-31,Jules Vanaret,jules.vanaret@univ-amu.fr,MIT,https://github.com/jules-vanaret/napari-utrack-loader/issues,https://pypi.org/project/napari-utrack-loader/,,,"A simple plugin to load images, detections and tracks from the u-track software into napari",>=3.9,"['numpy', 'magicgui', 'qtpy', 'tifffile', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-utrack-loader

[![License MIT](https://img.shields.io/pypi/l/napari-utrack-loader.svg?color=green)](https://github.com/jules-vanaret/napari-utrack-loader/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-utrack-loader.svg?color=green)](https://pypi.org/project/napari-utrack-loader)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-utrack-loader.svg?color=green)](https://python.org)
[![tests](https://github.com/jules-vanaret/napari-utrack-loader/workflows/tests/badge.svg)](https://github.com/jules-vanaret/napari-utrack-loader/actions)
[![codecov](https://codecov.io/gh/jules-vanaret/napari-utrack-loader/branch/main/graph/badge.svg)](https://codecov.io/gh/jules-vanaret/napari-utrack-loader)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-utrack-loader)](https://napari-hub.org/plugins/napari-utrack-loader)

A simple plugin to use FooBar segmentation within napari

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-utrack-loader` via [pip]:

    pip install napari-utrack-loader



To install latest development version :

    pip install git+https://github.com/jules-vanaret/napari-utrack-loader.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-utrack-loader"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/jules-vanaret/napari-utrack-loader/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/jules-vanaret/napari-utrack-loader/issues', 'Documentation, https://github.com/jules-vanaret/napari-utrack-loader#README.md', 'Source Code, https://github.com/jules-vanaret/napari-utrack-loader', 'User Support, https://github.com/jules-vanaret/napari-utrack-loader/issues']",,,napari-utrack-loader.UtrackLoader,,,,
455,napari-unicell,napari-unicell,unicell,0.0.1.post3,2022-11-12,2022-11-12,Jun Ma,junma.ma@mail.utoronto.ca,Apache-2.0,https://github.com/JunMa11/napari-unicell/issues,https://pypi.org/project/napari-unicell/,,https://github.com/JunMa11/napari-unicell,universal cell segmentation models,>=3.8,"['torch', 'imagecodecs', 'scipy', 'numpy', 'magicgui', 'qtpy', 'scikit-image', 'monai', 'einops', 'PyQt5', 'napari', 'napari-plugin-engine', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-unicell

[![License Apache Software License 2.0](https://img.shields.io/pypi/l/napari-unicell.svg?color=green)](https://github.com/JunMa11/napari-unicell/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-unicell.svg?color=green)](https://pypi.org/project/napari-unicell)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-unicell.svg?color=green)](https://python.org)
[![tests](https://github.com/JunMa11/napari-unicell/workflows/tests/badge.svg)](https://github.com/JunMa11/napari-unicell/actions)
[![codecov](https://codecov.io/gh/JunMa11/napari-unicell/branch/main/graph/badge.svg)](https://codecov.io/gh/JunMa11/napari-unicell)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-unicell)](https://napari-hub.org/plugins/napari-unicell)

universal cell segmentation models

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-unicell` via [pip]:

    pip install napari-unicell




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""napari-unicell"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/JunMa11/napari-unicell/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: Apache Software License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/JunMa11/napari-unicell/issues', 'Documentation, https://github.com/JunMa11/napari-unicell#README.md', 'Source Code, https://github.com/JunMa11/napari-unicell', 'User Support, https://github.com/JunMa11/napari-unicell/issues']",,,napari-unicell.unicell_widget,,,,
456,napari-vascilia,Napari-VASCilia,VASCilia,1.3.0,2024-06-28,2024-11-25,Yasmin Kassim,ymkgz8@mail.missouri.edu,"Copyright (c) 2024, Yasmin Kas...",https://github.com/ucsdmanorlab/Napari-VASCilia,https://pypi.org/project/Napari-VASCilia/,,https://github.com/ucsdmanorlab/Napari-VASCilia,VASCilia (Vision Analysis StereoCilia): A Napari Plugin for Deep Learning-Based 3D Analysis of Cochlear Hair Cell Stereocilia Bundles,>=3.9,"['numpy', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""']","# VASCilia (Vision Analysis StereoCilia): A Napari Plugin for Deep Learning-Based 3D Analysis of Cochlear Hair Cell Stereocilia Bundles 

<p align=""left"">
  <img src=""images/logo_3d.png"" alt=""VASCilia Logo"" width=""170"">
</p>

Explore the complexities of the cochlea with VASCilia, a Napari plugin created to aid in the 3D segmentation and quantification of stereocilia bundles. Equipped with a range of thoughtful features, VASCilia stands for (Vision Analysis StereoCilia) and it provides a supportive tool for auditory research, including:  
1. Slice Selection: Easily navigate through 3D stacks to find the slices that matter most for your research.
2. Stack Rotation: Adjust the orientation of your stack to facilitate better analysis.
3. 3D Instance Segmentation: Identify and assess individual bundles with clear separation using deep learning.
4. Bundle Deletion: Remove unwanted bundles to streamline your dataset.
5. Regional Classification: identify whether the region is from BASE, MIDDLE, or APEX in the cochlea using deep learning.
6. Hair Cell Differentiation: Distinguish between Inner Hair Cells and Outer Hair Cells with confidence using deep learning.
7. Measurement Analysis: Calculate various measurements such as volume, centroid location, and surface area.
8. Fluorescence Intensity Analysis: Assess the intensity of signal or protein with detailed precision.
9. 3D Bundle Height Calculation: Measure the 3D distance from the peak to the base of each bundle, according to your sample's resolution.
10. Bundle orientation: Determine bundle orientation for all hair cells based on two strategies: Height-only and Height&Distance.

VASCilia &#x2764;&#xfe0f; is a valuable resource for the ear research community &#128066;, simplifying the complexity of measurement and analysis. It comes with a suite of pre-trained models to facilitate 3D segmentation, cell type identification and regional classification.

Furthermore, we are committed to supporting research growth with a comprehensive training section for those looking to explore different staining techniques or develop new segmentation models through annotation and refinement.

VASCilia is here to support researchers in their quest for deeper understanding and innovation in the study of cochlear structures.  
*[click the image to see a highlights reel of the plugin](https://youtu.be/MwMOxJQ_elo)*  

[![Watch the video](images/VASCilia_pipeline2.png)](https://youtu.be/MwMOxJQ_elo)

*[Click me to see a video demo of the entire workflow](https://youtu.be/mNPJ1g0vEW8)*  

## How to install : 
STEP1[Install WSL]:  
1. Open the Command Prompt and install the Ubuntu 20.04 Distribution by simply copy paste this command  
wsl --install -d Ubuntu-20.04
2. After the setup successfully completes, reboot your computer. Open Ubuntu by typing ""Ubuntu"" in the search bar. A pop-up window for Ubuntu will appear. To check if CUDA and the GPU are correctly installed and available, type nvidia-smi in the terminal  

STEP2[Download the deep learning trained models]:
1. Download the VASCilia_trained_models from https://www.dropbox.com/scl/fo/jsvldda8yvma3omfijxxn/ALeDfYUbiOuj69Flbc728rs?rlkey=mtilfz33qiizpul7uyisud5st&st=41kjlbw0&dl=0 
now you should have a folder called 'models'

- ð **models** `[Trained models]`
    - ð **cell_type_identification_model** `[has weights for cell type identification IHC vs OHC]`
    - ð **new_seg_model** `[incase you fine tune the existing model, the new model will be stored here]`
    - ð **region_prediction** `[has weights for region prediction]`
    - ð **seg_model**  `[has the weights for the 3D instance segmentation model]`
    - ð **Train_predict_stereocilia_exe** `[executible needed by the plugin to segment and retrain the model using WSL]`  
    - ð **ZFT_trim_model** `[deep learning model weights for z focus tracker algorithm]`  
    - ð **rotation_correction_model** `[deep learning model weights for correcting the orientation of the stack]`  
 
STEP3[download one dataset to test VASCilia]:  
download one sample from our datasets to try in this link https://www.dropbox.com/scl/fo/pg3i39xaf3vtjydh663n9/h?rlkey=agtnxau73vrv3ism0h55eauek&dl=0  
create a folder, called raw_data folder and put the downloaded dataset inside the raw_data folder

  - ð **raw_data** `[raw data (stacks) is placed here]`
    - ð Litter 12 Mouse 4 MIDDLE - delBUNdelCAP_Airyscan Processing.czi
   
Also create another folder called processed_data in which the plugin will use to store the results of the analysis
  
  - ð **processed_data** `[processed data will be stored here]`

## Instructions for Cloning the Repository [You can do either Option A or Option B]:
## Option A: Cloning the Repository:  
```sh
git clone https://github.com/ucsdmanorlab/Napari-VASCilia.git
cd Napari-VASCilia
conda create -y -n napari-VASCilia -c conda-forge python=3.10    
conda activate napari-VASCilia    
pip install -r requirements.txt
pip install -e .
napari  
```
## Option B: Installing via PyPI:
```sh
conda create -y -n napari-VASCilia -c conda-forge python=3.10    
conda activate napari-VASCilia 
# Download the requirements.txt file from this repository and ensure you have it in your working directory. 
pip install -r requirements.txt
pip install Napari-VASCilia
napari  
```
Post-installation:  
1. Activate the plugin through Plugins -> VASCilia UI (Napari-VASCilia).
2. This will generate the config.json file at C:/Users/Username/.napari-vascilia/config.json. Update the paths in config.json as needed.
config.json will be generated upon running the plugin for the first time.

- ð C:/Users/Username/   [your home folder]
  - ð **.napari-vascilia** `[Folder_path]`
    - ð **config.json**

Please update the /.../ portion according to your paths:

```sh
{
    ""rootfolder"": ""C:/Users/.../processed_data/"",
    ""wsl_executable"": ""C:/Users/.../models/Train_predict_stereocilia_exe/Train_Predict_stereocilia_exe_v2"",
    ""model"": ""C:/Users/.../models/seg_model/stereocilia_v7/"",
    ""model_output_path"": ""C:/Users/.../models/new_seg_model/stereocilia_v8/"",
    ""model_region_prediction"": ""C:/Users/.../models/region_prediction/resnet50_best_checkpoint_resnet50_balancedclass.pth"",
    ""model_celltype_identification"": ""C:/Users/.../models/cell_type_identification_model/"",
    ""ZFT_trim_model"": ""C:/Users/.../models/ZFT_trim_model/"",
    ""rotation_correction_model"": ""C:/Users/.../models/rotation_correction_model/"",
    ""green_channel"": 0,
    ""red_channel"": 1,
    ""blue_channel"": -1,
    ""signal_intensity_channel"": 0,
    ""flag_to_resize"": false,
    ""flag_to_pad"": false,
    ""resize_dimension"": 1200,
    ""pad_dimension"": 1500,
    ""button_width"": 100,
    ""button_height"": 35
}
```

Congratulations :) &#127881;, now you can enjoy working with the plugin. 

## Unique about VASCilia :  
VASCilia saves all the intermediate results and the variables inside a pickle file while the user is using it in a very effiecint way. That allows a super fast uploading for the analysis if the user or their supervisor wants to keep working or review the analysis steps.  
*[Click me to learn how to upload a z-stack](https://youtu.be/Sxm_fsjoWL0)*  

## How to use VASCilia :  
*[Click me to see a video demo of the entire workflow](https://youtu.be/mNPJ1g0vEW8)*  

There are several buttons inside the blugin in the right hand side of Napari:

1. 'Open CZI Cochlea Files and Preprocess' button: read the CZI file.
2. 'Upload Processed CZI Stack' button: Incase you already have processed the stack, then just uplead your Analysis_state.pkl that usually has all the variables needed to upload your analysis
3. 'Trim Full Stack' button: this button allows you to choose only the slices of interest (has been automated in v_1_1_0)
4. ""Rotate' buttom: this button allows to rotate the stack to have proper analysis (has been automated in v_1_1_0)  
5. Segment with 3DBundleSeg: it is a two steps algorithm (2D detection + multi-object assignment algorithm across all slices) to produce robust 3D detection. 3DBundleSeg is the first instance segmentation model for stereocilia bundles in the literature. It is trained on P5 and P21 3D stacks (thousands of 2D instances) and it produces highly acccurate boundary delineation even in the most challenging datasets. Here are some examples:  

<p align=""center"">
  <strong>3DBundleSeg can tackle challenged cases</strong>  
  <br>
  <img src=""images/challenged_cases_gray.png"" width=""100%"">
</p>

<p align=""center"">
  <strong>Multi-object assignment algorithm to produce robust 3D detection</strong>  
  <br>
  <img src=""images/3DBundleSeg.png"" width=""100%"">
</p>


6. Delete Label 'button': delete the unwanted detection if it is near the boundary or for any other reason.
7. Calculate measurments 'button': calculate different measurments from the detected bundles and store them in csv file
8. Calculate Bundle Height 'button': compute the 3D distance from the highest point in the 3D detection of each bundle to it's base. This calculation will consider the sample resolution.
9. Perform Cell Clustering 'button': find the IHC, OHC1, OHC2, and OHC3 using either GMM, Kmeans or Deep Learning. Those layers will be added to the plugin to be used during the analysis. 
10. Compute Fluorescence Intensity 'button': produce plots and CSV files that has the accumelated intensity and mean intensity for the fluorescence signal.
11. Predict Region 'button': Predict whether the region is from the BASE, MIDDLE, or APEX region using a RESNET50 trained model. 
12. Compute Orientation: It computes the orientation using two strategies.

<p align=""center"">
  <strong>Bundle Height with top and bottom adjustable points in red and green, orientation with two points in magenta, and bundle ID in green</strong>  
  <br>
  <img src=""images/Bundles.png"" width=""50%"">
</p>

<p align=""center"">
  <strong>Cell type identification (IHC1 in yellow, OHC1 in cyan, OHC2 in green, and OHC3 in magenta)</strong>  
  <br>
  <img src=""images/clustering.png"" width=""50%"">
</p>

13. Training Section.

<p align=""center"">
  <strong>Training section</strong>  
  <br>
  <img src=""images/Training_section2.png"" width=""40%"">
</p>

The training section is for the research ear community incase their datasets are little different than ours then they can easily create their cround truth, train a new model and use it in the plugin
1. Create/Save Ground Truth 'button': this button will create a new layer to draw new ground truth and save them as variables inside the plugin
2. Generate Ground Truth Mask 'button': this button will save all the generated masks after finish annotating to a new folder. 
3. Display Stored Ground Truth 'button': this button will display the stored masks in the plugin.
4. Copy Segmentation Masks to Ground Truth 'button': this button helps in speeding up the annotation process by copying what our trained model is producing sothat the annotator will only correct the wrong part.
5. Move Ground Truth to Training Folder 'button': this button will move all the annotated ground truth to the training folder to start the training process. 
6. Check Training Data 'button': this button checks the training data whether they follow the format needed by the architecture. It checks whether there are training and valiation folders and it reads every single file to make sure it doesn't have redundant or no information. It gives warning messages incase it finds an issue.
7. Train New Model for 3DBundleSeg 'button': this button will start the training.

VASCilia also equipped with two more buttons for resetting (to facilitate transitions between analyzing several stacks) and also exit VASCilia.  
We are still working on the documentation, so this gihub will be continiuosly updated.

## Multi-Batch Processing Feature: Required File
The **Multi-Batch Processing** feature in this package requires an additional file: `track_me_SORT_v3_exe.exe`. This file is **not included** in the repository or the pip installation due to size constraints.
### Download the File
You can download the file from the following link:  
[Download track_me_SORT_v3_exe.exe]*[[https://www.dropbox.com/your-file-link](https://www.dropbox.com/scl/fo/sud3ziayvo7efcsbzgrd7/ACeJ6uMjNLcyk7ev0upJREE?rlkey=e6nzvpz8aoebzq4w3o5f339le&st=1qtmf3mf&dl=0)]
### If You Clone the Repository
1. Download the file from the link above.
2. Place the file in the following directory within the cloned repository: src/napari_vascilia/core/
### If You Installed the Package via pip
1. Download the file from the link above.
2. Locate the installation directory for the package. You can find the installation path by running the following Python code: 
```python
import napari_vascilia
print(napari_vascilia.__file__)
```
3. Place the downloaded file in the following directory: <package_installation_path>/src/napari_vascilia/core/  
Note: All other features of the package will function as expected without this file. This file is exclusively for batch processing of multiple files.

## Testing Other Lab Data  
Liberman Data *[Click me to see a video demo of the entire workflow](https://youtu.be/PIG3q7G6Xr0)*  
Artur Indzhykulian Data *[Click me to see a video demo of the entire workflow](https://youtu.be/WseYK4Zn-3o)*  

## Paper and Citation

This work will be submitted very soon. If you want to read or cite the paper &#128522;, you can find it [here](https://doi.org/10.1101/2024.06.17.599381).  

Kassim, Y. M., Rosenberg, D. B., Renero, A., Das, S., Rahman, S., Al Shammaa, I., Salim, S., Huang, Z., Huang, K., Ninoyu, Y., Friedman, R. A., Indzhykulian, A. A., & Manor, U. (2024). VASCilia (Vision Analysis StereoCilia): A Napari Plugin for Deep Learning-Based 3D Analysis of Cochlear Hair Cell Stereocilia Bundles. bioRxiv. https://doi.org/10.1101/2024.06.17.599381

## Project Authors and Contacts

**Python Implementation of this repository:** Dr. Yasmin M. Kassim    
**Contact:** ykassim@ucsd.edu, ymkgz8@mail.missouri.edu  
Yasmin Kassim was responsible for the plugin design, fully implemented all functions in Python, wrote the manuscript,
proofread the ground truth data, created all figures, and established the GitHub repository and codebase.

**Stacks used in this study imaged by:** Dr. David Rosenberg   

**Height bundle ground truth analyses**: Samprita Das and Alma Renero.  

**StereoCilia Bundles Ground Truth**: 55 (P5 and P21) 3D stacks were manually annotated by Yasmin Kassim and five undergraduate students using the CVAT annotation tool. This is an extremely challenging process, as each 3D stack might have up to 60 bundles in a 3D setting, which could translate to around 1000 bundles in a 2D setting across all frames. The students involved in this effort are:  
**Samia Rahman, Ibraheem Al Shammaa, Samer Salim, Zhuoling Huang, and Kevin Huang**.

This dataset will be the first annotated dataset in the literature to 3D segment the stereocilia bundles and it will be published and available for the ear research community with the publication of this paper.

**Other Lab Support**:   
Yuzuru Ninoyu assisted with some of the imaging data, with Rick Friedmanâs supervision and support.   
Artur Indzhykulian provided additional imaging data for testing.  

**Lab Supervisor:** Dr. Uri Manor   
The Principal Investigator, conceived and supervised the project, and provided critical
revisions and updates to the manuscript.  

**Contact:** u1manor@UCSD.EDU  
**Department:** Cell and Development Biology Department/ UCSD  
**Lab Website:** https://manorlab.ucsd.edu/




","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']",,,,Napari-VASCilia.initialize_ui,,,,
457,napari-update-checker,napari-update-checker,napari update-checker,0.1.0,2024-12-23,2024-12-23,napari team,napari team <napari-steering-council@googlegroups.com>,Unavailable,https://github.com/napari/napari-plugin-manager,https://pypi.org/project/napari-update-checker/,,,Updates checker plugin for napari.,>=3.8,"['qtpy', 'superqt', 'pip', 'PyQt5; extra == ""dev""', 'pre-commit; extra == ""dev""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'virtualenv; extra == ""testing""', 'sphinx>6; extra == ""docs""', 'sphinx-autobuild; extra == ""docs""', 'sphinx-external-toc; extra == ""docs""', 'sphinx-copybutton; extra == ""docs""', 'sphinx-favicon; extra == ""docs""', 'myst-nb; extra == ""docs""', 'napari-sphinx-theme>=0.3.0; extra == ""docs""']","# napari-update-checker

[![License](https://img.shields.io/pypi/l/napari-update-checker.svg?color=green)](https://github.com/napari/update-checker/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-update-checker.svg?color=green)](https://pypi.org/project/napari-update-checker)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-update-checker.svg?color=green)](https://python.org)
[![tests](https://github.com/napari/update-checker/actions/workflows/test_and_deploy.yml/badge.svg)](https://github.com/napari/update-checker/actions/workflows/test_and_deploy.yml)
[![codecov](https://codecov.io/gh/napari/update-checker/branch/main/graph/badge.svg)](https://codecov.io/gh/napari/update-checker)

[napari] update checker to query for new napari versions.

You can read the documentation at [napari.org/update-checker](https://napari.org/update-checker).

## Overview

The `napari-update-checker` is a plugin that checks for newer versions of napari available either on [conda-forge], or on [PyPI], by querying the repository release tags.

![Screenshot of the napari-update-checker interface, showcasing the plugin](https://raw.githubusercontent.com/napari/update-checker/refs/heads/main/images/description.png)

`napari-update-checker` knows how to detect if napari was installed using `conda` or `pip` or if it was installed using the application bundle to provide the correct documentation on how to update napari to the latest version.

## Widget

![Screenshot of the napari-update-checker widget](https://raw.githubusercontent.com/napari/update-checker/refs/heads/main/images/widget.png)

## License

Distributed under the terms of the [BSD-3] license, ""napari-update-checker"" is free and open source
software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[file an issue]: https://github.com/napari/update-checker/issues
[conda-forge]: https://anaconda.org/conda-forge/napari
[PyPI]: https://pypi.org/napari
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[napari]: https://github.com/napari/napari
","['Development Status :: 3 - Alpha', 'Environment :: X11 Applications :: Qt', 'Framework :: napari', 'Intended Audience :: Education', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: BSD License', 'Programming Language :: C', 'Programming Language :: Python', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Scientific/Engineering :: Information Analysis', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Utilities', 'Operating System :: Microsoft :: Windows', 'Operating System :: POSIX', 'Operating System :: Unix', 'Operating System :: MacOS']","['homepage, https://github.com/napari/napari-plugin-manager']",,,napari-update-checker.UpdateChecker,,,,
458,napari-vector-graphics,napari-vector-graphics,Napari Vector Graphics,0.1.0,2025-01-02,2025-01-02,JordÃ£o Bragantini,jordao.bragantini@czbiohub.org,"Copyright (c) 2024, JordÃ£o Bra...",https://github.com/JoOkuma/napari-vector-graphics/issues,https://pypi.org/project/napari-vector-graphics/,,,Helper plugin to export napari viewer content as SVG,>=3.9,"['numpy', 'drawsvg', 'qtpy', 'scikit-image', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'opencv-python-headless; extra == ""all""']","# napari-vector-graphics

[![License BSD-3](https://img.shields.io/pypi/l/napari-vector-graphics.svg?color=green)](https://github.com/JoOkuma/napari-vector-graphics/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-vector-graphics.svg?color=green)](https://pypi.org/project/napari-vector-graphics)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-vector-graphics.svg?color=green)](https://python.org)
[![tests](https://github.com/JoOkuma/napari-vector-graphics/workflows/tests/badge.svg)](https://github.com/JoOkuma/napari-vector-graphics/actions)
[![codecov](https://codecov.io/gh/JoOkuma/napari-vector-graphics/branch/main/graph/badge.svg)](https://codecov.io/gh/JoOkuma/napari-vector-graphics)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-vector-graphics)](https://napari-hub.org/plugins/napari-vector-graphics)

Helper plugin to export napari viewer content as SVG

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-vector-graphics` via [pip]:

    pip install napari-vector-graphics

If you want to be able to vectorize segmentation layers, you will need `python-opencv-headless`.
To install it, run:

    pip install ""napari-vector-graphics[all]""


To install latest development version :

    pip install git+https://github.com/JoOkuma/napari-vector-graphics.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-vector-graphics"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/JoOkuma/napari-vector-graphics/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/JoOkuma/napari-vector-graphics/issues', 'Documentation, https://github.com/JoOkuma/napari-vector-graphics#README.md', 'Source Code, https://github.com/JoOkuma/napari-vector-graphics', 'User Support, https://github.com/JoOkuma/napari-vector-graphics/issues']",,,napari-vector-graphics.widget,,,,
459,napari-vectorizer,napari-vectorizer,Labels Vectorization,0.0.5,2025-02-28,2025-03-25,Nicola Santacroce,nicola.santacroce@protonmail.com,"Copyright (c) 2025, Nicola San...",https://github.com/tha-santacruz/napari-vectorizer/issues,https://pypi.org/project/napari-vectorizer/,,,A plugin to convert label layers to vector layers,>=3.9,"['napari[all]', 'numpy', 'magicgui', 'qtpy', 'scikit-image', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-vectorizer

[![License BSD-3](https://img.shields.io/pypi/l/napari-vectorizer.svg?color=green)](https://github.com/tha-santacruz/napari-vectorizer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-vectorizer.svg?color=green)](https://pypi.org/project/napari-vectorizer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-vectorizer.svg?color=green)](https://python.org)
[![tests](https://github.com/tha-santacruz/napari-vectorizer/workflows/tests/badge.svg)](https://github.com/tha-santacruz/napari-vectorizer/actions)
[![codecov](https://codecov.io/gh/tha-santacruz/napari-vectorizer/branch/main/graph/badge.svg)](https://codecov.io/gh/tha-santacruz/napari-vectorizer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-vectorizer)](https://napari-hub.org/plugins/napari-vectorizer)

A plugin to convert label layers to vector layers

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-vectorizer` via [pip]:

    pip install napari-vectorizer



To install latest development version :

    pip install git+https://github.com/tha-santacruz/napari-vectorizer.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-vectorizer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/tha-santacruz/napari-vectorizer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/tha-santacruz/napari-vectorizer/issues', 'Documentation, https://github.com/tha-santacruz/napari-vectorizer#README.md', 'Source Code, https://github.com/tha-santacruz/napari-vectorizer', 'User Support, https://github.com/tha-santacruz/napari-vectorizer/issues']",,,napari-vectorizer.make_vectorization_widget,napari-vectorizer.load_conifer_sample_data,,,
460,napari-validate-random-label-predictions,napari-validate-random-label-predictions,napari validate random label predictions,0.0.1,2022-11-23,2022-11-23,Niklas Netter,niknett@gmail.com,BSD-3-Clause,https://github.com/gatoniel/napari-validate-random-label-predictions/issues,https://pypi.org/project/napari-validate-random-label-predictions/,,https://github.com/gatoniel/napari-validate-random-label-predictions,Validate separate instances of label predictions manually,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-validate-random-label-predictions

[![License BSD-3](https://img.shields.io/pypi/l/napari-validate-random-label-predictions.svg?color=green)](https://github.com/gatoniel/napari-validate-random-label-predictions/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-validate-random-label-predictions.svg?color=green)](https://pypi.org/project/napari-validate-random-label-predictions)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-validate-random-label-predictions.svg?color=green)](https://python.org)
[![tests](https://github.com/gatoniel/napari-validate-random-label-predictions/workflows/tests/badge.svg)](https://github.com/gatoniel/napari-validate-random-label-predictions/actions)
[![codecov](https://codecov.io/gh/gatoniel/napari-validate-random-label-predictions/branch/main/graph/badge.svg)](https://codecov.io/gh/gatoniel/napari-validate-random-label-predictions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-validate-random-label-predictions)](https://napari-hub.org/plugins/napari-validate-random-label-predictions)

Validate separate instances of label predictions manually

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-validate-random-label-predictions` via [pip]:

    pip install napari-validate-random-label-predictions



To install latest development version :

    pip install git+https://github.com/gatoniel/napari-validate-random-label-predictions.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-validate-random-label-predictions"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/gatoniel/napari-validate-random-label-predictions/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/gatoniel/napari-validate-random-label-predictions/issues', 'Documentation, https://github.com/gatoniel/napari-validate-random-label-predictions#README.md', 'Source Code, https://github.com/gatoniel/napari-validate-random-label-predictions', 'User Support, https://github.com/gatoniel/napari-validate-random-label-predictions/issues']",,,napari-validate-random-label-predictions.make_qwidget,,,,
461,napari-vemseg,napari-vemseg,napari-vemseg,0.0.9,2023-03-14,2023-03-15,Matous Elphick,matous.elphick@gmail.com,BSD-3-Clause,,https://pypi.org/project/napari-vemseg/,None,,A simple plugin for semi-automated segmentation of volume electron microscopy images.,>=3.8,"['torch', 'numpy', 'scikit-image', 'magicgui', 'qtpy', 'napari', 'tqdm', 'apoc', 'superqt', 'setuptools', 'vemseg']","
<img width=""250""  src=""https://github.com/MatousE/napari-vemseg/blob/main/images/VEMSEG-FINAL.svg""> 

# napari-vemseg


[![License BSD-3](https://img.shields.io/pypi/l/napari-vemseg.svg?color=green)](https://github.com/MatousE/napari-vemseg/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-vemseg.svg?color=green)](https://pypi.org/project/napari-vemseg)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-vemseg.svg?color=green)](https://python.org)
[![tests](https://github.com/MatousE/napari-vemseg/workflows/tests/badge.svg)](https://github.com/MatousE/napari-vemseg/actions)
[![codecov](https://codecov.io/gh/MatousE/napari-vemseg/branch/main/graph/badge.svg)](https://codecov.io/gh/MatousE/napari-vemseg)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-vemseg)](https://napari-hub.org/plugins/napari-vemseg)

A simple plugin to do semi-automated segmentation within napari using vemseg built on
XGBoost.

## Installation
### `conda` Installation and Environment Creation
To start with a conda environment must be created.
```
conda create -n vemseg-env python=3.8
conda activate vemseg-env
```
### `napari` Instillation
We must then install [napari]:

```
pip install ""napari[all]""
```
### `napari-vemseg` Instillation
You can finally install `napari-vemseg` via [pip]:
```
conda install pyopencl
pip install napari-vemseg
```
## Usage
### Train VEMClassifier

### Predict Using Pretrained VEMClassifier


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-vemseg"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Topic :: Scientific/Engineering :: Image Processing']",,,,napari-vemseg.vemseg_pixel_classifier,,,,
462,napari-vedo-bridge,napari-vedo-bridge,napari vedo bridge,0.3.0,2023-07-03,2025-06-13,"Johannes Soltwedel, Marco Musy",johannes_richard.soltwedel@tu-dresden.de,"Copyright (c) 2023, Johannes S...",https://github.com/jo-mueller/napari-vedo-bridge/issues,https://pypi.org/project/napari-vedo-bridge/,,,Transfer mesh data between napari and vedo for interactive processing,>=3.9,"['numpy', 'magicgui', 'qtpy', 'vedo>=2024.5.2', 'napari-timelapse-processor', 'napari', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-vedo-bridge

[![License BSD-3](https://img.shields.io/pypi/l/napari-vedo-bridge.svg?color=green)](https://github.com/jo-mueller/napari-vedo-bridge/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-vedo-bridge.svg?color=green)](https://pypi.org/project/napari-vedo-bridge)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-vedo-bridge.svg?color=green)](https://python.org)
[![tests](https://github.com/jo-mueller/napari-vedo-bridge/workflows/tests/badge.svg)](https://github.com/jo-mueller/napari-vedo-bridge/actions)
[![codecov](https://codecov.io/gh/jo-mueller/napari-vedo-bridge/branch/main/graph/badge.svg)](https://codecov.io/gh/jo-mueller/napari-vedo-bridge)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-vedo-bridge)](https://napari-hub.org/plugins/napari-vedo-bridge)

To be able to use interactive processing of meshes in napari, this plugin provides a bridge to the vedo library. It allows to transfer meshes between napari and vedo and to use the interactive processing capabilities of vedo in napari. 

## I/O

The plugin allows to export and import meshes and point layers. The following are supported:

| napari layer type | File Format | Import | Export | Features |
|:------------------:|:-----------:|:------:|:------:|:--------:|
| Surface | .vtp | â | â |  â |
| Surface | .vtk | â | â |  â |
| Surface | .obj | â | â |  â |
| Surface | .stl | â | â |  â |
| Surface | .ply | â | â |  â |
| Points | .vtp | â | â |  â |
| Points | .vtk | â | â |  â |
| Points | .ply | â | â |  â |
| Points | .obj | â | â |  â |

## Interactive mesh cutting
To interactively cut meshes in the napari-vedo MeshCutter, install the plugin (see below) and open the plugin it from the napari plugins menu (`Plugins > Mesh Cutter (napari-vedo-bridge)`). 

To cut meshes you can use the following cutters:
- `PlaneCutter`: cuts a mesh with a plane
- `SphereCutter`: cuts a mesh with a sphere
- `BoxCutter`: cuts a mesh with a box

![](https://github.com/jo-mueller/napari-vedo-bridge/raw/main/docs/imgs/screenshot_box_cutter.png)

To send and get data into and from the plugin, you can:

- Retrieve the current mesh from napari (click `Retrieve mesh from napari`) - this imports the **currently selected mesh layer** from napari
- Load a mesh from file (click `Load mesh`)
- Send a mesh to napari (click `Send back to napari`) - this creates a new mesh layer in napari

## Mesh Processing Functions

The plugin also provides a set of mesh processing functions that can be used in napari. These functions are wrapped from the vedo library and provide various mesh processing capabilities. The following functions are available:

- `compute_normals`: Compute normals for the given mesh.
- `shrink`: Shrink the given mesh.
- `join`: Join the given meshes.
- `subdivide`: Subdivide the given mesh.
- `decimate`: Decimate the given mesh.
- `decimate_pro`: Decimate the given mesh using the Pro algorithm.
- `decimate_binned`: Decimate the given mesh using the Binned algorithm.
- `smooth`: Smooth the given mesh.
- `fill_holes`: Fill holes in the given mesh.
- `inside_points`: Get the points inside the given mesh.
- `extrude`: Extrude the given mesh.
- `split`: Split the given mesh into connected components.
- `extract_largest_region`: Extract the largest region from the given mesh.
- `binarize`: Binarize the given mesh.

## Pointcloud Processing Functions

The plugin also provides a set of pointcloud processing functions that can be used in napari. These functions are wrapped from the vedo library and provide various pointcloud processing capabilities. The following functions are available:

- `smooth_points`: Smooth the given points.
- `decimate_points`: Decimate the given points.
- `cluster_points`: Cluster the given points.
- `remove_outliers`: Remove outliers from the given points.
- `compute_normals_points`: Compute normals for the given points.
- `extract_largest_cluster`: Extract the largest cluster from the given points.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-vedo-bridge` via [pip]:

    pip install napari-vedo-bridge

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-vedo-bridge"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/jo-mueller/napari-vedo-bridge/issues', 'Documentation, https://github.com/jo-mueller/napari-vedo-bridge#README.md', 'Source Code, https://github.com/jo-mueller/napari-vedo-bridge', 'User Support, https://github.com/jo-mueller/napari-vedo-bridge/issues']",napari-vedo-bridge.load_points,napari-vedo-bridge.write_points,napari-vedo-bridge.cutter_widget,napari-vedo-bridge.data.mouse_limb1,['*.vtp'],['.vtp'],"['.vtp', '.vtk', '.obj', '.stl', '.ply']"
463,napari-video-cvdask,napari-video-cvdask,napari VideoCVDask,0.2.1,2022-02-24,2022-02-25,Nicholas A. Del Grosso,delgrosso.nick@gmail.com,MIT,https://github.com/nickdelgrosso/napari-video-cvdask/issues,https://pypi.org/project/napari-video-cvdask/,,https://github.com/nickdelgrosso/napari-video-cvdask,A Video File Reader that uses OpenCV2 and Dask Arrays,>=3.7,"['dask-image', 'av']","# napari-video-cvdask

[![License](https://img.shields.io/pypi/l/napari-video-cvdask.svg?color=green)](https://github.com/nickdelgrosso/napari-video-cvdask/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-video-cvdask.svg?color=green)](https://pypi.org/project/napari-video-cvdask)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-video-cvdask.svg?color=green)](https://python.org)
[![tests](https://github.com/nickdelgrosso/napari-video-cvdask/workflows/tests/badge.svg)](https://github.com/nickdelgrosso/napari-video-cvdask/actions)
[![codecov](https://codecov.io/gh/nickdelgrosso/napari-video-cvdask/branch/main/graph/badge.svg)](https://codecov.io/gh/nickdelgrosso/napari-video-cvdask)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-video-cvdask)](https://napari-hub.org/plugins/napari-video-cvdask)

A Video File Reader that used to use OpenCV2 and Dask Arrays, and now uses dask-image, which does the same thing but better.  (Pro-tip, never name a package after its dependencies!)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


## Installation

You can install `napari-video-cvdask` via [pip]:

    pip install napari-video-cvdask



To install latest development version :

    pip install git+https://github.com/nickdelgrosso/napari-video-cvdask.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""napari-video-cvdask"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/nickdelgrosso/napari-video-cvdask/issues', 'Documentation, https://github.com/nickdelgrosso/napari-video-cvdask#README.md', 'Source Code, https://github.com/nickdelgrosso/napari-video-cvdask', 'User Support, https://github.com/nickdelgrosso/napari-video-cvdask/issues']",napari-video-cvdask.get_reader,,,,"['*.mp4', '*.mov', '*.avi']",,
464,napari-vesicles-segmentation,napari-vesicles-segmentation,Vesicles Segmentation,0.0.1,2022-07-08,2022-07-08,Alexis Japas,alexis.japas@proton.me,BSD-3-Clause,https://github.com/alexisjapas/napari-vesicles-segmentation/issues,https://pypi.org/project/napari-vesicles-segmentation/,,https://github.com/alexisjapas/napari-vesicles-segmentation,A simple plugin to detect vesicles in cells images.,>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'scipy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""scikit-image ; extra == 'testing'"", ""scipy ; extra == 'testing'""]","# napari-vesicles-segmentation

[![License BSD-3](https://img.shields.io/pypi/l/napari-vesicles-segmentation.svg?color=green)](https://github.com/alexisjapas/napari-vesicles-segmentation/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-vesicles-segmentation.svg?color=green)](https://pypi.org/project/napari-vesicles-segmentation)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-vesicles-segmentation.svg?color=green)](https://python.org)
[![tests](https://github.com/alexisjapas/napari-vesicles-segmentation/workflows/tests/badge.svg)](https://github.com/alexisjapas/napari-vesicles-segmentation/actions)
[![codecov](https://codecov.io/gh/alexisjapas/napari-vesicles-segmentation/branch/main/graph/badge.svg)](https://codecov.io/gh/alexisjapas/napari-vesicles-segmentation)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-vesicles-segmentation)](https://napari-hub.org/plugins/napari-vesicles-segmentation)

A simple plugin to detect vesicles in cells images.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `napari-vesicles-segmentation` via [pip]:

    pip install napari-vesicles-segmentation



To install latest development version :

    pip install git+https://github.com/alexisjapas/napari-vesicles-segmentation.git

## Usage
1. Open napari
2. Open your data
![usage-open-data](images/usage-open-data.png)
3. Launch the vesicles-segmentation plugin
4. Select the data you want to segment and set the parameters of the segmentation
![usage-setup](images/usage-setup.png)
    * **image**: The image to segment vesicles in. The image can be a 2D or 3D temporal stack of images.
    * **minimum vesicles size**: The minimum size of the vesicles to detect. Smaller detected vesicles are removed.
    * **membrane erosion**: The size of the disk radius used for eroding the cell. This is used to remove the external membrane. This parameter scales when downsizing the image, for more information see 'downsizing ratio' parameter.
    * **closing size**: The size of the disk radius used for closing the cell. This is used to fill holes in the cell. This parameter scales when downsizing the image, for more information see 'downsizing ratio' parameter.
    * **clip**: If set to zero, no standardization is performed. Otherwise, the standard deviation of the image is set to n_sigma * the standard deviation of the image, the image is standardized and its values are clipped to the range [-1, 1] in order to remove outliers. The higher the value of n_sigma, the less outliers are removed. This operation can lead to a better detection of the cell.
    * **downsampling ratio**: The downsampling ratio used for the downsampled image. This is used to speed up the computation. Downsampling the image have impact in reducing the resolution of erosion and closing e.g. for a downsize ratio of 2, setting the erosion size to 3 will result in an erosion size of 6.
    * **display cell detection**: If set to True, the cell detection is displayed in the viewer instead of the vesicle detection.
5. Click on the ""Segment"" button to start the segmentation. This can take few seconds or minutes depending on the size of the data. The result is added to the viewer as below.
![usage-segmentation](images/usage-segmentation.png)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-vesicles-segmentation"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/alexisjapas/napari-vesicles-segmentation/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/alexisjapas/napari-vesicles-segmentation/issues', 'Documentation, https://github.com/alexisjapas/napari-vesicles-segmentation#README.md', 'Source Code, https://github.com/alexisjapas/napari-vesicles-segmentation', 'User Support, https://github.com/alexisjapas/napari-vesicles-segmentation/issues']",,,napari-vesicles-segmentation.make_qwidget,,,,
465,napari-video,napari_video,napari_video,0.2.10,2021-02-27,2024-10-13,Jan Clemens,clemensjan@googlemail.com,Unavailable,https://github.com/janclemenslab/napari-video/issues,https://pypi.org/project/napari_video/,,https://github.com/janclemenslab/napari-video,napari plugin for reading videos.,>=3.6,"['numpy', 'pyvideoreader']","# napari-video
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari_video)](https://napari-hub.org/plugins/napari_video)

Napari plugin for working with videos.

Relies on [pyvideoreader](https://pypi.org/project/pyvideoreader/) as a backend which itself uses [opencv](https://opencv.org) for reading videos.

## Installation
```shell
pip install napari[all] napari_video
```

## Usage
From a terminal:
```shell
napari video.avi
```

Or from within python:
```shell
import napari
from napari_video.napari_video import VideoReaderNP

path='video.mp4'
vr = VideoReaderNP(path)
with napari.gui_qt():
    viewer = napari.view_image(vr, name=path)
```

## Internals
`napari_video.napari_video.VideoReaderNP` exposes a video with a numpy-like interface, using opencv as a backend.

For instance, open a video:
```python
vr = VideoReaderNP('video.avi')
print(vr)
```
```
video.avi with 60932 frames of size (920, 912, 3) at 100.00 fps
```
Then

- `vr[100]` will return the 100th frame as a numpy array with shape `(902, 912, 3)`.
- `vr[100:200:10]` will return 10 frames evenly spaced between frame number 100 and 200 (shape `(10, 902, 912, 3)`).
- Note that by default, single-frame and slice indexing return 3D and 4D arrays, respectively. To consistently return 4D arrays, open the video with `remove_leading_singleton=False`. `vr[100]` will then return a `(1, 902, 912, 3)` array.
- We can also request specific ROIs and channels. For instance, `vr[100:200:10,100:400,800:850,1]` will return an array with shape `(10, 300, 50, 1)`.


","['License :: OSI Approved :: MIT License', 'Framework :: napari', 'Operating System :: OS Independent']","['Bug Tracker, https://github.com/janclemenslab/napari-video/issues', 'Documentation, https://github.com/janclemenslab/napari-video/blob/main/README.md', 'Source Code, https://github.com/janclemenslab/napari-video', 'User Support, https://github.com/janclemenslab/napari-video/issues']",napari_video.napari_get_reader,,,,['*'],,
466,napari-workflow-inspector,napari-workflow-inspector,napari-workflow-inspector,0.2.2,2021-12-04,2022-05-15,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-workflow-inspector/issues,https://pypi.org/project/napari-workflow-inspector/,,https://github.com/haesleinhuepf/napari-workflow-inspector,Inspect relationships between image processing operations in active workflows in napari,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari-tools-menu', 'networkx', 'matplotlib', 'napari-workflows']","# napari-workflow-inspector

[![License](https://img.shields.io/pypi/l/napari-workflow-inspector.svg?color=green)](https://github.com/haesleinhuepf/napari-workflow-inspector/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-workflow-inspector.svg?color=green)](https://pypi.org/project/napari-workflow-inspector)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-workflow-inspector.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-workflow-inspector/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-workflow-inspector/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-workflow-inspector/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-workflow-inspector)
[![Development Status](https://img.shields.io/pypi/status/napari-workflow-inspector.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-workflow-inspector)](https://napari-hub.org/plugins/napari-workflow-inspector)

Inspect relationships between image processing operations in active workflows in napari. Open the inspector by clicking the menu `Tools > Visualization > Workflow Inspector`.

![img_1.png](https://github.com/haesleinhuepf/napari-workflow-inspector/raw/main/docs/screenshot_graph.png)

Also install the [napari-script-editor](https://www.napari-hub.org/plugins/napari-script-editor) 
to generate code from active workflows.

![img_2.png](https://github.com/haesleinhuepf/napari-workflow-inspector/raw/main/docs/screenshot_script_editor.png)

For recording workflows, all napari image processing plugins that use the `@time_slicer` interface are supported. See
[napari-time-slicer](https://www.napari-hub.org/plugins/napari-time-slicer) for a list. More to come, stay tuned.

## Installation

You can install `napari-workflow-inspector` via [pip]:

```
pip install napari-workflow-inspector
```

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-workflow-inspector"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-workflow-inspector/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Topic :: Scientific/Engineering :: Medical Science Apps.', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-workflow-inspector/issues', 'Documentation, https://github.com/haesleinhuepf/napari-workflow-inspector#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-workflow-inspector', 'User Support, https://github.com/haesleinhuepf/napari-workflow-inspector/issues']",,,napari-workflow-inspector.WorkflowWidget,,,,
467,napari-vodex,napari-vodex,VoDEx,1.0.12,2023-01-04,2023-04-17,Anna Nadtochiy,lemonjustgithub@gmail.com,BSD-3-Clause,https://github.com/LemonJust/napari-vodex/issues,https://pypi.org/project/napari-vodex/,,https://github.com/LemonJust/napari-vodex,A napari plugin for VoDEx : Volumetric Data and Experiment Manager. Allows to load volumetric data based on experimental conditions.,>=3.8,"['vodex (>=1.0.12)', 'numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-vodex

[![License BSD-3](https://img.shields.io/pypi/l/napari-vodex.svg?color=green)](https://github.com/LemonJust/napari-vodex/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-vodex.svg?color=green)](https://pypi.org/project/napari-vodex)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-vodex.svg?color=green)](https://python.org)
[![tests](https://github.com/LemonJust/napari-vodex/workflows/tests/badge.svg)](https://github.com/LemonJust/napari-vodex/actions)
[![codecov](https://codecov.io/gh/LemonJust/napari-vodex/branch/main/graph/badge.svg)](https://codecov.io/gh/LemonJust/napari-vodex)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-vodex)](https://napari-hub.org/plugins/napari-vodex)

A plugin to load volumetric data based on experimental conditions.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-vodex` via [pip]:

    pip install napari-vodex



To install latest development version :

    pip install git+https://github.com/LemonJust/napari-vodex.git

## How-To Guide

To get started with napari_vodex, please see details and examples in [How-To Guide](https://lemonjust.github.io/vodex/napari/how-to/) .


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-vodex"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/LemonJust/napari-vodex/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/LemonJust/napari-vodex/issues', 'Documentation, https://lemonjust.github.io/vodex/napari/', 'Source Code, https://github.com/LemonJust/napari-vodex', 'User Support, https://github.com/LemonJust/napari-vodex/issues']",,,napari-vodex.vodex_qwidget,,,,
468,napari-workflow-optimizer,napari-workflow-optimizer,napari-workflow-optimizer,0.1.4,2021-12-24,2022-04-15,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/napari-workflow-optimizer/issues,https://pypi.org/project/napari-workflow-optimizer/,,https://github.com/haesleinhuepf/napari-workflow-optimizer,Optimize image processing workflows in napari for segmentation quality,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'pyclesperanto-prototype', 'scikit-learn', 'napari-time-slicer', 'matplotlib', 'scipy', 'napari-workflows', 'napari-assistant (>=0.1.9)']","# napari-workflow-optimizer

[![License](https://img.shields.io/pypi/l/napari-workflow-optimizer.svg?color=green)](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-workflow-optimizer.svg?color=green)](https://pypi.org/project/napari-workflow-optimizer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-workflow-optimizer.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-workflow-optimizer/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-workflow-optimizer/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-workflow-optimizer/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-workflow-optimizer)
[![Development Status](https://img.shields.io/pypi/status/napari-workflow-optimizer.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-workflow-optimizer)](https://napari-hub.org/plugins/napari-workflow-optimizer)

Optimize image processing workflows in napari for segmentation quality

![img.png](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/napari-workflow-optimizer.gif)

## Usage

The starting point for workflow optimization is a workflow and some reference (""ground truth"") labels image. 
The label image can be a sparse annotation, which means only some objects and also parts of objets are annotated (see [hints](https://github.com/haesleinhuepf/napari-workflow-optimizer#optimization-hints)). 
These datasets should be ready. You can reproduce the following procedure by downloading an 
[examle raw image](https://github.com/haesleinhuepf/napari-workflow-optimizer/blob/main/demo/membranes_2d.tif) (derived from the 
[scikit-image cells3d example data set](https://scikit-image.org/docs/dev/api/skimage.data.html#skimage.data.cells3d)) and a corresponding 
[sparse annotation label image](https://github.com/haesleinhuepf/napari-workflow-optimizer/blob/main/demo/membranes_2d_sparse_labels.tif).
For reproducing the following procedure, also follow the [installation instructions](https://github.com/haesleinhuepf/napari-workflow-optimizer#optimization-hints) below.
The whole procedure is [also shown in this video](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/napari-workflow-optimizer.mp4), an extended version of the trailer above.

### Step 0: Loading data and setting up the workflow

Load the ""membranes_2d.tif"" data set, e.g. by drag&drop on napari and start the Assistant from the `Tools > Utilities > Assistant (clEsperanto)` menu.

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot1_start_raw.png)

Click the `Label` button and select as operation ""Seeded watershed using local minima as seeds and an intensity threshold (nsbatwm)"".

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot2_labeled_beginning.png)

Draw an annotation in a new labels layer or load the example spare annotation ""membranes_2d_sparse_labels.tif"". 

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot4_loaded_manual_annotation.png)

In case the image is not displayed as label image, convert it to a label image by right-clicking on the entry in the layers list:

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot3_load_manual_annotation.png)

### Step 1: The Workflow Optimizer

Start the Workflow Optimizer from the `Tools > Utilities > Workflow optimizer (Labels)` menu. 
Configure the target layer, showing the label image that should be optimized.
Select the manual annotation as reference layer for the optimization. 
Consider increasing the number of iterations. This number depends on your segmenation problem. 
In the present example, 100 iterations should be enough.

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot5_start_optimization.png)

The optimizer will plot quality over the number of iterations to show the progress of optimization. 
To determine the quality, the optimizer will measure the maximum overlap ([Jaccard index](https://en.wikipedia.org/wiki/Jaccard_index)) 
of any labeled object over the manually annotated objects and calculate the mean of this value over all annotated objects.
After a moment, optimization will finish and update the labeled image. 
If your starting point for the optimization was already good, the result may now look better than before.

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot6_finished_optimization.png)

### Step 2: Manual parameter space plotting

In case the result is not perfect yet (as the fringed segmentation above suggests), consider manual plotting of the 
individual parameters and their relation to segmentation quality to get an idea about the surrounding parameter space.
Therefore, click the `Plot` button next to one of the workflow parameters.
Select the range in which the labeling quality should be determined (green arrows). In our example, the optimizer was setting the parameter to 2.34. 
Thus, to demonstrate the procedure we plot the parameter space beween 0 and 10. 
The quality plotted over this parameter obviously has a local maxium at 2.34, which was detected by the optimizer.
However, it also has another local maxium at 8 and actually a plateau in the quality plot (orange arrows).

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot7_parameter_quality_plot.png)

For further optimization, we re-configure the algorithm and set a new starting point for optimization of the parameter to 8.
Afterwards, we restart the optimization. It will then optimize the settings again from the new starting point.

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot8_start_optimization_again.png)

After another moment, optimization will finish again, potentially leading to an even better result.

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot9_finished_optimization_again.png)

### Step 3: Visualization of results

Make sure the segmentation has high quality by inspecting the result visually. Use the `contour` setting of the labels layer
and hide/show the outlines of the labeled layer:

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot10_contours_on.png)

![](https://github.com/haesleinhuepf/napari-workflow-optimizer/raw/main/docs/screenshot11_contours_off.jpg)

### Optimization Hints

The Workflow Optimizer uses the [Nelder-Mead simplex method](https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method)
for optimizing parameters. This algorithm varies individual parameters and makes steps in the parameter space ideally following a gradient 
to a local optimum. Hence, this algorithm may not be capable of determining a global optimum in parameter space. 
Parameter optimization is no magic. If it does not immediately work on your data, plot the parameters as introduced in Step 2 
and identify parameters with a clear gradient and those with many local maxima. 
Consider optimizing the parameters with many local maxima manually and de-selecting their checkboxes for the optimization.
The optimizer will then only optimize the parameters showing the clear gradient. 
Repeat these steps a couple of times to get a feeling for your parameter space. 

Furthermore, parameter optimization works well if
* the initial settings are close to a good segmentation,
* a small number of parameters (a short workflow) are optimized,
* the reference annotation is prepared carefully and
* the dataset is small. Consider using a small representative crop in case of bigger datasets.

### Workflow optimization scripting

For optimizing workflows from within a jupyter notebook, check out our [example notebook for optimization using spare labels](https://github.com/haesleinhuepf/napari-workflow-optimizer/blob/main/demo/sparse_label_image_optimizer.ipynb). 
The examples are more flexible than the graphical user interface and allow for example [optimizing intensity images](https://github.com/haesleinhuepf/napari-workflow-optimizer/blob/main/demo/intensity_image_optimizer.ipynb)
and [binary images](https://github.com/haesleinhuepf/napari-workflow-optimizer/blob/main/demo/binary_image_optimizer.ipynb).
The membrane segmentation workflow optimization similar to the one shown above is also available as [jupyter notebook](https://github.com/haesleinhuepf/napari-workflow-optimizer/blob/main/demo/membrane_segmentation.ipynb).

### Known issues

If you change the workflow architecture after the optimizer window was opened, please re-open it
to select the parameters that should be optimized. Changing parameters is ok and re-opening is not necessary.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

Furthermore, to reproduce the procedure above, please download and install 
[napari](https://napari.org/),
[pyopencl](https://documen.tician.de/pyopencl/),
the [napari-pyclesperanto-assistant](https://www.napari-hub.org/plugins/napari-pyclesperanto-assistant) and
the [napari-segment-blobs-and-things-with-membranes](https://www.napari-hub.org/plugins/napari-segment-blobs-and-things-with-membranes) plugin. E.g. using 
[conda](https://docs.conda.io/en/latest/) and [pip](https://pypi.org/project/pip/):

```
conda create --name napari-opti python=3.8
conda activate napari-opti

conda install pyopencl napari
pip install napari-pyclesperanto-assistant napari-segment-blobs-and-things-with-membranes
pip install napari-workflow-optimizer
```

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-workflow-optimizer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-workflow-optimizer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/napari-workflow-optimizer/issues', 'Documentation, https://github.com/haesleinhuepf/napari-workflow-optimizer#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-workflow-optimizer', 'User Support, https://github.com/haesleinhuepf/napari-workflow-optimizer/issues']",,,napari-workflow-optimizer.WorkflowOptimizer,,,,
469,napari-workshop-plugin,napari-workshop-plugin,Workshop 2023 demo plugin,1.0.4,2023-09-06,2023-09-18,MetaCell,sean.martin@metacell.us,MIT,https://github.com/seankmartin/napari-software-development-workshop,https://pypi.org/project/napari-workshop-plugin/,,https://www.napari-hub.org/plugins/napari-workshop-plugin,A plugin to demonstrate some concepts from the 2023 workshop on software development related to napari,>=3.8,"['numpy <2,>=1.23', 'magicgui', 'qtpy', ""mkdocs-material ; extra == 'docs'"", ""mkdocstrings-python ; extra == 'docs'"", ""mkdocstrings ; extra == 'docs'"", ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-workshop-plugin

[![License MIT](https://img.shields.io/pypi/l/napari-workshop-plugin.svg?color=green)](https://github.com/MetaCell/napari-workshop-plugin/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-workshop-plugin.svg?color=green)](https://pypi.org/project/napari-workshop-plugin)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-workshop-plugin.svg?color=green)](https://python.org)
[![tests](https://github.com/seankmartin/napari-software-development-workshop/actions/workflows/test.yml/badge.svg)](https://github.com/seankmartin/napari-software-development-workshop/actions)
[![codecov](https://codecov.io/gh/seankmartin/napari-software-development-workshop/branch/main/graph/badge.svg)](https://codecov.io/gh/seankmartin/napari-software-development-workshop)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-workshop-plugin)](https://napari-hub.org/plugins/napari-workshop-plugin)

The purpose of this repository is to provide a template for a napari plugin that can be used as a starting point for the napari software development workshop 2023.
It should help you to see the basics of building documentation, testing, and continuous integration for a napari plugin.

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.
The cookiecutter plugin is also a great jumping off point for your own plugin development.

## Check out a template you can use for your own README

[template.md](template.md)

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-workshop-plugin` via [pip]:

    pip install napari-workshop-plugin

## License

Distributed under the terms of the [MIT] license,
""napari-workshop-plugin"" is free and open source software

## Issues

If you encounter any problems, please file an issue along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[pip]: https://pypi.org/project/pip/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/seankmartin/napari-software-development-workshop/issues', 'Documentation, https://seankmartin.github.io/napari-software-development-workshop/', 'Source Code, https://github.com/seankmartin/napari-software-development-workshop', 'User Support, https://napari.zulipchat.com']",napari-workshop-plugin.get_reader,,napari-workshop-plugin.make_widget,napari-workshop-plugin.sample_data,['*.npy'],,
470,napari-workshop-browser,napari-workshop-browser,Napari Workshop Browser,0.0.3,2023-07-05,2023-10-17,Kyle Harrington,napari@kyleharrington.com,BSD-3-Clause,https://github.com/kephale/napari-workshop-browser/issues,https://pypi.org/project/napari-workshop-browser/,,https://github.com/kephale/napari-workshop-browser,A plugin to browse and follow napari workshops,>=3.8,"['numpy', 'superqt', 'qtpy', 'notebook <7.0.0', 'jupytext', 'napari', 'appdirs', 'requests', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-workshop-browser

[![License BSD-3](https://img.shields.io/pypi/l/napari-workshop-browser.svg?color=green)](https://github.com/kephale/napari-workshop-browser/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-workshop-browser.svg?color=green)](https://pypi.org/project/napari-workshop-browser)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-workshop-browser.svg?color=green)](https://python.org)
[![tests](https://github.com/kephale/napari-workshop-browser/workflows/tests/badge.svg)](https://github.com/kephale/napari-workshop-browser/actions)
[![codecov](https://codecov.io/gh/kephale/napari-workshop-browser/branch/main/graph/badge.svg)](https://codecov.io/gh/kephale/napari-workshop-browser)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-workshop-browser)](https://napari-hub.org/plugins/napari-workshop-browser)

A plugin to browse and follow napari workshops

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## How to use this

1. Download napari as an app (e.g. the latest napari releases are
   available here: https://github.com/napari/napari/releases)
2. Open napari
3. Select `Plugins \ Plugin Manager`
4. Install this plugin, and restart napari.
6. Run this plugin and enter the URL of your workshop's zip file
7. Click `Launch workshop`

## Installation

You can install `napari-workshop-browser` via [pip]:

    pip install napari-workshop-browser



To install latest development version :

    pip install git+https://github.com/kephale/napari-workshop-browser.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-workshop-browser"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kephale/napari-workshop-browser/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kephale/napari-workshop-browser/issues', 'Documentation, https://github.com/kephale/napari-workshop-browser#README.md', 'Source Code, https://github.com/kephale/napari-workshop-browser', 'User Support, https://github.com/kephale/napari-workshop-browser/issues']",,,napari-workshop-browser.make_qwidget,,,,
471,napari-wsireg,napari-wsireg,napari-wsireg,0.1.2,2022-04-27,2022-08-16,Nathan Heath Patterson,heath.patterson@vanderbilt.edu,BSD-3-Clause,https://github.com/nhpatterson/napari-wsireg/issues,https://pypi.org/project/napari-wsireg/,,https://github.com/nhpatterson/napari-wsireg,plugin to perform whole slide image registration with wsireg,>=3.8,"['wsireg (>=0.3.6)', 'SimpleITK', 'czifile', 'dask', 'imagecodecs', 'napari', 'numpy', 'ome-types', 'pint', 'qtpy', 'tifffile', 'zarr (>=2.10.3)', 'napari-geojson', 'networkx', 'matplotlib']","# napari-wsireg

![Alt text](https://github.com/NHPatterson/napari-wsireg/blob/main/src/napari_wsireg/gui/resources/wsireg-logo-light.svg?raw=true ""wsireg"")

[//]: # ([![License]&#40;https://img.shields.io/pypi/l/napari-wsireg.svg?color=green&#41;]&#40;https://github.com/nhpatterson/napari-wsireg/raw/main/LICENSE&#41;)

[//]: # ([![PyPI]&#40;https://img.shields.io/pypi/v/napari-wsireg.svg?color=green&#41;]&#40;https://pypi.org/project/napari-wsireg&#41;)

[//]: # ([![Python Version]&#40;https://img.shields.io/pypi/pyversions/napari-wsireg.svg?color=green&#41;]&#40;https://python.org&#41;)

[//]: # ([![tests]&#40;https://github.com/nhpatterson/napari-wsireg/workflows/tests/badge.svg&#41;]&#40;https://github.com/nhpatterson/napari-wsireg/actions&#41;)

[//]: # ([![napari hub]&#40;https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-wsireg&#41;]&#40;https://napari-hub.org/plugins/napari-wsireg&#41;)


Plugin to perform whole slide image registration based on wsireg.

Please see [wsireg](https://github.com/nhpatterson/wsireg) for more info image formats, features and how registration works.


## Usage

Add images from napari layers or from file and set up ""registration paths"" between them. OME-TIFF is best supported format.

### Constructed registration graph in action

![Alt Text](assets/graph_in_action.gif)


_Solid arrows_: direct registration between two images.

_Dashed arrows_: indriect registration paths.

## Installation

You can install `napari-wsireg` via [pip]:

    pip install napari-wsireg



To install latest development version :

    pip install git+https://github.com/nhpatterson/napari-wsireg.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-wsireg"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/nhpatterson/napari-wsireg/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/nhpatterson/napari-wsireg/issues', 'Documentation, https://github.com/nhpatterson/napari-wsireg#README.md', 'Source Code, https://github.com/nhpatterson/napari-wsireg', 'User Support, https://github.com/nhpatterson/napari-wsireg/issues']",,,napari-wsireg.make_qwidget,,,,
472,napari-wsi,napari-wsi,WSI Reader,1.2.1,2023-02-01,2025-02-26,Philipp Plewa,Philipp Plewa <philipp.plewa@astrazeneca.com>,Unavailable,https://github.com/AstraZeneca/napari-wsi,https://pypi.org/project/napari-wsi/,,,A plugin to read whole-slide images within napari.,>=3.11,"['dask>=2025.1', 'magicgui>=0.10', 'numpy>=1.26', 'pillow>=11.1', 'typing-extensions>=4.6.1', 'universal-pathlib>=0.2', 'zarr>=3.0', ""colorspacious>=1.1.2; extra == 'all'"", ""openslide-python>=1.4; extra == 'all'"", ""pandas>=2.0; extra == 'all'"", ""rasterio>=1.4; extra == 'all'"", ""shapely>=2.0; extra == 'all'"", ""wsidicom>=0.22; extra == 'all'"", ""openslide-python>=1.4; extra == 'openslide'"", ""rasterio>=1.4; extra == 'rasterio'"", ""colorspacious>=1.1.2; extra == 'wsidicom'"", ""pandas>=2.0; extra == 'wsidicom'"", ""shapely>=2.0; extra == 'wsidicom'"", ""wsidicom>=0.22; extra == 'wsidicom'""]","# napari-wsi

[![PyPI](https://img.shields.io/pypi/v/napari-wsi.svg?color=green)](https://pypi.org/project/napari-wsi)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-wsi)](https://napari-hub.org/plugins/napari-wsi)
[![Tests](https://github.com/AstraZeneca/napari-wsi/actions/workflows/main.yml/badge.svg)](https://github.com/AstraZeneca/napari-wsi/actions)
![Maturity Level-1](https://img.shields.io/badge/Maturity%20Level-ML--1-yellow)

A plugin to read whole-slide images within [napari].

---

## Installation via pip

You can install `napari-wsi` via [pip]:

```bash
pip install ""napari-wsi[all]>=1.0""
```

This automatically installs all optional backends, as a shortcut for:

```bash
pip install ""napari-wsi[openslide,rasterio,wsidicom]>=1.0""
```

In addition, to be able to read images using the `openslide` backend, it is
required to install the OpenSlide library itself, for example by installing the
[openslide-bin] python package (also via [pip]).

## Installation via conda

You can also install `napari-wsi` via [conda]:

```bash
conda install -c conda-forge ""napari-wsi>=1.0""
```

This already installs all optional dependencies, including OpenSlide.

# Description

This [napari] plugin provides a widget for reading various whole-slide image
formats using a common [zarr] store inteface, based on the libraries
[openslide], [rasterio], and [wsidicom].

# Quickstart

After installation, open the `Plugins` menu in the viewer and select
`WSI Reader` to open the widget. Then select a `Backend` to use, select a `Path`
to open, and click `Load`.

![The napari viewer displaying a sample image.](./resources/sample_data.jpg)

If `sRGB` is selected in the `Color Space` menu and an ICC profile is attached
to the given image, a transformation to this color space will be applied when
the image data is read. Otherwise, the raw RGB image data will be displayed.

This plugin can also be used to open image files via drag and drop into the
viewer window. The file suffixes '.bif', '.ndpi', '.scn', '.svs' are registered
with the `openslide` backend, while the suffixes '.tif' and '.tiff' are
registered with the `rasterio` backend. These files can also be opened directly
from the command line or from a python script:

```bash
napari CMU-1.svs
```

```python
from napari import Viewer

viewer = Viewer()
viewer.open(""CMU-1.svs"", plugin=""napari-wsi"")
```

It is also possible to use the different backend classes directly, in which case
some more features are available, for example:

```python
from napari import Viewer
from napari_wsi.backends.openslide import OpenSlideStore

viewer = Viewer()

# Display the image in the sRGB color space and a physical coordinate system:
store = OpenSlideStore(""CMU-1.svs"", color_space=""sRGB"")
(layer,) = store.to_viewer(viewer, spatial_transform=True)
assert layer.metadata[""color_space""] == ""sRGB""

# Display a scale bar to indicate milli- or micrometers, depending on the zoom level:
viewer.scale_bar.visible = True
viewer.scale_bar.colored = True
```

```python
from napari import Viewer
from napari_wsi.backends.wsidicom import WSIDicomStore
from requests.auth import HTTPBasicAuth
from wsidicom import WsiDicomWebClient

viewer = Viewer()
client = WsiDicomWebClient.create_client(""..."", auth=HTTPBasicAuth(""..."", ""...""))
store = WSIDicomStore(client=client, study_uid=""..."", series_uids=""..."")
store.to_viewer(viewer)
```

The sample images used above are part of the OpenSlide test data (see [Aperio]
and [DICOM]).

# Known Issues & Other Notes

- This plugin is prototype research software and there may be **breaking
  changes** with each release of the plugin, which is also the case for current
  releases of the [napari] viewer itself.
- The `wsidicom` backend supports loading annotations together with the image
  data. However, this may take several minutes, depending on the number and
  complexity of the annotations. When loading more than a few thousand polygon
  annotations, make sure that the experimental ""[triangles] speedup"" setting is
  enabled.

[Aperio]: https://openslide.cs.cmu.edu/download/openslide-testdata/Aperio/
[conda]: https://conda-forge.org/
[DICOM]: https://openslide.cs.cmu.edu/download/openslide-testdata/DICOM/
[napari]: https://github.com/napari/napari
[openslide]: https://github.com/openslide/openslide-python
[openslide-bin]: https://pypi.org/project/openslide-bin/
[pip]: https://github.com/pypa/pip
[rasterio]: https://github.com/rasterio/rasterio
[triangles]: https://napari.org/island-dispatch/blog/triangles_speedup_beta.html
[wsidicom]: https://github.com/imi-bigpicture/wsidicom
[zarr]: https://github.com/zarr-developers/zarr-python
","['Framework :: napari', 'Intended Audience :: Developers', 'Operating System :: OS Independent', 'Topic :: Scientific/Engineering :: Image Processing']","['Repository, https://github.com/AstraZeneca/napari-wsi']",napari-wsi.wsi_reader_openslide,,napari-wsi.wsi_reader_widget,,"['*.bif', '*.ndpi', '*.scn', '*.svs']",,
473,napari-xgboost,napari-xgboost,Pixel Classification XGBoost,0.1.0,2024-07-05,2024-07-05,Robert Haase,robert.haase@uni-leipzig.de,"Copyright (c) 2024, Robert Haa...",https://github.com/haesleinhuepf/napari-xgboost/issues,https://pypi.org/project/napari-xgboost/,,,A plugin for pixel classification using XGBoost,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'xgboost', 'apoc', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-xgboost

[![License BSD-3](https://img.shields.io/pypi/l/napari-xgboost.svg?color=green)](https://github.com/haesleinhuepf/napari-xgboost/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-xgboost.svg?color=green)](https://pypi.org/project/napari-xgboost)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-xgboost.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/napari-xgboost/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/napari-xgboost/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/napari-xgboost/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/napari-xgboost)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-xgboost)](https://napari-hub.org/plugins/napari-xgboost)

A plugin for pixel classification using [XGBoost](https://xgboost.readthedocs.io/en/stable/), inspired by [Digital Sreeni's Youtube video](https://www.youtube.com/watch?v=yqkNslkzLk4).

Note: This plugin is work-in-progress. Check out the [github issues](https://github.com/haesleinhuepf/napari-xgboost/issues) to see what's currently being worked on.

## Usage

Load an example image into napari. Add a Labels layer by clicking on this button:

![img.png](https://github.com/haesleinhuepf/napari-xgboost/raw/main/docs/images/img.png)

Then, draw a sparse annotation on the image. Try to draw thin lines on background and foreground, e.g. like this:

![img_1.png](https://github.com/haesleinhuepf/napari-xgboost/raw/main/docs/images/img_1.png)

Then click the menu `Layers > Segment > Train Pixel Classifier (XGBoost)`.

![img_2.png](https://github.com/haesleinhuepf/napari-xgboost/raw/main/docs/images/img_2.png)

In the dialog, select the original image and the labels layer. Also enter a filename where the model should be saved. 
Afterwards, click on `Run` to explore the result.

![img_3.png](https://github.com/haesleinhuepf/napari-xgboost/raw/main/docs/images/img_3.png)

## Installation

You can install `napari-xgboost` via [pip]:

    pip install napari-xgboost

To install latest development version :

    pip install git+https://github.com/haesleinhuepf/napari-xgboost.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-xgboost"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/napari-xgboost/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/haesleinhuepf/napari-xgboost/issues', 'Documentation, https://github.com/haesleinhuepf/napari-xgboost#README.md', 'Source Code, https://github.com/haesleinhuepf/napari-xgboost', 'User Support, https://github.com/haesleinhuepf/napari-xgboost/issues']",,,napari-xgboost.make_function_widget,,,,
474,napari-yolo5-mitosis-detector,napari-yolo5-mitosis-detector,Yolo5 Mitosis Detector,0.0.1,2023-12-15,2023-12-15,Titouan Poquillon,titouan.poquillon@gmail.com,BSD-3-Clause,https://github.com/TPoquillon/napari-yolo5-mitosis-detector/issues,https://pypi.org/project/napari-yolo5-mitosis-detector/,,https://github.com/TPoquillon/napari-yolo5-mitosis-detector,A simple plugin to use yolo5 for mitosis detection with napari,>=3.9,"['numpy ==1.26.2', 'magicgui ==0.8.0', 'qtpy ==2.4.1', 'scikit-image ==0.20.0', 'opencv-python ==4.8.1.78', 'torch ==2.1.1', 'ultralytics ==8.0.222', 'shapely ==2.0.2', 'importlib-resources ==6.1.1', 'pandas ==2.1.3', 'napari-aicsimageio ==0.7.2', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-yolo5-mitosis-detector

[![License BSD-3](https://img.shields.io/pypi/l/napari-yolo5-mitosis-detector.svg?color=green)](https://github.com/TPoquillon/napari-yolo5-mitosis-detector/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-yolo5-mitosis-detector.svg?color=green)](https://pypi.org/project/napari-yolo5-mitosis-detector)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-yolo5-mitosis-detector.svg?color=green)](https://python.org)
[![tests](https://github.com/TPoquillon/napari-yolo5-mitosis-detector/workflows/tests/badge.svg)](https://github.com/TPoquillon/napari-yolo5-mitosis-detector/actions)
[![codecov](https://codecov.io/gh/TPoquillon/napari-yolo5-mitosis-detector/branch/main/graph/badge.svg)](https://codecov.io/gh/TPoquillon/napari-yolo5-mitosis-detector)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-yolo5-mitosis-detector)](https://napari-hub.org/plugins/napari-yolo5-mitosis-detector)

A simple plugin to use yolo5 for mitosis detection with napari

tpoquillon@gmail.com

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-yolo5-mitosis-detector` via [pip]:

    pip install napari-yolo5-mitosis-detector



To install latest development version :

    pip install git+https://github.com/TPoquillon/napari-yolo5-mitosis-detector.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-yolo5-mitosis-detector"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/TPoquillon/napari-yolo5-mitosis-detector/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/TPoquillon/napari-yolo5-mitosis-detector/issues', 'Documentation, https://github.com/TPoquillon/napari-yolo5-mitosis-detector#README.md', 'Source Code, https://github.com/TPoquillon/napari-yolo5-mitosis-detector', 'User Support, https://github.com/TPoquillon/napari-yolo5-mitosis-detector/issues']",,,napari-yolo5-mitosis-detector.make_yolov5_qwidget,,,,
475,napari-yapic-prediction,napari-yapic-prediction,napari-yapic-prediction,0.2.0,2021-04-19,2022-02-04,"Duway Nicolas Lesmes Leon, Pranjal Dhole","dlesmesleon@hotmail.com, dhole.pranjal@gmail.com",GNU GPL v3.0,https://github.com/yapic/napari-yapic-prediction,https://pypi.org/project/napari-yapic-prediction/,,https://github.com/yapic/napari-yapic-prediction,napari widget that performs image segmentation with yapic model in the napari window. Install TENSORFLOW to use this plugin.,>=3.6,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari[all]', 'yapic', 'scikit-image']","# napari-yapic-prediction

[![License](https://img.shields.io/pypi/l/napari-yapic-prediction.svg?color=green)](https://github.com/yapic/napari-yapic-prediction/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-yapic-prediction.svg?color=green)](https://pypi.org/project/napari-yapic-prediction)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-yapic-prediction.svg?color=green)](https://python.org)
[![tests](https://github.com/yapic/napari-yapic-prediction/workflows/tests/badge.svg)](https://github.com/yapic/napari-yapic-prediction/actions)
[![codecov](https://codecov.io/gh/yapic/napari-yapic-prediction/branch/master/graph/badge.svg?token=amah2YwOpx)](https://codecov.io/gh/yapic/napari-yapic-prediction)

A napari widget plugin to perform YAPiC model segmentation prediction in the napari window. 

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Description

This napari plugin provides a widget to upload a [YAPiC] trained model and perform segmentation over all the present images in the napari window. The segmentation results are uploaded as napari layers into the viewer automatically with the name structure of *imgename_prediction*.

## Installation

1. Please install either GPU or CPU version of tensorflow that is compatible with your `cuda` and `cudnn` libraries before installing the plugin depending on your system.
One of the plugin dependency is `yapic` that currently has sensitivity to tensorflow versions.

2. You can install `napari-yapic-prediction` via [pip]:

    ```pip install napari-yapic-prediction```

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-yapic-prediction"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/yapic/napari-yapic-prediction/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[YAPiC]: https://yapic.github.io/yapic/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']",,,,napari-yapic-prediction.MyWidget,,,,
476,napari-zplane-depth-colorizer,napari-zplane-depth-colorizer,napari-zplane-depth-colorizer,1.0.1,2024-10-14,2025-01-29,Mai Hoang,maihan.hoang1208@gmail.com,"Copyright (c) 2024, Mai Hoang
...",https://github.com/maihanhoang/napari-zplane-depth-colorizer/issues,https://pypi.org/project/napari-zplane-depth-colorizer/,,,A simple plugin to color and merge z-planes of 3D data to give depth information.,>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# napari-zplane-depth-colorizer

[![License BSD-3](https://img.shields.io/pypi/l/napari-zplane-depth-colorizer.svg?color=green)](https://github.com/maihanhoang/napari-zplane-depth-colorizer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-zplane-depth-colorizer.svg?color=green)](https://pypi.org/project/napari-zplane-depth-colorizer)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-zplane-depth-colorizer.svg?color=green)](https://python.org)
[![tests](https://github.com/maihanhoang/napari-zplane-depth-colorizer/workflows/tests/badge.svg)](https://github.com/maihanhoang/napari-zplane-depth-colorizer/actions)
[![codecov](https://codecov.io/gh/maihanhoang/napari-zplane-depth-colorizer/branch/main/graph/badge.svg)](https://codecov.io/gh/maihanhoang/napari-zplane-depth-colorizer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-zplane-depth-colorizer)](https://napari-hub.org/plugins/napari-zplane-depth-colorizer)

A simple plugin for 3d+t files that visualizes z-planes in 3 colors for depth information. 

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

This plugin can colorize and provide depth information on single-channel 3D+t files. The color coding enhances the visibility of structures and the detection/annotations of dynamic events. 

<p align=""middle"">
  <img src=""https://github.com/maihanhoang/napari-zplane-depth-colorizer/raw/main/assets/plugin_demo.gif"" width=""100%"" />
</p>

Identifying dynamic events such as cellular divisions can be challenging in 3D time-lapses of developing tissues such as organoids or embryos. Visualizing and annotating such events in dense 3D stacks obtained by light-sheet or two-photon microscopy where nuclei are almost in contact is especially challenging. With this visualization method, the tissue section can be ""augmented"" in 3D by visualizing the surrounding tissue layers in different colors. 

This plugin is for bioimaging researchers who need to annotate events in time lapses of dense tissues. It supports 3D+t stacks in the TZYX format. 

## Installation

You can install `napari-zplane-depth-colorizer` via [pip]:

    pip install napari-zplane-depth-colorizer

To install latest development version :

    pip install git+https://github.com/maihanhoang/napari-zplane-depth-colorizer.git

## Quick Start
A sample file can be found at `src/napari_zplane_depth_colorizer/data/3D+t.tif`

1. Open a 3D+t tif in napari, make sure it is in TZYX format
2. If it's a 4D file, it will automatically appear in the drop-down menu of *Input*
3. Use default parameters for *Z-Projection Type* and *Depth Range*
4. Click *Merge to RGB*
5. Result will appear in the viewer and in *Output*
6. To save, select the colored stack in *Output*, select saving format (*Save as*), and click *Save RGB*

## Parameters
There are two depth augmentation parameters for each RGB color channel: Z-Projection Type and Depth Range. Depth Range indicates which and how many z-planes are projected for a channel. The Z-Projection Type specifies which type of projection is applied. The **How it works** section below might help you understand the parameters better.

### Z-Projection Types 
The Z-projection types are the same ones found in [Fiji](https://imagej.net/software/fiji/), except for ""Raw. ""Raw is the original stack without any projection.

### Depth Range
- Depth Range is a range and consists of two numbers [range_start, range_end]. The range is inclusive and requires range_start <= range_end. 

- Exception if Z-Projection Type is ""Raw"" since no z-projection is applied. The Depth Range for Raw can either be empty (equals 0 then) or a single number. 

- The Depth Range indicates the z-planes relative to the reference plane that are projected and then assigned to a color channel. The reference plane is the plane for which the color merging is currently computed.

- In the illustration below, the current reference plane is the 4. plane (indicated by the color wheel in the right stack). A Depth Range of [-3, -1] for the red channel denotes the first three planes above the reference plane. Similarly, a Depth Range of [1, 2] for the blue channel indicates the first two planes below the reference plane. Negative numbers are for the planes above, and positive numbers are for ones below the reference plane. 0 is the same as the reference plane (the green plane in the illustration).   

<p align=""middle"">
  <img src=""https://github.com/maihanhoang/napari-zplane-depth-colorizer/raw/main/assets/entire_stack_zproj.jpg"" width=""100%"" />
</p>


## How it works
### Creating a colored image from a single-channel stack

To colorize a single-channel stack, multiple z-planes are assigned to different color (RGB) channels and then overlaid to create a composite colored image. For a simple z-stack with three planes, the 1. plane is assigned to red, the 2. to green, and the 3. plane to blue. They are overlaid/merged to create a single composite RGB-color plane. In the composite image, multiple z-planes are displayed simultaneously, with the colors providing the depth information. In this example, red indicates that cells are in the upper, while blue cells are in the deeper z-planes. The colors make it easier to detect and track cells that move or split in the z-direction.  


<!---------
In other words, instead of having multiple channels from different fluorescence labels, the z-planes are treated as different channels and then merged to create a composite image.


<img src=""./assets/3_plane_stack.gif"" alt=""Demo GIF"" style=""width:100%;"">
-------->
<p align=""middle"">
  <img src=""https://github.com/maihanhoang/napari-zplane-depth-colorizer/raw/main/assets/3_plane_stack.gif"" width=""100%"" />
</p>

On the left is an image of a single plane of an organoid and on the right is the colorized plane. To create the colors, the same plane was overlaid with the direct upper and lower plane, as shown in the illustration above. 
<p align=""middle"">
  <img src=""https://github.com/maihanhoang/napari-zplane-depth-colorizer/raw/main/assets/img_gray.png"" width=""49%"" />
  <img src=""https://github.com/maihanhoang/napari-zplane-depth-colorizer/raw/main/assets/img_color.png"" width=""49%"" /> 
</p>

### Colorizing the entire stack
To obtain a colorized stack of the same size as the original stack, the merging is applied for each z-plane. At the boundaries, the colors can differ, as there are no further z-planes to assign to a color channel. For example, the first plane in the colorized stack consists of an overlay of only two planes in green and blue, which results in a blue/green/cyan-colored image. Similarly, the last plane of the colorized stack is a red/green/yellowish image since it lacks a blue channel.    

<p align=""middle"">
  <img src=""https://github.com/maihanhoang/napari-zplane-depth-colorizer/raw/main/assets/entire_stack.gif"" width=""100%"" />
</p>

### Varying the depth with z-projections
It is also possible to vary the depth and overlay more than three planes. To do this, a z-projection is applied to the planes before assigning them to a color and merging. In the illustration below, a different number of planes is assigned to each color. Before merging the three RGB color channels, a z-projection is applied if more than one plane is assigned to a color. In the illustration below, three planes are selected for the red color channel. A z-projection (e.g. average intensity) is applied to generate a single plane for the red channel. This z-projected plane is merged with the raw, green plane and the z-projected plane of the blue channel. 


<p align=""middle"">
  <img src=""https://github.com/maihanhoang/napari-zplane-depth-colorizer/raw/main/assets/entire_stack_zproj.jpg"" width=""100%"" />
</p>

For the entire stack:
<p align=""middle"">
  <img src=""https://github.com/maihanhoang/napari-zplane-depth-colorizer/raw/main/assets/entire_stack_zproj.gif"" width=""100%"" />
</p>

On the left is an image of a single plane of an organoid, and on the right is the colorized plane. To create the colors, the same plane was overlaid with three upper and two lower z-planes, as shown in the illustration above. 

<p align=""middle"">
  <img src=""https://github.com/maihanhoang/napari-zplane-depth-colorizer/raw/main/assets/img_gray.png"" width=""49%"" />
  <img src=""https://github.com/maihanhoang/napari-zplane-depth-colorizer/raw/main/assets/img_color_zproj.png"" width=""49%"" /> 
</p>

## Acknowledgements
[Sham Tlili](https://scholar.google.com/citations?user=8ykCpTIAAAAJ&hl=fr) provided the sample data and developed the visualization method implemented in this plugin

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-zplane-depth-colorizer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/maihanhoang/napari-zplane-depth-colorizer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/maihanhoang/napari-zplane-depth-colorizer/issues', 'Documentation, https://github.com/maihanhoang/napari-zplane-depth-colorizer#README.md', 'Source Code, https://github.com/maihanhoang/napari-zplane-depth-colorizer', 'User Support, https://github.com/maihanhoang/napari-zplane-depth-colorizer/issues']",,,napari-zplane-depth-colorizer.make_qwidget,,,,
477,napping,napping,napping,0.2.4,2021-02-02,2023-02-17,Jonas Windhager,jonas.windhager@uzh.ch,MIT,https://github.com/BodenmillerGroup/napping/issues,https://pypi.org/project/napping/,,https://github.com/BodenmillerGroup/napping,Control point mapping and coordination transformation using napari,>=3.8,"['imagecodecs', 'imageio', 'napari[all] (>=0.4.16)', 'numpy', 'pandas', 'qtpy', 'scikit-image']","# napping

[![PyPI](https://img.shields.io/pypi/v/napping.svg?color=green)](https://pypi.org/project/napping)
[![License](https://img.shields.io/pypi/l/napping.svg?color=green)](https://github.com/BodenmillerGroup/napping/raw/main/LICENSE)
[![Python Version](https://img.shields.io/pypi/pyversions/napping.svg?color=green)](https://python.org)
[![Issues](https://img.shields.io/github/issues/BodenmillerGroup/napping)](https://github.com/BodenmillerGroup/napping/issues)
[![Pull requests](https://img.shields.io/github/issues-pr/BodenmillerGroup/napping)](https://github.com/BodenmillerGroup/napping/pulls)

Control point mapping and coordinate transformation using napari

## Installation

You can install `napping` via [pip](https://pypi.org/project/pip/):

    pip install napping

To install latest development version:

    pip install git+https://github.com/BodenmillerGroup/napping.git

## Usage

Run `napping` for control point mapping and coordinate transformation

## Authors

Created and maintained by Jonas Windhager [jonas.windhager@uzh.ch](mailto:jonas.windhager@uzh.ch)

## Contributing

[Contributing](https://github.com/BodenmillerGroup/napping/blob/main/CONTRIBUTING.md)

## Changelog

[Changelog](https://github.com/BodenmillerGroup/napping/blob/main/CHANGELOG.md)

## License

[MIT](https://github.com/BodenmillerGroup/napping/blob/main/LICENSE.md)
","['Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: MIT License']","['Bug Tracker, https://github.com/BodenmillerGroup/napping/issues', 'Documentation, https://github.com/BodenmillerGroup/napping/#README.md', 'Source Code, https://github.com/BodenmillerGroup/napping', 'User Support, https://github.com/BodenmillerGroup/napping/issues']",,,,,,,
478,napari-zulip,napari-zulip,napari-zulip,0.0.2,2023-04-22,2023-04-22,Kyle Harrington,czi@kyleharrington.com,BSD-3-Clause,https://github.com/kephale/napari-zulip/issues,https://pypi.org/project/napari-zulip/,,https://github.com/kephale/napari-zulip,A simple plugin for interacting with Zulip from napari,>=3.9,"['numpy', 'magicgui', 'qtpy', 'zulip', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# napari-zulip

[![License BSD-3](https://img.shields.io/pypi/l/napari-zulip.svg?color=green)](https://github.com/kephale/napari-zulip/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-zulip.svg?color=green)](https://pypi.org/project/napari-zulip)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-zulip.svg?color=green)](https://python.org)
[![tests](https://github.com/kephale/napari-zulip/workflows/tests/badge.svg)](https://github.com/kephale/napari-zulip/actions)
[![codecov](https://codecov.io/gh/kephale/napari-zulip/branch/main/graph/badge.svg)](https://codecov.io/gh/kephale/napari-zulip)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-zulip)](https://napari-hub.org/plugins/napari-zulip)

A simple plugin for interacting with Zulip from napari.

![An example screenshot of napari-zulip in action. It shows the plugin napari-boids and a filtered noise image, as well as a docked version of the napari-zulip plugin](./resources/demo_screenshot.png)  

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `napari-zulip` via [pip]:

    pip install napari-zulip



To install latest development version :

    pip install git+https://github.com/kephale/napari-zulip.git

### Setting it up

The plugin is going to look for a file in `<home directory>/.zulip.d/napari.zulipchat.com.zuliprc`.

**If you want to use this on a different zulip then adjust the `napari.zulipchat.com` to whatever the correct domain should be.**

#### How to generate a `.zuliprc` file

In the Zulip app:
- Select `Menu`
- Select `Personal settings`
- Select `Account & privacy`
- Click on `Show/change your API key`
- Enter your password
- Click `Download .zuliprc` 
- Save the file as `<home directory>/.zulip.d/napari.zulipchat.com.zuliprc` (or change the domain name if using a different Zulip server)

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""napari-zulip"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kephale/napari-zulip/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kephale/napari-zulip/issues', 'Documentation, https://github.com/kephale/napari-zulip#README.md', 'Source Code, https://github.com/kephale/napari-zulip', 'User Support, https://github.com/kephale/napari-zulip/issues']",,,napari-zulip.screenshot_to_Zulip,,,,
479,ndev-sampledata,ndev-sampledata,ndev Sampledata,0.0.3,2025-07-05,2025-07-07,Tim Monko,timmonko@gmail.com,"Copyright (c) 2025, Tim Monko
...",https://github.com/ndev-kit/ndev-sampledata/issues,https://pypi.org/project/ndev-sampledata/,,,Sample data for the ndev kit,>=3.10,"['bioio', 'bioio-imageio', 'bioio-ome-tiff', 'napari[all]; extra == ""all""', 'napari; extra == ""testing""', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""']","# ndev-sampledata

[![License BSD-3](https://img.shields.io/pypi/l/ndev-sampledata.svg?color=green)](https://github.com/ndev-kit/ndev-sampledata/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/ndev-sampledata.svg?color=green)](https://pypi.org/project/ndev-sampledata)
[![Python Version](https://img.shields.io/pypi/pyversions/ndev-sampledata.svg?color=green)](https://python.org)
[![tests](https://github.com/ndev-kit/ndev-sampledata/workflows/tests/badge.svg)](https://github.com/ndev-kit/ndev-sampledata/actions)
[![codecov](https://codecov.io/gh/ndev-kit/ndev-sampledata/branch/main/graph/badge.svg)](https://codecov.io/gh/ndev-kit/ndev-sampledata)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/ndev-sampledata)](https://napari-hub.org/plugins/ndev-sampledata)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

Sample data for the ndev kit

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `ndev-sampledata` via [pip]:

```
pip install ndev-sampledata
```

If napari is not already installed, you can install `ndev-sampledata` with napari and Qt via:

```
pip install ""ndev-sampledata[all]""
```


To install latest development version :

```
pip install git+https://github.com/ndev-kit/ndev-sampledata.git
```



## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""ndev-sampledata"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/ndev-kit/ndev-sampledata/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/ndev-kit/ndev-sampledata/issues', 'Documentation, https://github.com/ndev-kit/ndev-sampledata#README.md', 'Source Code, https://github.com/ndev-kit/ndev-sampledata', 'User Support, https://github.com/ndev-kit/ndev-sampledata/issues']",,,,ndev-sampledata.make_ndev_logo,,,
480,napari-yolov5,napari-yolov5,napari-yolov5,0.2.14,2021-12-29,2022-10-26,Richard De Mets,demets.richard@gmail.com,GPL-3.0-only,https://github.com/rdemets/napari-yolov5,https://pypi.org/project/napari-yolov5/,,https://github.com/rdemets/napari-yolov5,Plugin adapted from Ultralytics to bring YOLOv5 into Napari,>=3.7,"['connected-components-3d>=3.6.0', 'flask>=2.2.2', 'imageio-ffmpeg>=0.4.7', 'matplotlib>=3.2.2', 'napari-plugin-engine>=0.1.4', 'napari>=0.4.15', 'numpy>=1.18.5', 'opencv-python>=4.1.2', 'Pillow>=7.1.2', 'PyYAML>=5.3.1', 'qtpy>=2.2.1', 'requests>=2.23.0', 'scikit-image>=0.19.3', 'scipy>=1.4.1', 'tensorboard>=1.15.0', 'tensorflow>=2.10.0', 'torch>=1.9.0', 'torchvision>=0.8.1', 'tqdm>=4.41.0', 'seaborn>=0.11.2', 'wandb>=0.13.4']","# napari-yolov5

[![License](https://img.shields.io/pypi/l/napari-yolov5.svg?color=green)](https://github.com/rdemets/napari-yolov5/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-yolov5.svg?color=green)](https://pypi.org/project/napari-yolov5)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-yolov5.svg?color=green)](https://python.org)
[![tests](https://github.com/rdemets/napari-yolov5/workflows/tests/badge.svg)](https://github.com/rdemets/napari-yolov5/actions)
[![codecov](https://codecov.io/gh/rdemets/napari-yolov5/branch/main/graph/badge.svg)](https://codecov.io/gh/rdemets/napari-yolov5)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/napari-yolov5)](https://napari-hub.org/plugins/napari-yolov5)

Plugin adapted from Ultralytics to bring YOLOv5 into Napari. 

Training and detection can be done using the GUI. Training dataset must be prepared prior to using this plugin. Further development will allow users to use Napari to prepare the dataset. Follow instructions stated on [Ultralytics Github](https://github.com/ultralytics/yolov5) to prepare the dataset.

The plugin includes 3 pre-trained networks that are able to identify mitosis stages or apoptosis on soSPIM images. More details can be found on the [pre-print](https://www.biorxiv.org/content/10.1101/2021.03.26.437121v1.full).

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

First install conda and create an environment for the plugin
```
conda create --prefix env-napari-yolov5 python=3.9
conda activate env-napari-yolov5
```
You can install `napari-yolov5` and `napari` via [pip]:

    pip install napari-yolov5
    pip install napari[all]

For GPU support :
```
pip uninstall torch
pip install torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html
```

## Usage

First select if you would like to train a new network or detect objects.

![alt text](https://github.com/rdemets/napari-yolov5/blob/main/src/napari_yolov5/resources/Readme/1.jpg?raw=true)


***For `Training` :***

Data preparation should be done following [Ultralytics'](https://github.com/ultralytics/yolov5) instructions.

Select the size of the network, the number of epochs, the number of images per batch to load on the GPU, the size of the images (must be a stride of 32), and the name of the network.

![alt text](https://github.com/rdemets/napari-yolov5/blob/main/src/napari_yolov5/resources/Readme/2.jpg?raw=true)

An example of the YAML config file is provided in `src/napari_yolov5/resources` folder.

![alt text](https://github.com/rdemets/napari-yolov5/blob/main/src/napari_yolov5/resources/Readme/3.jpg?raw=true)


Progress can be seen on the Terminal or on the right-hand side of the viewer.

![alt text](https://github.com/rdemets/napari-yolov5/blob/main/src/napari_yolov5/resources/Readme/4.jpg?raw=true)


***For `Detection` :***

It is possible to perform the detection on a single layer chosen in the list, all the layers opened, or by giving a folder path. For folder detection, all the images will be loaded as a single stack.

![alt text](https://github.com/rdemets/napari-yolov5/blob/main/src/napari_yolov5/resources/Readme/5.jpg?raw=true)

Nucleus size of the prediction layer has te be filled to resize the image to the training dataset. Nucleus size of the training dataset will be asked in case of a custom network.

Confidence threshold defines the minimum value for a detected object to be considered positive. 
iou nms threshold (intersection-over-union non-max-suppression) defines the overlapping area of two boxes as a single object. Only the box with the maximum confidence is kept.
Progress can be seen on the Terminal.

![alt text](https://github.com/rdemets/napari-yolov5/blob/main/src/napari_yolov5/resources/Readme/6.jpg?raw=true)

Few options allow for modification on how the boxes are being displayed (default : box + class + confidence score ; box + class ; box only) and if the box coordinates and the image overlay will be exported.
Post-processing option will perform a simple 3D assignment based on 3D connected component analysis. A median filter (1x1x3 XYZ) is applied prior to the assignment. 
The centroid of each object is then saved into a new point layer as a 3D point with a random color for each class. 

![alt text](https://github.com/rdemets/napari-yolov5/blob/main/src/napari_yolov5/resources/Readme/7.jpg?raw=true)

The localisation of each centroid is saved and the path is shown in the Terminal at the end of the detection. It is also possible now to define the export folder.

![alt text](https://github.com/rdemets/napari-yolov5/blob/main/src/napari_yolov5/resources/Readme/8.jpg?raw=true)


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [GNU GPL v3.0] license,
""napari-yolov5"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)']",,,,napari-yolov5.widget_wrapper,,,,
481,napari-zelda,napari-zelda,napari-zelda,0.1.12,2021-10-17,2023-08-10,"Rocco D'Antuono, Giuseppina Pisignano",rocco.dantuono@hotmail.it,BSD-3-Clause,https://github.com/RoccoDAnt/napari-zelda,https://pypi.org/project/napari-zelda/,,https://github.com/RoccoDAnt/napari-zelda,ZELDA: a 3D Image Segmentation and Parent-Child relation plugin for microscopy image analysis in napari,>=3.7,"['datatable', 'json5', 'magicgui', 'matplotlib>=3.4.3', 'napari!=0.4.11', 'napari-plugin-engine>=0.1.4', 'numpy', 'pandas', 'scikit-image', 'scipy']","# napari-zelda

[![License](https://img.shields.io/pypi/l/napari-zelda.svg?color=green)](https://github.com/RoccoDAnt/napari-zelda/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/napari-zelda.svg?color=green)](https://pypi.org/project/napari-zelda)
[![Python Version](https://img.shields.io/pypi/pyversions/napari-zelda.svg?color=green)](https://python.org)
[![tests](https://github.com/RoccoDAnt/napari-zelda/workflows/tests/badge.svg)](https://github.com/RoccoDAnt/napari-zelda/actions)
[![codecov](https://codecov.io/gh/RoccoDAnt/napari-zelda/branch/master/graph/badge.svg)](https://codecov.io/gh/RoccoDAnt/napari-zelda)

## ZELDA: a 3D Image Segmentation and Parent-Child relation plugin for microscopy image analysis in napari
#### Authors: Rocco D'Antuono, Giuseppina Pisignano

###### Article: Front. Comput. Sci., 04 January 2022 | https://doi.org/10.3389/fcomp.2021.796117

###### Examples of 2D and 3D data sets: [https://doi.org/10.5281/zenodo.5651284](https://zenodo.org/record/5651284#.YYgn_WDP2Ch)
----------------------------------

## What you can do with ZELDA plugin for napari
The plugin can be used to analyze 2D/3D image data sets.  
Multidimensional images (each channel corresponding to a napari layer) can be used to:

1. Segment objects such as cells and organelles in 2D/3D.

2. Segment two populations in 2D/3D (e.g. cells and organelles, nuclei and nuclear spots, tissue structures and cells) establishing the ""Parent-Child"" relation: count how many mitochondria are contained in each cell, how many spots localize in every nucleus, how many cells are within a tissue compartment.

  Example: cell cytoplasms (parent objects) and mitochondria (child objects)
  ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/2D-AF488.png) <br> **Actin** | ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/2D-MT.png) <br> **Mitochondria**| ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/2D-AF488_MT.png) <br> **Merge**
  ------ | ------| -----
  ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/2D-AF488_parents.png) <br> **Parent cell cytoplasms** | ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/2D-MT_children.png) <br> **Children mitochondria**| ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/2D-MT_childrenbyParent.png) <br> **Children labelled by Parents**

The images shown above are available in the [**docs**](https://github.com/RoccoDAnt/napari-zelda/tree/main/docs) folder of this repository and were segmented using ZELDA with the following parameters:


   | **Parent objects** | **GB: sigma=2.0-> Th_parents=60.0-> DistMap-> Maxima: min_dist=10** |
   | -----|  ----|
   | **Children objects** | **GB: sigma=0.3-> Th_children=450.0 -> DistMap-> Maxima: min_dist=2**|

For small monitors it may be convenient to float the protocol panel

  |![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/Clipboard_ZELDA_Plugin-set_panel_to_float.png) <br> **Float a panel in napari** |
  ------ |

3. Plot results within napari interface.

    ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/Plot_hist_Area.png) <br> **Histogram** | ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/Plot_scatter_Area-EqDiam.png) <br> **Scatterplot**|
    ------ | ------|

4. Customize an image analysis workflow in graphical mode (no scripting knowledge required).

    | ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/CustomProtocol.png) <br> **Custom image analysis workflow** |
    ------ |

5. Import and Export Protocols (image analysis workflows) in graphical mode (share with the community!).

    | ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/Clipboard_Import_and_Export_Protocols.png) <br> **Import and Export of ZELDA Protocols** |
    ------ |

## Installation

**Option A.** The easiest option is to use the napari interface to install ZELDA (make sure napari!=0.4.11):
1. Plugins / Install/Uninstall Package(s)

  ![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/Clipboard_ZELDA_Plugin_install_in_napari.png)

2. Choose ZELDA
![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/Clipboard_ZELDA_Plugin_install_ZELDA_in_napari_Arrow.png)

3. ZELDA is installed
![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/Clipboard_ZELDA_Plugin_installed_ZELDA_in_napari_Arrow.png)

4. Launch ZELDA
![](https://raw.githubusercontent.com/RoccoDAnt/napari-zelda/main/docs/Clipboard_ZELDA_Launch_ZELDA.png)


**Option B.** You can install `napari-zelda` also via [pip]. For the best experience, create a conda environment and use napari!=0.4.11, using the following instructions:

    conda create -y -n napari-env python=3.8  
    conda activate napari-env
    conda install napari pyqt  
    pip install napari-zelda  


**Option C.** Alternatively, clone the repository and install locally via [pip]:

    pip install -e .

**Option D.** Get the latest code with [git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git) and [pip]:

    conda create -y -n napari-env python=3.8 git
    conda activate napari-env
    conda install napari pyqt
    pip install git+https://github.com/RoccoDAnt/napari-zelda.git


## Specifications

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

The GUI has been developed using [magicgui](https://github.com/napari/magicgui) widgets, while the image analysis and processing include functions from [scikit-image](https://scikit-image.org/), [SciPy](https://scipy.org/), and [NumPy](https://numpy.org/). Results are handled with [pandas](https://pandas.pydata.org/) and [datatable](https://datatable.readthedocs.io/en/latest/). Plots are obtained with [matplotlib](https://matplotlib.org/).  
<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->


## Contributing

Contributions are welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

Users can add new protocol steps to their local installation using [magicgui](https://github.com/napari/magicgui) widgets.
Code can be added at the end of napari_zelda.py file:

>###Add here new functionalities for ZELDA ###
>
>###@magicgui(layout=""vertical"")
>
>###def new_functionality_widget(viewer: 'napari.Viewer'):
>
>###...
>
>###
>
>###End###



## License

Distributed under the terms of the [BSD-3] license,
""napari-zelda"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/RoccoDAnt/napari-zelda/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,napari-zelda.launch_ZELDA,,,,
482,natari,natari,natari,0.2.7,2021-10-17,2021-12-22,Robert Haase,robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/natari/issues,https://pypi.org/project/natari/,,https://github.com/haesleinhuepf/natari,Napari gaming,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari', 'scipy', 'napari-tools-menu']","# natari

[![License](https://img.shields.io/pypi/l/natari.svg?color=green)](https://github.com/haesleinhuepf/natari/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/natari.svg?color=green)](https://pypi.org/project/natari)
[![Python Version](https://img.shields.io/pypi/pyversions/natari.svg?color=green)](https://python.org)

Napari gaming

## Sliding puzzle

Restore the image by reordering the superpixels using the `W`, `A`, `S`, `D` keys! 

![](https://github.com/haesleinhuepf/natari/raw/master/images/sliding_puzzle.gif)

## Cell counting arcade
Commander! Cells are intruding our dish! Control your tiny space ship using `1` and `2` keys to move it left/right.
Use the `9` key to shoot a anti-cell bullet.

![](https://github.com/haesleinhuepf/natari/raw/master/images/cell_counting_arcade.gif)

The image originates from [BBBC022v1](https://bbbc.broadinstitute.org/BBBC022) (Gustafsdottir et al., PLOS ONE, 2013), available from the Broad Bioimage Benchmark Collection (Ljosa et al., Nature Methods, 2012).

## Snake
Two mitochondria navigating in a cell searching for stress granules. 
The two players can control their mito using the `W`, `A`, `S`, `D` and `I`, `J`, `K`, `L`  keys, respectively.

![](https://github.com/haesleinhuepf/natari/raw/master/images/snake.gif)

## Ping pong
Don't drop the organoid! Use your racket and hit it back to your colleague!
The two players can use `W`, `S` and `I`, `K` to control their racket, respectively.

![](https://github.com/haesleinhuepf/natari/raw/master/images/ping_pong.gif)


This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

## Installation

You can install `natari` via [pip]:

    pip install natari

## Known issues

* To make the keyboard buttons work, you sometimes have to click within the image after starting the game.

## Contributing

Contributions are very welcome. 

## License

""natari"" is free and open source software. The code is in the public domain.

[See also: unlicense.org](https://unlicense.org)

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/natari/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 3 - Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/natari/issues', 'Documentation, https://github.com/haesleinhuepf/natari#README.md', 'Source Code, https://github.com/haesleinhuepf/natari', 'User Support, https://github.com/haesleinhuepf/natari/issues']",,,natari.napari_experimental_provide_function,,,,
483,neurogenesis-napari,neurogenesis-napari,TUM.ai + Helmholtz,0.1.0a1.post2,2025-07-29,2025-07-29,TUM.ai,"""TUM.ai"" <contact@tum-ai.com>",MIT,https://github.com/tum-ai/neurogenesis_napari,https://pypi.org/project/neurogenesis-napari/,,,A napari plugin to segment and classify cells.,>=3.10,"['cellpose==3.1.1.2', 'huggingface-hub>=0.33.0', 'magicgui', 'napari-czifile2', 'napari[pyqt5]', 'numpy==1.26.4', 'opencv-python==4.11.0.86', 'pandas==2.3.0', 'qtpy', 'sam2==1.1.0', 'scikit-image==0.25.2', 'scikit-learn==1.2.2', 'tifffile<=2023.4.12', 'torch==2.7.1']","# TUMai Helmholtz Neurogenesis Napari Plugin

[![License MIT](https://img.shields.io/pypi/l/neurogenesis-napari.svg?color=green)](LICENSE)
[![PyPI](https://img.shields.io/pypi/v/neurogenesis-napari.svg?color=green)](https://pypi.org/project/neurogenesis-napari)
[![Python Version](https://img.shields.io/pypi/pyversions/neurogenesis-napari.svg?color=green)](https://python.org)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/neurogenesis-napari)](https://napari-hub.org/plugins/neurogenesis-napari)

This plugin provides one-click color normalization, denoising, and Cellpose-based nuclear segmentation.

## Key Features

| Widget | Function | Input | Output |
|--------|----------|-------|---------|
| **Normalize + Denoise** | Color normalization and denoising | Bright-field image | Processed image |
| **Segment** | Nuclear segmentation | DAPI/nuclear stain | Masks, centroids, bounding boxes |
| **Segment + Classify** | End-to-end cell analysis | 4-channel images | Cell segmentation + classification |

## Quick Start

### Installation

```bash
pip install neurogenesis-napari
```

Or install through napari:
1. Open napari
2. Go to `Plugins` â `Install/Uninstall Plugins`
3. Search for **""TumAI Histology Toolkit""**
4. Click Install

### Basic Usage

1. **Load your images** into napari
2. **Select the appropriate widget** from the `Plugins` menu
3. **Choose your image layers** from the dropdown menus
4. **Click the action button** to process

The plugin will automatically download required AI models on first use.

---

## Widget Documentation

### Normalize + Denoise

**Purpose**: Standardizes color variations and reduces noise in bright-field images.

#### Usage
1. Load a bright-field image into napari
2. Open `Plugins` â `Normalize and Denoise`
3. Select your bright-field image from the **BF** dropdown
4. Click **""Normalize + Denoise""**

#### What it does
- **Color Normalization**: Adjusts colors against an internal reference to standardize appearance across different images/scanners
- **Denoising**: Removes noise while preserving important cellular structures
- **Output**: Creates a new layer named `{original_name}_denoised`

---

### Segment

**Purpose**: Detects and segments individual cell nuclei using Cellpose.

#### Usage
1. Load a nuclear staining image (DAPI) into napari
2. Open `Plugins` â `Segment`
3. Select your nuclear image from the **DAPI** dropdown
4. Optionally adjust:
   - **GPU**: Enable for faster processing
   - **Model**: Choose Cellpose model (`cyto3` default)
5. Click **""Segment Nuclei""**

#### What it does
- **Segmentation**: Uses Cellpose to identify individual nuclei
- **Creates 3 new layers**:
  - `{name}_masks`: Segmentation masks
  - `{name}_centroids`: Center points of each detected cell
  - `{name}_bboxes`: Bounding boxes around each cell

---

### Segment + Classify

**Purpose**: Complete pipeline that segments nuclei AND classifies cell types in multi-channel images.

#### Usage
1. Load a **4-channel image** into napari as separate layers:
   - **DAPI**: Nuclear staining
   - **Tuj1**: Î²-III-tubulin
   - **RFP**: Red fluorescent protein marker
   - **BF**: Bright-field
2. Open `Plugins` â `Segment and Classify`
3. Select each channel from the respective dropdowns
4. Choose **Reuse cached**:
   - **True**: Reuse previous segmentation (faster) from the segment widget
   - **False**: Perform fresh segmentation
5. Click **""Segment + Classify""**

#### What it does
1. **Segmentation**: Does segmentation same as the segment widget above
2. **Feature extraction**: Uses a Variational Autoencoder (VAE) to extract features
3. **Classification**: Nearest-centroid classifier assigns cell types

#### Output
Creates colored bounding box layers for each detected cell type:
- **ð£ Astrocytes** (magenta boxes)
- **â« Dead Cells** (gray boxes)
- **ðµ Neurons** (cyan boxes)
- **ð¢ OPCs** (lime boxes)

Layer names show counts: `{count}_{cell_type}s` (e.g., `23_Neurons`)

---

### Supported Image Formats
- `.czi` (via napari-czifile2)
- `.png`, `.jpg`
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: MacOS :: MacOS X', 'Operating System :: Microsoft :: Windows', 'Operating System :: OS Independent', 'Operating System :: POSIX :: Linux', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Repository, https://github.com/tum-ai/neurogenesis_napari']",,,neurogenesis-napari.normalize_and_denoise_widget,,,,
484,nellie,nellie,Nellie,0.4.1,2024-03-21,2024-10-31,Austin E. Y. T. Lefebvre,austin.e.lefebvre+nellie@gmail.com,Unavailable,https://github.com/aelefebv/nellie,https://pypi.org/project/nellie/,,https://github.com/aelefebv/nellie,"Automated organelle segmentation, tracking, and hierarchical feature extraction in 2D/3D live-cell microscopy",>=3.9,"['numpy==1.26.4', 'scipy==1.12.0', 'scikit-image==0.22.0', 'nd2==0.9.0', 'ome-types==0.5.2', 'pandas==2.2.1', 'matplotlib==3.8.3', 'napari[all]', 'imagecodecs', 'pydantic==2.9.2', 'pydantic-core==2.23.4']","# Nellie
## Automated organelle segmentation, tracking, and hierarchical feature extraction in 2D/3D live-cell microscopy

<img src=""https://github.com/aelefebv/nellie/assets/26515909/96b7a113-be60-4028-bcd9-b444bdb943f6"" width=""200px"" align=""left"" /> *arXiv* 

  [Preprint Link](https://arxiv.org/abs/2403.13214) | [Cite](#reference)

**Abstract:** The analysis of dynamic organelles remains a formidable challenge, though key to understanding biological processes. We introduce Nellie, an automated and unbiased pipeline for segmentation, tracking, and feature extraction of diverse intracellular structures. Nellie adapts to image metadata, eliminating user input. Nellieâs preprocessing pipeline enhances structural contrast on multiple intracellular scales allowing for robust hierarchical segmentation of sub-organellar regions. Internal motion capture markers are generated and tracked via a radius-adaptive pattern matching scheme, and used as guides for sub-voxel flow interpolation. Nellie extracts a plethora of features at multiple hierarchical levels for deep and customizable analysis. Nellie features a Napari-based GUI that allows for code-free operation and visualization, while its modular open-source codebase invites customization by experienced users. 

**Nellie's pipeline and Napari plugin are both very much in early stages,** therefore [I highly encourage any and all feedback](#getting-help).

## Example output intermediates

https://github.com/aelefebv/nellie/assets/26515909/1df8bf1b-7116-4d19-b5fb-9658f744675b

## Installation (~ 1 minute)

**Notes:** 
- It is recommended (but usually not required) to [create a new environment](https://docs.python.org/3/library/venv.html) for Nellie to avoid conflicts with other packages.
- May take several minutes to install.
- Choose one of the following methods, and only one!
- If you do not already have Python 3.9 or higher installed, download it via the [python website]([url](https://www.python.org/downloads/)).

https://github.com/user-attachments/assets/50b1cd4b-6df7-4f19-8db3-4dcc03388513


### Option 1. Via Napari plugin manager:
If not already installed, install Napari: https://napari.org/stable/tutorials/fundamentals/installation

https://github.com/user-attachments/assets/0d44abe5-f575-4bd4-962a-2c102faf737c


1. Open Napari
2. Go to ```Plugins > Install/Uninstall Plugins...```
3. Search for Nellie and click ```Install```
4. Make sure Nellie is updated to the latest version.
5. Restart Napari.
### Option 2. Via PIP:


https://github.com/user-attachments/assets/b63df093-e3e1-49cb-925b-7efce36b9015


```bash
python3 -m pip install nellie
```
#### Option 2a for NVIDIA GPU acceleration, optional (Windows, Linux):
To use GPU acceleration via NVIDIA GPUs, you also need to install cupy:
```bash
pip install cupy-cudaXXx
```
- replace ```cupy-cudaXXx``` with the [appropriate version](https://docs.cupy.dev/en/stable/install.html#installing-cupy) for your CUDA version.
  - i.e. ```cupy-cuda11x``` for CUDA 11.x or ```cupy-cuda12x``` for CUDA 12.x
- if you don't have CUDA installed, [go here](https://docs.cupy.dev/en/stable/install.html).
- Mac Metal GPU-acceleration coming... eventually.

## Usage
The sample dataset shown below is in the repo if you want to play around without, and can be downloaded [here](https://github.com/aelefebv/nellie/tree/main/sample_data).

### General data preparation
- It is strongly recommended to have your data in a parsable format, such as .ome.tif, .nd2, or other raw data files from microscopes.
  - Importing into ImageJ/FIJI and saving via BioFormats with the proper image dimensions should do the trick.
  - If the metadata cannot be parsed, you will have to manually enter it.
- It is also recommended to crop your image as much as possible to reduce processing time and memory usage. But really, unless you have massive lightsheet data, it should be pretty fast (seconds to minutes on a typical modern desktop computer).

### 3D + Timeseries dataset

https://github.com/user-attachments/assets/531f76ee-f58e-4058-b5dc-4fdf09af3660

### 3D (no Timeseries) dataset

https://github.com/user-attachments/assets/30d55bfa-bade-4987-88f0-255bb36cb7e8

### 2D + Timeseries dataset

https://github.com/user-attachments/assets/d534c6e1-df31-4964-9c12-edff56228be3

### Running Nellie's processing pipeline
1. Start Napari (open a Terminal and type napari)
    ```bash
    napari
    ```
2. Go to 
```Plugins > Nellie (nellie)``` then to the ```File select``` tab.
3. Click ```Select File``` of ```Select Folder``` to select your image(s).
   - If the metadata boxes do not fill in automatically and turn red, this means Nellie did not detect that metadata portion from your image, and you must manually enter it or reformat your image and try again.
     - The metadata slot will appear green if it is in the correct format.
   - *Note, if you are batch processing, the metadata must be the same for all images if any of them are in an incorrect format (this will be fixed eventually). If they are different, but all pass validation, then it will process fine.
   - You can preview your image via the ```Open preview``` button once the metadata is filled in to ensure it looks correct.
   - From this tab, you can also choose what time points and channel you want to analyze, if your file contains more than one slice in those dimensions.
4. Click the ```Process``` tab.
5. You can run the full pipeline with ```Run Nellie```, or run individual steps below.
    - Steps can only be run once its previous step has been run.
    - Likewise, visualizations in the ```Visualization``` tab can only be opened once its respective step has been run.
6. All intermediate files and output csvs will be saved to ```[image_directory]/nellie_output/```, which can be accessed via the ```Open output directory``` button.
   - A separate .csv is created for each level of the organellar hierarchy.
7. Once features have been exported, Nellie will automatically detect this, and allow analysis via the ```Analyze``` tab.
   - Analysis at this point is optional, but can be helpful for visualizing, and selectively exporting data.

### Using Nellie's visualization plugin
1. Follow the previous processing steps, you only need to do this once per file as long as you don't move or delete the files.
2. Open the ```Visualization``` tab
3. Select a visualization from the list.
   1. ```Raw```: Visualize the raw data for the processed channel.
   2. ```Preprocessed```: Visualize the contrast-enhanced data.
   3. ```Segmentation```: Visualize the organelle and branch instance segmentation masks.
   4. ```Mocap Markers```: Visualize the mocap markers used for waypoints.
   5. ```Reassigned Labels```: Visualize the organelle and branch instance segmentation masks where voxels are reassigned based on the first timepoint.
4. To visualize tracks, open and select one of the segmentation layers.
5. To visualize all tracks of all organelles/branches, click the ```Visualize all frame labels' tracks``` button.
6. To visualize all tracks of a specific organelle/branch:
   1. Click on the layer, and use the eyedropper tool at the top to select an organelle/branch to track.
   2. Click the ```Visualize selected label's tracks```.

### Using Nellie's analysis plugin
1. Follow the previous processing steps, you only need to do this once per file as long as you don't move or delete the files.
2. Open the ```Analyze``` tab, select the hierarchy level you want to visualize from the dropdown.
3. Select the level-specific feature you want to visualize from the new dropdown.
4. A histogram of all the data will be displayed.
   - This histogram can be directly exported via the ```Save graph``` button. A .png will be saved to ```[image_directory]/nellie_output/graphs/``` with the current datetime.
   - The values of the histogram can be exported via the ```Export graph data``` button. A .csv will be saved to ```[image_directory]/nellie_output/graphs/``` with the current datetime.
   - The histogram's x-axis can be viewed in log10 scale via the ```Log scale``` checkbox.
   - By default, the histogram shows lines at the mean +/- 1 standard deviation. This can instead be switched to median and quartiles via the ```Median view``` checkbox.
5. Press the ```Overlay mask``` button to colormap the organelle mask based on your selected feature.
   - Once overlaid, toggle the ```Timepoint data``` checkbox to allow you to select a specific timepoint to visualize via the slider.

## Other features
- Nellie's plugin offers an ```Easy screenshot``` feature:
  - Press the button under ```Easy screenshot``` or hit Ctrl/Cmd-Shift-E after clicking your image.
  - The .png will be saved to ```[image_directory]/nellie_output/screenshots/``` with the current datetime.

## Feedback / Getting Help
A few options are available for providing feedback or getting help with Nellie:

[Github Issues](https://github.com/aelefebv/nellie/issues/new) | [email](mailto:austin.e.lefebvre+nellie@gmail.com) | [X](https://twitter.com/Austin_Lefebvre) | wherever else you can find me!

To avoid any unnecessary back-and-forth, please include any/all (if possible) of the following information in your bug report:
- What kind of computer do you have, and what are its specs?
- Send me screenshots of what is not working.
- Send me any error logs in your terminal.
- Send me the file you ran (if possible).
- Any other information that might be helpful

## Other Info
For a 16bit dataset, the output:input ratio is ~15x. There is an option in the GUI to automatically delete intermediates after processing, keeping only the CSV files containing the extracted features.

## Requirements
Nellie has been tested on the following configurations:
- Mac, Linux, and Windows operating systems
- Python >= 3.9

## License
Nellie Â© 2024 by [Austin E. Y. T. Lefebvre](https://github.com/aelefebv) is licensed under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)

## Reference
If you used Nelly or found this work useful in your own research, please cite our [arXiv preprint](https://arxiv.org/abs/2403.13214):

Lefebvre, A. E. Y. T., Sturm, G., et. al. Nellie: Automated organelle segmentation, tracking, and hierarchical feature extraction in 2D/3D live-cell microscopy, arXiv, 2024, https://arxiv.org/abs/2403.13214

```
@misc{lefebvre2024nellie,
      title={Nellie: Automated organelle segmentation, tracking, and hierarchical feature extraction in 2D/3D live-cell microscopy}, 
      author={Austin E. Y. T. Lefebvre and Gabriel Sturm and Ting-Yu Lin and Emily Stoops and Magdalena Preciado Lopez and Benjamin Kaufmann-Malaga and Kayley Hake},
      year={2024},
      eprint={2403.13214},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

## More fun examples
### Microtubule growing ends:

https://github.com/aelefebv/nellie/assets/26515909/88578dc9-f5c5-4188-a0e2-4e37037a44a9

### Endoplasmic reticulum:

https://github.com/aelefebv/nellie/assets/26515909/db76d388-a9cc-4650-b93d-69d357ace418

### Peroxisomes:

https://github.com/aelefebv/nellie/assets/26515909/58bda3cb-6489-4620-8584-a3728cd6b2ec

## Code contents:
Full documentation can be found within the code, and compiled by Sphinx in the file docs/_build/html/index.html

### Nellie pipeline
All the Nellie pipeline code is found within the nellie folder
- File and metadata loading, and file preparation is found at nellie/im_info/verifier.py
- Preprocessing is found at nellie/segmentation/filtering.py
- Segmentation of organelles is found at nellie/segmentation/labelling.py
- Skeletonization and segmentation of branches is found at nellie/segmentation/networking.py
- Mocap marker detection is found at nellie/segmentation/mocap_marking.py
- Mocap marker tracking is found at nellie/tracking/hu_tracking.py
- Voxel reassignment via flow interpolation is found at nellie/tracking/voxel_reassignment.py
- Hierarchical feature extraction is found at nellie/feature_extraction/hierarchical.py

### Nellie Napari plugin
All the Napari plugin code is found with the nellie_napari folder
- The home tab is found at nellie_napari/nellie_home.py
- The file selection tab is found at nellie_napari/nellie_fileselect.py
- The processing tab is found at nellie_napari/nellie_processor.py
- The visualization tab is found at nellie_napari/nellie_visualizer.py
- The analysis tab is found at nellie_napari/nellie_analysis.py
- The settings tab is found at nellie_napari/nellie_settings.py
",['Framework :: napari'],,,,nellie.loader,,,,
485,neurofly,neurofly,neurofly,0.1.4,2024-10-30,2025-04-03,Rubin Zhao,Rubin Zhao <beanli161514@gmail.com>,GPL-3.0-or-later,https://github.com/beanli161514/neurofly,https://pypi.org/project/neurofly/,,,A framework to annotate single neurons at whole-brain scale,>=3.8,"['PyQt5', 'napari', 'Rtree', 'networkx', 'tqdm', 'magicgui', 'brightest-path-lib', 'tifffile', 'scikit-image', 'scipy', 'torch', 'tinygrad>=0.9.2', 'pathlib', 'h5py', 'zarr']","# NeuroFly: A framework for single neuron reconstruction at whole-brain scale

This package provides tools for semi-automatic neuron reconstruction. Features based on deep learning, like image segmentation and deconvolution are implemented in [tinygrad](https://github.com/tinygrad/tinygrad), which can run on almost any GPU (NVIDIA, AMD, Apple, Qualcomm, Intel).

<img src=""https://github.com/beanli161514/neurofly/raw/main/assets/main.png"" width=""640"">

## Update

Our transformer-based autonomous driving model is available now!


Press shortcut 'd' to automatically extend segments.

<img src=""https://github.com/beanli161514/neurofly/raw/main/assets/autonomous.gif"" width=""640"">

## Installation

Install the latest version
```
pip install --upgrade git+https://github.com/beanli161514/neurofly.git
```
or
```
pip install neurofly
```

You can also install from [napari hub](https://www.napari-hub.org/plugins/neurofly), using their plugin manager with GUI.

## Dataset

We provide several expert-proofread reconstruction results for testing, model training, and evaluation. [Zenodo Link](https://zenodo.org/records/13328867)


### Content of samples
| name           | size  | species | label type  | imaging |
|----------------|-------|---------|-------------|---------|
| rm009_labeled  | 629MB | macaque | skeleton    | VISoR   |
| mouse_labeled  | 260MB | mouse   | skeleton    | VISoR   |
| z002_labeled   | 204MB | mouse   | skeleton    | VISoR   |
| fmost_labeled  | 370MB | mouse   | skeleton    | fMOST   |
| RM009_noisy_1  | 65MB  | macaque | morphology  | VISoR   |
| RM009_noisy_2  | 65MB  | macaque | morphology  | VISoR   |
| fmost_test     | 65MB  | mouse   | morphology  | fMOST   |
| z002_dendrites | 768MB | mouse   | morphology  | VISoR   |
| RM009_arbor_1  | 288MB | macaque | morphology  | VISoR   |
| RM009_axons_1  | 600MB | macaque | morphology  | VISoR   |
| RM009_axons_2  | 600MB | macaque | morphology  | VISoR   |
| z002           | 8.92G | mouse   | morphology* | VISoR   |

$*$ annotation in progress
### Label format
Morphology labels are graphs saved in SQLite database with 3 tables:
|    segments    |  nodes  |  edges  |
|:--------------:|:-------:|:-------:|
|       sid      |   nid   |   src   |
|     points     |  coord  |   des   |
| sampled_points | creator |   date  |
|                |  status | creator |
|                |   type  |         |
|                |   date  |         |
|                | checked |         |

Segments are results of the segmentation stage, they are used to generate initial nodes and edges.


## Basic usage example

<img src=""https://github.com/beanli161514/neurofly/raw/main/assets/pipeline.png"" width=""640"">

NeuroFly packaged 4 napari plugins for image browsing, image segmentation, and data annotation.

<img src=""https://github.com/beanli161514/neurofly/raw/main/assets/menu.png"" width=""320"">

### Segmentation

NeuroFly supports whole brain image saved in hierarchical data structures(ims, h5, and zarr) in [Imaris File Format](https://imaris.oxinst.com/support/imaris-file-format) and small image volumes saved in single-channel tiff format. Here we use a mouse brain in our dataset named z002.zarr.zip as example.

This brain is sparsely labeled, which means only a tiny puny part of neurons are lighted and imaged. To extract these foreground singals, you can use the provided command line interface 'seg'. We provide a default weight trained on images captured by VISoR and fMOST.
```
seg -i z002.zarr.zip -vis -d z002.db
```
or use the graphical interface

<img align src=""https://github.com/beanli161514/neurofly/raw/main/assets/neuron_seger.png"" width=""200"">


This process may take about 10 hours depending on your you hardware configuration. When finished, you should see the extracted segments and a database file named z002.db in your working dictionary.


An image block with severe contamination and the segmentation result

<img align src=""https://github.com/beanli161514/neurofly/raw/main/assets/segmentation.gif"" width=""640"">


### Manual connection and proofreading

Launch annotation tool from napari menu, Plugin -> neurofly -> Segs Annotator

#### Load data
Load image file (z002.zarr.zip) and database file (z002.db), then click **refresh panorama** button to show the panorama view.

<img src=""https://github.com/beanli161514/neurofly/raw/main/assets/overall.png"" width=""600"">


#### Select one node as start point of annotation
In panorama mode, you can easily identify sparse, bright signals that are promising for reconstruction. The silde bars 'short segs filter', 'length thres', and 'point size' can be adjusted to hide noise and short segments. 

If you can clearly identify foreground segments, click on one of the conspicuous segments to select it as start point of annotation. Once selected, the id of picked node will be displayed at **node selection**. Then click 'switch mode' to switch to labeling mode, and the tasks will be generated automatically.


#### Task generation
Given a selected node, task generator analyses its connected component and extract all unchecked terminal nodes. The tasks are designed very simple: Connect the center node with the surrounding nodes if there should be an edge. The criterion is whether the edge aligns well with the imaged neuron fibers.

<img src=""https://github.com/beanli161514/neurofly/raw/main/assets/task_generation.png"" width=""480"">


#### Node operations
<img src=""https://github.com/beanli161514/neurofly/raw/main/assets/labeling_mode.png"" width=""480"">

In each task, a center node and nearby segments are rendered, you can add/remove nodes and edges to get a reasonable local structure.


Left click on nodes to add/remove an edge between it and the center node

<img src=""https://github.com/beanli161514/neurofly/raw/main/assets/add_edges.gif"" width=""480"">

Right click to remove a node

<img src=""https://github.com/beanli161514/neurofly/raw/main/assets/remove_nodes.gif"" width=""480"">

Press 'g' or use left panel to switch to 'image' layer, then right click to add points

<img src=""https://github.com/beanli161514/neurofly/raw/main/assets/add_nodes.gif"" width=""480"">

Use dropdown selection in right panel to add type label for center node.

<img src=""https://github.com/beanli161514/neurofly/raw/main/assets/change_type.gif"" width=""480"">

#### Deconvolution

Press 'i' or click on 'deconvolution' to deconvolve the image

<img src=""https://github.com/beanli161514/neurofly/raw/main/assets/deconv.gif"" width=""640"">


#### Proofreading

If you find something wrong when labeling, for example, two somas are connected together. You can use proofreading mode to check the neuron branch by branch.
<img src=""https://github.com/beanli161514/neurofly/raw/main/assets/proofreading.gif"" width=""640"">



### Performance
NeuroFly supports rendering of more than ten million points. (tested on M3 Macbook Air and RTX 3090 workstation)

<img src=""https://github.com/beanli161514/neurofly/raw/main/assets/dense.jpg"" width=""640"">



### Export as swc file
Switch to panorama mode, adjust 'length_thres' to filter out short segments and keep only complete neurons. Then press 'export swc files', each neuron will be saved as one .swc file in your working dictionary.


<img src=""https://github.com/beanli161514/neurofly/raw/main/assets/export.jpg"" width=""640"">
","['Framework :: napari', 'Programming Language :: Python :: 3']","['Homepage, https://github.com/beanli161514/neurofly']",,,neurofly.segs_annotator,,,,
486,organelle-segmenter-plugin,organelle-segmenter-plugin,Infer sub-Cellular Object Npe2 plugin,0.0.6,2023-05-13,2024-11-12,Andy Henrie,ergonyc@gmail.com,BSD-3,https://github.com/ndcn/organelle-segmenter-plugin/issues,https://pypi.org/project/organelle-segmenter-plugin/,,https://github.com/ndcn/organelle-segmenter-plugin,"A plugin that enables organelle segmentation, forked from tools from Allen Institute for Cell Science",>=3.8,"['napari', 'napari-plugin-engine>=0.1.4', 'aicssegmentation', 'aicsimageio', 'numpy', 'scikit-image', 'aicsimageio>=4.7.0', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# organelle-segmenter-plugin

[![License BSD-3](https://img.shields.io/pypi/l/organelle-segmenter-plugin.svg?color=green)](https://github.com/ndcn/organelle-segmenter-plugin/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/organelle-segmenter-plugin.svg?color=green)](https://pypi.org/project/organelle-segmenter-plugin)
[![Python Version](https://img.shields.io/pypi/pyversions/organelle-segmenter-plugin.svg?color=green)](https://python.org)
[![tests](https://github.com/ndcn/organelle-segmenter-plugin/workflows/tests/badge.svg)](https://github.com/ndcn/organelle-segmenter-plugin/actions)
[![codecov](https://codecov.io/gh/ndcn/organelle-segmenter-plugin/branch/main/graph/badge.svg)](https://codecov.io/gh/ndcn/organelle-segmenter-plugin)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/organelle-segmenter-plugin)](https://napari-hub.org/plugins/organelle-segmenter-plugin)


### A [napari](https://napari.org/stable/) plugin implementing [`infer-subc`](https://github.com/ndcn/infer-subc) segmentation workflows. 
See [`infer-subc`](https://github.com/ndcn/infer-subc) for more information.

# FRAMEWORK, RESOURCES & CONTRIBUTIONS
 
## Forked from Allen Institute for Cell Science project
The Allen Cell & Structure Segmenter plugin for napari, from which this projects is forked, provides an intuitive graphical user interface to access the powerful segmentation capabilities of an open source 3D segmentation software package developed and maintained by the Allen Institute for Cell Science (classic workflows only with v1.0). â[The Allen Cell & Structure Segmenter](https://allencell.org/segmenter) is a Python-based open source toolkit developed at the Allen Institute for Cell Science for 3D segmentation of intracellular structures in fluorescence microscope images. This toolkit brings together classic image segmentation and iterative deep learning workflows first to generate initial high-quality 3D intracellular structure segmentations and then to easily curate these results to generate the ground truths for building robust and accurate deep learning models. The toolkit takes advantage of the high replicate 3D live cell image data collected at the Allen Institute for Cell Science of over 30 endogenous fluorescently tagged human induced pluripotent stem cell (hiPSC) lines. Each cell line represents a different intracellular structure with one or more distinct localization patterns within undifferentiated hiPS cells and hiPSC-derived cardiomyocytes.

More details about Segmenter can be found at https://allencell.org/segmenter

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

## Contributing

Contributions are very welcome. 

## License

Distributed under the terms of the [BSD-3] license

""organelle-segmenter-plugin"" is free and open source software.



[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/ndcn/organelle-segmenter-plugin/issues
[napari]: https://github.com/napari/napari
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 3 - Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Scientific/Engineering :: Information Analysis', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/ndcn/organelle-segmenter-plugin/issues', 'Documentation, https://github.com/ndcn/organelle-segmenter-plugin#README.md', 'Source Code, https://github.com/ndcn/organelle-segmenter-plugin', 'User Support, https://github.com/ndcn/organelle-segmenter-plugin/issues']",organelle-segmenter-plugin.get_reader,,organelle-segmenter-plugin.make_batch_widget,,"['*.xyz', '*.czi', '*.tif', '*.tiff']",,
487,nfinder,nfinder,nfinder,0.3,2021-12-06,2022-02-05,Santiago N. Rodriguez Alvarez,rodriguezsantiago96@gmail.com,Unavailable,https://github.com/santi-rodriguez/nfinder,https://pypi.org/project/nfinder/,,https://github.com/santi-rodriguez/nfinder,Automatic inference of neighboring cells based on their Delaunay triangulation.,>=3.7,,"# Nfinder
Automatic inference of neighboring cells based on their Delaunay triangulation.

## Dependencies 
nfinder was tested with:

- python = 3.8.5
- napari = 0.4.12
- numpy = 1.21.2
- pandas = 1.3.4
- scikit-image = 0.18.3
- scipy = 1.7.1
- importlib-resources 5.4.0


## Installation

It can be installed with `pip` from PyPI:

```
pip install nfinder
```


## Usage
For usage examples, please check out the [notebook](https://github.com/santi-rodriguez/nfinder/blob/main/examples.ipynb) in our GitHub repository.



","['Development Status :: 4 - Beta', 'Programming Language :: Python :: 3.7', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Framework :: napari']",,,,nfinder.find,,,,
488,offset-subtraction,Offset-Subtraction,Offset-Subtraction,0.0.5,2022-01-13,2022-01-13,"Marc Boucsein, Robin Koch",,BSD-3,https://github.com/MBPhys/Offset-Subtraction,https://pypi.org/project/Offset-Subtraction/,,https://github.com/MBPhys/Offset-Subtraction,A napari plugin in oder to subtract an intensity offset such as autofluorescence,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'dask']","# Offset-Subtraction

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/Offset-Subtraction/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/Offset-Subtraction.svg?color=green)](https://pypi.org/project/Offset-Subtraction)
[![Python Version](https://img.shields.io/pypi/pyversions/Offset-Subtraction.svg?color=green)](https://python.org)


A napari plugin in oder to subtract an intensity offset such as autofluorescence

----------------------------------

## Installation

You can install `Offset-Subtraction` via [pip]:

    pip install Offset-Subtraction

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""Offset-Subtraction"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/Offset-Subtraction/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,Offset-Subtraction.Subtraction,,,,
489,ortho-view-napari,ortho-view-napari,ortho-view-napari,0.1.1,2021-06-15,2021-06-15,Jordao Bragantini,jordao.bragantini@czbiohub.org,BSD-3,https://github.com/JoOkuma/ortho-view-napari/issues,https://pypi.org/project/ortho-view-napari/,,https://github.com/JoOkuma/ortho-view-napari,It displays the lateral view of the current 3D stack. This could be a starting point for a orthorviewer.,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy']","# ortho-view-napari

[![License](https://img.shields.io/pypi/l/ortho-view-napari.svg?color=green)](https://github.com/JoOkuma/ortho-view-napari/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/ortho-view-napari.svg?color=green)](https://pypi.org/project/ortho-view-napari)
[![Python Version](https://img.shields.io/pypi/pyversions/ortho-view-napari.svg?color=green)](https://python.org)
[![tests](https://github.com/JoOkuma/ortho-view-napari/workflows/tests/badge.svg)](https://github.com/JoOkuma/ortho-view-napari/actions)
[![codecov](https://codecov.io/gh/JoOkuma/ortho-view-napari/branch/master/graph/badge.svg)](https://codecov.io/gh/JoOkuma/ortho-view-napari)

It displays the lateral view of the current 3D stack. This could be a starting point for a orthorviewer.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `ortho-view-napari` via [pip]:

    pip install ortho-view-napari

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""ortho-view-napari"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/JoOkuma/ortho-view-napari/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/JoOkuma/ortho-view-napari/issues', 'Documentation, https://github.com/JoOkuma/ortho-view-napari#README.md', 'Source Code, https://github.com/JoOkuma/ortho-view-napari', 'User Support, https://github.com/JoOkuma/ortho-view-napari/issues']",,,ortho-view-napari.Widget,,,,
490,okapi-em,okapi-em,napari okapi-em,0.0.10,2022-10-19,2023-08-14,Luis Perdigao,luis.perdigao@rfi.ac.uk,Apache-2.0,,https://pypi.org/project/okapi-em/,None,,napari plugin to deal with charging artifacts in tomography electron microscopy data,>=3.7,"['numpy', 'magicgui', 'chafer', 'napari[all]', 'opencv-python', 'quoll >=0.0.4', ""imageio-ffmpeg ; extra == 'all'"", ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'""]","# okapi-em

https://github.com/rosalindfranklininstitute/okapi-em

<!--
[![License](https://img.shields.io/pypi/l/okapi-em.svg?color=green)](https://github.com/rosalindfranklininstitute/okapi-em/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/okapi-em.svg?color=green)](https://pypi.org/project/okapi-em)
[![Python Version](https://img.shields.io/pypi/pyversions/okapi-em.svg?color=green)](https://python.org)
[![tests](https://github.com/perdigao1/okapi-em/workflows/tests/badge.svg)](https://github.com/rosalindfranklininstitute/okapi-em/actions)
[![codecov](https://codecov.io/gh/perdigao1/okapi-em/branch/main/graph/badge.svg)](https://codecov.io/gh/rosalindfranklininstitute/okapi-em)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/okapi-em)](https://napari-hub.org/plugins/okapi-em)
-->

A napari plugin for processing serial-FIB-SEM data.

Powered by [chafer] and [quoll].


A full description of this software is presented in biorXiv preprint paper:

https://doi.org/10.1101/2022.12.15.520541

This [napari] plugin contains the following tools:

- slice alignment using constrained SIFT
- two charge artifact suppression filters
    - directional fourier bandapass filter
    - line-by-line filter function optimiser and subtraction (requires charge artifact labels) - uses [chafer]
- fourier ring correlation (FRC) resolution estimation - uses [quoll]

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `okapi-em` via [pip]:

`>pip install okapi-em`

or using napari's plugin installation engine `Plugins->Install/Uninstall Plugins...` and filter for **Okapi-EM**.

For installing in development mode , clone this package then navigate to the cloned `okapi-em` folder and run:

`>pip install -e .`

Okapi-EM is a napari plugin. Launching napari is therefore required.

`>napari`

and then navigate `Menu->Plugins->Okapi-EM`

Note that to launch napari in older versions of python (<=3.7) you will need to use the command:

`>python -m napari`

## Computing requirements
Okapi-EM does not require powerful computers to run. None of the tools use GPU accelaration.

The minimum recommended RAM depends on the size of the data being used in napari. For a full image stack of 1Gb, it is recommended that user ensure that 3Gb of RAM is available or can be used. Modern OS's can extend physical RAM using `swap` memory (Linux) or cache (in Windows and also known as virtual memory), but processing can be significantly slower.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [Apache Software License 2.0] license,
""okapi-em"" is free and open source software

## Citing

Please cite usage using the following reference.

PerdigÃ£o, L. M. A. et al. Okapi-EM â a napari plugin for processing and analysing cryogenic serial FIB/SEM images. 2022.12.15.520541 Preprint at https://doi.org/10.1101/2022.12.15.520541 (2022).


## Issues

There is currently a known issue with napari running in Linux machines, that it does not find the OpenGL driver correctly.
This will hopefully be resolved in the near future. If you bump into this issue we recommend trying to downgrade the python version. This is not an Okapi-EM problem.

If you encounter any problems, please file an issue along with a detailed description.

[quoll]: https://github.com/rosalindfranklininstitute/quoll
[chafer]: https://github.com/rosalindfranklininstitute/chafer
[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin


[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: Apache Software License']",,,,okapi-em.main_qwidget,,,,
491,palmari,palmari,Palmari,0.3.0,2022-05-06,2023-05-01,Hippolyte Verdier,hverdier@pasteur.fr,"""CeCILL""...",https://github.com/hippover/palmari/issues,https://pypi.org/project/palmari/,,https://github.com/hippover/palmari,"Palmari provides a plugin to analyze PALM movies, as well as microscope recordings of other SMLM-based SPT modalities. Set up your pipeline on one file, run it on a folder !",>=3.8,"['click', 'dask (>=2022.1.0)', 'dask-image (>=2021.12.0)', 'imageio-ffmpeg', 'magicgui (>=0.5.0)', 'matplotlib (>=3.5)', 'munkres', 'napari', 'napari-aicsimageio', 'numpy', 'pandas', 'pyyaml', 'qtpy', 'scikit-image (>=0.18.3)', 'scikit-learn', 'toml', 'tqdm', 'trackpy (>=0.5.0)', ""tox ; extra == 'testing'"", ""PyQt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'""]","# Palmari

[![Documentation Status](https://readthedocs.org/projects/palmari/badge/?version=latest)](https://palmari.readthedocs.io/en/latest/?badge=latest)
[![Python Version](https://img.shields.io/pypi/pyversions/palmari.svg?color=green)](https://python.org)
[![tests](https://github.com/hippover/palmari/workflows/tests/badge.svg)](https://github.com/hippover/palmari/actions)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/palmari)](https://napari-hub.org/plugins/palmari)
[![License](https://img.shields.io/pypi/l/palmari.svg?color=green)](https://github.com/hippover/palmari/raw/main/LICENSE)

A processing pipeline for PALM movies analysis (pre-processing, localization, drift correction, tracking).

Check out the [documentation] to get started.

![napari_plugin](https://github.com/hippover/palmari/raw/main/docs/images/plugin_steps.png ""Fine-tune your pipelines on a movie, run it on a batch easily !"")

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

## Installation

You can install `palmari` via [pip]:

    pip install palmari



To install latest development version :

    pip install git+https://github.com/hippover/palmari.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [CeCILL] license.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/hippover/palmari/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[CeCILL]: http://cecill.info/index.en.html
[documentation]: https://palmari.readthedocs.io/en/latest/
","['Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Environment :: Plugins', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing', 'Operating System :: OS Independent', 'License :: OSI Approved :: CEA CNRS Inria Logiciel Libre License, version 2.1 (CeCILL-2.1)']","['Bug Tracker, https://github.com/hippover/palmari/issues', 'Documentation, https://palmari.readthedocs.io/en/latest/', 'Source Code, https://github.com/hippover/palmari', 'User Support, https://github.com/hippover/palmari/issues']",,,palmari.make_qwidget,,,,
492,partial-aligner,Partial-Aligner,Partial-Aligner,0.0.1,2022-01-14,2022-01-14,"Marc Boucsein, Robin Koch",,BSD-3,https://github.com/DKFZ-TMTRR/Partial-Aligner,https://pypi.org/project/Partial-Aligner/,,https://github.com/DKFZ-TMTRR/Partial-Aligner,A napari plugin for manual registration of (a part of) an image,>=3.9,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'packaging', 'dask']","# Partial-Aligner

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/Partial-Aligner/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/Partial-Aligner.svg?color=green)](https://pypi.org/project/Partial-Aligner)
[![Python Version](https://img.shields.io/pypi/pyversions/Partial-Aligner.svg?color=green)](https://python.org)


A napari plugin to affine transform images and parts of images in 2D and 3D. It was developed in the context of brain slice registration and solves multiple, related problems when working with histology slices.

----------------------------------

## Installation

You can install `Partial-Aligner` via [pip]:

    pip install Partial-Aligner
    
To make full use of this plugin, please also install the sister plugins:

    pip install Label-Creator
    pip install Layer-Data-Replace
    pip install World2Data

## Usage

It is important to note that this plugin is part of a group of plugins ([Label-Creator](https://github.com/DKFZ-TMTRR/Label-Creator, ""Creates Labels""), [Layer-Data-Replace](https://github.com/DKFZ-TMTRR/Layer-Data-Replace, ""Replaces the data of a layer with other data""), [World2Data](https://github.com/DKFZ-TMTRR/World2Data, ""Applies a transformation to an image"")) which are intended to be used together. 

The principle workflow with this plugin is as follows:

1. Load an image of interest (ioi) using standard napari.
2. Find out meaningful transformation parameters for the ioi (or part of it) based on what you see in the viewer.
3. (optional) Save the affine transformation matrix (can later be applied to other modalities)
4. Apply the transformation to create a new, altered version of the ioi (use plugin [World2Data](https://github.com/DKFZ-TMTRR/World2Data, ""Applies a transformation to an image""))

Decisions on the parameters (step 2) are made based on the problem at hand:

- Registration: You have a second (fixed) image and you want to align your ioi to that image? Transform your whole ioi! Just play with the transformation parameters until you are happy with the alignment of ioi and fixed image.

<p align=""center"">
    <img src=""https://user-images.githubusercontent.com/36212786/149524198-9a25b6dc-4169-4546-85b3-7c2f57fccc97.png"" width=""50%"" height=""50%"">  <br /> 
     <i>DAPI staining (red) before (left) and after (right) manual registration on an MRI image (green).</i> 
</p>

- Histology artifact repair: Parts of your histology slice are misplaced? Transform the misplaced parts! Label them and change the transformation parameters for the misplaced parts until you are happy with their alignment with the rest of the image.

<p align=""center"">
<img src=""https://user-images.githubusercontent.com/36212786/149526385-09aeebe2-d03e-4dd4-a424-d0f3af207529.png"" width=""50%"" height=""50%"">  <br /> 
     <i> Original slice with misplaced region (left), marked using the label function (middle) and after manual adjustment (right), where the misplaced region (green) was cut and newly positioned.</i> 
</p>

To make this plugin run reasonably fast, the affine transformations are not applied to the image data in real time. Instead, the internal napari viewing parameters are changed according to the transformation parameters. Therefore, to save transformed image data, the [World2Data](https://github.com/DKFZ-TMTRR/World2Data, ""Applies a transformation to an image"") plugin is used, which calculates and saves the resulting image based on the internal napari viewing parameters.


Here we showcase a resulting multimodal 3D alignment of a whole mouse brain. The modalities are CT, MRI, simulated radiation dose distributions, DAPI staining and DNA-damage repair foci, with a Nissl-staining mouse atlas as template.

https://user-images.githubusercontent.com/36212786/149530462-51a53631-bf74-459b-ab4e-572c52cf2692.mov







## Contributing

Contributions are very welcome. Tests can be run with [tox].

## License

Distributed under the terms of the [BSD-3] license,
""Partial-Aligner"" is free and open source software.

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/Partial-Aligner/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,Partial-Aligner.Aligner,,,,
493,platemapper,platemapper,ndev PlateMapper,0.1.1,2025-03-05,2025-03-06,Tim Monko,timmonko@gmail.com,"Copyright (c) 2025, Tim Monko
...",,https://pypi.org/project/platemapper/,None,,Map microplate treatments to image metadata.,>=3.9,"['numpy', 'pandas[output-formatting]', 'seaborn', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""']","# platemapper

[![License BSD-3](https://img.shields.io/pypi/l/platemapper.svg?color=green)](https://github.com/ndev-kit/platemapper/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/platemapper.svg?color=green)](https://pypi.org/project/platemapper)
[![Python Version](https://img.shields.io/pypi/pyversions/platemapper.svg?color=green)](https://python.org)
[![tests](https://github.com/ndev-kit/platemapper/workflows/tests/badge.svg)](https://github.com/ndev-kit/platemapper/actions)
[![codecov](https://codecov.io/gh/ndev-kit/platemapper/branch/main/graph/badge.svg)](https://codecov.io/gh/ndev-kit/platemapper)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/platemapper)](https://napari-hub.org/plugins/platemapper)

Map microplate treatments to metadata.

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `platemapper` via [pip]:

    pip install platemapper

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""platemapper"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']",,,,,,,,
494,platetrack,platetrack,platetrack,0.0.7,2023-12-03,2024-03-20,Abigail S McGovern,abigail_mcgovern@hotmail.com,BSD-3-Clause,https://github.com/abigailmcgovern/platelet-tracking/issues,https://pypi.org/project/platetrack/,,https://github.com/AbigailMcGovern/platelet-tracking,napari plugin for tracking platelets with trackpy,>=3.7,"['napari', 'numpy', 'trackpy', 'pandas', 'plateletanalysis']","# platetrack
A small napari plugin for tracking platelets. Platetrack requires a segmentation and an image containing raw data. We recomend trying the napari plugin iterseg to generate these. Platetrack uses trackpy for tracking and outputs a dataframe with platelet coordinates, tracking information, and several other variables, which provide information about each platelet. 


## Installation

There are three main ways to install platetrack:

### Install Using pip

Type the following into your terminal (MacOS or Ubuntu) or annaconda prompt (windows):

```bash
pip install platetrack
```

### Install via napari hub

Type the following into your terminal (MacOS or Ubuntu) or annaconda prompt (windows):

```bash
install napari
napari
```

Once napari has opened (this may take a second the first time you open it), go to the pannel at the top of the screen and select the 'plugins' dropdown. Then select install/uninstall plugins. A new window will open showing available plugins. Either scroll down to or search 'platetrack' and click 'install'. 

### Install from Source Code
*please use this for now*

Type the following into your terminal (MacOS or Ubuntu) or annaconda prompt (windows):

```bash
git clone <repository https or ssh>
cd platetrack
pip install .
```


## Opening Platetrack
Once annotrack is properly installed you will be able to open platetrack by opening napari. You can open napari through the command line (terminal (MacOS or Ubuntu) or annaconda prompt (windows)) as follows:

```bash
napari
```

You can find the platetrack widgets by selecting the dropdown 'plugins' at the pannel at the top of the screen and selecting the platetrack widget 'track_platelets'.  


## Tracking Platelets
You can track platelets and obtain a dataframe of information about platelet observation by providing an image/s (t, z, y, x) and a segmentation (t, z, y, x). There are no specific file format requirements, only that you first load the image and segmentation into napari. The napari plugin iterseg provides a widget that will help you load zarr format files. If you have an image with multiple channels (i.e., laser colours), load them into separate napari layers. Iterseg has an option for this called ""split channels"". Otherwise, refer to the napari website for instructions on using napari layers. 

### Parameters for widget

- **labels_layer**: The napari layer containing the segmentation.
- **image_layer**: The napari layer containing the image (you only need this if you don't want to use all image layers).
- **use_all_image_layers**: If you have several image channels selecting this will obtain information about each channel. The info about image intensity will be stored in columns of the data frame named *[layer name]*_max, *[layer name]*_mean_, 
- **sample_name**: what is the name of the sample (i.e., an identifyer for the biological sample including, for example, the animal number, date, experimental conditions, etc.). This is important if you are planning to combine data frames with different treatment groups. 
- **treatment_name**: name of treatement group or experimental condition (will be added as a categorical variable). This is important if you are planning to combine data frames with different treatment groups. 
- **x_microns**: How big are pixels in the x axis (probably in microns). We need this so that physical rather than pixel coordinates can be computed. 
- **y_microns**: How big are pixels in the y axis (probably in microns). We need this so that physical rather than pixel coordinates can be computed. 
- **z_microns**: How big are pixels in the z axis (probably in microns). We need this so that physical rather than pixel coordinates can be computed. 
- **save_dir**: Directory into which you want to save output data
- **save_file**: name to give the file, 
- **save_format**: There are two options for save format ""parquet"" or ""csv"".  
- **search_range**: This is a parameter for the tracking. The search range is how far away (in physical units, e.g., microns) the tracking algorithm will look for the same platelet at the next time point. This can be reduced if trackpy is running out of computational resources due to a high number of observations (platelets)  
- **xy_origin**: If you are rotating the data (e.g., you might want to align the blood flow with the y axis like we do) this parameter defines the centre of rotation. If you would like to use the geometric centre of the image just use ""centre"". Otherwise, provide a tuple (computer word â basically a list of numbers between brackets) of coordinates in physical units in yx format (e.g., (126, 148)). 
- **rotation**: The number of degrees by which to rotate the data counterclockwise. 



## Platelet data outputted
A number of variables are computed about the platelets alongside the tracking. Each variable is reported for every platelet observation (execpt veclocity, which is only reported for tracked platelets after the first observation). 

- Mean platelet intensity in each image channel
- Max platelet pixel intensity in each channel
- Platelet elongation (0-1, 0 being least elongated, 1 being most elongated)
- Platelet flatness (0-1, 0 being least flat, 1 being most flat)
- Platelet velocity (dv)
- Platelet coordinate velocities (dvx, dvy, dvz)
- Platelet local density (density of platlets in a 15 um radius around the platelet)
- Lists of platelet neighbours within 15 um radius
- Lists of distances of each platelet neighbours within 15 um radius


## Contributing and User Support

**User support:** If you have an issue with platetrack please add an issue (go to the Issues tab at the top of the GitHub page). If your issue is a bug, please include as much information as possible to help debug the problem. Examples of information include: details about the image and segmentation data (dimensions), number of images, number of samples you are trying to take. If you are requesting an improvement, try to be as clear as possible about what you need. 

**Contributing:** If you want to contribute to platetrack, please fork the repo and if you want to make changes make a pull request with as much detail about the change as possible. Please ensure any changes you want to make don't break the existing functions.
","['Framework :: napari', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License', 'Intended Audience :: Science/Research', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/abigailmcgovern/platelet-tracking/issues', 'Documentation, https://github.com/abigailmcgovern/platelet-tracking#README.md', 'Source Code, https://github.com/abigailmcgovern/platelet-tracking', 'User Support, https://github.com/abigailmcgovern/platelet-tracking/issues']",platetrack.load_tracks,,platetrack.track_platelets,,"['*.csv', '*.parquet']",,
495,partseg-smfish,PartSeg-smfish,PartSeg-smfish,0.1.3,2022-10-24,2022-12-06,Grzegorz Bokota,g.bokota@cent.uw.edu.pl,BSD-3-Clause,https://github.com/4DNucleome/PartSeg-smfish/issues,https://pypi.org/project/PartSeg-smfish/,,https://github.com/4DNucleome/PartSeg-smfish,PartSeg and napari plugin for smfish data,>=3.8,"['PartSeg (>=0.13.0)', 'numpy', 'napari', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'""]","# PartSeg-smfish

[![License BSD-3](https://img.shields.io/pypi/l/PartSeg-smfish.svg?color=green)](https://github.com/4DNucleome/PartSeg-smfish/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/PartSeg-smfish.svg?color=green)](https://pypi.org/project/PartSeg-smfish)
[![Python Version](https://img.shields.io/pypi/pyversions/PartSeg-smfish.svg?color=green)](https://python.org)
[![tests](https://github.com/4DNucleome/PartSeg-smfish/workflows/tests/badge.svg)](https://github.com/4DNucleome/PartSeg-smfish/actions)
[![codecov](https://codecov.io/gh/4DNucleome/PartSeg-smfish/branch/main/graph/badge.svg)](https://codecov.io/gh/4DNucleome/PartSeg-smfish)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/PartSeg-smfish)](https://napari-hub.org/plugins/PartSeg-smfish)

PartSeg and napari plugin for smfish data

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `PartSeg-smfish` via [pip]:

    pip install PartSeg-smfish



To install latest development version :

    pip install git+https://github.com/4DNucleome/PartSeg-smfish.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""PartSeg-smfish"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/4DNucleome/PartSeg-smfish/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/4DNucleome/PartSeg-smfish/issues', 'Documentation, https://github.com/4DNucleome/PartSeg-smfish#README.md', 'Source Code, https://github.com/4DNucleome/PartSeg-smfish', 'User Support, https://github.com/4DNucleome/PartSeg-smfish/issues']",,,PartSeg-smfish.verify_points.verify_segmentation,,,,
496,platelet-unet-watershed,platelet-unet-watershed,platelet-unet-watershed,0.0.3,2021-07-01,2021-09-20,Juan Nunez-Iglesias & Abigail McGovern,juan.nunez-iglesias@monash.edu,BSD-3,https://github.com/jni/platelet-unet-watershed/issues,https://pypi.org/project/platelet-unet-watershed/,,https://github.com/jni/platelet-unet-watershed,Segment platelets with pretrained unet and affinity watershed,>=3.7,"['magicgui>=0.2.11', 'napari>=0.4.11', 'napari-plugin-engine>=0.1.4', 'numba>=0.50', 'numpy', 'scikit-image', 'scipy', 'toolz', 'torch', 'torchvision', 'tqdm']","# platelet-unet-watershed

[![License](https://img.shields.io/pypi/l/platelet-unet-watershed.svg?color=green)](https://github.com/jni/platelet-unet-watershed/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/platelet-unet-watershed.svg?color=green)](https://pypi.org/project/platelet-unet-watershed)
[![Python Version](https://img.shields.io/pypi/pyversions/platelet-unet-watershed.svg?color=green)](https://python.org)
[![tests](https://github.com/jni/platelet-unet-watershed/workflows/tests/badge.svg)](https://github.com/jni/platelet-unet-watershed/actions)
[![codecov](https://codecov.io/gh/jni/platelet-unet-watershed/branch/master/graph/badge.svg)](https://codecov.io/gh/jni/platelet-unet-watershed)

Segment platelets with pretrained unet and affinity watershed

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `platelet-unet-watershed` via [pip]:

    pip install platelet-unet-watershed

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""platelet-unet-watershed"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/jni/platelet-unet-watershed/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/jni/platelet-unet-watershed/issues', 'Documentation, https://github.com/jni/platelet-unet-watershed#README.md', 'Source Code, https://github.com/jni/platelet-unet-watershed', 'User Support, https://github.com/jni/platelet-unet-watershed/issues']",,,platelet-unet-watershed.UNetPredictWidget,,,,
497,partseg,PartSeg,PartSeg,0.16.3,2020-10-27,2025-07-10,Grzegorz Bokota,Grzegorz Bokota <g.bokota@uw.edu.pl>,BSD-3-Clause,https://github.com/4DNucleome/PartSeg/issues,https://pypi.org/project/PartSeg/,,,"PartSeg is python GUI and set of napari plugins for bio imaging analysis especially nucleus analysis,",>=3.9,"['IPython>=7.7.0', 'PartSegCore-compiled-backend<0.16.0,>=0.13.11', 'PartSegData==0.10.0', 'QtAwesome!=1.2.0,>=1.0.3', 'QtPy>=1.10.0', 'SimpleITK>=2.1.0', 'appdirs>=1.4.4', 'czifile>=2019.5.22', 'defusedxml>=0.6.0', 'fonticon-fontawesome6>=6.1.1', 'h5py>=3.3.0', 'imagecodecs>=2020.5.30', 'imageio>=2.20.0', 'ipykernel>=5.2.0', 'local-migrator>=0.1.7', 'magicgui!=0.5.0,>=0.4.0', 'mahotas>=1.4.12', 'napari>=0.4.19', 'nme>=0.1.7', 'numpy>=1.22.2; python_version >= ""3.10""', 'numpy<2,>=1.22.2; python_version < ""3.10""', 'oiffile>=2020.1.18', 'openpyxl>=3.0.7', 'packaging>=22.0', 'pandas>=1.3.0', 'psygnal>=0.3.4', 'pydantic<3,>=1.9.1', 'pygments>=2.12.0', 'qtconsole>=4.7.7', 'requests>=2.25.0', 'scipy>=1.5.4', 'sentry-sdk>=2.4.0', 'six>=1.11.0', 'superqt>=0.4.1', 'sympy>=1.10', 'tifffile>=2020.9.30', 'traceback-with-variables>=2.0.4', 'vispy>=0.14.1', 'xlrd>=1.1.0', 'xlsxwriter>=2.0.0', 'PartSeg[accelerate,pyqt5]; extra == ""all""', 'autodoc-pydantic; extra == ""docs""', 'sphinx!=3.0.0,!=3.5.0; extra == ""docs""', 'sphinx-autodoc-typehints; extra == ""docs""', 'sphinx-qt-documentation; extra == ""docs""', 'PartSeg[pyinstaller_base,pyqt5]; extra == ""pyinstaller""', 'PartSeg[accelerate]; extra == ""pyinstaller-base""', 'PyInstaller; extra == ""pyinstaller-base""', 'pydantic; extra == ""pyinstaller-base""', 'PartSeg[pyqt5]; extra == ""pyqt""', 'PyQt5!=5.15.0,>=5.12.3; extra == ""pyqt5""', 'napari[pyqt5]; extra == ""pyqt5""', 'PyQt6; extra == ""pyqt6""', 'napari[pyqt6]>=0.5.0; extra == ""pyqt6""', 'PartSeg[pyside2]; extra == ""pyside""', 'PySide2!=5.15.0,>=5.12.3; extra == ""pyside2""', 'napari[pyside]; extra == ""pyside2""', 'PySide6; extra == ""pyside6""', 'napari[pyside6_experimental]>=0.5.0; extra == ""pyside6""', 'coverage; extra == ""test""', 'lxml[html_clean]; extra == ""test""', 'pytest>=7.0.0; extra == ""test""', 'pytest-qt; extra == ""test""', 'pytest-timeout; extra == ""test""', 'scikit-image; extra == ""test""', 'pytest; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'lxml; extra == ""testing""']","# PartSeg

![Contributions](https://img.shields.io/badge/Contributions-Welcome-brightgreen.svg)
![Tests](https://github.com/4DNucleome/PartSeg/workflows/Tests/badge.svg?branch=develop)
[![PyPI version](https://badge.fury.io/py/PartSeg.svg)](https://badge.fury.io/py/PartSeg)
[![Anaconda version](https://anaconda.org/conda-forge/partseg/badges/version.svg)](https://anaconda.org/conda-forge/partseg)
[![Python Version](https://img.shields.io/pypi/pyversions/partseg.svg)](https://pypi.org/project/partseg)
[![Documentation Status](https://readthedocs.org/projects/partseg/badge/?version=latest)](https://partseg.readthedocs.io/en/latest/?badge=latest)
[![Azure Pipelines Build Status](https://dev.azure.com/PartSeg/PartSeg/_apis/build/status/4DNucleome.PartSeg?branchName=develop)](https://dev.azure.com/PartSeg/PartSeg/_build/latest?definitionId=1&branchName=develop)
[![DOI](https://zenodo.org/badge/166421141.svg)](https://zenodo.org/badge/latestdoi/166421141)
[![Publication DOI](https://img.shields.io/badge/Publication%20DOI-10.1186%2Fs12859--021--03984--1-blue)](https://doi.org/10.1186/s12859-021-03984-1)
[![Licence: BSD3](https://img.shields.io/github/license/4DNucleome/PartSeg)](https://github.com/4DNucleome/PartSeg/blob/master/License.txt)
[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)
[![Code Style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/charliermarsh/ruff/main/assets/badge/v1.json)](https://github.com/charliermarsh/ruff)
[![CodeQL](https://github.com/4DNucleome/PartSeg/actions/workflows/codeql-analysis.yml/badge.svg?branch=develop)](https://github.com/4DNucleome/PartSeg/actions/workflows/codeql-analysis.yml)
[![Codacy Badge](https://app.codacy.com/project/badge/Grade/f9b0f1eb2c92486d9efd99ed5b2ef326)](https://www.codacy.com/gh/4DNucleome/PartSeg/dashboard?utm_source=github.com&utm_medium=referral&utm_content=4DNucleome/PartSeg&utm_campaign=Badge_Grade)
[![codecov](https://codecov.io/gh/4DNucleome/PartSeg/branch/develop/graph/badge.svg?token=nbAbkOAe1C)](https://codecov.io/gh/4DNucleome/PartSeg)
[![DeepSource](https://deepsource.io/gh/4DNucleome/PartSeg.svg/?label=active+issues&show_trend=true&token=RuuHPIzqyqGaU-bKtOKPFWTg)](https://deepsource.io/gh/4DNucleome/PartSeg/?ref=repository-badge)

PartSeg is a GUI and a library for segmentation algorithms. PartSeg also provide napari plugins for IO and labels measurement.

This application is designed to help biologist with segmentation based on threshold and connected components.

![interface](https://raw.githubusercontent.com/4DNucleome/PartSeg/master/images/roi_analysis.png)

## Tutorials

- Tutorial: **Chromosome 1 (as gui)** [link](https://github.com/4DNucleome/PartSeg/blob/master/tutorials/tutorial-chromosome-1/tutorial-chromosome1_16.md)
- Data for chromosome 1 tutorial [link](https://4dnucleome.cent.uw.edu.pl/PartSeg/Downloads/PartSeg_samples.zip)
- Tutorial: **Different neuron types (as library)** [link](https://github.com/4DNucleome/PartSeg/blob/master/tutorials/tutorial_neuron_types/Neuron_types_example.ipynb)

## Installation

- From binaries:

  - [Windows](https://github.com/4DNucleome/PartSeg/releases/download/v0.16.3/PartSeg-0.16.3-windows.zip) (build on Windows 10)
  - [Linux](https://github.com/4DNucleome/PartSeg/releases/download/v0.16.3/PartSeg-0.16.3-linux.zip) (build on Ubuntu 20.04)
  - [macOS](https://github.com/4DNucleome/PartSeg/releases/download/v0.16.3/PartSeg-0.16.3-macos.zip) (build on macOS 13)
  - [macOS arm](https://github.com/4DNucleome/PartSeg/releases/download/v0.16.3/PartSeg-0.16.3-macos-arm64.zip) (build on macOS 14)
    There are reported problems with permissions systems on macOS. If you have a problem with starting the application, please try to run it from the terminal.

- With pip:

  - From pypi: `pip install PartSeg[all]`
  - From repository: `pip install git+https://github.com/4DNucleome/PartSeg.git`

- With conda:

  - `conda install -c conda-forge partseg`
  - `mamba install -c conda-forge partseg` - As mamba is faster than conda

- With napari:

  If you do not know how to setup python environment on your system you may use [napari](https://napari.org/) to run PartSeg.
  It is a GUI for scientific image analysis. PartSeg is also a plugin for napari so could be installed from plugin dialog.
  To install napari bundle please download it [napari bundle](https://github.com/napari/napari/releases/latest)
  and follow [installation instructions](https://napari.org/stable/tutorials/fundamentals/installation.html#install-as-a-bundled-app).

Installation troubleshooting information could be found in wiki: [wiki](https://github.com/4DNucleome/PartSeg/wiki/Instalation-troubleshoot).
If this information does not solve problem you can open [issue](https://github.com/4DNucleome/PartSeg/issues).

### Qt 6 support

PartSeg development branch support (and stable since 0.15.0) has experimental Qt6 support. Test are passing but not whole GUI code is covered by tests. Inf you Find any problem please report it.

## Running

If you downloaded binaries, run the `PartSeg` (or `PartSeg.exe` for Windows) file inside the `PartSeg` folder

If you installed from repository or from pip, you can run it with `PartSeg` command or `python -m PartSeg`.
First option does not work on Windows.

PartSeg export few commandline options:

- `--no_report` - disable error reporting
- `--no_dialog` - disable error reporting and error dialog. Use only when running from terminal.
- `roi` - skip launcher and start *ROI analysis* gui
- `mask`- skip launcher and start *ROI mask* gui

## napari plugin

PartSeg provides napari plugins for io to allow reading projects format in napari viewer.

## Save Format

Saved projects are tar files compressed with gzip or bz2.

Metadata is saved in data.json file (in json format).
Images/masks are saved as \*.npy (numpy array format).

## Interface

Launcher. Choose the program that you will launch:

![launcher](https://raw.githubusercontent.com/4DNucleome/PartSeg/master/images/launcher.png)

Main window of Segmentation Analysis:

![interface](https://raw.githubusercontent.com/4DNucleome/PartSeg/master/images/roi_analysis.png)

Main window of Segmentation Analysis with view on measurement result:

![interface](https://raw.githubusercontent.com/4DNucleome/PartSeg/master/images/roi_analysis2.png)

Window for creating a set of measurements:

![statistics](https://raw.githubusercontent.com/4DNucleome/PartSeg/master/images/measurement.png)

Main window of Mask Segmentation:

![mask interface](https://raw.githubusercontent.com/4DNucleome/PartSeg/master/images/roi_mask.png)

## Laboratory

Laboratory of Functional and Structural Genomics
[http://4dnucleome.cent.uw.edu.pl/](http://4dnucleome.cent.uw.edu.pl/)

## Cite as

Bokota, G., Sroka, J., Basu, S. et al. PartSeg: a tool for quantitative feature extraction
from 3D microscopy images for dummies. BMC Bioinformatics 22, 72 (2021).
[https://doi.org/10.1186/s12859-021-03984-1](https://doi.org/10.1186/s12859-021-03984-1)


## Changelog

All notable changes to this project will be documented in this file.

### 0.16.3 - 2025-07-10

#### ð Bug Fixes

- Do not use default parameters in default leaf ([#1283](https://github.com/4DNucleome/PartSeg/pull/1283))

#### ð§ª Testing

- [Automatic] Constraints upgrades: `napari`, `numpy`, `pydantic`, `sentry-sdk`, `tifffile`, `vispy` ([#1273](https://github.com/4DNucleome/PartSeg/pull/1273))
- [Automatic] Constraints upgrades: `h5py`, `ipython`, `magicgui`, `numpy`, `pandas`, `pydantic`, `requests`, `sentry-sdk`, `superqt`, `tifffile`, `xlrd` ([#1276](https://github.com/4DNucleome/PartSeg/pull/1276))
- [Automatic] Constraints upgrades: `numpy`, `pygments`, `scipy`, `simpleitk`, `superqt`, `xlsxwriter` ([#1278](https://github.com/4DNucleome/PartSeg/pull/1278))
- [Automatic] Constraints upgrades: `ipython`, `napari`, `partsegcore-compiled-backend`, `psygnal`, `sentry-sdk` ([#1281](https://github.com/4DNucleome/PartSeg/pull/1281))

#### âï¸ Miscellaneous Tasks

- Block `sentry==3.0.0a1` for pre-tests ([#1272](https://github.com/4DNucleome/PartSeg/pull/1272))
- Add fallback version for `setuptools_scm` ([#1271](https://github.com/4DNucleome/PartSeg/pull/1271))
- [pre-commit.ci] pre-commit autoupdate ([#1270](https://github.com/4DNucleome/PartSeg/pull/1270))
- Use ubuntu 22.04 when building pyinstaller bundle ([#1275](https://github.com/4DNucleome/PartSeg/pull/1275))
- [pre-commit.ci] pre-commit autoupdate ([#1274](https://github.com/4DNucleome/PartSeg/pull/1274))
- [pre-commit.ci] pre-commit autoupdate ([#1277](https://github.com/4DNucleome/PartSeg/pull/1277))
- Block sentry alpha 3.0.0a1 and 3.0.0a2 ([#1279](https://github.com/4DNucleome/PartSeg/pull/1279))
- Block `pytest-qt==4.5.0` (for `pyside2` compatibility) ([#1282](https://github.com/4DNucleome/PartSeg/pull/1282))
- [pre-commit.ci] pre-commit autoupdate ([#1280](https://github.com/4DNucleome/PartSeg/pull/1280))
- Migrate Windows images from 2019 to 2022 in Azure Pipelines and GitHub Actions ([#1284](https://github.com/4DNucleome/PartSeg/pull/1284))

### 0.16.2 - 2025-05-12

#### ð§ª Testing

- [Automatic] Constraints upgrades: `numpy`, `partsegcore-compiled-backend`, `tifffile` ([#1253](https://github.com/4DNucleome/PartSeg/pull/1253))
- [Automatic] Constraints upgrades: `imagecodecs`, `ipython`, `pydantic`, `sentry-sdk`, `superqt`, `tifffile` ([#1255](https://github.com/4DNucleome/PartSeg/pull/1255))
- [Automatic] Constraints upgrades: `ipython`, `napari`, `numpy`, `packaging`, `pydantic`, `sentry-sdk`, `simpleitk`, `sympy`, `xlsxwriter` ([#1266](https://github.com/4DNucleome/PartSeg/pull/1266))
- [Automatic] Constraints upgrades: `oiffile`, `psygnal`, `scipy`, `sentry-sdk`, `tifffile` ([#1267](https://github.com/4DNucleome/PartSeg/pull/1267))

#### âï¸ Miscellaneous Tasks

- [pre-commit.ci] pre-commit autoupdate ([#1251](https://github.com/4DNucleome/PartSeg/pull/1251))
- Prepare for napari 0.6.0 deprecations ([#1256](https://github.com/4DNucleome/PartSeg/pull/1256))
- [pre-commit.ci] pre-commit autoupdate ([#1254](https://github.com/4DNucleome/PartSeg/pull/1254))
- [pre-commit.ci] pre-commit autoupdate ([#1259](https://github.com/4DNucleome/PartSeg/pull/1259))
- Update workflow to use Ubuntu 22.04 instead of 20.04 ([#1261](https://github.com/4DNucleome/PartSeg/pull/1261))
- [pre-commit.ci] pre-commit autoupdate ([#1260](https://github.com/4DNucleome/PartSeg/pull/1260))
- Try to fix Upgrade dependencies workflow part 2 ([#1265](https://github.com/4DNucleome/PartSeg/pull/1265))
- [pre-commit.ci] pre-commit autoupdate ([#1268](https://github.com/4DNucleome/PartSeg/pull/1268))

#### ð¡ï¸ Security

- *(deps)* Bump peter-evans/create-pull-request from 6 to 7 ([#1262](https://github.com/4DNucleome/PartSeg/pull/1262))
- *(deps)* Bump codecov/codecov-action from 4 to 5 ([#1263](https://github.com/4DNucleome/PartSeg/pull/1263))

### 0.16.1 - 2025-03-10

#### ð Bug Fixes

- Fix rendering of alternative representation if there are more components in the alternative representation than in ROI ([#1240](https://github.com/4DNucleome/PartSeg/pull/1240))
- Enable czifile workaround for 2019.7.2.1 ([#1246](https://github.com/4DNucleome/PartSeg/pull/1246))

#### ð§ª Testing

- [Automatic] Constraints upgrades: `ipython`, `magicgui`, `numpy`, `partsegcore-compiled-backend`, `pydantic` ([#1231](https://github.com/4DNucleome/PartSeg/pull/1231))
- [Automatic] Constraints upgrades: `imagecodecs` ([#1233](https://github.com/4DNucleome/PartSeg/pull/1233))
- [Automatic] Constraints upgrades: `oiffile`, `pygments`, `scipy`, `superqt` ([#1234](https://github.com/4DNucleome/PartSeg/pull/1234))
- [Automatic] Constraints upgrades: `imageio`, `napari`, `numpy`, `partsegcore-compiled-backend`, `pydantic`, `pygments`, `scipy`, `sentry-sdk`, `simpleitk`, `tifffile`, `xlsxwriter` ([#1236](https://github.com/4DNucleome/PartSeg/pull/1236))
- [Automatic] Constraints upgrades: `ipython`, `xlsxwriter` ([#1239](https://github.com/4DNucleome/PartSeg/pull/1239))
- [Automatic] Constraints upgrades: `numpy`, `partsegcore-compiled-backend`, `psygnal`, `qtpy`, `scipy`, `sentry-sdk` ([#1241](https://github.com/4DNucleome/PartSeg/pull/1241))
- [Automatic] Constraints upgrades: `czifile`, `h5py`, `ipython`, `qtawesome`, `sentry-sdk`, `tifffile`, `traceback-with-variables` ([#1247](https://github.com/4DNucleome/PartSeg/pull/1247))

#### âï¸ Miscellaneous Tasks

- [pre-commit.ci] pre-commit autoupdate ([#1232](https://github.com/4DNucleome/PartSeg/pull/1232))
- [pre-commit.ci] pre-commit autoupdate ([#1235](https://github.com/4DNucleome/PartSeg/pull/1235))
- [pre-commit.ci] pre-commit autoupdate ([#1237](https://github.com/4DNucleome/PartSeg/pull/1237))
- Drop python 3.9 tests for napari repository ([#1244](https://github.com/4DNucleome/PartSeg/pull/1244))
- Block ipykernel 7.0.0a1 ([#1248](https://github.com/4DNucleome/PartSeg/pull/1248))
- [pre-commit.ci] pre-commit autoupdate ([#1242](https://github.com/4DNucleome/PartSeg/pull/1242))
- Switch to `get_qapp` from `get_app` to handle napari deprecation ([#1249](https://github.com/4DNucleome/PartSeg/pull/1249))

### 0.16.0 - 2024-12-21

#### ð Features

- Allow set units that will be used for load/save data using PartSeg as napari plugin ([#1228](https://github.com/4DNucleome/PartSeg/pull/1228))
- Show filename when importing with PartSeg in napari ([#1226](https://github.com/4DNucleome/PartSeg/pull/1226))

#### ð Bug Fixes

- Fix error when image changed during segmentation ([#1218](https://github.com/4DNucleome/PartSeg/pull/1218))
- Fix pre release tests ([#1219](https://github.com/4DNucleome/PartSeg/pull/1219))
- Drop imagej LUTs of size `24*x` ([#1227](https://github.com/4DNucleome/PartSeg/pull/1227))

#### ð§ª Testing

- [Automatic] Constraints upgrades: `h5py`, `imageio`, `ipython`, `napari`, `numpy`, `sentry-sdk` ([#1201](https://github.com/4DNucleome/PartSeg/pull/1201))
- [Automatic] Constraints upgrades: `sentry-sdk` ([#1214](https://github.com/4DNucleome/PartSeg/pull/1214))
- [Automatic] Constraints upgrades: `ipython`, `traceback-with-variables` ([#1221](https://github.com/4DNucleome/PartSeg/pull/1221))
- [Automatic] Constraints upgrades: `numpy`, `packaging`, `pydantic`, `qtconsole`, `qtpy`, `sentry-sdk`, `traceback-with-variables` ([#1223](https://github.com/4DNucleome/PartSeg/pull/1223))
- [Automatic] Constraints upgrades: `imageio`, `ipython`, `pydantic` ([#1225](https://github.com/4DNucleome/PartSeg/pull/1225))
- [Automatic] Constraints upgrades: `napari`, `numpy`, `pydantic`, `sentry-sdk`, `six`, `superqt`, `tifffile` ([#1229](https://github.com/4DNucleome/PartSeg/pull/1229))

#### âï¸ Miscellaneous Tasks

- Stop using mambaforge in tests ([#1203](https://github.com/4DNucleome/PartSeg/pull/1203))
- [pre-commit.ci] pre-commit autoupdate ([#1202](https://github.com/4DNucleome/PartSeg/pull/1202))
- [pre-commit.ci] pre-commit autoupdate ([#1204](https://github.com/4DNucleome/PartSeg/pull/1204))
- Remove defining default version of language in pre-commit configuration ([#1208](https://github.com/4DNucleome/PartSeg/pull/1208))
- [pre-commit.ci] pre-commit autoupdate ([#1209](https://github.com/4DNucleome/PartSeg/pull/1209))
- Drop python 3.8 ([#1206](https://github.com/4DNucleome/PartSeg/pull/1206))
- Use `PublishPipelineArtifact` in place of `PublishBuildArtifacts` to reduce CI fragility ([#1213](https://github.com/4DNucleome/PartSeg/pull/1213))
- Update CI configuration to use more modern OS and python versions ([#1207](https://github.com/4DNucleome/PartSeg/pull/1207))
- Fix `upgrade-dependencies.yaml`docs constraints ([#1215](https://github.com/4DNucleome/PartSeg/pull/1215))
- [pre-commit.ci] pre-commit autoupdate ([#1216](https://github.com/4DNucleome/PartSeg/pull/1216))
- Add changelog 0.16.0a1
- [pre-commit.ci] pre-commit autoupdate ([#1222](https://github.com/4DNucleome/PartSeg/pull/1222))
- [pre-commit.ci] pre-commit autoupdate ([#1230](https://github.com/4DNucleome/PartSeg/pull/1230))

### 0.15.4 - 2024-09-27

#### ð Features

- Add preview of image metadata ([#1154](https://github.com/4DNucleome/PartSeg/pull/1154))
- Add option to combine channels using sum and max ([#1159](https://github.com/4DNucleome/PartSeg/pull/1159))
- Add metadata viewer as napari widget ([#1195](https://github.com/4DNucleome/PartSeg/pull/1195))
- Read channel colors from `*.czi` metadata ([#1198](https://github.com/4DNucleome/PartSeg/pull/1198))
- Use image color when add layer to napari ([#1200](https://github.com/4DNucleome/PartSeg/pull/1200))

#### ð Bug Fixes

- Fix selection of custom label colors for napari 0.5.0 ([#1138](https://github.com/4DNucleome/PartSeg/pull/1138))
- Add pint call to enforce initialization of unit registry ([#1146](https://github.com/4DNucleome/PartSeg/pull/1146))
- Workaround for lack of zsd support in czifile ([#1142](https://github.com/4DNucleome/PartSeg/pull/1142))
- Fix preparing data for `mahotas.haralick` to avoid overflow problem ([#1150](https://github.com/4DNucleome/PartSeg/pull/1150))
- Fix `use_convex` type from `int` to `bool` for segmentation algorithms ([#1152](https://github.com/4DNucleome/PartSeg/pull/1152))
- Prevent propagation of decreasing contrast limits set by user ([#1166](https://github.com/4DNucleome/PartSeg/pull/1166))
- Prevent error on searching component if there is no component ([#1167](https://github.com/4DNucleome/PartSeg/pull/1167))
- Fix checking if channel requested by MeasurementProfile exists ([#1165](https://github.com/4DNucleome/PartSeg/pull/1165))
- Fix trying to access to just deleted measurement profile from edit window. ([#1168](https://github.com/4DNucleome/PartSeg/pull/1168))
- Fix bug in code for checking for survey file ([#1174](https://github.com/4DNucleome/PartSeg/pull/1174))
- Fix plugin discovery in bundle to register them in napari viewer ([#1175](https://github.com/4DNucleome/PartSeg/pull/1175))
- Fix problem with setting range of auto-generated widget ([#1187](https://github.com/4DNucleome/PartSeg/pull/1187))
- Fix reading channel names from single channel czi files ([#1194](https://github.com/4DNucleome/PartSeg/pull/1194))

#### ð Refactor

- Make warnings error in tests ([#1192](https://github.com/4DNucleome/PartSeg/pull/1192))
- Merge all channel-specific attributes of the Image class ([#1191](https://github.com/4DNucleome/PartSeg/pull/1191))

#### ð Documentation

- Change homepage URL ([#1139](https://github.com/4DNucleome/PartSeg/pull/1139))
- Add link for download macOS arm bundle ([#1140](https://github.com/4DNucleome/PartSeg/pull/1140))
- Add changelog for 0.15.4 release
- Update changelog ([#1176](https://github.com/4DNucleome/PartSeg/pull/1176))

#### ð§ª Testing

- [Automatic] Constraints upgrades: `napari`, `sentry-sdk`, `sympy` ([#1128](https://github.com/4DNucleome/PartSeg/pull/1128))
- [Automatic] Constraints upgrades: `mahotas`, `numpy`, `sentry-sdk`, `sympy` ([#1145](https://github.com/4DNucleome/PartSeg/pull/1145))
- [Automatic] Constraints upgrades: `numpy`, `tifffile` ([#1163](https://github.com/4DNucleome/PartSeg/pull/1163))
- [Automatic] Constraints upgrades: `napari`, `sentry-sdk`, `tifffile` ([#1169](https://github.com/4DNucleome/PartSeg/pull/1169))
- [Automatic] Constraints upgrades: `magicgui`, `sentry-sdk` ([#1172](https://github.com/4DNucleome/PartSeg/pull/1172))
- [Automatic] Constraints upgrades: `sympy`, `tifffile` ([#1177](https://github.com/4DNucleome/PartSeg/pull/1177))
- [Automatic] Constraints upgrades: `imageio`, `napari`, `numpy` ([#1180](https://github.com/4DNucleome/PartSeg/pull/1180))
- Constraints upgrades: `sentry-sdk` and fix tests ([#1182](https://github.com/4DNucleome/PartSeg/pull/1182))
- `napari==0.5.3` related fixes, Constraints upgrades: `imageio`, `ipython`, `numpy`, `qtconsole`, `scipy`, `simpleitk`, `tifffile` ([#1183](https://github.com/4DNucleome/PartSeg/pull/1183))
- [Automatic] Constraints upgrades: `numpy`, `pydantic` ([#1188](https://github.com/4DNucleome/PartSeg/pull/1188))
- [Automatic] Constraints upgrades: `imagecodecs`, `pandas`, `pydantic`, `sentry-sdk`, `sympy`, `tifffile` ([#1190](https://github.com/4DNucleome/PartSeg/pull/1190))

#### âï¸ Miscellaneous Tasks

- Speedup tests by use `tox-uv` ([#1141](https://github.com/4DNucleome/PartSeg/pull/1141))
- Get additional dict from PR branch for checking PR title ([#1144](https://github.com/4DNucleome/PartSeg/pull/1144))
- Relax numpy constraint ([#1143](https://github.com/4DNucleome/PartSeg/pull/1143))
- Allow to skip spellchecking PR title ([#1147](https://github.com/4DNucleome/PartSeg/pull/1147))
- [pre-commit.ci] pre-commit autoupdate ([#1149](https://github.com/4DNucleome/PartSeg/pull/1149))
- Create only archive with version in name on azures pipeline ([#1151](https://github.com/4DNucleome/PartSeg/pull/1151))
- Fix tests for napari from repository ([#1148](https://github.com/4DNucleome/PartSeg/pull/1148))
- Use python 3.11 to determine updated packages in PR description ([#1160](https://github.com/4DNucleome/PartSeg/pull/1160))
- [pre-commit.ci] pre-commit autoupdate ([#1164](https://github.com/4DNucleome/PartSeg/pull/1164))
- [pre-commit.ci] pre-commit autoupdate ([#1170](https://github.com/4DNucleome/PartSeg/pull/1170))
- Disable thumbnail generation in napari layer as it is fragile and not used ([#1171](https://github.com/4DNucleome/PartSeg/pull/1171))
- [pre-commit.ci] pre-commit autoupdate ([#1173](https://github.com/4DNucleome/PartSeg/pull/1173))
- [pre-commit.ci] pre-commit autoupdate ([#1178](https://github.com/4DNucleome/PartSeg/pull/1178))
- Fix call of logger to properly pass arguments to messages ([#1179](https://github.com/4DNucleome/PartSeg/pull/1179))
- Fix coverage files upload by enable hidden files upload ([#1186](https://github.com/4DNucleome/PartSeg/pull/1186))
- [pre-commit.ci] pre-commit autoupdate ([#1184](https://github.com/4DNucleome/PartSeg/pull/1184))
- Use PyQt6 in pre-tests ([#1196](https://github.com/4DNucleome/PartSeg/pull/1196))
- Add missed code from #1191 ([#1197](https://github.com/4DNucleome/PartSeg/pull/1197))
- [pre-commit.ci] pre-commit autoupdate ([#1189](https://github.com/4DNucleome/PartSeg/pull/1189))
- Auto add ""skip check PR title"" label in update dependencies PR ([#1199](https://github.com/4DNucleome/PartSeg/pull/1199))

#### Build

- Remove PyOpenGL-accelerate from dependencies because of numpy incompatibility ([#1155](https://github.com/4DNucleome/PartSeg/pull/1155))
- Update install constraints on numpy and qt packages ([#1157](https://github.com/4DNucleome/PartSeg/pull/1157))
- Enforce napari 0.5.0 for Qt6 bindings ([#1161](https://github.com/4DNucleome/PartSeg/pull/1161))
- Require napari>=0.5.0 only for python 3.9+ ([#1162](https://github.com/4DNucleome/PartSeg/pull/1162))

### 0.15.3 - 2024-07-08

#### ð Features

- Pydantic 2 compatibility ([#1084](https://github.com/4DNucleome/PartSeg/pull/1084))

#### ð Bug Fixes

- Fix rendering icons in colormap preview ([#1040](https://github.com/4DNucleome/PartSeg/pull/1040))
- Fix test for validation length of message for sentry-sdk 2.0 release ([#1098](https://github.com/4DNucleome/PartSeg/pull/1098))
- When fix reader check lowercase extension for validate compatibility ([#1097](https://github.com/4DNucleome/PartSeg/pull/1097))
- Fix napari 0.5.0 compatibility ([#1116](https://github.com/4DNucleome/PartSeg/pull/1116))

#### ð Refactor

- Fix Qt flags ([#1041](https://github.com/4DNucleome/PartSeg/pull/1041))
- Fix qt flags in roi mask code ([#1042](https://github.com/4DNucleome/PartSeg/pull/1042))
- Fix qt flags in roi analysis ([#1043](https://github.com/4DNucleome/PartSeg/pull/1043))
- Migrate from setup.cfg to `pyproject.toml` ([#1070](https://github.com/4DNucleome/PartSeg/pull/1070))

#### ð Documentation

- Allow to use newer release of build docs dependencies ([#1057](https://github.com/4DNucleome/PartSeg/pull/1057))

#### ð§ª Testing

- [Automatic] Constraints upgrades: `imagecodecs`, `imageio`, `ipykernel`, `ipython`, `numpy`, `oiffile`, `pandas`, `psygnal`, `pyinstaller`, `qtconsole`, `qtpy`, `sentry-sdk`, `simpleitk`, `superqt`, `tifffile`, `xlsxwriter` ([#1020](https://github.com/4DNucleome/PartSeg/pull/1020))
- [Automatic] Constraints upgrades: `h5py`, `imageio`, `ipython`, `numpy`, `packaging`, `pydantic`, `pyinstaller`, `pyqt5`, `scipy`, `sentry-sdk`, `superqt`, `tifffile`, `xlsxwriter` ([#1027](https://github.com/4DNucleome/PartSeg/pull/1027))
- [Automatic] Constraints upgrades: `imageio`, `magicgui`, `xlsxwriter` ([#1030](https://github.com/4DNucleome/PartSeg/pull/1030))
- [Automatic] Constraints upgrades: `ipykernel`, `pandas`, `qtpy` ([#1032](https://github.com/4DNucleome/PartSeg/pull/1032))
- [Automatic] Constraints upgrades: `imageio`, `ipykernel`, `ipython`, `numpy`, `pandas`, `psygnal`, `pygments`, `pyinstaller`, `qtconsole`, `scipy`, `sentry-sdk`, `simpleitk` ([#1035](https://github.com/4DNucleome/PartSeg/pull/1035))
- [Automatic] Constraints upgrades: `imagecodecs`, `imageio`, `ipykernel`, `magicgui`, `pandas`, `pyinstaller`, `qtawesome`, `sentry-sdk`, `tifffile` ([#1048](https://github.com/4DNucleome/PartSeg/pull/1048))
- [Automatic] Constraints upgrades: `ipykernel`, `numpy`, `pandas`, `partsegcore-compiled-backend`, `pydantic`, `scipy`, `sentry-sdk` ([#1058](https://github.com/4DNucleome/PartSeg/pull/1058))
- Improve test of PartSegImage ([#1072](https://github.com/4DNucleome/PartSeg/pull/1072))
- Improve test suite for `PartSegCore` ([#1077](https://github.com/4DNucleome/PartSeg/pull/1077))
- [Automatic] Constraints upgrades: `imageio`, `ipykernel`, `local-migrator`, `napari`, `numpy`, `pandas`, `partsegcore-compiled-backend`, `pyinstaller`, `sentry-sdk`, `tifffile`, `vispy`, `xlsxwriter` ([#1063](https://github.com/4DNucleome/PartSeg/pull/1063))
- [Automatic] Constraints upgrades: `magicgui`, `packaging`, `psygnal`, `pyinstaller`, `sentry-sdk`, `superqt` ([#1086](https://github.com/4DNucleome/PartSeg/pull/1086))
- [Automatic] Constraints upgrades: `psygnal`, `pydantic`, `sentry-sdk`, `vispy` ([#1090](https://github.com/4DNucleome/PartSeg/pull/1090))
- [Automatic] Constraints upgrades: `h5py`, `ipykernel`, `mahotas`, `pandas`, `psygnal`, `pydantic`, `pyinstaller`, `qtawesome`, `scipy`, `sentry-sdk`, `superqt` ([#1092](https://github.com/4DNucleome/PartSeg/pull/1092))
- [Automatic] Constraints upgrades: `imageio`, `tifffile` ([#1100](https://github.com/4DNucleome/PartSeg/pull/1100))
- [Automatic] Constraints upgrades: `pydantic`, `sentry-sdk`, `superqt`, `tifffile` ([#1102](https://github.com/4DNucleome/PartSeg/pull/1102))
- [Automatic] Constraints upgrades: `psygnal`, `pygments`, `qtconsole`, `sentry-sdk`, `superqt`, `tifffile` ([#1105](https://github.com/4DNucleome/PartSeg/pull/1105))
- [Automatic] Constraints upgrades: `imagecodecs`, `magicgui`, `oiffile`, `openpyxl`, `packaging`, `pydantic`, `pyinstaller`, `requests`, `scipy`, `sentry-sdk`, `superqt`, `sympy`, `tifffile`, `vispy` ([#1107](https://github.com/4DNucleome/PartSeg/pull/1107))
- [Automatic] Constraints upgrades: `pydantic` ([#1112](https://github.com/4DNucleome/PartSeg/pull/1112))

#### âï¸ Miscellaneous Tasks

- [pre-commit.ci] pre-commit autoupdate ([#1019](https://github.com/4DNucleome/PartSeg/pull/1019))
- Remove plugin page preview as it is no longer maintained ([#1021](https://github.com/4DNucleome/PartSeg/pull/1021))
- [pre-commit.ci] pre-commit autoupdate ([#1022](https://github.com/4DNucleome/PartSeg/pull/1022))
- [pre-commit.ci] pre-commit autoupdate ([#1026](https://github.com/4DNucleome/PartSeg/pull/1026))
- [pre-commit.ci] pre-commit autoupdate ([#1031](https://github.com/4DNucleome/PartSeg/pull/1031))
- [pre-commit.ci] pre-commit autoupdate ([#1034](https://github.com/4DNucleome/PartSeg/pull/1034))
- Use new semgrep configuration ([#1039](https://github.com/4DNucleome/PartSeg/pull/1039))
- Upload raw coverage information ([#1044](https://github.com/4DNucleome/PartSeg/pull/1044))
- [pre-commit.ci] pre-commit autoupdate ([#1036](https://github.com/4DNucleome/PartSeg/pull/1036))
- Run coverage upload in separate steep ([#1053](https://github.com/4DNucleome/PartSeg/pull/1053))
- Generate local report in `Tests` workflow and use proper script for fetch report ([#1054](https://github.com/4DNucleome/PartSeg/pull/1054))
- Move coverage back to main workflow ([#1055](https://github.com/4DNucleome/PartSeg/pull/1055))
- [pre-commit.ci] pre-commit autoupdate ([#1056](https://github.com/4DNucleome/PartSeg/pull/1056))
- [pre-commit.ci] pre-commit autoupdate ([#1059](https://github.com/4DNucleome/PartSeg/pull/1059))
- Update `actions/upload-artifact` and `actions/download-artifact` from 3 to 4 ([#1062](https://github.com/4DNucleome/PartSeg/pull/1062))
- [pre-commit.ci] pre-commit autoupdate ([#1064](https://github.com/4DNucleome/PartSeg/pull/1064))
- Group actions update ([#1065](https://github.com/4DNucleome/PartSeg/pull/1065))
- [pre-commit.ci] pre-commit autoupdate ([#1068](https://github.com/4DNucleome/PartSeg/pull/1068))
- Remove requirement of 2 builds upload to codecov.io ([#1073](https://github.com/4DNucleome/PartSeg/pull/1073))
- Re add tests to coverage report ([#1074](https://github.com/4DNucleome/PartSeg/pull/1074))
- Switch from setup.cfg to pyproject.toml in workflows ([#1076](https://github.com/4DNucleome/PartSeg/pull/1076))
- Fix compiling pyinstaller pre-deps ([#1075](https://github.com/4DNucleome/PartSeg/pull/1075))
- Add codespell to pre-commit and fix pointed bugs ([#1078](https://github.com/4DNucleome/PartSeg/pull/1078))
- Add new ruff rules and apply them ([#1079](https://github.com/4DNucleome/PartSeg/pull/1079))
- [pre-commit.ci] pre-commit autoupdate ([#1080](https://github.com/4DNucleome/PartSeg/pull/1080))
- [pre-commit.ci] pre-commit autoupdate ([#1081](https://github.com/4DNucleome/PartSeg/pull/1081))
- Fix upgrade depenecies workflow ([#1083](https://github.com/4DNucleome/PartSeg/pull/1083))
- Block using `mpmath==1.4.0a0` and `sentry-sdk` 2.0.0a1/a2 in pre-test ([#1085](https://github.com/4DNucleome/PartSeg/pull/1085))
- [pre-commit.ci] pre-commit autoupdate ([#1089](https://github.com/4DNucleome/PartSeg/pull/1089))
- Fix jupyter failing test by using constraints ([#1093](https://github.com/4DNucleome/PartSeg/pull/1093))
- [pre-commit.ci] pre-commit autoupdate ([#1091](https://github.com/4DNucleome/PartSeg/pull/1091))
- [pre-commit.ci] pre-commit autoupdate ([#1096](https://github.com/4DNucleome/PartSeg/pull/1096))
- Add python 3.12 testing ([#1087](https://github.com/4DNucleome/PartSeg/pull/1087))
- Exclude pyside2 on python 3.11 and 3.12 from testing ([#1099](https://github.com/4DNucleome/PartSeg/pull/1099))
- [pre-commit.ci] pre-commit autoupdate ([#1101](https://github.com/4DNucleome/PartSeg/pull/1101))
- [pre-commit.ci] pre-commit autoupdate ([#1103](https://github.com/4DNucleome/PartSeg/pull/1103))
- Bump macos runners to macos-13 (both azure and GHA) ([#1113](https://github.com/4DNucleome/PartSeg/pull/1113))
- [pre-commit.ci] pre-commit autoupdate ([#1108](https://github.com/4DNucleome/PartSeg/pull/1108))
- Remove pyqt5 from constraints ([#1118](https://github.com/4DNucleome/PartSeg/pull/1118))
- Add workflow for releases from GHA ([#1117](https://github.com/4DNucleome/PartSeg/pull/1117))
- Add actionlint to CI to early prevent bug in github workflows ([#1119](https://github.com/4DNucleome/PartSeg/pull/1119))
- Fix release workflow, by update permissions
- Check if release notes are properly created ([#1122](https://github.com/4DNucleome/PartSeg/pull/1122))
- Proper use enum in checking new version ([#1123](https://github.com/4DNucleome/PartSeg/pull/1123))
- Refactor and simplify menu bar creation, add workaround for macOS numpy problem ([#1124](https://github.com/4DNucleome/PartSeg/pull/1124))
- Simplify release workflow ([#1126](https://github.com/4DNucleome/PartSeg/pull/1126))
- Fix `make_release.yml` to proper detect release, attempt 3 ([#1127](https://github.com/4DNucleome/PartSeg/pull/1127))

#### ð¡ï¸ Security

- *(deps)* Bump actions/checkout from 3 to 4 ([#1029](https://github.com/4DNucleome/PartSeg/pull/1029))
- *(deps)* Bump conda-incubator/setup-miniconda from 2 to 3 ([#1038](https://github.com/4DNucleome/PartSeg/pull/1038))
- *(deps)* Bump aganders3/headless-gui from 1 to 2 ([#1047](https://github.com/4DNucleome/PartSeg/pull/1047))
- *(deps)* Bump actions/checkout from 3 to 4 ([#1045](https://github.com/4DNucleome/PartSeg/pull/1045))
- *(deps)* Bump hynek/build-and-inspect-python-package from 1 to 2 ([#1050](https://github.com/4DNucleome/PartSeg/pull/1050))
- *(deps)* Bump actions/setup-python from 4 to 5 ([#1046](https://github.com/4DNucleome/PartSeg/pull/1046))
- *(deps)* Bump github/codeql-action from 2 to 3 ([#1051](https://github.com/4DNucleome/PartSeg/pull/1051))
- *(deps)* Bump peter-evans/create-pull-request from 5 to 6 ([#1067](https://github.com/4DNucleome/PartSeg/pull/1067))
- *(deps)* Bump codecov/codecov-action from 3 to 4 ([#1066](https://github.com/4DNucleome/PartSeg/pull/1066))

#### Build

- Fix not bundling `Font Awesome 6 Free-Solid-900.otf` file to executable ([#1114](https://github.com/4DNucleome/PartSeg/pull/1114))
- Update readme and release to point to GitHub releases ([#1115](https://github.com/4DNucleome/PartSeg/pull/1115))
- Do not create archive twice when create bundle ([#1120](https://github.com/4DNucleome/PartSeg/pull/1120))
- Enable macOS-arm bundle builds ([#1121](https://github.com/4DNucleome/PartSeg/pull/1121))

### 0.15.2 - 2023-08-28

#### ð Bug Fixes

- Fix range threshold selection of algorithms ([#1009](https://github.com/4DNucleome/PartSeg/pull/1009))
- When run batch check if file extension is supported by loader ([#1016](https://github.com/4DNucleome/PartSeg/pull/1016))
- Do not allow to select and render corrupted batch plans ([#1015](https://github.com/4DNucleome/PartSeg/pull/1015))

#### ð§ª Testing

- [Automatic] Constraints upgrades: `imagecodecs`, `ipykernel`, `magicgui`, `psygnal`, `scipy`, `superqt`, `tifffile` ([#1011](https://github.com/4DNucleome/PartSeg/pull/1011))
- [Automatic] Constraints upgrades: `imageio`, `pyinstaller`, `tifffile` ([#1018](https://github.com/4DNucleome/PartSeg/pull/1018))

#### âï¸ Miscellaneous Tasks

- Use faster version of black ([#1010](https://github.com/4DNucleome/PartSeg/pull/1010))
- [pre-commit.ci] pre-commit autoupdate ([#1013](https://github.com/4DNucleome/PartSeg/pull/1013))

### 0.15.1 - 2023-08-08

#### ð Features

- Allow to save multiple napari image layers to single tiff file ([#1000](https://github.com/4DNucleome/PartSeg/pull/1000))
- Add option to export batch project with data ([#996](https://github.com/4DNucleome/PartSeg/pull/996))

#### ð Bug Fixes

- Fix possible problem of double registration napari plugin in PartSeg bundle ([#974](https://github.com/4DNucleome/PartSeg/pull/974))
- Bump OS versions for part of testing workflows. ([#977](https://github.com/4DNucleome/PartSeg/pull/977))
- Bump os version for main tests workflow. ([#979](https://github.com/4DNucleome/PartSeg/pull/979))
- Ensure that the module `PartSegCore.channel_class` is present in bundle ([#980](https://github.com/4DNucleome/PartSeg/pull/980))
- Lower npe2 schema version to work with older napari version ([#981](https://github.com/4DNucleome/PartSeg/pull/981))
- Generate test report per platform ([#978](https://github.com/4DNucleome/PartSeg/pull/978))
- Importing plugins in bundle keeping proper module names ([#983](https://github.com/4DNucleome/PartSeg/pull/983))
- Fix napari repo workflow ([#985](https://github.com/4DNucleome/PartSeg/pull/985))
- Fix bug in read tiff files with double `Q` in axes but one related to dummy dimension ([#992](https://github.com/4DNucleome/PartSeg/pull/992))
- Fix bug that lead to corrupted state when saving calculation plan to excel file ([#995](https://github.com/4DNucleome/PartSeg/pull/995))
- Enable python 3.11 test on CI, fix minor errors ([#869](https://github.com/4DNucleome/PartSeg/pull/869))

#### ð§ª Testing

- [Automatic] Constraints upgrades: `imageio`, `ipython`, `psygnal`, `scipy`, `sentry-sdk` ([#975](https://github.com/4DNucleome/PartSeg/pull/975))
- [Automatic] Constraints upgrades: `h5py`, `imagecodecs`, `imageio`, `ipykernel`, `napari`, `numpy`, `pandas`, `pydantic`, `pyinstaller`, `scipy`, `sentry-sdk`, `tifffile`, `vispy` ([#986](https://github.com/4DNucleome/PartSeg/pull/986))
- [Automatic] Constraints upgrades: `imagecodecs`, `sentry-sdk`, `tifffile` ([#997](https://github.com/4DNucleome/PartSeg/pull/997))
- [Automatic] Constraints upgrades: `ipykernel`, `pydantic` ([#1002](https://github.com/4DNucleome/PartSeg/pull/1002))
- [Automatic] Constraints upgrades: `numpy`, `pygments`, `sentry-sdk`, `superqt` ([#1007](https://github.com/4DNucleome/PartSeg/pull/1007))

#### âï¸ Miscellaneous Tasks

- [pre-commit.ci] pre-commit autoupdate ([#973](https://github.com/4DNucleome/PartSeg/pull/973))
- [pre-commit.ci] pre-commit autoupdate ([#982](https://github.com/4DNucleome/PartSeg/pull/982))
- [pre-commit.ci] pre-commit autoupdate ([#987](https://github.com/4DNucleome/PartSeg/pull/987))
- [pre-commit.ci] pre-commit autoupdate ([#988](https://github.com/4DNucleome/PartSeg/pull/988))
- [pre-commit.ci] pre-commit autoupdate ([#991](https://github.com/4DNucleome/PartSeg/pull/991))
- [pre-commit.ci] pre-commit autoupdate ([#998](https://github.com/4DNucleome/PartSeg/pull/998))
- [pre-commit.ci] pre-commit autoupdate ([#1004](https://github.com/4DNucleome/PartSeg/pull/1004))
- Change markdown linter from pre-commit to mdformat ([#1006](https://github.com/4DNucleome/PartSeg/pull/1006))
- [pre-commit.ci] pre-commit autoupdate ([#1008](https://github.com/4DNucleome/PartSeg/pull/1008))

### 0.15.0 - 2023-05-30

#### ð Features

- Add `PARTSEG_SENTRY_URL` env variable support and basic documentation about error reporting ([#802](https://github.com/4DNucleome/PartSeg/pull/802))
- Allow to see underlying exception when show warning caused by exception ([#829](https://github.com/4DNucleome/PartSeg/pull/829))
- Add voxel size measurement and allow to overwrite voxel size in batch ([#853](https://github.com/4DNucleome/PartSeg/pull/853))
- Add alpha support for Qt6 ([#866](https://github.com/4DNucleome/PartSeg/pull/866))
- Add option to create projection alongside z-axis ([#919](https://github.com/4DNucleome/PartSeg/pull/919))
- Add napari image custom representation for better error report via sentry ([#861](https://github.com/4DNucleome/PartSeg/pull/861))
- Add import and export operation for labels and colormaps ([#936](https://github.com/4DNucleome/PartSeg/pull/936))
- Implement napari widgets for colormap and labels control ([#935](https://github.com/4DNucleome/PartSeg/pull/935))
- Add forget all button to multiple files widget ([#942](https://github.com/4DNucleome/PartSeg/pull/942))
- Do not abort processing whole mask segmentation project during exception on single component ([#943](https://github.com/4DNucleome/PartSeg/pull/943))
- Add distance based watersheed to flow methods ([#915](https://github.com/4DNucleome/PartSeg/pull/915))
- Add napari widgets for all group of algorithms ([#958](https://github.com/4DNucleome/PartSeg/pull/958))
- Add napari widget to copy labels along z-axis ([#968](https://github.com/4DNucleome/PartSeg/pull/968))

#### ð Bug Fixes

- Print all exceptions instead of the latest one in exception dialog ([#799](https://github.com/4DNucleome/PartSeg/pull/799))
- Fix ROIExtractionResult `__str__`and `__repr__` to use `ROIExtractionResult` not `SegmentationResult` ([#810](https://github.com/4DNucleome/PartSeg/pull/810))
- Fix code to address changes in napari repository ([#817](https://github.com/4DNucleome/PartSeg/pull/817))
- Fix problem with resize of multiline widgets ([#832](https://github.com/4DNucleome/PartSeg/pull/832))
- Fix tox configuration to run all required tests ([#840](https://github.com/4DNucleome/PartSeg/pull/840))
- Fix MSO `step_limit` description in GUI ([#843](https://github.com/4DNucleome/PartSeg/pull/843))
- Fix `redefined-while-unused`import code for python 3.9.7 ([#844](https://github.com/4DNucleome/PartSeg/pull/844))
- Fix warnings reported by Deepsource ([#846](https://github.com/4DNucleome/PartSeg/pull/846))
- Ensure that ""ROI"" layer is in proper place for proper visualization ([#856](https://github.com/4DNucleome/PartSeg/pull/856))
- Fix tests of napari widgets ([#862](https://github.com/4DNucleome/PartSeg/pull/862))
- Fix build of bundle for a new psygnal release ([#863](https://github.com/4DNucleome/PartSeg/pull/863))
- Fix minimal requirements pipeline ([#877](https://github.com/4DNucleome/PartSeg/pull/877))
- Update pyinstaller configuration ([#926](https://github.com/4DNucleome/PartSeg/pull/926))
- Use text icon, not pixmap icon in colormap and labels list ([#938](https://github.com/4DNucleome/PartSeg/pull/938))
- Resolve warnings when testing custom save dialog. ([#941](https://github.com/4DNucleome/PartSeg/pull/941))
- Add padding zeros for component num when load Mask seg file to ROI GUI ([#944](https://github.com/4DNucleome/PartSeg/pull/944))
- Proper calculate bounds for watershed napari widget ([#969](https://github.com/4DNucleome/PartSeg/pull/969))
- Fix bug in the wrong order of axis saved in napari contribution ([#972](https://github.com/4DNucleome/PartSeg/pull/972))

#### ð Refactor

- Simplify and refactor github workflows. ([#864](https://github.com/4DNucleome/PartSeg/pull/864))
- Better load Mask project in Roi Analysis ([#921](https://github.com/4DNucleome/PartSeg/pull/921))
- Use more descriptive names in `pylint: disable` ([#922](https://github.com/4DNucleome/PartSeg/pull/922))
- Remove `pkg_resources` usage as it is deprecated ([#967](https://github.com/4DNucleome/PartSeg/pull/967))
- Convert napari plugin to npe2 ([#966](https://github.com/4DNucleome/PartSeg/pull/966))

#### ð Documentation

- Update README and project metadata ([#805](https://github.com/4DNucleome/PartSeg/pull/805))
- Create release notes for PartSeg 0.15.0 ([#971](https://github.com/4DNucleome/PartSeg/pull/971))

#### ð¨ Styling

- Change default theme to dark, remove blinking windows on startup. ([#809](https://github.com/4DNucleome/PartSeg/pull/809))

#### ð§ª Testing

- [Automatic] Dependency upgrades: `packaging`, `pyinstaller`, `pyopengl-accelerate`, `tifffile`, `xlsxwriter` ([#932](https://github.com/4DNucleome/PartSeg/pull/932))
- [Automatic] Constraints upgrades: `fonticon-fontawesome6`, `imageio`, `numpy`, `partsegcore-compiled-backend`, `pygments`, `sentry-sdk` ([#937](https://github.com/4DNucleome/PartSeg/pull/937))
- [Automatic] Constraints upgrades: `imageio`, `ipython`, `pandas`, `requests`, `sentry-sdk` ([#948](https://github.com/4DNucleome/PartSeg/pull/948))
- [Automatic] Constraints upgrades: `ipython`, `nme`, `qtconsole`, `requests`, `sentry-sdk` ([#955](https://github.com/4DNucleome/PartSeg/pull/955))
- [Automatic] Constraints upgrades: `ipykernel`, `local-migrator`, `pyinstaller`, `sentry-sdk`, `sympy` ([#957](https://github.com/4DNucleome/PartSeg/pull/957))
- [Automatic] Constraints upgrades: `sentry-sdk`, `xlsxwriter` ([#959](https://github.com/4DNucleome/PartSeg/pull/959))
- [Automatic] Constraints upgrades: `requests` ([#961](https://github.com/4DNucleome/PartSeg/pull/961))
- [Automatic] Constraints upgrades: `imageio`, `pandas`, `pydantic`, `pyopengl-accelerate`, `sentry-sdk`, `xlsxwriter` ([#970](https://github.com/4DNucleome/PartSeg/pull/970))

#### âï¸ Miscellaneous Tasks

- Improve ruff configuration, remove isort ([#815](https://github.com/4DNucleome/PartSeg/pull/815))
- Use `fail_on_no_env` feature from `tox-gh-actions` ([#842](https://github.com/4DNucleome/PartSeg/pull/842))
- Add python 3.11 to list of supported versions ([#867](https://github.com/4DNucleome/PartSeg/pull/867))
- Disable python 3.11 test because of timeout ([#870](https://github.com/4DNucleome/PartSeg/pull/870))
- Bump ruff to 0.0.218, remove flake8 from pre-commit ([#880](https://github.com/4DNucleome/PartSeg/pull/880))
- Replace GabrielBB/xvfb-action@v1 by aganders3/headless-gui, part 2 ([#887](https://github.com/4DNucleome/PartSeg/pull/887))
- Better minimal requirements test ([#888](https://github.com/4DNucleome/PartSeg/pull/888))
- Improve regexp for proper generate list of packages in update report ([#894](https://github.com/4DNucleome/PartSeg/pull/894))
- Add check for PR title ([#933](https://github.com/4DNucleome/PartSeg/pull/933))
- Update codecov configuration to wait on two reports before post information ([#934](https://github.com/4DNucleome/PartSeg/pull/934))
- [pre-commit.ci] pre-commit autoupdate ([#945](https://github.com/4DNucleome/PartSeg/pull/945))
- Migrate from `nme` to `local_migrator` ([#951](https://github.com/4DNucleome/PartSeg/pull/951))
- [pre-commit.ci] pre-commit autoupdate ([#956](https://github.com/4DNucleome/PartSeg/pull/956))
- [pre-commit.ci] pre-commit autoupdate ([#964](https://github.com/4DNucleome/PartSeg/pull/964))

#### ð¡ï¸ Security

- *(deps)* Bump peter-evans/create-pull-request from 4 to 5 ([#928](https://github.com/4DNucleome/PartSeg/pull/928))

#### Bugfix

- Fix bug with generation of form for model with hidden field ([#920](https://github.com/4DNucleome/PartSeg/pull/920))

#### Dep

- [Automatic] Dependency upgrades ([#824](https://github.com/4DNucleome/PartSeg/pull/824))
- [Automatic] Dependency upgrades ([#828](https://github.com/4DNucleome/PartSeg/pull/828))
- [Automatic] Dependency upgrades: `ipykernel`, `packaging` ([#838](https://github.com/4DNucleome/PartSeg/pull/838))
- [Automatic] Dependency upgrades: `imageio`, `ipykernel`, `napari`, `numpy`, `sentry` ([#850](https://github.com/4DNucleome/PartSeg/pull/850))
- [Automatic] Dependency upgrades: `imagecodecs`, `ipykernel`, `numpy`, `psygnal` ([#859](https://github.com/4DNucleome/PartSeg/pull/859))
- [Automatic] Dependency upgrades: `pydantic`, `pygments`, `xlsxwriter` ([#874](https://github.com/4DNucleome/PartSeg/pull/874))
- [Automatic] Dependency upgrades: `imageio`, `packaging`, `scipy`, `xlsxwriter` ([#878](https://github.com/4DNucleome/PartSeg/pull/878))
- [Automatic] Dependency upgrades: `ipykernel`, `requests`, `sentry`, `xlsxwriter` ([#884](https://github.com/4DNucleome/PartSeg/pull/884))
- [Automatic] Dependency upgrades: `h5py`, `imagecodecs`, `imageio`, `ipykernel`, `pandas`, `sentry`, `tifffile` ([#889](https://github.com/4DNucleome/PartSeg/pull/889))
- [Automatic] Dependency upgrades: `ipython`, `pyqt5` ([#893](https://github.com/4DNucleome/PartSeg/pull/893))
- [Automatic] Dependency upgrades: `imageio`, `ipykernel`, `ipython`, `numpy`, `openpyxl`, `psygnal`, `pydantic`, `pyinstaller`, `pyqt5`, `scipy`, `sentry-sdk`, `tifffile`, `xlsxwriter` ([#897](https://github.com/4DNucleome/PartSeg/pull/897))
- [Automatic] Dependency upgrades: `imageio`, `psygnal` ([#905](https://github.com/4DNucleome/PartSeg/pull/905))
- [Automatic] Dependency upgrades: `ipython`, `magicgui`, `scipy`, `sentry-sdk`, `tifffile` ([#906](https://github.com/4DNucleome/PartSeg/pull/906))
- [Automatic] Dependency upgrades: `imagecodecs`, `imageio`, `ipykernel`, `openpyxl`, `pydantic`, `pyinstaller`, `qtawesome`, `qtconsole`, `sentry-sdk`, `tifffile`, `xlsxwriter` ([#908](https://github.com/4DNucleome/PartSeg/pull/908))
- [Automatic] Dependency upgrades: `imageio`, `ipykernel`, `ipython`, `pandas`, `psygnal`, `pydantic`, `pygments`, `pyinstaller`, `qtpy`, `sentry-sdk`, `tifffile` ([#917](https://github.com/4DNucleome/PartSeg/pull/917))

### 0.14.6 - 2022-11-13

#### ð Bug Fixes

- Fix bug when loading already created project causing hide of ROI layer ([#787](https://github.com/4DNucleome/PartSeg/pull/787))

### 0.14.5 - 2022-11-09

#### ð Features

- Add option for ensure type in EventedDict and use it to validate profiles structures ([#776](https://github.com/4DNucleome/PartSeg/pull/776))
- Add option to create issue from error report dialog ([#782](https://github.com/4DNucleome/PartSeg/pull/782))
- Add option for multiline field in algorithm parameters ([#766](https://github.com/4DNucleome/PartSeg/pull/766))

#### ð Bug Fixes

- Fix scalebar color ([#774](https://github.com/4DNucleome/PartSeg/pull/774))
- Fix bug when saving segmentation parameters in mask analysis ([#781](https://github.com/4DNucleome/PartSeg/pull/781))
- Fix multiple error related to loading new file in interactive mode ([#784](https://github.com/4DNucleome/PartSeg/pull/784))

#### ð Refactor

- Optimize CLI actions ([#772](https://github.com/4DNucleome/PartSeg/pull/772))
- Clean warnings about threshold methods ([#783](https://github.com/4DNucleome/PartSeg/pull/783))

#### Build

- *(deps)* Bump chanzuckerberg/napari-hub-preview-action from 0.1.5 to 0.1.6 ([#775](https://github.com/4DNucleome/PartSeg/pull/775))

### 0.14.4 - 2022-10-24

#### ð Features

- Load alternatives labeling when open PartSeg projects in napari ([#731](https://github.com/4DNucleome/PartSeg/pull/731))
- Add option to toggle scale bar ([#733](https://github.com/4DNucleome/PartSeg/pull/733))
- Allow customize settings directory using the `PARTSEG_SETTINGS_DIR` environment variable ([#751](https://github.com/4DNucleome/PartSeg/pull/751))
- Separate recent algorithms from general application settings ([#752](https://github.com/4DNucleome/PartSeg/pull/752))
- Add multiple otsu as threshold method with selection range of components ([#710](https://github.com/4DNucleome/PartSeg/pull/710))
- Add function to load components from Mask Segmentation with background in ROI Analysis ([#768](https://github.com/4DNucleome/PartSeg/pull/768))

#### ð Bug Fixes

- Fix typos
- Fix `get_theme` calls to prepare for napari 0.4.17 ([#729](https://github.com/4DNucleome/PartSeg/pull/729))
- Fix saving pipeline from GUI ([#756](https://github.com/4DNucleome/PartSeg/pull/756))
- Fix profile export/import dialogs ([#761](https://github.com/4DNucleome/PartSeg/pull/761))
- Enable compare button if ROI is available ([#765](https://github.com/4DNucleome/PartSeg/pull/765))
- Fix bug in cut with roi to do not make black artifacts ([#767](https://github.com/4DNucleome/PartSeg/pull/767))

#### ð§ª Testing

- Add new build and inspect wheel action ([#747](https://github.com/4DNucleome/PartSeg/pull/747))

#### âï¸ Miscellaneous Tasks

- Prepare pyinstaller configuration for napari 0.4.17 ([#748](https://github.com/4DNucleome/PartSeg/pull/748))
- Add ruff linter ([#754](https://github.com/4DNucleome/PartSeg/pull/754))

#### Bugfix

- Fix sentry tests ([#742](https://github.com/4DNucleome/PartSeg/pull/742))
- Fix reporting error in load settings from drive ([#725](https://github.com/4DNucleome/PartSeg/pull/725))

#### Build

- *(deps)* Bump actions/checkout from 2 to 3 ([#716](https://github.com/4DNucleome/PartSeg/pull/716))
- *(deps)* Bump actions/download-artifact from 1 to 3 ([#709](https://github.com/4DNucleome/PartSeg/pull/709))

### 0.14.3 - 2022-08-18

#### ð Bug Fixes

- Delay setting image if an algorithm is still running ([#627](https://github.com/4DNucleome/PartSeg/pull/627))
- Wrong error report when no component is found in restartable segmentation algorithm. ([#633](https://github.com/4DNucleome/PartSeg/pull/633))
- Fix process of build documentation ([#653](https://github.com/4DNucleome/PartSeg/pull/653))

#### ð Refactor

- Clean potential vulnerabilities ([#630](https://github.com/4DNucleome/PartSeg/pull/630))

#### ð§ª Testing

- Add more tests for common GUI elements ([#622](https://github.com/4DNucleome/PartSeg/pull/622))
- Report coverage per package. ([#639](https://github.com/4DNucleome/PartSeg/pull/639))
- Update conda environment to not use PyQt5 in test ([#646](https://github.com/4DNucleome/PartSeg/pull/646))
- Add tests files to calculate coverage ([#655](https://github.com/4DNucleome/PartSeg/pull/655))

#### Build

- *(deps)* Bump qtpy from 2.0.1 to 2.1.0 in /requirements ([#613](https://github.com/4DNucleome/PartSeg/pull/613))
- *(deps)* Bump pyinstaller from 5.0.1 to 5.1 in /requirements ([#629](https://github.com/4DNucleome/PartSeg/pull/629))
- *(deps)* Bump tifffile from 2022.4.28 to 2022.5.4 in /requirements ([#619](https://github.com/4DNucleome/PartSeg/pull/619))
- *(deps)* Bump codecov/codecov-action from 1 to 3 ([#637](https://github.com/4DNucleome/PartSeg/pull/637))
- *(deps)* Bump requests from 2.27.1 to 2.28.0 in /requirements ([#647](https://github.com/4DNucleome/PartSeg/pull/647))
- *(deps)* Bump actions/setup-python from 3 to 4 ([#648](https://github.com/4DNucleome/PartSeg/pull/648))
- *(deps)* Bump pyqt5 from 5.15.6 to 5.15.7 in /requirements ([#652](https://github.com/4DNucleome/PartSeg/pull/652))
- *(deps)* Bump sentry-sdk from 1.5.12 to 1.6.0 in /requirements ([#659](https://github.com/4DNucleome/PartSeg/pull/659))
- *(deps)* Bump numpy from 1.22.4 to 1.23.0 in /requirements ([#660](https://github.com/4DNucleome/PartSeg/pull/660))
- *(deps)* Bump lxml from 4.9.0 to 4.9.1 in /requirements ([#665](https://github.com/4DNucleome/PartSeg/pull/665))
- *(deps)* Bump mahotas from 1.4.12 to 1.4.13 in /requirements ([#662](https://github.com/4DNucleome/PartSeg/pull/662))
- *(deps)* Bump pyinstaller from 5.1 to 5.2 in /requirements ([#667](https://github.com/4DNucleome/PartSeg/pull/667))

### 0.14.2 - 2022-05-05

#### ð Bug Fixes

- Fix bug in save label colors between sessions ([#610](https://github.com/4DNucleome/PartSeg/pull/610))
- Register PartSeg plugins before start napari widgets. ([#611](https://github.com/4DNucleome/PartSeg/pull/611))
- Mouse interaction with components work again after highlight. ([#620](https://github.com/4DNucleome/PartSeg/pull/620))

#### ð Refactor

- Limit test run ([#603](https://github.com/4DNucleome/PartSeg/pull/603))
- Filter and solve warnings in tests ([#607](https://github.com/4DNucleome/PartSeg/pull/607))
- Use QAbstractSpinBox.AdaptiveDecimalStepType in SpinBox instead of hardcoded bounds ([#616](https://github.com/4DNucleome/PartSeg/pull/616))
- Clean and test `PartSeg.common_gui.universal_gui_part` ([#617](https://github.com/4DNucleome/PartSeg/pull/617))

#### ð Documentation

- Update changelog ([#621](https://github.com/4DNucleome/PartSeg/pull/621))

#### ð§ª Testing

- Speedup test by setup cache for pip ([#604](https://github.com/4DNucleome/PartSeg/pull/604))
- Setup cache for azure pipelines workflows ([#606](https://github.com/4DNucleome/PartSeg/pull/606))

#### Build

- *(deps)* Bump sentry-sdk from 1.5.10 to 1.5.11 in /requirements ([#615](https://github.com/4DNucleome/PartSeg/pull/615))

### 0.14.1 - 2022-04-27

#### ð Features

- Use pygments for coloring code in exception window ([#591](https://github.com/4DNucleome/PartSeg/pull/591))
- Add option to calculate Measurement per Mask component ([#590](https://github.com/4DNucleome/PartSeg/pull/590))

#### ð Bug Fixes

- Update build wheels and sdist to have proper version tag ([#583](https://github.com/4DNucleome/PartSeg/pull/583))
- Fix removing the first measurement entry in the napari Measurement widget ([#584](https://github.com/4DNucleome/PartSeg/pull/584))
- Fix compatybility bug for conda Pyside2 version ([#595](https://github.com/4DNucleome/PartSeg/pull/595))
- Error when synchronization is loaded and new iloaded image has different dimensionality than currently loaded. ([#598](https://github.com/4DNucleome/PartSeg/pull/598))

#### ð Refactor

- Refactor the create batch plan widgets and add test for it ([#587](https://github.com/4DNucleome/PartSeg/pull/587))
- Drop napari below 0.4.12 ([#592](https://github.com/4DNucleome/PartSeg/pull/592))
- Update the order of ROI Mask algorithms to be the same as in older PartSeg versions ([#600](https://github.com/4DNucleome/PartSeg/pull/600))

#### Build

- *(deps)* Bump partsegcore-compiled-backend from 0.13.11 to 0.14.0 in /requirements ([#582](https://github.com/4DNucleome/PartSeg/pull/582))
- *(deps)* Bump simpleitk from 2.1.1 to 2.1.1.2 in /requirements ([#589](https://github.com/4DNucleome/PartSeg/pull/589))
- *(deps)* Bump pyinstaller from 4.10 to 5.0 in /requirements ([#586](https://github.com/4DNucleome/PartSeg/pull/586))

### 0.14.0 - 2022-04-14

#### ð Features

- Allow to set zoom factor from interface in Search Label napari plugin ([#538](https://github.com/4DNucleome/PartSeg/pull/538))
- Add controlling of zoom factor of search ROI in main GUI ([#540](https://github.com/4DNucleome/PartSeg/pull/540))
- Better serialization mechanism allow for declaration data structure migration locally ([#462](https://github.com/4DNucleome/PartSeg/pull/462))
- Make \`\*.obsep"" file possible to load in PartSeg Analysis ([#564](https://github.com/4DNucleome/PartSeg/pull/564))
- Add option to extract measurement profile or roi extraction profile from batch plan ([#568](https://github.com/4DNucleome/PartSeg/pull/568))
- Allow import calculation plan from batch result excel file ([#567](https://github.com/4DNucleome/PartSeg/pull/567))
- Improve error reporting when fail to deserialize data ([#574](https://github.com/4DNucleome/PartSeg/pull/574))
- Launch PartSeg GUI from napari ([#581](https://github.com/4DNucleome/PartSeg/pull/581))

#### ð Bug Fixes

- Fix ""Show selected"" rendering mode in PartSeg ROI Mask ([#565](https://github.com/4DNucleome/PartSeg/pull/565))

#### ð Refactor

- Store PartSegImage.Image channels as separated arrays ([#554](https://github.com/4DNucleome/PartSeg/pull/554))
- Remove deprecated modules. ([#429](https://github.com/4DNucleome/PartSeg/pull/429))
- Switch serialization backen to `nme` ([#569](https://github.com/4DNucleome/PartSeg/pull/569))

#### ð Documentation

- Update changelog and add new badges to readme ([#580](https://github.com/4DNucleome/PartSeg/pull/580))

#### ð§ª Testing

- Add test of creating AboutDialog ([#539](https://github.com/4DNucleome/PartSeg/pull/539))
- Setup test for python 3.10. Disable class_generator test for this python ([#570](https://github.com/4DNucleome/PartSeg/pull/570))

#### Bugfix

- Add access by operator [] to pydantic.BaseModel base structures for keep backward compatybility ([#579](https://github.com/4DNucleome/PartSeg/pull/579))

#### Build

- *(deps)* Bump sentry-sdk from 1.5.2 to 1.5.3 in /requirements ([#512](https://github.com/4DNucleome/PartSeg/pull/512))
- *(deps)* Bump ipython from 8.0.0 to 8.0.1 in /requirements ([#513](https://github.com/4DNucleome/PartSeg/pull/513))
- *(deps)* Bump pandas from 1.3.5 to 1.4.0 in /requirements ([#514](https://github.com/4DNucleome/PartSeg/pull/514))
- *(deps)* Bump oiffile from 2021.6.6 to 2022.2.2 in /requirements ([#521](https://github.com/4DNucleome/PartSeg/pull/521))
- *(deps)* Bump numpy from 1.22.1 to 1.22.2 in /requirements ([#524](https://github.com/4DNucleome/PartSeg/pull/524))
- *(deps)* Bump tifffile from 2021.11.2 to 2022.2.2 in /requirements ([#523](https://github.com/4DNucleome/PartSeg/pull/523))
- *(deps)* Bump qtpy from 2.0.0 to 2.0.1 in /requirements ([#522](https://github.com/4DNucleome/PartSeg/pull/522))
- *(deps)* Bump sentry-sdk from 1.5.3 to 1.5.4 in /requirements ([#515](https://github.com/4DNucleome/PartSeg/pull/515))
- *(deps)* Bump pyinstaller from 4.8 to 4.10 in /requirements ([#545](https://github.com/4DNucleome/PartSeg/pull/545))
- *(deps)* Bump pillow from 9.0.0 to 9.0.1 in /requirements ([#549](https://github.com/4DNucleome/PartSeg/pull/549))
- *(deps)* Bump sphinx from 4.4.0 to 4.5.0 in /requirements ([#561](https://github.com/4DNucleome/PartSeg/pull/561))
- *(deps)* Bump tifffile from 2022.2.9 to 2022.3.25 in /requirements ([#562](https://github.com/4DNucleome/PartSeg/pull/562))
- *(deps)* Bump sympy from 1.10 to 1.10.1 in /requirements ([#556](https://github.com/4DNucleome/PartSeg/pull/556))
- *(deps)* Bump sentry-sdk from 1.5.7 to 1.5.8 in /requirements ([#557](https://github.com/4DNucleome/PartSeg/pull/557))

### 0.13.15

#### Bug Fixes

- Using `translation` instead of `translation_grid` for shifting layers. (#474)
- Bugs in napari plugins (#478)
- Missing mask when using roi extraction from napari (#479)
- Fix segmentation fault on macos machines (#487)
- Fixes for napari 0.4.13 (#506)

#### Documentation

- Create 0.13.15 release (#511)
- Add categories and preview page workflow for the napari hub (#489)

#### Features

- Assign properties to mask layer in napari measurement widget (#480)

#### Build

- Bump qtpy from 1.11.3 to 2.0.0 in /requirements (#498)
- Bump pydantic from 1.8.2 to 1.9.0 in /requirements (#496)
- Bump sentry-sdk from 1.5.1 to 1.5.2 in /requirements (#497)
- Bump sphinx from 4.3.1 to 4.3.2 in /requirements (#500)
- Bump pyinstaller from 4.7 to 4.8 in /requirements (#502)
- Bump pillow from 8.4.0 to 9.0.0 in /requirements (#501)
- Bump requests from 2.26.0 to 2.27.1 in /requirements (#495)
- Bump numpy from 1.21.4 to 1.22.0 in /requirements (#499)
- Bump numpy from 1.22.0 to 1.22.1 in /requirements (#509)
- Bump sphinx from 4.3.2 to 4.4.0 in /requirements (#510)

### 0.13.14

#### Bug Fixes

- ROI alternative representation (#471)
- Change additive to translucent in rendering ROI and Mask (#472)

#### Features

- Add morphological watershed segmentation (#469)
- Add Bilateral image filter (#470)

### 0.13.13

#### Bug Fixes

- Fix bugs in the generation process of the changelog for release. (#428)
- Restoring ROI on home button click in compare viewer (#443)
- Fix Measurement name prefix in bundled PartSeg. (#458)
- Napari widgets registration in pyinstaller bundle (#465)
- Hide points button if no points are loaded, hide Mask checkbox if no mask is set (#463)
- Replace Label data instead of adding/removing layers - fix blending layers (#464)

#### Features

- Add threshold information in layer annotation in the Multiple Otsu ROI extraction method (#430)
- Add option to select rendering method for ROI (#431)
- Add callback mechanism to ProfileDict, live update of ROI render parameters (#432)
- Move the info bar on the bottom of the viewer (#442)
- Add options to load recent files in multiple files widget (#444)
- Add ROI annotations as properties to napari labels layer created by ROI Extraction widgets (#445)
- Add signals to ProfileDict, remove redundant synchronization mechanisms (#449)
- Allow ignoring updates for 21 days (#453)
- Save all components if no components selected in mask segmentation (#456)
- Add modal dialog for search ROI components (#459)
- Add full measurement support as napari widget (#460)
- Add search labels as napari widget (#467)

#### Refactor

- Export common code for load/save dialog to one place (#437)
- Change most of call QFileDialog to more generic code (#440)

#### Testing

- Add test for `PartSeg.common_backend` module (#433)

### 0.13.12

#### Bug Fixes

- Importing the previous version of settings (#406)
- Cutting without masking data (#407)
- Save in subdirectory in batch plan (#414)
- Loading plugins for batch processing (#423)

#### Features

- Add randomization option for correlation calculation (#421)
- Add Imagej TIFF writer for image. (#405)
- Mask create widget for napari (#395)
- In napari roi extraction method show information from roi extraction method (#408)
- Add `*[0-9].tif` button in batch processing window (#412)
- Better label representation in 3d view (#418)

#### Refactor

- Use Font Awesome instead of custom symbols (#424)

### 0.13.11

#### Bug Fixes

- Adding mask in Prepare Plan for batch (#383)
- Set proper completion mode in SearchComboBox (#384)
- Showing warnings on the error with ROI load (#385)

#### Features

- Add CellFromNucleusFlow ""Cell from nucleus flow"" cell segmentation method (#367)
- When cutting components in PartSeg ROI mask allow not masking outer data (#379)
- Theme selection in GUI (#381)
- Allow return points from ROI extraction algorithm (#382)
- Add measurement to get ROI annotation by name. (#386)
- PartSeg ROI extraction algorithms as napari plugins (#387)
- Add Pearson, Mander's, Intensity, Spearman colocalization measurements (#392)
- Separate standalone napari settings from PartSeg embedded napari settings (#397)

#### Performance

- Use faster calc bound function (#375)

#### Refactor

- Remove CustomApplication (#389)

### 0.13.10

- change tiff save backend to ome-tiff
- add `DistanceROIROI` and `ROINeighbourhoodROI` measurements

### 0.13.9

- annotation show bugfix

### 0.13.8

- napari deprecation fixes
- speedup simple measurement
- bundle plugins initial support

### 0.13.7

- add measurements widget for napari
- fix bug in pipeline usage

### 0.13.6

- Hotfix release
- Prepare for a new napari version

### 0.13.5

- Small fixes for error reporting
- Fix mask segmentation

### 0.13.4

- Bugfix for outdated profile/pipeline preview

### 0.13.3

- Fix saving roi_info in multiple files and history

### 0.13.2

- Fix showing label in select label tab

### 0.13.1

- Add Haralick measurements
- Add obsep file support

### 0.13.0

- Add possibility of custom input widgets for algorithms
- Switch to napari Colormaps instead of custom one
- Add points visualization
- Synchronization widget for builtin (View menu) napari viewer
- Drop Python 3.6

### 0.12.7

- Fixes for napari 0.4.6

### 0.12.6

- Fix prev_mask_get
- Fix cache mechanism on mask change
- Update PyInstaller build

### 0.12.5

- Fix bug in pipeline execute

### 0.12.4

- Fix ROI Mask windows related build (signal not properly connected)

### 0.12.3

- Fix ROI Mask

### 0.12.2

- Fix windows bundle

### 0.12.1

- History of last opened files
- Add ROI annotation and ROI alternatives
- Minor bugfix

### 0.12.0

- Toggle multiple files widget in View menu
- Toggle Left panel in ROI Analysis in View Menu
- Rename Mask Segmentation to ROI Mask
- Add documentation for interface
- Add Batch processing tutorial
- Add information about errors to batch processing output file
- Load image from the batch prepare window
- Add search option in part of list and combo boxes
- Add drag and drop mechanism to load list of files to batch window.

### 0.11.5

- add side view to viewer
- fix horizontal view for Measurements result table

### 0.11.4

- bump to napari 0.3.8 in bundle
- fix bug with not presented segmentation loaded from project
- add frame (1 pix) to image cat from base one based on segmentation
- pin to Qt version to 5.14

### 0.11.3

- prepare for napari 0.3.7
- split napari io plugin on multiple part
- better reporting for numpy array via sentry
- fix setting color for mask marking

### 0.11.2

- Speedup image set in viewer using async calls
- Fix bug in long name of sheet with parameters

### 0.11.1

- Add screenshot option in View menu
- Add Voxels measurements

### 0.11.0

- Make sprawl algorithm name shorter
- Unify capitalisation of measurement names
- Add simple measurements to mask segmentation
- Use napari as viewer
- Add possibility to preview additional output of algorithms (In View menu)
- Update names of available Algorithm and Measurement to be more descriptive.

### 0.10.8

- fix synchronisation between viewers in Segmentation Analysis
- fix batch crash on error during batch run, add information about file on which calculation fails
- add changelog preview in Help > About

### 0.10.7

- in measurements, on empty list of components mean will return 0

### 0.10.6

- fix border rim preview
- fix problem with size of image preview
- zoom with scroll and moving if rectangle zoom is not marked

### 0.10.5

- make PartSeg PEP517 compatible.
- fix multiple files widget on Windows (path normalisation)

### 0.10.4

- fix slow zoom

### 0.10.3

- deterministic order of elements in batch processing.

### 0.10.2

- bugfixes

### 0.10.1

- bugfixes

### 0.10.0

- Add creating custom label coloring.
- Change execs interpreter to python 3.7.
- Add masking operation in Segmentation Mask.
- Change license to BSD.
- Allow select root type in batch processing.
- Add median filter in preview.

### 0.9.7

- fix bug in compare mask

### 0.9.6

- fix bug in loading project with mask
- upgrade PyInstaller version (bug GHSA-7fcj-pq9j-wh2r)

### 0.9.5

- fix bug in loading project in ""Segmentation analysis""

### 0.9.4

- read mask segmentation projects
- choose source type in batch
- add initial support to OIF and CZI file format
- extract utils to PartSegCore module
- add automated tests of example notebook
- reversed mask
- load segmentation parameters in mask segmentation
- allow use sprawl in segmentation tool
- add radial split of mask for measurement
- add all measurement results in batch, per component sheet

### 0.9.3

- start automated build documentation
- change color map backend and allow for user to create custom color map.
- segmentation compare
- update test engines
- support of PySide2

### 0.9.2.3

- refactor code to make easier create plugin for mask segmentation
- create class base updater for update outdated algorithm description
- fix save functions
- fix different bugs

### 0.9.2.2

- extract static data to separated package
- update marker of fix range and add mark of gauss in channel control

### 0.9.2.1

- add VoteSmooth and add choosing of smooth algorithm

### 0.9.2

- add pypi base check for update

- remove resetting image state when change state in same image

- in stack segmentation add options to picking components from segmentation's

- in mask segmentation add:

  - preview of segmentation parameters per component,
  - save segmentation parameters in save file
  - new implementation of batch mode.

### 0.9.1

- Add multiple files widget

- Add Calculating distances between segmented object and mask

- Batch processing plan fixes:

  - Fix adding pipelines to plan
  - Redesign mask widget

- modify measurement backend to allow calculate multi channel measurements.

### 0.9

Begin of changelog
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: Implementation :: CPython', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Visualization']","['Homepage, https://partseg.github.io/', 'Documentation, https://partseg.readthedocs.io/en/stable/', 'Source Code, https://github.com/4DNucleome/PartSeg', 'User Support, https://github.com/4DNucleome/PartSeg/issues', 'Bug Tracker, https://github.com/4DNucleome/PartSeg/issues']",PartSeg.load_roi_project,PartSeg.write_tiff_image,PartSeg.SearchLabel,,"['*.tgz', '*.tbz2', '*.gz', '*.bz2']","['.tif', '.tiff']","['.tif', '.tiff']"
498,platymatch,PlatyMatch,PlatyMatch,0.0.3,2021-05-28,2021-06-08,Manan Lalit,lalit@mpi-cbg.de,BSD-3,https://github.com/juglab/PlatyMatch,https://pypi.org/project/PlatyMatch/,,https://github.com/juglab/PlatyMatch,PlatyMatch allows registration of volumetric images of embryos by establishing correspondences between cells,>=3.6,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'scikit-image', 'scikit-learn', 'tqdm', 'simpleitk', 'napari[all]', 'pandas', 'pytest']","[![DOI:10.1007/978-3-030-66415-2_30](https://zenodo.org/badge/DOI/10.1007/978-3-030-66415-2_30.svg)](https://link.springer.com/chapter/10.1007/978-3-030-66415-2_30)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![PyPI](https://img.shields.io/pypi/v/PlatyMatch.svg?color=green)](https://pypi.org/project/PlatyMatch)
[![Python Version](https://img.shields.io/pypi/pyversions/PlatyMatch.svg?color=green)](https://python.org)
[![tests](https://github.com/juglab/PlatyMatch/workflows/tests/badge.svg)](https://github.com/juglab/PlatyMatch/actions)
[![codecov](https://codecov.io/gh/juglab/PlatyMatch/branch/master/graph/badge.svg)](https://codecov.io/gh/juglab/PlatyMatch)


<p align=""center"">
  <img src=""https://user-images.githubusercontent.com/34229641/117537510-b26ee500-b001-11eb-9642-3baa461bfc94.png"" width=400 />
</p>
<h2 align=""center"">Registration of Multi-modal Volumetric Images by Establishing Cell Correspondence</h2>

## Table of Contents

- **[Introduction](#introduction)**
- **[Dependencies](#dependencies)**
- **[Getting Started](#getting-started)**
- **[Datasets](#datasets)**
- **[Registering your data](#registering-your-data)**
- **[Contributing](#contributing)**
- **[Issues](#issues)**
- **[Citation](#citation)**

### Introduction
This repository hosts the version of the code used for the **[publication](https://link.springer.com/chapter/10.1007/978-3-030-66415-2_30)** **Registration of Multi-modal Volumetric Images by Establishing Cell Correspondence**. 

We refer to the techniques elaborated in the publication, here as **PlatyMatch**. `PlatyMatch` performs a linear registration of volumetric, microscopy images of embryos by establishing correspondences between cells. 

`PlatyMatch` first detects nuclei in the two images being considered, next calculates unique `shape context` features for each nucleus detection which encapsulates the neighborhood as seen by that nucleus, and finally identifies pairs of matching nuclei through maximum bipartite matching applied to the pairwise distance matrix generated from these features. 

### Dependencies 

You can install `PlatyMatch` via **[pip]**:

```
conda create -y -n PlatyMatchEnv python==3.8
conda activate PlatyMatchEnv
python3 -m pip install PlatyMatch
```

### Getting Started

Type in the following commands in a new terminal window.

```
conda activate PlatyMatchEnv
napari
```

Next, select `PlatyMatch` from `Plugins> Add Dock Widget`.

### Datasets

Datasets are available in **`bic_eccv_data.zip`** as release assets **[here](https://github.com/juglab/PlatyMatch/releases/tag/v0.0.1)**.
These comprise of images, nuclei detections and keypoint locations for confocal images of 12 individual specimens under the `01-insitus` directory and static snapshots of a live embryo imaged through Light Sheet Microscopy under the `02-live` directory. 
Folders with the same name in these two directories correspond in their developmental age, for example, `01-insitus/02` corresponds to `02-live/02`, `01-insitus/03` corresponds to `02-live/03` and so on.   


### Registering your data

- **Detect Nuclei** 
	- Drag and drop your images in the viewer 
	- Click on `Sync with Viewer` button to refresh the drop-down menus 
	- Select the appropriate image in the drop down menu (for which nuclei detections are desired)
	- Select **`Detect Nuclei`** from the drop-down menu
	- Specify the anisotropy factor (`Anisotropy (Z)`) (i.e. the ratio of the size of the z pixel with respect to the x or y pixel. This factor is typically more than 1.0 because the z dimension is often undersampled)
	- Ideally min scales and max scales should be estimated from your data (`min_scale` should be set as `min_radius/sqrt(3)` and `max_scale` should be set as `max_radius/sqrt(3)`. The default values of `min_scale=5` and `max_scale=9` generally works well).  
	- Click `Run Scale Space Log` button. Please note that this step takes a few minutes.
	- Wait until a confirmation message suggesting that nuclei detection is over shows up on the terminal
	- Export the nuclei locations (`Export detections to csv`) to a csv file
	- Repeat this step for all images which need to be matched




https://user-images.githubusercontent.com/34229641/120660618-cd5d3980-c487-11eb-8996-326264a4df87.mp4


- **Estimate Transform**
	- In case, nuclei were exported to a csv in the `Detect Nuclei` panel, tick `csv` checkbox
	- If the nuclei detected were specified in the order id, z, y and x in the csv file, then tick `IZYXR` checkbox
	- Additionally if there is a header in the csv file, tick `Header` checkbox
	- Load the detections for the `Moving Image`, which is defined as the image which will be transformed to later match another `fixed` image
	- Load the detections for the `Fixed Image`
	- Click on `Run` pushbutton. Once the calculation is complete, a confirmation message shows up in the terminal. Export the transform matrix to a csv (Note that this step can take a few minutes)
	- It is also possible to estimate the transform in a `supervised` fashion. For this, upload the locations of a few matching keypoints in both images. These locations serve to provide a good starting point for the transform calculation. Once the keypoint files have been uploaded for both the images, then click `Run` and then export the transform matrix to a csv file 


https://user-images.githubusercontent.com/34229641/120685628-53857a00-c4a0-11eb-8f92-7ffac730e28a.mp4



- **Evaluate Metrics**
	- Drag images which need to be transformed, in the viewer
	- Click on `Sync with Viewer` button to refresh the drop-down menus
	- Specify the anisotropy factor (`Moving Image Anisotropy (Z)` and `Fixed Image Anisotropy (Z)`) (i.e. the ratio of the size of the z pixel with respect to the x or y pixel. This factor is typically more than 1.0 because the z dimension is often undersampled)
	- Load the transform which was calculated in the previous steps
	- If you simply wish to export a transformed version of the moving image, click on `Export Transformed Image`
	- Additionally, one could quantify metrics such as average registration error evaluated on a few keypoints. To do so, tick the `csv` checkbox, if keypoints and detections are available as a csv file. Then load the keypoints for the moving image (`Moving Kepoints`) and the fixed image (`Fixed Keypoints`)
	- Also, upload the detections calculated in the previous steps (`Detect Nuclei`)  by uploading the `Moving Detections` and the `Fixed Detections`
	- Click on the `Run` push button
	- The text fields such as `Matching Accuracy`(0 to 1, with 1 being the best) and `Average Registration Error` (the lower the better) should become populated once the results are available



https://user-images.githubusercontent.com/34229641/120685654-5b451e80-c4a0-11eb-8d7d-de58b8b8304d.mp4


### Contributing

Contributions are very welcome. Tests can be run with **[tox]**.

### Issues

If you encounter any problems, please **[file an issue]** along with a detailed description.

[file an issue]: https://github.com/juglab/PlatyMatch/issues
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/EmbedSeg/


### Citation
If you find our work useful in your research, please consider citing:

```bibtex
@InProceedings{10.1007/978-3-030-66415-2_30,
author=""Lalit, Manan and Handberg-Thorsager, Mette and Hsieh, Yu-Wen and Jug, Florian and Tomancak, Pavel"",
editor=""Bartoli, Adrien
and Fusiello, Andrea"",
title=""Registration of Multi-modal Volumetric Images by Establishing Cell Correspondence"",
booktitle=""Computer Vision -- ECCV 2020 Workshops"",
year=""2020"",
publisher=""Springer International Publishing"",
address=""Cham"",
pages=""458--473"",
isbn=""978-3-030-66415-2""
}
```

`PlatyMatch` plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/juglab/PlatyMatch/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,PlatyMatch.DetectNuclei,,,,
499,poser-napari,PoseR-napari,PoseR,0.0.1b4,2023-02-21,2024-11-14,Pierce Mullen,pnm1@st-andrews.ac.uk,BSD-3-Clause,https://github.com/pnm4sfix/PoseR/issues,https://pypi.org/project/PoseR-napari/,,https://github.com/pnm4sfix/PoseR,A deep learning toolbox for decoding animal behaviour,>=3.10,"['napari[all]==0.4.14', 'npe2==0.6.2', 'pydantic==1.10.4', 'numpy==1.23.5', 'magicgui', 'qtpy', 'napari-video', 'napari-plot==0.1.5', 'tables', 'imageio-ffmpeg==0.4.8', 'pytorch-lightning', 'test-tube', 'scikit-learn', 'matplotlib', 'numba', 'networkx', 'seaborn', 'ultralytics', 'torcheval==0.0.7', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# PoseR

[![License BSD-3](https://img.shields.io/pypi/l/PoseR.svg?color=green)](https://github.com/pnm4sfix/PoseR/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/PoseR-napari.svg?color=green)](https://pypi.org/project/PoseR-napari)
[![Python Version](https://img.shields.io/pypi/pyversions/PoseR-napari.svg?color=green)](https://python.org)
[![tests](https://github.com/pnm4sfix/PoseR/workflows/tests/badge.svg)](https://github.com/pnm4sfix/PoseR/actions)
[![codecov](https://codecov.io/gh/pnm4sfix/PoseR/branch/main/graph/badge.svg)](https://codecov.io/gh/pnm4sfix/PoseR)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/PoseR)](https://napari-hub.org/plugins/PoseR)

A deep learning toolbox for decoding animal behaviour

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->
![alt text](https://github.com/pnm4sfix/PoseR/blob/add-functionality/docs/logo.png?raw=true)

## Installation

Create an anaconda environment:

    conda create -n PoseR python=3.10

Activate PoseR environment:

    conda activate PoseR

Install CUDA if using NVIDIA GPU:

    conda install -c ""nvidia/label/cuda-11.7.0"" cuda

Install Pytorch:
For GPU:

    conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia

For CPU only version:

    conda install pytorch torchvision torchaudio cpuonly -c pytorch

Install napari:

    pip install napari[all]==0.4.14 npe2==0.6.2 pydantic==1.10.4


You can install `PoseR` via [pip]:

    pip install PoseR-napari



To install latest development version :

    pip install git+https://github.com/pnm4sfix/PoseR.git


## Quick start

https://github.com/pnm4sfix/PoseR/blob/generalise-species/docs/QuickStart.md

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""PoseR"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/pnm4sfix/PoseR/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/pnm4sfix/PoseR/issues', 'Documentation, https://github.com/pnm4sfix/PoseR#README.md', 'Source Code, https://github.com/pnm4sfix/PoseR', 'User Support, https://github.com/pnm4sfix/PoseR/issues']",,,PoseR-napari.make_qwidget,,,,
500,popidd-io,popidd-io,POPIDD IO,0.0.3,2024-09-30,2025-03-05,Ferran Cardoso Rodriguez,ferran.cardoso@icr.ac.uk,"GNU GENERAL PUBLIC LICENSE
   ...",,https://pypi.org/project/popidd-io/,None,,A simple plugin to read digital pathology images and annotations Made at the IPU (ICR/RMH).,>=3.10,"['magicgui', 'qtpy', 'scikit-image', 'napari', 'numpy', 'zarr<3', 'dask', 'pathlib', 'tifffile==2025.1.10', 'imagecodecs', 'geopandas', 'pyarrow', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'pre-commit; extra == ""testing""']","# popidd-io

[![License GNU GPL v3.0](https://img.shields.io/pypi/l/popidd-io.svg?color=green)](https://github.com/IntegratedPathologyUnit-ICR/popidd-io/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/popidd-io.svg?color=green)](https://pypi.org/project/popidd-io)
[![Python Version](https://img.shields.io/pypi/pyversions/popidd-io.svg?color=green)](https://python.org)
[![tests](https://github.com/IntegratedPathologyUnit-ICR/popidd-io/workflows/tests/badge.svg)](https://github.com/IntegratedPathologyUnit-ICR/popidd-io/actions)
[![codecov](https://codecov.io/gh/IntegratedPathologyUnit-ICR/popidd-io/branch/main/graph/badge.svg)](https://codecov.io/gh/IntegratedPathologyUnit-ICR/popidd-io)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/popidd-io)](https://napari-hub.org/plugins/popidd-io)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.14185575.svg)](https://doi.org/10.5281/zenodo.14185575)



A simple plugin to read digital pathology images and annotations.
Made by Ferran Cardoso at the Integrated Pathology Unit (ICR/RMH).

This is still an experimental and in-development project,
so expect considerable additions and changes to existing methods.
Documentation and tests will be added in the coming weeks.

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation


Setup conda environment

    mamba create -n popidd_io python pip pyqt

Activate conda environment

    mamba activate popidd_io

### End users

You can install `popidd-io` via [pip]:

    pip install popidd-io

### Development

Install test version from project base directory

    pip install -e "".[testing]""

Run dev environment with

    python developing.py

Before contributing, please install and use pre-commit hooks:

    pip install pre-commit
    pre-commit install

## Description

This plugin brings support for brightfield and fluorescence images to Napari,
as well as adding support for polygonal annotations in geoJSON files saved by QuPath.

Brightfield images are loaded as a single layer, incorporating also resolution
information if found on the metadata.
Fluorescence images are separated into channels annotated using the information
present in the image metadata.
Support for this latter modality is still ongoing and will improve in the coming weeks.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Made by Ferran Cardoso Rodriguez with the help of colleagues at the Integrated Pathology Unit.

Distributed under the terms of the [GNU GPL v3.0] license,
""popidd-io"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']",,popidd-io.get_image_reader,,popidd-io.wLoadImage,,"['*.tiff', '*.tif', '*.svs', '*.ndpi', '*.qptiff']",,
501,pssr,pssr,PSSR2,2.4.0,2024-06-01,2025-05-22,Hayden Stites,,MIT,https://github.com/ucsdmanorlab/PSSR2,https://pypi.org/project/pssr/,,,Point-Scanning Super-Resolution 2,">=3.9,<4.0","['czifile (>=2019.7.2,<2020.0.0)', 'magicgui (>=0.6.0,<=0.8.2)', 'napari (>=0.4.13,<0.5.0) ; extra == ""napari""', 'numpy (>=1.22.4,<2.0.0)', 'pillow (>=9.1.0)', 'psutil (>=5.0.0)', 'pytorch-msssim (>=1.0.0,<2.0.0)', 'scikit-image (>=0.18.0)', 'scikit-optimize (>=0.9.0)', 'tifffile (>=2019.7.26)', 'timm (>=0.8.0)', 'torch (>=1.11.0)', 'tqdm (>=4.0.0,<5.0.0)']","# Point-Scanning Super-Resolution 2 (**PSSR2**)

**PSSR2** is a user-friendly [PyTorch](https://pytorch.org)-based workflow for super-resolution tasks using microscopy images.
This is the official reimplementation and extention of the methods described in the original paper: [Deep learning-based point-scanning super-resolution imaging](https://www.nature.com/articles/s41592-021-01080-z).
**PSSR2** contains various improvements from its predecessor, which are elaborated in the following manuscript:
[PSSR2: a user-friendly Python package for democratizing deep learning-based point-scanning super-resolution microscopy](https://bmcmethods.biomedcentral.com/articles/10.1186/s44330-024-00020-5).
If you utilize **PSSR2** in your publication, please consider [citing it](https://bmcmethods.biomedcentral.com/articles/10.1186/s44330-024-00020-5#citeas).

The functionality of **PSSR2** is accessible in three ways:

- Directly through the [Python package](https://pypi.org/project/pssr)
- Through the integrated [Command Line Interface](https://ucsdmanorlab.github.io/PSSR2/reference/CLI.html)
- Through the integrated [Napari plugin](https://ucsdmanorlab.github.io/PSSR2/guide/napari.html)

The **PSSR2** User Guide and full API Reference is available in the [PSSR2 Documentation](https://ucsdmanorlab.github.io/PSSR2).

If you have never used **PSSR2** before, [Getting Started](https://ucsdmanorlab.github.io/PSSR2/guide/start.html) outlines installation and basic usage.
Full reference and explanations of all **PSSR2** tools is available in [API Reference](https://ucsdmanorlab.github.io/PSSR2/reference/api.html).

This package is under continuous development. All code can be found at [https://github.com/ucsdmanorlab/PSSR2](https://github.com/ucsdmanorlab/PSSR2).
If you experience any bugs, unexpected behaviors, or have any suggestions, make sure to [open a ticket](https://github.com/ucsdmanorlab/PSSR2/issues).

","['Development Status :: 5 - Production/Stable', 'Environment :: GPU :: NVIDIA CUDA', 'Framework :: napari', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Documentation :: Sphinx', 'Topic :: Scientific/Engineering :: Artificial Intelligence', 'Topic :: Scientific/Engineering :: Image Processing']","['Documentation, https://ucsdmanorlab.github.io/PSSR2', 'Repository, https://github.com/ucsdmanorlab/PSSR2']",,,pssr.napari.train,,,,
502,psf-analysis-cfim,psf-analysis-CFIM,psf-analysis-CFIM,1.7.6,2025-02-11,2025-07-04,Markus L. Bille,github+Markus@bille.dk,BSD-3-Clause,https://github.com/MaxusTheOne/napari-psf-analysis-CFIM-edition/issues,https://pypi.org/project/psf-analysis-CFIM/,,https://github.com/MaxusTheOne/napari-psf-analysis-CFIM-edition,"A continuation of napari_psf_analysis, developed for CFIM - KU",>=3.9,"['aicsimageio', 'aicspylibczi', 'matplotlib<3.9', 'matplotlib-inline', 'matplotlib-scalebar', 'napari[all]<0.6', 'numpy<2.0,>=1.26', 'pandas', 'pydantic', 'PyYAML', 'QtPy', 'scipy', 'reportlab', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'tox; extra == ""testing""']","# psf-analysis-CFIM

[![License](https://img.shields.io/badge/License-BSD_3--Clause-blue.svg)](https://opensource.org/licenses/BSD-3-Clause)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/psf-analysis-CFIM)](https://napari-hub.org/plugins/psf-analysis-CFIM)

---
![application_screenshot](figs/PSF_CFIM_demo_v170.gif)

## Installation

You can install this package using one of the following options:
```bash
  pip install psf-analysis-CFIM -U
```
For the latest stable version (recommended)

---

or

```bash
  pip install git+https://github.com/MaxusTheOne/napari-psf-analysis-CFIM-edition
```
To install the latest version (not guaranteed to be stable)

---
Additionally, it can be installed via napari plugin manager under the name **psf-analysis-CFIM**.

## About

This is a **fork** of the [napari-psf-analysis](https://github.com/fmi-faim/napari-psf-analysis) project.

The features from this edition are made as requested by the staff at CFIM.

Please contact me through Github or mail for any issues or help with development
---

## Extra Features

This edition includes the following additional features:

- **Bulk Analysis for channels**: Allows for bulk analysis of multiple channels.
  - **Combined Summary**: Adds a combined summary of all channels.
  - **Channel Offset Table**: Adds a table with the relative offset of the channels.
- **Bead Averaging**: Adds an image of an averaged bead from all selected.
- **Visualisation**: Improves visualisation of the psf. Most notable color by wavelength.
  - **Range indicator** Button to mark the min and max values of the image.
- **PSF Report**: Adds a graded report on the quality of the PSF. <- WIP
- **Bead Detection**: Detects beads in the image.
- **Auto-Filling of Plugin Parameters**: Automatically populates parameters for the plugin.
  - At least 1 input also looks better
- **Auto Analysis of Image for PSF**: Performs automatic image analysis to ascertain the quality.
- **CZI Reader**: Adds support for reading CZI image files.
- **Debugging**: Adds a debug class to the IPython console. Small, but hey, we can show the psf box
- **Error Handling**: Less likely to crash. errors points can be seen in viewer | Error UI.
- **Bug fixes**: Fixes bugs involving zyx boxes, loading bar and other issues.

## Known Issues

- for autofilling, only .czi files are supported. Unlikely to work with other formats.
- Installing plugin under paths including non-ASCII characters, like ""Ã¦Ã¸Ã¥"" cause unintended behavior.
- The output.csv file is comma seperated with dot as decimal seperator, this might require a legacy workaround in programs like Excel.
- Intensity for bead finder is hardcoded for now.
- Some images might still crash in the analysis.
- Might have missed some requirements


## License

Distributed under the terms of the [BSD-3] license,
""psf-analysis-CFIM"" is free and open source software
","['Development Status :: 5 - Production/Stable', 'Framework :: napari', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Visualization']","['Documentation, https://github.com/MaxusTheOne/napari-psf-analysis-CFIM-edition#README.md', 'Source Code, https://github.com/MaxusTheOne/napari-psf-analysis-CFIM-edition', 'Issue Tracker, https://github.com/MaxusTheOne/napari-psf-analysis-CFIM-edition/issues']",psf-analysis-CFIM.czi_reader.read_czi,,psf-analysis-CFIM.PsfAnalysis,,['*.czi'],,
503,qhyccd-capture,qhyccd-capture,qhyccd-capture,0.0.4.0,2024-10-23,2024-12-10,QHYCCD,lq@qhyccd.com,Unavailable,,https://pypi.org/project/qhyccd-capture/,None,,The basic operations for QHYCCD series cameras,>=3.9,"['numpy', 'magicgui', 'qtpy', 'opencv-python', 'PyQt5', 'matplotlib', 'astropy', 'psutil', 'photutils<1.14.0,>=1.11.0', 'pybind11', 'pyqtgraph', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""']","# qhyccd-capture

## Project Introduction

`qhyccd-capture` is a basic operation library for handling QHYCCD series cameras. This library provides functionalities to interact with QHYCCD cameras, including camera connection, parameter setting, image capture, and display. This project is a [napari] plugin, aimed at simplifying the use of the camera through a graphical user interface.

## Features

- **Camera Connection**: Supports loading the corresponding QHYCCD dynamic link libraries on different operating systems (such as Windows, Linux, macOS) and initializing camera resources.
- **Parameter Setting**: Provides the functionality to set camera parameters, such as exposure time, gain, offset, USB bandwidth, etc.
- **Image Capture**: Supports single-frame mode exposure and retrieves image data.
- **Image Display**: Displays captured images through napari, supports distributed display, single display, and sequence display modes.
- **Histogram and White Balance**: Provides histogram equalization and white balance adjustment functions.
- **ROI (Region of Interest)**: Supports creating and applying ROIs to operate on specific areas.
- **Video Recording**: Supports video recording and saves in various video formats.
- **Temperature Control**: Supports temperature control and displays temperature.
- **CFW Control**: Supports CFW control and displays CFW status.
- **Star Point Resolution**: Supports star point resolution and displays the results.

![qhyccd-capture æä»¶çé¢æ¾ç¤º](https://raw.githubusercontent.com/LiuQiang-AI/qhyccd-capture/main/src/qhyccd_capture/images/image.png)

## Installation
You can install via pip:

    pip install qhyccd-capture

To install the latest development version:

    pip install git+https://github.com/nightliar-L/qhyccd-capture.git

## Dependency Installation
#### Astrometry.net 
Currently, astrometry.net only supports the Ubuntu system.

    sudo apt-get install astrometry.net
    sudo apt-get install astrometry-data-tycho2
    sudo vim ~/.bashrc
    # Add the following content
    export PATH=$PATH:/usr/local/astrometry/bin

## Version Changes

- 2024-10-23 Version 0.0.1 Initial version
- 2024-10-24 Version 0.0.2 Fixed some issues introduced by the release
- 2024-10-24 Version 0.0.3 Optimized some functions and processing logic

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""qhyccd-capture"" is free and open source software
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']",,qhyccd-capture.read_raw_image,,qhyccd-capture.qhyccd_capture,,['*.raw'],,
504,pycudadecon,pycudadecon,pyCUDAdecon,0.5.1,2022-08-10,2024-08-15,Talley Lambert,Talley Lambert <talley.lambert@gmail.com>,MIT,https://github.com/tlambert03/pycudadecon/issues,https://pypi.org/project/pycudadecon/,,,Python wrapper for CUDA-accelerated 3D deconvolution,>=3.8,"['numpy', 'tifffile', 'typing-extensions', ""ipython; extra == 'dev'"", ""mypy; extra == 'dev'"", ""pdbpp; extra == 'dev'"", ""pre-commit; extra == 'dev'"", ""rich; extra == 'dev'"", ""ruff; extra == 'dev'"", ""furo==2022.9.29; extra == 'docs'"", ""ghp-import==2.1.0; extra == 'docs'"", ""jupyter-book==0.13.1; extra == 'docs'"", ""sphinx-autodoc-typehints==1.19.1; extra == 'docs'"", ""pytest-cov; extra == 'test'"", ""pytest>=6.0; extra == 'test'""]","# pyCUDAdecon

This package provides a python wrapper and convenience functions for
[cudaDecon](https://github.com/scopetools/cudaDecon), which is a CUDA/C++
implementation of an accelerated Richardson Lucy Deconvolution
algorithm<sup>1</sup>.

* CUDA accelerated deconvolution with a handful of artifact-reducing features.
* radially averaged OTF generation with interpolation for voxel size
  independence between PSF and data volumes
* 3D deskew, rotation, general affine transformations
* CUDA-based camera-correction for [sCMOS artifact correction](https://llspy.readthedocs.io/en/latest/camera.html)


### Install

The conda package includes the required pre-compiled libraries for Windows and Linux. See GPU driver requirements [below](#gpu-requirements)

```sh
conda install -c conda-forge pycudadecon
```

*macOS is not supported*

### ð   &nbsp; [Documentation](http://www.talleylambert.com/pycudadecon)


### GPU requirements

This software requires a CUDA-compatible NVIDIA GPU. The underlying cudadecon
libraries have been compiled against different versions of the CUDA toolkit.
The required CUDA libraries are bundled in the conda distributions so you don't
need to install the CUDA toolkit separately.  If desired, you can pick which
version of CUDA you'd like based on your needs, but please note that different
versions of the CUDA toolkit have different GPU driver requirements:

To specify a specific cudatoolkit version, install as follows (for instance, to
use `cudatoolkit=10.2`)

```sh
conda install -c conda-forge pycudadecon cudatoolkit=10.2
```

| CUDA | Linux driver | Win driver |
| ---- | ------------ | ---------- |
| 10.2 | â¥ 440.33     | â¥ 441.22   |
| 11.0 | â¥ 450.36.06  | â¥ 451.22   |
| 11.1 | â¥ 455.23     | â¥ 456.38   |
| 11.2 | â¥ 460.27.03  | â¥ 460.82   |


If you run into trouble, feel free to [open an
issue](https://github.com/tlambert03/pycudadecon/issues) and describe your
setup.


## Usage


The [`pycudadecon.decon()`](https://www.talleylambert.com/pycudadecon/deconvolution.html#pycudadecon.decon) function is designed be able to handle most basic applications:

```python
from pycudadecon import decon

# pass filenames of an image and a PSF
result = decon('/path/to/3D_image.tif', '/path/to/3D_psf.tif')

# decon also accepts numpy arrays
result = decon(img_array, psf_array)

# the image source can also be a sequence of arrays or paths
result = decon([img_array, '/path/to/3D_image.tif'], psf_array)

# see docstrings for additional parameter options
```

For finer-tuned control, you may wish to make an OTF file from your PSF using [`pycudadecon.make_otf()`](https://www.talleylambert.com/pycudadecon/otf.html#pycudadecon.make_otf), and then use the [`pycudadecon.RLContext`](https://www.talleylambert.com/pycudadecon/deconvolution.html#pycudadecon.RLContext) context manager to setup the GPU for use with the [`pycudadecon.rl_decon()`](https://www.talleylambert.com/pycudadecon/deconvolution.html#pycudadecon.rl_decon) function.  (Note all images processed in the same context must have the same input shape).

```python
from pycudadecon import RLContext, rl_decon
from glob import glob
import tifffile

image_folder = '/path/to/some_images/'
imlist = glob(image_folder + '*488*.tif')
otf_path = '/path/to/pregenerated_otf.tif'

with tifffile.TiffFile(imlist[0]) as tf:
    imshape = tf.series[0].shape

with RLContext(imshape, otf_path, dz) as ctx:
    for impath in imlist:
        image = tifffile.imread(impath)
        result = rl_decon(image, ctx.out_shape)
        # do something with result...
```

If you have a 3D PSF volume, the [`pycudadecon.TemporaryOTF`](https://www.talleylambert.com/pycudadecon/otf.html#pycudadecon.TemporaryOTF) context manager facilitates temporary OTF generation...

```python
 # continuing with the variables from the previous example...
 psf_path = ""/path/to/psf_3D.tif""
 with TemporaryOTF(psf) as otf:
     with RLContext(imshape, otf.path, dz) as ctx:
         for impath in imlist:
             image = tifffile.imread(impath)
             result = rl_decon(image, ctx.out_shape)
             # do something with result...
```

... and that bit of code is essentially what the [`pycudadecon.decon()`](https://www.talleylambert.com/pycudadecon/deconvolution.html#pycudadecon.decon) function is doing, with a little bit of additional conveniences added in.

*Each of these functions has many options and accepts multiple keyword arguments. See the [documentation](https://www.talleylambert.com/pycudadecon/index.html) for further information on the respective functions.*

For examples and information on affine transforms, volume rotations, and deskewing (typical of light sheet volumes acquired with stage-scanning), see the [documentation on Affine Transformations](https://www.talleylambert.com/pycudadecon/affine.html)
___

<sup>1</sup> D.S.C. Biggs and M. Andrews, Acceleration of iterative image restoration algorithms, Applied Optics, Vol. 36, No. 8, 1997. https://doi.org/10.1364/AO.36.001766
","['Development Status :: 4 - Beta', 'Environment :: GPU :: NVIDIA CUDA', 'Framework :: napari', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: MIT License', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering']","['Documentation, https://tlambert03.github.io/pycudadecon/', 'Source, https://github.com/tlambert03/pycudadecon', 'Tracker, https://github.com/tlambert03/pycudadecon/issues']",,,pycudadecon.deconvolve,,,,
505,quantpunc,quantpunc,QuantPunc,0.0.1.post1,2025-07-30,2025-07-31,tehahn,,Unavailable,https://github.com/tehahn/quantpunc/,https://pypi.org/project/quantpunc/,,,A Napari plugin for puncta analysis and quantification in 2D microscopy images.,>=3.10,"['numpy<2.3', 'magicgui', 'qtpy', 'scikit-image', 'scikit-learn>=1.6.1', 'pywavelets>=1.6.0', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# QuantPunc

[![PyPI](https://img.shields.io/pypi/v/quantpunc.svg?color=green)](https://pypi.org/project/quantpunc)
[![Python Version](https://img.shields.io/pypi/pyversions/quantpunc.svg?color=green)](https://python.org)
[![License BSD-3](https://img.shields.io/pypi/l/quantpunc.svg?color=green)](https://github.com/tehahn/quantpunc/blob/main/LICENSE)

QuantPunc is a Napari plugin for puncta analysis and quantification in 2D microscopy images. A brief overview of QuantPunc's workflow can be found below. 

A comprehensive guide to QuantPunc can be found at https://tehahn.github.io/quantpunc/.

QuantPunc is currently in beta. Please report any problems to the [issues page].

## Features
1. Automated puncta labeling and counting
2. Watershed segmentation
3. Colocalization analysis 
4. Exportable counts and stats

## Installation
You can install `quantpunc` via Napari's plugin manager:

1. Click on ""Plugins"" in the toolbar.
2. Click on ""Install/Uninstall Plugins..."" in the context menu.
3. Type ""quantpunc"" in the searchbar.
4. Click install.

You can also install `quantpunc` via [pip]:

    pip install quantpunc

## Puncta Quantification and Workflow
Hereâs an ideal, high-level workflow for puncta segmentation and quantification. This is the recommended way of using QuantPunc. However, QuantPuncâs widgets are modularly designed so that they can be used as standalone tools. If this is your first time working with these tools, you can access the more in-depth guide mentioned above [here].

### 1. Preprocessing (optional but recommended)
QuantPunc uses wavelet denoising and adaptive histogram equalization to enhance edge information and contrast in your image. If you feel that your image has sufficient contrast and minimal noise, feel free to skip this step.

<img 
src=""https://raw.githubusercontent.com/tehahn/quantpunc/refs/heads/main/demo_imgs/preprocessing_example.gif"" 
alt="""" 
width=""1000""
style=""border-radius: 10px; max-width: 100%;"">

### 2. Automated labeling
There are two automated labeling methods. One of them uses [skimageâs blob detection] algorithms and the other uses a random forest classifier with features inspired by [ilastik]. You also have the option to only segment puncta within ROIs. You can provide your own ROIs or create them using a labels layer in Napari.

### Random forest classifier (RFC)
You can use Napari to create annotations or provide your own. After annotating your puncta and specifying your integer labels, you can then train the RFC. Click on *Label puncta* to segment your puncta.

<img 
src=""https://raw.githubusercontent.com/tehahn/quantpunc/refs/heads/main/demo_imgs/rfc_example.gif"" 
alt="""" 
width=""1000""
style=""border-radius: 10px; max-width: 100%;"">

### Skimage blob detection
Select your favorite blob detection algorithm from the *Method* dropdown menu. After parameterizing it, click on *Label puncta*.

<img 
src=""https://raw.githubusercontent.com/tehahn/quantpunc/refs/heads/main/demo_imgs/skimage_blob_example.gif"" 
alt="""" 
width=""1000""
style=""border-radius: 10px; max-width: 100%;"">

### 3. Manual labeling
You can remove any puncta labels you donât want from automated segmentation by using Napariâs layer control toolbar. You also have the option to do a full manual segmentation using a labels layer and quantify your annotations after.

### 4. Watershed segmentation (optional)
If your puncta exhibits lots of clumping, you can use the watershed tool to perform instance segmentation on your puncta labels layer. You can choose either to use a distance transform or Sobel filter to generate the elevation map.

<img 
src=""https://raw.githubusercontent.com/tehahn/quantpunc/refs/heads/main/demo_imgs/watershed_example.gif""
alt="""" 
width=""1000""
style=""border-radius: 10px; max-width: 100%;"">

### Seed point generation
You can either provide your own seed points or generate them using skimageâs blob counting algorithms with a low min and max sigma.

### 5. Puncta counting
After you have a segmentation youâre happy with, select the image you want to quantify and click *Count puncta*. Make sure that your puncta labels layer is named after the image youâre quantifying with â_punctaâ as its suffix, e.g., âyour_img_punctaâ.

<img 
src=""https://raw.githubusercontent.com/tehahn/quantpunc/refs/heads/main/demo_imgs/counts_example.gif"" 
alt="""" 
height=""750""
style=""border-radius: 10px; max-width: 100%;"">

### 6. Colocalization analysis (optional)
Colocalization is measured using the intersection over union (IoU), aka the Jaccard Index. Select two puncta labels layers and click on *Compute IoU*.

<img 
src=""https://raw.githubusercontent.com/tehahn/quantpunc/refs/heads/main/demo_imgs/coloc_example.gif"" 
alt="""" 
height=""750""
style=""border-radius: 10px; max-width: 100%;"">

### 7. Displaying stats and saving
Click on any of the tabs in the table widget to view different summaries of the puncta youâve quantified. To export the tables as a csv for the layer youâve selected, click on *Save selected data*. If you want to save the data for all the images youâve quantified click on *Save all data*.

## Contributing
Contributions are very, very welcome. QuantPunc allows you to implement your own automated puncta labeler. Look in the Github repo at [abstract_puncta_labeler] to see what methods need to be implemented and [default_puncta_labelers] for examples. If you're interested in making it available to everyone else or have any other improvements, feel free to send a pull request!

## License
Distributed under the terms of the [BSD-3] license,
QuantPunc is free and open source software

## Issues
QuantPunc is still in beta, so bugs are to be expected. Please report any problems to the [issues page].


[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[pip]: https://pypi.org/project/pip/

[ilastik]: https://www.ilastik.org/
[skimageâs blob detection]: https://scikit-image.org/docs/0.25.x/auto_examples/features_detection/plot_blob.html

[abstract_puncta_labeler]: https://github.com/tehahn/quantpunc/blob/main/src/quantpunc/quantification/abstract_puncta_labeler.py
[default_puncta_labelers]: https://github.com/tehahn/quantpunc/blob/main/src/quantpunc/quantification/default_puncta_labelers.py

[Napari hub]: https://napari-hub.org/plugins/quantpunc.html
[here]: https://tehahn.github.io/quantpunc/
[issues page]: https://github.com/tehahn/quantpunc/issues
","['Development Status :: 4 - Beta', 'Framework :: napari', 'Intended Audience :: Science/Research', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering :: Image Processing']","['Documentation, https://tehahn.github.io/quantpunc/', 'Repository, https://github.com/tehahn/quantpunc/']",,,quantpunc.create_puncta_counter,,,,
506,psfmodels,psfmodels,psfmodels,0.3.3,2022-04-17,2023-05-06,Talley Lambert,talley.lambert@gmail.com,GPL-3.0,https://github.com/tlambert03/psfmodels,https://pypi.org/project/psfmodels/,,https://github.com/tlambert03/psfmodels,Scalar and vectorial models of the microscope point spread function (PSF).,>=3.7,"['numpy', 'scipy (>=0.14.0)', 'typing-extensions', ""black ; extra == 'dev'"", ""flake8 ; extra == 'dev'"", ""flake8-docstrings ; extra == 'dev'"", ""flake8-typing-imports ; extra == 'dev'"", ""ipython ; extra == 'dev'"", ""isort ; extra == 'dev'"", ""mypy ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""pydocstyle ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""pytest-cov ; extra == 'dev'"", ""tox ; extra == 'dev'"", ""tox-conda ; extra == 'dev'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""jax ; extra == 'testing'"", 'magicgui ; (platform_system != ""Linux"") and extra == \'testing\'', 'qtpy ; (platform_system != ""Linux"") and extra == \'testing\'', 'pyside2 ; (platform_system != ""Linux"" and python_version < ""3.11"") and extra == \'testing\'']","# psfmodels

[![PyPI](https://img.shields.io/pypi/v/psfmodels.svg?color=green)](https://pypi.org/project/psfmodels)
[![Python
Version](https://img.shields.io/pypi/pyversions/psfmodels.svg?color=green)](https://python.org)
[![CI](https://github.com/tlambert03/psfmodels/actions/workflows/ci.yml/badge.svg)](https://github.com/tlambert03/psfmodels/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/tlambert03/psfmodels/branch/main/graph/badge.svg)](https://codecov.io/gh/tlambert03/psfmodels)

Python bindings for scalar and vectorial models of the point spread function.

Original C++ code and MATLAB MEX bindings Copyright &copy; 2006-2013, [Francois
Aguet](http://www.francoisaguet.net/software.html), distributed under GPL-3.0
license. Python bindings by Talley Lambert

This package contains three models:

1. The vectorial model is described in Auget et al 2009<sup>1</sup>. For more
information and implementation details, see Francois' Thesis<sup>2</sup>.
2. A scalar model, based on Gibson & Lanni<sup>3</sup>.
3. A gaussian approximation (both paraxial and non-paraxial), using paramters from Zhang et al (2007)<sup>4</sup>.

<small>

<sup>1</sup> [F. Aguet et al., (2009) Opt. Express 17(8), pp.
6829-6848](https://doi.org/10.1364/OE.17.006829)

<sup>2</sup> [F. Aguet. (2009) Super-Resolution Fluorescence Microscopy Based on
Physical Models. Swiss Federal Institute of Technology Lausanne, EPFL Thesis no.
4418](http://bigwww.epfl.ch/publications/aguet0903.html)

<sup>3</sup> [F. Gibson and F. Lanni (1992) J. Opt. Soc. Am. A, vol. 9, no. 1, pp. 154-166](https://opg.optica.org/josaa/abstract.cfm?uri=josaa-9-1-154)

<sup>4</sup> [Zhang et al (2007). Appl Opt
. 2007 Apr 1;46(10):1819-29.](https://doi.org/10.1364/AO.46.001819)

</small>

### see also:

For a different (faster) scalar-based GibsonâLanni PSF model, see the
[MicroscPSF](https://github.com/MicroscPSF) project, based on [Li et al
(2017)](https://doi.org/10.1364/JOSAA.34.001029) which has been implemented in
[Python](https://github.com/MicroscPSF/MicroscPSF-Py),
[MATLAB](https://github.com/MicroscPSF/MicroscPSF-Matlab), and
[ImageJ/Java](https://github.com/MicroscPSF/MicroscPSF-ImageJ)

## Install

```sh
pip install psfmodels
```

### from source

```sh
git clone https://github.com/tlambert03/PSFmodels.git
cd PSFmodels
pip install -e "".[dev]""  # will compile c code via pybind11
```

## Usage

There are two main functions in `psfmodels`: `vectorial_psf` and `scalar_psf`.
Additionally, each version has a helper function called `vectorial_psf_centered`
and `scalar_psf_centered` respectively. The main difference is that the `_psf`
functions accept a vector of Z positions `zv` (relative to coverslip) at which
PSF is calculated. As such, the point source may or may not actually be in the
center of the rendered volume. The `_psf_centered` variants, by contrast, do
_not_ accecpt `zv`, but rather accept `nz` (the number of z planes) and `dz`
(the z step size in microns), and always generates an output volume in which the
point source is positioned in the middle of the Z range, with planes equidistant
from each other. All functions accept an argument `pz`, specifying the position
of the point source relative to the coverslip. See additional keyword arguments
below

_Note, all output dimensions (`nx` and `nz`) should be odd._

```python
import psfmodels as psfm
import matplotlib.pyplot as plt
from matplotlib.colors import PowerNorm

# generate centered psf with a point source at `pz` microns from coverslip
# shape will be (127, 127, 127)
psf = psfm.make_psf(127, 127, dxy=0.05, dz=0.05, pz=0)
fig, (ax1, ax2) = plt.subplots(1, 2)
ax1.imshow(psf[nz//2], norm=PowerNorm(gamma=0.4))
ax2.imshow(psf[:, nx//2], norm=PowerNorm(gamma=0.4))
plt.show()
```

![Image of PSF](fig.png)

```python
# instead of nz and dz, you can directly specify a vector of z positions
import numpy as np

# generate 31 evenly spaced Z positions from -3 to 3 microns
psf = psfm.make_psf(np.linspace(-3, 3, 31), nx=127)
psf.shape  # (31, 127, 127)
```

**all** PSF functions accept the following parameters. Units should be provided
in microns unless otherwise stated. Python API may change slightly in the
future.  See function docstrings as well.

```
nx (int):       XY size of output PSF in pixels, must be odd.
dxy (float):    pixel size in sample space (microns) [default: 0.05]
pz (float):     depth of point source relative to coverslip (in microns) [default: 0]
ti0 (float):    working distance of the objective (microns) [default: 150.0]
ni0 (float):    immersion medium refractive index, design value [default: 1.515]
ni (float):     immersion medium refractive index, experimental value [default: 1.515]
tg0 (float):    coverslip thickness, design value (microns) [default: 170.0]
tg (float):     coverslip thickness, experimental value (microns) [default: 170.0]
ng0 (float):    coverslip refractive index, design value [default: 1.515]
ng (float):     coverslip refractive index, experimental value [default: 1.515]
ns (float):     sample refractive index [default: 1.47]
wvl (float):    emission wavelength (microns) [default: 0.6]
NA (float):     numerical aperture [default: 1.4]
```

## Comparison with other models

While these models are definitely slower than the one implemented in [Li et al
(2017)](https://doi.org/10.1364/JOSAA.34.001029) and
[MicroscPSF](https://github.com/MicroscPSF), there are some interesting
differences between the scalar and vectorial approximations, particularly with
higher NA lenses, non-ideal sample refractive index, and increasing spherical
aberration with depth from the coverslip.

For an interactive comparison, see the [examples.ipynb](notebooks/examples.ipynb) Jupyter
notebook.

## Lightsheet PSF utility function

The `psfmodels.tot_psf()` function provides a quick way to simulate the total
system PSF (excitation x detection) as might be observed on a light sheet
microscope (currently, only strictly orthogonal illumination and detection are
supported).  See the [lightsheet.ipynb](notebooks/lightsheet.ipynb) Jupyter notebook for
examples.
","['Development Status :: 3 - Alpha', 'Framework :: napari', 'License :: OSI Approved :: GNU General Public License v3 (GPLv3)', 'Natural Language :: English', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10']","['Source Code, https://github.com/tlambert03/psfmodels']",,,psfmodels.make_psf,,,,
507,samcell-napari,samcell-napari,samcell-napari,1.0.0,2025-04-02,2025-04-14,Saahil Sanganeriya,saahilsanganeria666@gmail.com,Unavailable,https://github.com/saahilsanganeriya/samcell-napari/issues,https://pypi.org/project/samcell-napari/,,https://github.com/saahilsanganeriya/samcell-napari,A napari plugin for cell segmentation with SAMCell 1.0,>=3.8,"['napari>=0.4.14', 'numpy', 'torch>=1.9', 'transformers>=4.26.0', 'scikit-image>=0.19.0', 'opencv-python>=4.5.0', 'timm>=0.6.0', 'safetensors>=0.3.0; extra == ""safetensors""', 'black; extra == ""dev""', 'pytest; extra == ""dev""', 'pytest-cov; extra == ""dev""']","# samcell-napari

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PyPI](https://img.shields.io/pypi/v/samcell-napari)](https://pypi.org/project/samcell-napari/)

A napari plugin for cell segmentation using the Segment Anything Model (SAM) foundation model.

![SAMCell Segmentation Example](https://github.com/saahilsanganeriya/samcell-napari/raw/main/docs/images/samcell-napari.jpg)

## Description

SAMCell-napari provides an intuitive interface for segmenting cells in microscopy images using deep learning. It leverages the power of the Segment Anything Model (SAM) adapted specifically for biological cell segmentation, providing accurate results with minimal tuning.

### Key Features:
- Simple, user-friendly interface within napari
- Compatible with SAMCell models in multiple formats (`.pt`, `.bin`, `.safetensors`)
- Support for both SAM-ViT-Base and SAM-ViT-Large model architectures
- Adjustable segmentation parameters for fine-tuning
- Real-time visualization of results
- Distance map visualization for analyzing cell proximity
- Full integration with napari's layer system
- Enhanced sliding window algorithm with advanced blending for seamless segmentation of large images

### What's New in v1.0.0:
- Support for multiple model file formats (`.pt`, `.bin`, `.safetensors`)
- Improved sliding window algorithm with smooth blending between crops
- Better handling of small images and edge cases
- Enhanced error recovery and logging
- Multiple threshold testing capability
- Optimized default thresholds for better segmentation results
- Support for both SAM-ViT-Base and SAM-ViT-Large model variants

## Installation

You can install `samcell-napari` via [pip]:

```bash
pip install samcell-napari
```

To install latest development version:

```bash
pip install git+https://github.com/saahilsanganeriya/samcell-napari.git
```

## Usage

1. Start napari
   ```bash
   napari
   ```

2. Load your image in napari

3. Open the SAMCell plugin:
   ```
   Plugins > samcell-napari > SAMCell Segmentation
   ```

4. Provide the path to your SAMCell model file (supports `.pt`, `.bin`, or `.safetensors` formats)
   - You can download pre-trained models from the [official SAMCell release page](https://github.com/saahilsanganeriya/SAMCell/releases/tag/v1)

5. Adjust parameters if needed:
   - Cell peak threshold: Higher values detect fewer cells (default: 0.47)
   - Cell fill threshold: Lower values create larger cells (default: 0.09)
   - Crop size: Size of image crops for processing (default: 256)

6. Click ""Run Segmentation""

7. View the segmentation results in napari as a Labels layer

## Requirements

- Python 3.8 or higher
- napari 0.4.14 or higher
- PyTorch 1.9 or higher
- transformers 4.20.0 or higher
- CUDA-capable GPU recommended for faster processing

## Model Compatibility

The plugin is compatible with SAMCell model files in multiple formats:
- PyTorch model files (`.pt`)
- Binary model files (`.bin`) - including the standard `pytorch_model.bin`
- SafeTensors files (`.safetensors`) - a safer alternative to PyTorch's pickle-based format

The plugin supports models based on:
- SAM-ViT-Base architecture - Primary model type
- SAM-ViT-Large architecture - Fallback if a model doesn't load with base architecture

Pre-trained models can be downloaded from the [official SAMCell release page](https://github.com/saahilsanganeriya/SAMCell/releases/tag/v1).

Recommended models include:
- SAMCell1.0-Cellpose-cyto: Trained on the Cellpose cytoplasm dataset
- SAMCell1.0-livecell: Trained on the LiveCELL dataset

These models are part of the release assets for the paper ""SAMCell: Generalized Label-Free Biological Cell Segmentation with Segment Anything"".

## How It Works

SAMCell operates using an enhanced sliding window approach to process large images:

1. The image is divided into overlapping crops with intelligent handling of image boundaries
2. Each crop is processed through a SAM-based model
3. A distance map is created, representing cell centers and boundaries
4. The crops are stitched back together with smooth blending for seamless transitions
5. The distance map is processed to extract individual cell masks using watershed segmentation
6. Results are displayed in napari as labels

## Technical Details

### Model Type Detection

The plugin intelligently determines the appropriate SAM model architecture:
1. First tries to load the model with SAM-ViT-Base architecture
2. If that fails, automatically falls back to SAM-ViT-Large
3. This ensures maximum compatibility with various pre-trained models

### Sliding Window Algorithm

The plugin uses an advanced sliding window algorithm that:
- Handles images of any size, including those smaller than the crop size
- Creates appropriate overlaps between crops to ensure no cells are missed
- Uses a cosine-based blending mask to create smooth transitions between crops
- Fills any potential gaps using nearest neighbor interpolation

### Multiple Threshold Testing

For researchers who want to optimize segmentation parameters, the plugin includes a batch processing capability to test multiple threshold combinations at once (available via the API).

## Contributing

Contributions are very welcome! Please feel free to submit a Pull Request.

## License

Distributed under the MIT License. See `LICENSE` for more information.

## Citation

If you use this plugin in your research, please cite:

```
@article{samcell2023,
  title={SAMCell: Generalized Label-Free Biological Cell Segmentation with Segment Anything},
  author={...},
  journal={...},
  year={2023}
}
``` 
","['Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Framework :: napari', 'Intended Audience :: Science/Research', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/saahilsanganeriya/samcell-napari/issues']",,,samcell-napari.widget,samcell-napari.data.sample_2d,,,
508,segment-embryo,segment-embryo,Embryo Segmentation,0.5,2024-11-27,2025-01-15,Volker Baecker,volker.baecker@mri.cnrs.fr,MIT,https://github.com/MontpellierRessourcesImagerie/segment-embryo/releases,https://pypi.org/project/segment-embryo/,,,"3D Segment ascidian embryos using cellpose. The images are first rescaled to be isotropic and then downscaled, before cellpose is used. The resulting labels are upscaled to match the original data.",>=3.9,"['numpy', 'magicgui', 'qtpy', 'scikit-image', 'cellpose', 'czifile', 'napari-czifile2', 'set-calibration', 'big-fish', 'napari-bigfish', 'scikit-image', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""', 'numpy; extra == ""testing""']","# segment-embryo

[![License MIT](https://img.shields.io/pypi/l/segment-embryo.svg?color=green)](https://github.com/MontpellierRessourcesImagerie/segment-embryo/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/segment-embryo.svg?color=green)](https://pypi.org/project/segment-embryo)
[![Python Version](https://img.shields.io/pypi/pyversions/segment-embryo.svg?color=green)](https://python.org)
[![tests](https://github.com/MontpellierRessourcesImagerie/segment-embryo/workflows/tests/badge.svg)](https://github.com/MontpellierRessourcesImagerie/segment-embryo/actions)
[![codecov](https://codecov.io/gh/MontpellierRessourcesImagerie/segment-embryo/branch/main/graph/badge.svg)](https://codecov.io/gh/MontpellierRessourcesImagerie/segment-embryo)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/segment-embryo)](https://napari-hub.org/plugins/segment-embryo)

<img src=""https://github.com/user-attachments/assets/4459f48c-435f-489d-b27c-25a4ea390871"" align='left' width=""30%""></img> 3D Segment ascidian embryos using cellpose. The images are first rescaled to be isotropic and then downscaled, before cellpose is used. The resulting labels are upscaled to match the original data.

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `segment-embryo` via [pip]:

    pip install segment-embryo

## Usage

We will segment the cells of an embryo and count the mRNA spots tagged in another channel per cell.

### 1. Opening an image

Drag a tif- or czi-file from your file-browser and drop it into the napari window. The image will opened. The napari-plugin [napari-czifile2](https://github.com/BodenmillerGroup/napari-czifile2) is used to open czi-files.

### 2. Checking and modifying the voxel size 

Open the plugin [Scale-Tool plugin](https://pypi.org/project/set-calibration/) from the ``Plugins``-menu. Make sure the voxel-size values are set correctly in nm. Correct the values and the unit if necessary and press the ``Apply to all`` button.

<img src=""https://github.com/user-attachments/assets/409b669b-675f-495f-ba11-c6ded0442b2b"" align='left' width=""30%""></img> 

### 3. Segmenting the cells of the embryo

<img src=""https://github.com/user-attachments/assets/1b464f39-47ff-412d-bdb8-c2d61837af39"" align='right' width=""30%""></img> 

Close the [Scale-Tool plugin](https://pypi.org/project/set-calibration/) and open the ``Embryo Segmentation``-plugin from the ``Plugins``-menu. Select the layer containing the membranes as ``input image`` and the layer containing the nuclei as ``nuclei image``. Press the ``run`` button and wait until the segmentation is finished. When the segmentation is finished a ``Labels layer`` with the result will be added to the layers list. 

<img src=""https://github.com/user-attachments/assets/4dcf8aad-22ef-4a20-a6a6-50bcb81c7011"" align='left' width=""20%""></img> 

### 4. Exporting and curating the labels

If the labels need curation, select  the labels layer and save it to a tiff-file via the menu ``File>Save Selected Layers...``. Import the saved labels into the [Morphonet 2 standalone client](https://morphonet.org/downloads), make the corrrections and export the corrected labels to a tiff-file. Open the tiff-file in napari.

### 5. Detecting spots

Close the ``Embryo Segmentation`` plugin, select the layer containing the mRNA-spots and open the [Detect FISH spots-plugin](https://www.napari-hub.org/plugins/napari-bigfish) from the ``Plugins``-menu. Estimate the spot size in xy and z in ImageJ and enter the values into the corresponding fields. You can either estimate the threshold let the software find a threshold value. Press the ``detect spots button``. Depending on the result you might want to modify the threshold-value and run the plugin again.

<img src=""https://github.com/user-attachments/assets/6507eb3e-d732-4d69-8c63-02d83f8975f1"" align='left' width=""30%""></img> 

### 6. Counting Spots per cell

In the ``Spot Counting`` section of the plugin, select the spots layer as input and the labels layer for the ``cytoplasm labels`` and also for the ``nuclei labels``. 

![image](https://github.com/user-attachments/assets/445da47f-c3fc-4437-803d-e635500bf1af)

Press the ``Count Spots`` button! You will obtain a table with the numbers of spots per cell. If you provide the image twice, for the cytoplasm as well as for the nuclei, the spots will all be counted inside the nuclei. If you also want to know per cell how many spots are in the nucleus and how many are in the cytoplasm, you need to provide a mask or label image for the nuclei. You can obtain one by thresholding the nucleus image or by selecting ``segment nuclei`` in step 3.


<img src=""https://github.com/user-attachments/assets/7f325bc5-baaf-4b74-b240-f174b81d0e96"" align='left' width=""30%""></img>
<img src=""https://github.com/user-attachments/assets/463072c7-d647-4d23-90d9-15de3398bf31"" align='right' width=""30%""></img>

You can copy the data from the table to your spreadsheat software. Activate the table by clicking into it and press ``ctrl+a`` to select all rows and columns. Press ``ctrl+c`` to copy the data to the clipboard and ``ctrl+v`` to paste it into your spreadsheet.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""segment-embryo"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Topic :: Scientific/Engineering :: Image Processing']","['Homepage, https://github.com/MontpellierRessourcesImagerie/segment-embryo', 'Documentation, https://github.com/MontpellierRessourcesImagerie/segment-embryo#segment-embryo', 'Repository, https://github.com/MontpellierRessourcesImagerie/segment-embryo.git', 'Issues, https://github.com/MontpellierRessourcesImagerie/segment-embryo/issues', 'Changelog, https://github.com/MontpellierRessourcesImagerie/segment-embryo/releases']",,,segment-embryo.make_qwidget,segment-embryo.make_sample_data,,,
509,segmentree,SegmenTree,SegTree,0.1.dev12,2025-04-18,2025-04-18,Herearii Metuarea,herearii.metuarea@univ-angers.fr,"Copyright (c) 2025, Herearii M...",https://github.com/hereariim/segtree/issues,https://pypi.org/project/SegmenTree/,,,Individual tree segmentation,==3.10.16,"['torch>=2.3.1', 'torchvision>=0.18.1', 'numpy', 'magicgui', 'qtpy', 'aiofiles==23.2.1', 'altair==5.5.0', 'annotated-types==0.7.0', 'antlr4-python3-runtime==4.9.3', 'anyio==4.9.0', 'attrs==25.3.0', 'certifi==2025.1.31', 'charset-normalizer==3.4.1', 'click==8.1.8', 'coloredlogs==15.0.1', 'contourpy==1.3.1', 'cycler==0.12.1', 'fastapi==0.115.12', 'ffmpy==0.5.0', 'filelock==3.18.0', 'flatbuffers==25.2.10', 'fonttools==4.56.0', 'fsspec==2025.3.2', 'gradio==4.29.0', 'gradio-client==0.16.1', 'gradio-imageslider==0.0.20', 'h11==0.14.0', 'httpcore==1.0.7', 'httpx==0.28.1', 'huggingface-hub==0.30.1', 'humanfriendly==10.0', 'hydra-core==1.3.2', 'idna==3.10', 'imageio==2.37.0', 'importlib-resources==6.5.2', 'iopath==0.1.10', 'jinja2==3.1.6', 'joblib==1.4.2', 'jsonschema==4.23.0', 'jsonschema-specifications==2024.10.1', 'kiwisolver==1.4.8', 'lazy-loader==0.4', 'markdown-it-py==3.0.0', 'markupsafe==2.1.5', 'matplotlib==3.10.1', 'mdurl==0.1.2', 'mpmath==1.3.0', 'narwhals==1.33.0', 'networkx==3.4.2', 'numpy==1.26.4', 'omegaconf==2.3.0', 'onnx==1.17.0', 'onnxruntime==1.21.0', 'opencv-python==4.11.0.86', 'orjson==3.10.16', 'pandas==2.2.3', 'pillow==10.4.0', 'portalocker==3.1.1', 'protobuf==6.30.2', 'py-cpuinfo==9.0.0', 'pycocotools==2.0.8', 'pydantic==2.11.1', 'pydantic-core==2.33.0', 'pydub==0.25.1', 'pyparsing==3.2.3', 'pyreadline3==3.5.4', 'python-multipart==0.0.20', 'pytz==2025.2', 'pywin32==310', 'pyyaml==6.0.2', 'referencing==0.36.2', 'regex==2024.11.6', 'requests==2.32.3', 'rich==14.0.0', 'rpds-py==0.24.0', 'ruff==0.11.2', 'safetensors==0.5.3', 'scikit-image==0.25.2', 'scikit-learn==1.6.1', 'scipy==1.15.2', 'seaborn==0.13.2', 'semantic-version==2.10.0', 'shellingham==1.5.4', 'sniffio==1.3.1', 'starlette==0.46.1', 'sympy==1.13.1', 'threadpoolctl==3.6.0', 'tifffile==2025.3.30', 'timm==1.0.15', 'tokenizers==0.21.1', 'tomlkit==0.12.0', 'tqdm==4.67.1', 'transformers==4.50.3', 'typer==0.15.2', 'typing-inspection==0.4.0', 'tzdata==2025.2', 'ultralytics==8.3.99', 'ultralytics-thop==2.0.14', 'urllib3==2.3.0', 'uvicorn==0.34.0', 'websockets==11.0.3', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# segtree

[![License BSD-3](https://img.shields.io/pypi/l/segtree.svg?color=green)](https://github.com/hereariim/segtree/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/segtree.svg?color=green)](https://pypi.org/project/segtree)
[![Python Version](https://img.shields.io/pypi/pyversions/segtree.svg?color=green)](https://python.org)
[![tests](https://github.com/hereariim/segtree/workflows/tests/badge.svg)](https://github.com/hereariim/segtree/actions)
[![codecov](https://codecov.io/gh/hereariim/segtree/branch/main/graph/badge.svg)](https://codecov.io/gh/hereariim/segtree)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/segtree)](https://napari-hub.org/plugins/segtree)
[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)
[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)

Individual tree segmentation

----------------------------------

This [napari] plugin was generated with [copier] using the [napari-plugin-template].

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/napari-plugin-template#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `segtree` via [pip]:

    pip install segtree



To install latest development version :

    pip install git+https://github.com/hereariim/segtree.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""segtree"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[copier]: https://copier.readthedocs.io/en/stable/
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[napari-plugin-template]: https://github.com/napari/napari-plugin-template

[file an issue]: https://github.com/hereariim/segtree/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Programming Language :: Python :: 3.13', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/hereariim/segtree/issues', 'Documentation, https://github.com/hereariim/segtree#README.md', 'Source Code, https://github.com/hereariim/segtree', 'User Support, https://github.com/hereariim/segtree/issues']",segtree.get_reader,segtree.write_multiple,segtree.ind_segm,segtree.make_sample_data,['*.npy'],,['.npy']
510,recorder-napari,recOrder-napari,recOrder-napari,0.4.1,2022-04-19,2024-07-16,"Computational Microscopy Platform, CZ Biohub",shalin.mehta@czbiohub.org,BSD 3-Clause,https://github.com/mehta-lab/recOrder/issues,https://pypi.org/project/recOrder-napari/,,https://github.com/mehta-lab/recOrder,Computational microscopy toolkit for label-free imaging,>=3.9,"['waveorder ==2.0.0rc3', 'pycromanager ==0.27.2', 'click >=8.0.1', 'natsort >=7.1.1', 'colorspacious >=1.1.2', 'pyqtgraph >=0.12.3', 'napari-ome-zarr >=0.3.2', 'napari[pyqt6_experimental]', 'importlib-metadata', 'iohub ==0.1.0.dev5', 'wget >=3.2', ""pytest >=5.0.0 ; extra == 'dev'"", ""pytest-cov ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""tox ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""black ; extra == 'dev'"", ""hypothesis ; extra == 'dev'""]","# recOrder
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/recOrder-napari)
[![Python package index download statistics](https://img.shields.io/pypi/dm/recOrder-napari.svg)](https://pypistats.org/packages/recOrder-napari)
[![Python package index](https://img.shields.io/pypi/v/recOrder-napari.svg)](https://pypi.org/project/recOrder-napari)
[![Development Status](https://img.shields.io/pypi/status/napari.svg)](https://en.wikipedia.org/wiki/Software_release_life_cycle#Alpha)

`recOrder` is a collection of computational imaging methods. It currently provides QLIPP (quantitative label-free imaging with phase and polarization), phase from defocus, and fluorescence deconvolution. 

[![Unveiling the invisible](https://github.com/mehta-lab/recOrder/blob/main/docs/images/comms_video_screenshot.png?raw=true)](https://www.youtube.com/watch?v=JEZAaPeZhck)

Acquisition, calibration, background correction, reconstruction, and applications of QLIPP are described in the following [E-Life Paper](https://elifesciences.org/articles/55502):

```bibtex
Syuan-Ming Guo, Li-Hao Yeh, Jenny Folkesson, Ivan E Ivanov, Anitha P Krishnan, Matthew G Keefe, Ezzat Hashemi, David Shin, Bryant B Chhun, Nathan H Cho, Manuel D Leonetti, May H Han, Tomasz J Nowakowski, Shalin B Mehta, ""Revealing architectural order with quantitative label-free imaging and deep learning,"" eLife 2020;9:e55502 DOI: 10.7554/eLife.55502 (2020).
```

These are the kinds of data you can acquire with `recOrder` and QLIPP:

https://user-images.githubusercontent.com/9554101/271128301-cc71da57-df6f-401b-a955-796750a96d88.mov

https://user-images.githubusercontent.com/9554101/271128510-aa2180af-607f-4c0c-912c-c18dc4f29432.mp4

## What do I need to use `recOrder`
`recOrder` is to be used alongside a conventional widefield microscope. For QLIPP, the microscope must be fitted with an analyzer and a universal polarizer: 

https://user-images.githubusercontent.com/9554101/273073475-70afb05a-1eb7-4019-9c42-af3e07bef723.mp4

For phase-from-defocus or fluorescence deconvolution methods, the universal polarizer is optional.

The overall structure of `recOrder` is shown in Panel B, highlighting the structure of the graphical user interface (GUI) through a napari plugin and the command-line interface (CLI) that allows users to perform reconstructions.

![Flow Chart](https://github.com/mehta-lab/recOrder/blob/main/docs/images/recOrder_Fig1_Overview.png?raw=true)



## Software Quick Start

(Optional but recommended) install [anaconda](https://www.anaconda.com/products/distribution) and create a virtual environment:

```sh
conda create -y -n recOrder python=3.9
conda activate recOrder
```

Install `recOrder-napari`:

```sh
pip install recOrder-napari
```

Open `napari` with `recOrder-napari`:

```sh
napari -w recOrder-napari
```

For more help, see [`recOrder`'s documentation](https://github.com/mehta-lab/recOrder/tree/main/docs). To install `recOrder` 
on a microscope, see the [microscope installation guide](https://github.com/mehta-lab/recOrder/blob/main/docs/microscope-installation-guide.md).

## Dataset

[Slides](https://doi.org/10.5281/zenodo.5135889) and a [dataset](https://doi.org/10.5281/zenodo.5178487) shared during a workshop on QLIPP and recOrder can be found on Zenodo, and the napari plugin's sample contributions (`File > Open Sample > recOrder-napari` in napari).

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.5178487.svg)](https://doi.org/10.5281/zenodo.5178487)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.5135889.svg)](https://doi.org/10.5281/zenodo.5135889)
","['License :: OSI Approved :: BSD License', 'Programming Language :: Python', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering', 'Topic :: Scientific/Engineering :: Visualization', 'Topic :: Scientific/Engineering :: Information Analysis', 'Topic :: Scientific/Engineering :: Bio-Informatics', 'Topic :: Utilities', 'Framework :: napari', 'Operating System :: Microsoft :: Windows', 'Operating System :: POSIX', 'Operating System :: Unix', 'Operating System :: MacOS']","['Bug Tracker, https://github.com/mehta-lab/recOrder/issues', 'Documentation, https://github.com/mehta-lab/recOrder/wiki', 'Source Code, https://github.com/mehta-lab/recOrder/tree/main/recOrder', 'User Support, https://github.com/mehta-lab/recOrder/issues']",recOrder-napari.get_reader,,recOrder-napari.MainWidget,recOrder-napari.polarization_target_data,"['*.zarr', '*.tif']",,
511,redlionfish,RedLionfish,RedLionfish,0.10,2021-11-19,2024-03-22,Luis Perdigao,luis.perdigao@rfi.ac.uk,"Apache License, Version 2.0",https://github.com/rosalindfranklininstitute/RedLionfish,https://pypi.org/project/RedLionfish/,,https://github.com/rosalindfranklininstitute/RedLionfish,Fast Richardson-Lucy deconvolution of 3D volume data using GPU or CPU with napari plugin.,,"['numpy', 'scipy', 'pyopencl', 'reikna']","![RedLionfish Logo](./redlionfish_logo.svg)

# RedLionfish (RL) deconvolution

*Richardson-Lucy deconvolution for fishes, scientists and engineers.*


This software is for filtering 3D data using the Richardson-Lucy deconvolution algorithm.

Richardson-Lucy is an iterative deconvolution algorithm that is used to remove
point spread function (PSF) or optical transfer function (OTF) artifacts from experimental images.

The method was originally developed for astronomy to remove optical effects and simultaneously reduce poisson noise in 2D images.

[Lucy, L. B. An iterative technique for the rectification of observed distributions. The Astronomical Journal 79, 745 (1974). DOI: 10.1086/111605](https://ui.adsabs.harvard.edu/abs/1974AJ.....79..745L/abstract)

The method can also be applied to 3D data. Nowadays this filtering technique is also widely used by microscopists.

The Richardson-Lucy deconvolution algorigthm is iterative. Each iteration involves the calculation of 2 convolutions, one element-wise multiplication and one element-wise division.

When dealing with 3D data, the Richardson-Lucy algorithm is quite computional intensive primarly due to the calculation of the convolution, and can take a while to complete depending on the resources available. Convolution is significantly sped up using FFT compared to raw convolution.

This software was developed with the aim to make the R-L computation faster by exploiting GPU resources, and with the use of FFT convolution.

To make RedLionfish easily accessible, it is available through PyPi and anaconda (conda-forge channel). A useful plugin for Napari is also available.

Please note that this software only works with 3D data. For 2D data there are many alternatives such as the DeconvolutionLab2 in Fiji (ImageJ) and sckikit-image.

## Napari plugin

You can now use the Napari's plugin installation in *Menu -> Plugins -> Install/Uninstall Plugins...*.
However, if you chose to use this method, GPU acceleration may not be available and it will use the CPU backend. Better check.

![](resources\imag1.jpg)

Alternatively, if you follow the installation instructions below, and install the napari in the same python environment
then the plugin should be immediately available in the *Menu -> Plugins -> RedLionfish*.


## Installation

Previously there was a problem in installing using `pip`, because no PyOpenCL wheels for windows were avaiable. It is now avaialble.

This package can be installed using pip or conda.

Napari plugin installation engine can also be used to install this package.


### Install from PyPi

```
pip install redlionfish
```


### Conda install

This package is available in conda-forge channel.
It contains the precompiled libraries and it will install all the requirments for GPU-accelerated RL calculations.

`conda install redlionfish -c conda-forge`

In Linux , the package `ocl-icd-system` may also be useful.

```
conda install reikna pyopencl ocl-icd-system -c conda-forge
```


#### Manual installation using the conda package file.

Download the appropriate conda package .bz2 at [https://github.com/rosalindfranklininstitute/RedLionfish/releases](https://github.com/rosalindfranklininstitute/RedLionfish/releases)

In the command line, successively run:
```
conda install <filename.bz2>
conda update --all -c conda-forge
```
The second line is needed because you are installing from a local file, conda installer will not install dependencies. Right after this you should run the update command given.


### Manual installation (advanced and for developers)

Please note that in order to use OpenCL GPU accelerations, PyOpenCL must be installed.
The best way to get it working is to install it under a conda environment.

The installation is similar to the previously described for PyPi.

`conda install reikna pyopencl`

or

`conda install reikna pyopencl ocl-icd-system -c conda-forge` (Linux)

Clone/download from source [https://github.com/rosalindfranklininstitute/RedLionfish/](https://github.com/rosalindfranklininstitute/RedLionfish/)

and run

`python setup.py install`


### Debug installation
If you want to test and modify the code then you should probably install in debug mode using:

`python setup.py develop`

or

`pip install -e .`


## More information

The software has algorithms for Richardson-Lucy deconvolution that use either CPU and GPU.

The CPU version is very similar to the [skimage.restoration.richardson_lucy](https://scikit-image.org/docs/dev/api/skimage.restoration.html#skimage.restoration.richardson_lucy) code, with improvments in speed.
major differences are:

- the convolution steps use FFT only.
- PSF and PSF-flipped FFTs are precalculated before starting iterations.

The GPU version, was written in to use Reikna package, which does FFT using OpenCL, via PyOpenCL.

Unfortunately, a major limitation in RAM usage exists with PyOpenCL.
Large 3D data volumes with cause out-of-memory error when trying to upload data to the GPU for FFT calculations.
As such, to overcome this problem, a block algorithm is used, which splits data into blocks with padded data.
The results are then combined together to give the final result.
This affects the perfomance of the calculation rather significantly, but with the advantage of being possible to handle large data volumes.

If Richardson-Lucy deconvolution using the GPU method fails, RedLionfish will fallback to CPU calculation. Check console output for messages.

If you are using the RedLionfish in your code, note that, by default, `def doRLDeconvolutionFromNpArrays()` method it uses the GPU OpenCL version.

## Testing

Use pytest to test the package. Test files are in `/test` folder

Many examples can be found in `/scripts' folder.

A useful way to test and benchmark the package installation can be run from the proect root using the command:

'python scripts/test_and_benchm.py'

or in windows

'python scripts\test_and_benchm.py'

This will print out information about your GPU device (if available) and run some deconvolutions.
It initially creates some data programatically, convolutes with a gaussian PSF, and add Poisson noise.
Then it executes executes the
Richardson-Lucy deconvolution calculation using CPU and GPU methods, for 10 iterations.
During the calculation it will print some information to the console/terminal, including the time it takes to run the calculation.


Computer generated data and an experimental PSF can be found in `scripts\testdata`

### Testing Redlionfish in napari

Here is an example testing the Redlionfish plugin in napari:

1. load data `scripts/testdata/gendata_psfconv_poiss_large.tif` (can use draga and drop)
2. load psf data `scripts/testdata/PSF_RFI_8bit.tif`
3. In the RedLionfish side window ensure that 'gendata_psfconv_poiss_large' is selected in data dropdown widget, and `PSF_RFI_8bit` is selected in psfdata widget.
4. Choose number of iterations (default=10)
5. Click 'Go' button and wait until result shows as a new data layer.
6. Use controls of the left panel to compare before and after RL deconvolution: select 'RL-deconvolution' layer and set colormap to red. Hide PSF_RFI_8bit. Make sure that both 'RL-deconvolution' and 'gendata-psfconv' are visible. Now, hide/unhide RL-deconvolution layer to see before and after deconvolution. Adjust contrast limits of each layer as desired.


## GPU vs CPU

You may notice that choosing GPU does not make RL-calculation much faster compared with CPU, and sometimes is slower.

Which method runs the R-L deconvolution faster. That depends on the computer configuration/architecture.

GPU calculations will be generally faster than CPU with bigger data volumes.

GPU calculation will be significantly faster if using a dedicated GPU card.

Please see benchmark values that highlights significant variability in calculation speeds.


[benchmark_results.md](benchmark_results.md)


## Coding

Please feel free to browse the `/scripts` folder for examples.

In order to use the functions, add the follwoing import to your code,

`import RedLionfishDeconv`

The most useful function is perhaps the following.

`def doRLDeconvolutionFromNpArrays(data_np , psf_np ,*, niter=10, method='gpu', useBlockAlgorithm=False, callbkTickFunc=None, resAsUint8 = False) `

This will do the Richardson-Lucy deconvolution on the data_np (numpy, 3 dimensional data volume) using the provided PSF data volume, for 10 iterations. GPU method is generally faster but it may fail. If it does fail, the program will automatically use the CPU version that uses the scipy fft package.



## Manually building the conda package

For this installation, ensure that the conda-build package is installed

`conda install conda-build`

In windows, simply execute

`conda-create-package.bat`


Or, execute the following command-line to create the installation package.

`conda-build --output-folder ./conda-built-packages -c conda-forge conda-recipe`

and the conda package will be created in folder *conda-built-packages*.

Otherwise, navigate to `conda-recipe`, and execute on the command-line `conda build .`

It will take a while to complete.

## Contact

Report issues and questions in project's github page, please. Please don't try to send emails as they may be igored or spam-filtered.

","['Development Status :: 4 - Beta ', 'License :: OSI Approved :: Apache Software License', 'Natural Language :: English', 'Programming Language :: Python :: 3.8', 'Operating System :: Microsoft :: Windows', 'Operating System :: MacOS', 'Operating System :: POSIX :: Linux', 'Topic :: Scientific/Engineering :: Image Processing', 'Framework :: napari']",,,,RedLionfish.RedLionfish_widget,,,,
512,seu-3d,seu-3d,seu-3d,1.1.11,2025-05-27,2025-07-26,pxieLab,pxieLab <220242543@seu.edu.cn>,Unavailable,https://github.com/DingAnZhong/SEU-3D,https://pypi.org/project/seu-3d/,,,3d spatial visualization napari plugin,>=3.10,,"# SEU-3D

## description

3d visualization and analysis plugin for spatial transcription embryo base on napari

## updata log

[1.1.11] fix buges

[1.1.10] Fix buges and optimize SelectXYZ

[1.1.9] Multi-gene analysis adjusts image contrast by channel

[1.1.8] 1.A Z-axis control slider has been added
        2.A color bar was added to a single gene analysis
        3.Contrast adjustment has been added in moran's I
        4.Convert all contrast adjustment logic to quantiles
        5.Select tissue by legend tab available

[1.1.7] fix bug of one gene adjust contrast darker,expand adjust contrast function to 1/2/3gene analyse

[1.1.6] Expand select XY to select XYZ

[1.1.5] 1.Fixed the bug where visible cells decreased with the number of operations
        2.When creating a flatten layer, the visibility inherits from the original visibility
        3.Unify the length of the mask variable when calculating and plotting
        4.The original situation where the threshold constraints of each gene were mutually inherited has been changed. Now, they are all inherited from tissue_filter

[1.1.4] 1.Fixed the bug related to multi-gene screening 
        2.The calculation and plotting of moran's I have been optimized

[1.1.3] fix buges

[1.1.2] enrich function

[1.1.1] change color_map

[1.1.0] rebuild whole package

## acknowledge

https://github.com/GuignardLab/sc3D
https://github.com/GuignardLab/napari-sc3D-viewer

## environment
","['Framework :: napari', 'Programming Language :: Python :: 3', 'Operating System :: Microsoft :: Windows']","['Homepage, https://github.com/DingAnZhong/SEU-3D']",,,seu-3d.load_atlas,,,,
513,set-calibration,set-calibration,Calibration Tool,0.0.1,2023-11-03,2023-11-03,Clement H. Benedetti,clement.benedetti@mri.cnrs.fr,MIT,https://github.com/MontpellierRessourcesImagerie/set-calibration/issues,https://pypi.org/project/set-calibration/,,https://github.com/MontpellierRessourcesImagerie/set-calibration,"""A tool allowing to modify the calibration (physical units) of images""",>=3.8,"['numpy', 'magicgui', 'qtpy', 'scikit-image', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# set-calibration

[![License MIT](https://img.shields.io/pypi/l/set-calibration.svg?color=green)](https://github.com/MontpellierRessourcesImagerie/set-calibration/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/set-calibration.svg?color=green)](https://pypi.org/project/set-calibration)
[![Python Version](https://img.shields.io/pypi/pyversions/set-calibration.svg?color=green)](https://python.org)
[![tests](https://github.com/MontpellierRessourcesImagerie/set-calibration/workflows/tests/badge.svg)](https://github.com/MontpellierRessourcesImagerie/set-calibration/actions)
[![codecov](https://codecov.io/gh/MontpellierRessourcesImagerie/set-calibration/branch/main/graph/badge.svg)](https://codecov.io/gh/MontpellierRessourcesImagerie/set-calibration)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/set-calibration)](https://napari-hub.org/plugins/set-calibration)

""A tool allowing to modify the calibration (physical units) of images""

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `set-calibration` via [pip]:

    pip install set-calibration



To install latest development version :

    pip install git+https://github.com/MontpellierRessourcesImagerie/set-calibration.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""set-calibration"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/MontpellierRessourcesImagerie/set-calibration/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/MontpellierRessourcesImagerie/set-calibration/issues', 'Documentation, https://github.com/MontpellierRessourcesImagerie/set-calibration#README.md', 'Source Code, https://github.com/MontpellierRessourcesImagerie/set-calibration', 'User Support, https://github.com/MontpellierRessourcesImagerie/set-calibration/issues']",,,set-calibration.create_scale_panel,,,,
514,snouty-viewer,snouty-viewer,Snouty Viewer,0.2.5,2022-08-31,2023-07-27,Austin E. Y. T. Lefebvre,austin.e.lefebvre@gmail.com,MIT,https://github.com/aelefebv/snouty-viewer/issues,https://pypi.org/project/snouty-viewer/,,https://github.com/aelefebv/snouty-viewer,"A plugin to visualize, deskew, and combine Snouty data.",>=3.8,"['magicgui', 'napari', 'numpy', 'ome-types', 'tifffile', ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# snouty-viewer

[![License MIT](https://img.shields.io/pypi/l/snouty-viewer.svg?color=green)](https://github.com/aelefebv/snouty-viewer/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/snouty-viewer.svg?color=green)](https://pypi.org/project/snouty-viewer)
[![Python Version](https://img.shields.io/pypi/pyversions/snouty-viewer.svg?color=green)](https://python.org)
[![tests](https://github.com/aelefebv/snouty-viewer/workflows/tests/badge.svg)](https://github.com/aelefebv/snouty-viewer/actions/workflows/test_and_deploy.yml)
[![codecov](https://codecov.io/gh/aelefebv/snouty-viewer/branch/main/graph/badge.svg)](https://codecov.io/gh/aelefebv/snouty-viewer)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/snouty-viewer)](https://napari-hub.org/plugins/snouty-viewer)

## Description
Easy to use plugin for opening raw Snouty files and converting them to native view.

Allows for saving to ome.tif files with corresponding OME-XML based metadata.

Also allows for bulk deskewing and saving directories.

![Example](https://i.imgur.com/VirE5DM.gif)

## Intended Audience & Supported Data
This plugin is intended for those using a SOLS (Snouty) microscope collected via
[Alfred Millett-Sikking's code](https://github.com/amsikking/SOLS_microscope).

This plugin accepts a folder with at least subdirectories of data and metadata as an input.

## Quickstart

### A. Getting the plugin working (choose either a or b, you don't have to do both)
#### a. Through pip-install:
1. pip install snouty-viewer (within a virtual environment of Python 3.8, 3.9, or 3.10 recommended)
2. Open up napari
#### b. Through Napari:
1. Open up napari
2. Plugins > Install/Uninstall plugins
3. Search for ""snouty-viewer""
4. Install
5. (Maybe need to) reopen napari

### B. Viewing raw Snouty data
- Drag and drop a root folder of your Snouty data. This is the folder that includes the data and metadata subfolders.
- Select ""Snouty Viewer"" for opening.

### C. Converting raw Snouty data to its native view
1. Click plugins, snouty-viewer -> Native View
2. Select the file you want to convert
3. Press Deskew

### D. Saving your native view file
1. Select the channel (or multi-channel) layer you want to save
2. File > Save Selected Layer(s)...
3. Select where you want to save your file
4. Title your file, "".ome.tif"" will automatically be appended.
5. Save with ""Snouty Writer""
6. Wait (this could take a few minutes depending on your file's size and your hardware)

### E. Batch saving
1. Click plugins, snouty-viewer -> Batch Deskew & Save
2. Input a directory (without quotes) that contains 1 or more Snouty-acquired directories.
3. If you want to view your deskewed outputs, check the box.
4. If you want to automatically save the deskewed outputs, check the box.
5. Press Deskew and save
6. Wait (this could take a few minutes depending on your files' sizes and your hardware)
## Getting Help
- Open up an issue on [GitHub](https://github.com/aelefebv/snouty-viewer/issues).
- Start a thread on [image.sc](https://forum.image.sc/)

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `snouty-viewer` via [pip]:

    pip install snouty-viewer



To install latest development version :

    pip install git+https://github.com/aelefebv/snouty-viewer.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""snouty-viewer"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/aelefebv/snouty-viewer/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/aelefebv/snouty-viewer/issues', 'Documentation, https://github.com/aelefebv/snouty-viewer#README.md', 'Source Code, https://github.com/aelefebv/snouty-viewer', 'User Support, https://github.com/aelefebv/snouty-viewer/issues']",snouty-viewer.get_reader,snouty-viewer.write_single_image,snouty-viewer.get_native_view,,,['.ome.tif'],
515,skan,skan,skan,0.13.0,2023-01-31,2025-07-17,Juan Nunez-Iglesias,Juan Nunez-Iglesias <juan.nunez-iglesias@monash.edu>,BSD 3-Clause,https://github.com/jni//issues,https://pypi.org/project/skan/,,,Skeleton analysis in Python,>=3.9,"['imageio>=2.10.1', 'magicgui>=0.7.3', 'matplotlib>=3.4', 'networkx>=2.7', 'numba>=0.58', 'numpy>=1.25', 'pandas>=2.0.2', 'openpyxl>=2.6', 'scikit-image>=0.17.1', 'scipy>=1.7', 'toolz>=0.10.0', 'tqdm>=4.57.0', 'scikit-image[data]; extra == ""all""', 'coverage; extra == ""testing""', 'hypothesis; extra == ""testing""', 'napari[pyqt5]>=0.4.19rc1; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'seaborn<1.0; extra == ""testing""', 'tifffile; extra == ""testing""', 'napari[all]>=0.4.19rc1; extra == ""docs""', 'sphinx; extra == ""docs""', 'jupyter; extra == ""docs""', 'notebook; extra == ""docs""', 'seaborn<1.0,>=0.13; extra == ""docs""', 'sphinx-toggleprompt; extra == ""docs""', 'sphinx-copybutton; extra == ""docs""', 'sphinxcontrib-bibtex; extra == ""docs""', 'myst-nb; extra == ""docs""', 'zarr; extra == ""docs""', 'pydata-sphinx-theme<1.0; extra == ""docs""']","# skan: skeleton analysis in Python
Python module to analyse skeleton (thin object) images

[![Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/jni/skan/main?filepath=doc%2Fgetting_started.ipynb)
[![Coverage Status](https://coveralls.io/repos/github/jni/skan/badge.svg?branch=main)](https://coveralls.io/github/jni/skan?branch=master)

See the documentation at [https://skeleton-analysis.org](https://skeleton-analysis.org).
","['Development Status :: 3 - Alpha', 'Environment :: Console', 'Intended Audience :: Developers', 'Intended Audience :: Education', 'Intended Audience :: Science/Research', 'License :: OSI Approved :: BSD License', 'Programming Language :: Python', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering', 'Operating System :: Microsoft :: Windows', 'Operating System :: POSIX', 'Operating System :: Unix', 'Operating System :: MacOS', 'Framework :: napari']","['Source, https://github.com/jni/skan', 'Bug_Tracker, https://github.com/jni//issues', 'Documentation, https://skeleton-analysis.org/stable/']",,,skan.skeletonize,,,,
516,surforama,surforama,Surforama,0.0.9,2024-03-08,2024-04-18,Kyle Harrington,surforama@kyleharrington.com,MIT,https://github.com/cellcanvas/surforama/issues,https://pypi.org/project/surforama/,,https://github.com/cellcanvas/surforama,a tool for using surfaces to explore volumetric data in napari,>=3.8,"['magicgui', 'mrcfile', 'numpy', 'pooch', 'qtpy', 'pyacvd', 'pyvista', 'rich', 'scikit-image', 'starfile', 'trimesh', 'typer', ""napari ; extra == 'dev'"", ""pyqt5 ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""pytest-cov ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""tox ; extra == 'dev'"", ""pre-commit ; extra == 'dev'"", ""napari[all] ; extra == 'napari'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# surforama
a napari-based tool for using surfaces to explore volumetric data in napari

inspired by [membranorama](https://github.com/dtegunov/membranorama)

![Screenshot of surforama showing a surface in the slice of a tomogram](surforama_screenshot.png)

## installation
`surforama` requires the napari viewer. If you would like to install napari and surforama together in one line, you can use the following command:

```bash
pip install ""surforama[napari]""
```


If you already have napari installed, you can directly install surforama in the same environment:

```bash
pip install surforama
```

## usage
### launch with demo data
If you'd like to test surforama out, you can launch surforama with demo data:

```bash
surforama --demo
```

### launch without data
You can launch surforama using the command line interface. After you have installed surforama, you can launch it with the following command in your terminal:

```bash
surforama
```
After surforama launches, you can load your image and mesh into napari and get surfing!

### launch with data
If you have an MRC-formatted tomogram and an obj-formatted mesh, you can launch using the following command:

```bash
surforama --image-path /path/to/image.mrc --mesh-path /path/to/mesh.obj
```

## developer installation

If you would like to make changes to the surforama source code, you can install surformama with the developer tools as follows:

```bash
cd /path/to/your/surforama/source/code/folder
pip install -e "".[dev]""
```
We use pre-commit to keep the code tidy. Install the pre-commit hooks to activate the checks:

```bash
pre-commit install
```
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/cellcanvas/surforama/issues', 'Documentation, https://github.com/cellcanvas/surforama#README.md', 'Source Code, https://github.com/cellcanvas/surforama', 'User Support, https://github.com/cellcanvas/surforama/issues']",surforama.mesh_reader,,surforama.make_widget,surforama.thylakoid,['*.obj'],,
517,spots-in-yeasts,spots-in-yeasts,spots in yeasts,1.2.0,2023-08-29,2023-08-30,ClÃ©ment H. Benedetti,clement.benedetti@mri.cnrs.fr,MIT,https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts/issues,https://pypi.org/project/spots-in-yeasts/,,https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts,A Napari plugin segmenting yeast cells and fluo spots to extract statistics.,>=3.8,"['numpy', 'magicgui', 'magic-class', 'qtpy', 'opencv-python', 'matplotlib', 'termcolor', 'scikit-image', 'tifffile', 'cellpose', 'napari', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# spots-in-yeasts

[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/spots-in-yeasts.svg?color=green)](https://pypi.org/project/spots-in-yeasts)
[![Python Version](https://img.shields.io/pypi/pyversions/spots-in-yeasts.svg?color=green)](https://python.org)
[![tests](https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts/workflows/tests/badge.svg)](https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts/actions)
[![codecov](https://codecov.io/gh/MontpellierRessourcesImagerie/spots-in-yeasts/branch/master/graph/badge.svg)](https://codecov.io/gh/MontpellierRessourcesImagerie/spots-in-yeasts)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/spots-in-yeasts)](https://napari-hub.org/plugins/spots-in-yeasts)

A Napari plugin segmenting yeast cells and fluo spots to extract statistics.

----------------------------------

The skeleton on this [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.


## Introduction

> This Napari plugin's purpose is to extract statistics about fluo spots in yeast cells. We produce a segmentation of cells (based on the brightfield) and a segmentation of spots (based on the fluo channel). Then, we associate the measures to each cells.

Unless you use the `NapariJ` plugin to open images, or the `cast_extension.ijm` script to cast files, you can only launch this plugin on `.tif` images.

For now, the code produces JSON files compiling the metrics such as:
- The number of spots per cell.
- The average intensity of a spot.
- The area of each spot.
- The location of each spot.

We provide `cast_extension.ijm` which is another script meant to be used in Fiji/ImageJ. It is able to convert `.nd` and `.czi` images into basic `.tif` images so you can open them in Napari.

You can process your images either in __one-shot__ _(image per image)_ or in __batch mode__ _(by providing the path to a folder)_. In case you used batch mode, a control image is created so you can quickly check whether your segmentation was correctly performed.

Required packages in your environment:
- `napari`
- `cellpose`
- `numpy`
- `skimage`
- `termcolor`
- `matplotlib`
- `cv2`


## Installation

You can install `spots-in-yeasts` via [pip]:

    pip install spots-in-yeasts



To install latest development version :

    pip install git+https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts.git


## Example

- Your images must have exactly two channels. The number of slices in each channel is totally up to you.
- __First channel__: fluo spots, __second channel__: brightfield.
- If you want to use the batch mode, you must use `.tif` images.

The two following images are the __brightfield__ and __fluo spots__ channels of the same image:

![Brightfield](https://dev.mri.cnrs.fr/attachments/download/3017/bf.png)
![Spots](https://dev.mri.cnrs.fr/attachments/download/3018/fluo.png)

The following images are the __cells labels__ and the __spots positions__:

![Labeled cells](https://dev.mri.cnrs.fr/attachments/download/3016/cells.png)
![Detected spots](https://dev.mri.cnrs.fr/attachments/download/3019/spots.png)

## Usage

### One-shot

- Open Napari. Keep the terminal opened, it provides lots of information.
- Before starting, make sure that no layer is currently open. You can clear your viewer with the `Clear layers` button.
- Drag'n'drop your image into the Napari viewer. It should show up in the left column.
- Click the `Split channels` button to separate the brightfield and the fluo on two different layers. Now, you should have two layers named ""brightfield"" and ""fluo-spots"".
- To segment yeast cells, click the `Segment cells` button. The interface will certainly freeze during a few seconds (~10/30s). A new layer should appear, containing a value of intensity for each individual cell.
- Click on the `Segment spots` button. This is a pretty fast operation. A new layer containing spots just appeared. Spots are represented as small white dots. You can change that in the layer's settings you struggle controling the result.
- Finally, you can use the `Extract stats` button to create a JSON file. This file will automatically be opened in your default text editor, but it is a __temporary file__, which means that it is not saved anywhere and will get lost if you don't save it yourself.
- Once you are done, you can press the `Clear layers` button again and pass to your next image, repeating the previous steps.

### Batch mode

- Before starting, you need a folder containing correctly formated `.tif` files.
- Open Napari, and keep the terminal opened to see provided information.
- Set the `input folder` field to your folder containing `.tif` images.
- Set the `output folder` field to the path of a folder (preferably empty) that will receive the control images and the JSON files generated by the script.
- You can click the `Run batch` button to launch the process.

__Note:__ In batch mode, your viewer won't show anything. You must rely on the terminal's content and the progress bar to know what is going on. To open the progress bar in Napari, click on `activity` in the lower-right corner.

## Messages:

- `Export directory set to: /some/path/to/output`: Folder provided by the user to receive produced files (JSON, controls)
- `===== Working on: d1-230421-11S_2 (1/32)====`: Name of the image currently processed and its rank. For example here, ""d1-230421-11S_2"" is being processed and it is the first image processed from a folder containing 32 images.
- `Selected slices: (4, 8). (11 slices available)`: The script doesn't use all the slices in the image. Instead, it detects the most is-focus slice and takes N slices before and after it. In this example, 11 slices were available in the image. We are using the slices 4, 5, 6, 7, 8 for processing, so the most in-focus one is the 6th.
- `Segmenting cells...`: Notification that the script started segmenting yeasts cells.
- `Cells segmentation done. 219 cells found.`: End of cells segmentation. This message also provides you with the number of indiviual detected. This number is displayed before labels touching the borders are removed.
- `Segmented cells from d1-230421-11S_2 in 10.0s.`: Operations are timed. This is just the time report of cells segmentation.
- `Starting spots segmentation...`: Notification that the script started segmenting spots in the fluo channel.
- `102 spots found .`: Number of spots detected during the segmentation.
- `Segmented spots from d1-230421-11S_2 in 1.0s.`: Duration elapsed during spots segmentation.
- `Spots exported to: /some/path/to/output/d1-230421-11S_2.json`: Path to the exported metrics.
- `Focused slice too far from center!`: We don't use all the slices available. We detect the most in-focus one and take N slices before and after. This message means that there isn't N slices available after (or before) the most in-focus one. The process won't get interupted, but you want to be more careful about the segmentation of this image.
- `The image d1-230421 BG- failed to be processed.`: A basic sanity check is applied to the results before they get exported to reduce the amount of manual checking to perform. This message simply means that either the cells segmentation, or the spots segmentation is so bad that this image will be skipped.
- `========= DONE. (288.0s) =========`: Indicates that all the images contained in your folder were processed, the batch is over. The total amount of time if also displayed.

----------------------------------

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [MIT] license,
""spots-in-yeasts"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.


[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: MIT License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts/issues', 'Documentation, https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts#README.md', 'Source Code, https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts', 'User Support, https://github.com/MontpellierRessourcesImagerie/spots-in-yeasts/issues']",spots-in-yeasts.get_reader,,spots-in-yeasts.spots_in_yeasts,,['*.ysc'],,
518,smo,smo,smo,2.0.2,2021-11-09,2023-02-06,Mauro Silberberg,maurosilber@gmail.com,MIT,https://github.com/maurosilber/smo,https://pypi.org/project/smo/,,https://github.com/maurosilber/smo,Implementation of the Silver Mountain Operator (SMO) for the estimation of background distributions.,,"['numpy', 'scipy', 'typing-extensions ; python_version < ""3.9""', ""pre-commit ; extra == 'dev'"", ""pytest ; extra == 'dev'"", ""tox ; extra == 'dev'""]","![PyPi](https://img.shields.io/pypi/pyversions/smo.svg)
[![License](https://img.shields.io/github/license/maurosilber/smo)](https://opensource.org/licenses/MIT)
[![PyPi](https://img.shields.io/pypi/v/smo.svg)](https://pypi.python.org/pypi/smo)
[![Conda](https://img.shields.io/conda/pn/conda-forge/smo)](https://anaconda.org/conda-forge/smo)

# SMO

SMO is a Python package that implements the Silver Mountain Operator (SMO), which allows to recover an unbiased estimation of the background intensity distribution in a robust way.

We provide an easy to use Python package and plugins for some of the major image processing softwares: [napari](https://napari.org), [CellProfiler](https://cellprofiler.org), and [ImageJ](https://imagej.net) / [FIJI](https://fiji.sc). See Plugins section below.

## Citation

To learn more about the theory behind SMO, you can read the [pre-print in BioRxiv](https://doi.org/10.1101/2021.11.09.467975).

If you use this software, please cite that pre-print.

## Usage

To obtain a background-corrected image, it is as straightforward as:

```python
import skimage.data
from smo import SMO

image = skimage.data.human_mitosis()
smo = SMO(sigma=0, size=7, shape=(1024, 1024))
background_corrected_image = smo.bg_corrected(image)
```

where we used a sample image from `scikit-image`.
By default,
the background correction subtracts the median value of the background distribution.
Note that the background regions will end up with negative values,
but with a median value of 0.

A notebook explaining in more detail the meaning of the parameters and other possible uses for SMO is available here: [smo/examples/usage.ipynb](https://github.com/maurosilber/SMO/blob/main/smo/examples/usage.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/maurosilber/SMO/blob/main/smo/examples/usage.ipynb).

## Installation

It can be installed with `pip` from PyPI:

```
pip install smo
```

or with `conda` from the conda-forge channel:

```
conda install -c conda-forge smo
```

## Plugins
### Napari

A [napari](https://napari.org) plugin is available.

To install:

- Option 1: in napari, go to `Plugins > Install/Uninstall Plugins...` in the top menu, search for `smo` and click on the install button.

- Option 2: just `pip` install this package in the napari environment.

It will appear in the `Plugins` menu.

### CellProfiler

A [CellProfiler](https://cellprofiler.org) plugin in available in the [smo/plugins/cellprofiler](smo/plugins/cellprofiler) folder.

![](images/CellProfiler_SMO.png)

To install, save [this file](https://raw.githubusercontent.com/maurosilber/SMO/main/smo/plugins/cellprofiler/smo.py) into your CellProfiler plugins folder. You can find (or change) the location of your plugins directory in `File > Preferences > CellProfiler plugins directory`.

### ImageJ / FIJI

An [ImageJ](https://imagej.net) / [FIJI](https://fiji.sc) plugin is available in the [smo/plugins/imagej](smo/plugins/imagej) folder.

![](images/ImageJ_SMO.png)

To install, download [this file](https://raw.githubusercontent.com/maurosilber/SMO/main/smo/plugins/imagej/smo.py) and:

- Option 1: in the ImageJ main window, click on `Plugins > Install... (Ctrl+Shift+M)`, which opens a file chooser dialog. Browse and select the downloaded file. It will prompt to restart ImageJ for changes to take effect.

- Option 2: copy into your ImageJ plugins folder (`File > Show Folder > Plugins`).

To use the plugin, type `smo` on the bottom right search box:

![](images/ImageJ_MainWindow.png)

select `smo` in the `Quick Search` window and click on the `Run` button.

![](images/ImageJ_QuickSearch.png)

Note: the ImageJ plugin does not check that saturated pixels are properly excluded.

## Development

Code style is enforced via pre-commit hooks. To set up a development environment, clone the repository, optionally create a virtual environment, install the [dev] extras and the pre-commit hooks:

```
git clone https://github.com/maurosilber/SMO
cd SMO
conda create -n smo python pip numpy scipy
pip install -e .[dev]
pre-commit install
```
","['Intended Audience :: Science/Research', 'License :: OSI Approved :: MIT License', 'Operating System :: MacOS :: MacOS X', 'Operating System :: Microsoft :: Windows', 'Operating System :: POSIX', 'Programming Language :: Python', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Topic :: Scientific/Engineering', 'Framework :: napari']",,,,smo.napari_experimental_provide_function,,,,
519,stardist-napari,stardist-napari,stardist-napari,2024.8.6.1,2021-06-01,2024-08-06,"Uwe Schmidt, Martin Weigert","research@uweschmidt.org, martin.weigert@epfl.ch",BSD 3-Clause,https://github.com/stardist/stardist-napari/issues,https://pypi.org/project/stardist-napari/,,https://github.com/stardist/stardist,Object Detection with Star-convex Shapes,>=3.8,"['stardist>=0.8.3', 'napari>=0.4.13', 'magicgui>=0.4.0', 'tensorflow; platform_system != ""Darwin"" or platform_machine != ""arm64""', 'tensorflow-macos; platform_system == ""Darwin"" and platform_machine == ""arm64""', 'tensorflow-metal; platform_system == ""Darwin"" and platform_machine == ""arm64""', 'pytest; extra == ""test""', 'pytest-qt; extra == ""test""', 'napari[pyqt]>=0.4.13; extra == ""test""']","# StarDist Napari Plugin

[![PyPI version](https://img.shields.io/pypi/v/stardist-napari.svg)](https://pypi.org/project/stardist-napari)
[![Anaconda-Server Badge](https://anaconda.org/conda-forge/stardist-napari/badges/version.svg)](https://anaconda.org/conda-forge/stardist-napari)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/stardist-napari)](https://napari-hub.org/plugins/stardist-napari)
[![Image.sc forum](https://img.shields.io/badge/dynamic/json.svg?label=forum&url=https%3A%2F%2Fforum.image.sc%2Ftags%2Fstardist.json&query=%24.topic_list.tags.0.topic_count&colorB=brightgreen&suffix=%20topics&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAOCAYAAAAfSC3RAAABPklEQVR42m3SyyqFURTA8Y2BER0TDyExZ+aSPIKUlPIITFzKeQWXwhBlQrmFgUzMMFLKZeguBu5y+//17dP3nc5vuPdee6299gohUYYaDGOyyACq4JmQVoFujOMR77hNfOAGM+hBOQqB9TjHD36xhAa04RCuuXeKOvwHVWIKL9jCK2bRiV284QgL8MwEjAneeo9VNOEaBhzALGtoRy02cIcWhE34jj5YxgW+E5Z4iTPkMYpPLCNY3hdOYEfNbKYdmNngZ1jyEzw7h7AIb3fRTQ95OAZ6yQpGYHMMtOTgouktYwxuXsHgWLLl+4x++Kx1FJrjLTagA77bTPvYgw1rRqY56e+w7GNYsqX6JfPwi7aR+Y5SA+BXtKIRfkfJAYgj14tpOF6+I46c4/cAM3UhM3JxyKsxiOIhH0IO6SH/A1Kb1WBeUjbkAAAAAElFTkSuQmCC)](https://forum.image.sc/tags/stardist)

This project provides the [napari](https://napari.org/) plugin for [StarDist](https://github.com/stardist/stardist), a deep learning based 2D and 3D object detection method with star-convex shapes. StarDist has originally been developed (see [papers](https://github.com/stardist/stardist#stardist---object-detection-with-star-convex-shapes)) for the segmentation of densely packed cell nuclei in challenging images with low signal-to-noise ratios. The plugin allows to apply pretrained and custom trained models from within napari.

If you use this plugin for your research, please [cite us](https://github.com/stardist/stardist#how-to-cite).

![Screenshot](https://github.com/stardist/stardist-napari/raw/main/images/stardist_napari_screenshot_small.png)


## Installation

Install the plugin with `pip install stardist-napari` or from within napari via `Plugins > Install/Uninstall Pluginsâ¦`. If you want GPU-accelerated prediction, please read the more detailed [installation instructions](https://github.com/stardist/stardist#installation) for StarDist.

- You can activate the plugin in napari via `Plugins > stardist-napari: StarDist`.
- Example images for testing are provided via `File > Open Sample > stardist-napari`.


## Documentation

The two main buttons at the bottom of the plugin are (see right side of screenshot above):

**Restore Defaults**: Restore default values for [inputs](#inputs) (exceptions: *Input Image*, *Image Axes*, *Custom Model*).

**Run**: Start the prediction with the selected inputs and create the [outputs](#outputs) when done.

All plugin activity is shown in the napari *activity dock*, which can be shown/hidden by clicking on the word `activity` next to the little arrow at the bottom right of the napari window.

### Inputs

The plugin does perform input validation, i.e. it will disable the `Run` button if it detects a problem with the selected inputs. Problematic input fields are highlighted with a ""lightcoral"" background color ![](https://via.placeholder.com/15/f08080/f08080.png), and their [*tooltips*](https://en.wikipedia.org/wiki/Tooltip) typically explain what the problem is. Some error messages are shown at the bottom in napari's status bar, such as for incompatibilities between multiple input fields. Input fields with warnings (also explained via tooltips) are highlighted with an orange background color ![](https://via.placeholder.com/15/ffa500/ffa500.png).

**Input Image**: Select a napari layer of type `Image` as the input.  
*Tooltip:* Shows the shape of the image.

**Image Axes**: String that describes the semantic image axes and their order, e.g. `YX` for a 2D image. This parameter is automatically chosen (i.e. guessed) when a new input image is selected and should work in most cases. Permissible axis values are: `X` (width/columns), `Y` (height/rows), `Z` (depth/planes), `C` (channels), `T` (frames/time).  
*Tooltip:* Shows the mapping of semantic axes to the shape of the selected input image.

**Predict on field of view (only for 2D models in 2D view)**: If enabled, the StarDist prediction is only applied to the current field of view of the napari viewer. As the name of this checkbox indicates, this only works for 2D StarDist models and when the napari viewer is in 2D viewing mode. The checkbox is not even shown if those conditions are not met.

#### *Neural Network Prediction*

**Model Type**: Choice whether to use registered pre-trained models (`2D`, `3D`) or provide a path to a model folder (`Custom 2D/3D`). Based on this choice, either the input for *Pre-trained Model* or *Custom Model* is shown below.  
(Further information regarding pre-trained models: [how to register your own model](https://nbviewer.org/github/CSBDeep/CSBDeep/blob/master/examples/other/technical.ipynb#Registry-for-pretrained-models), [model registration in StarDist](https://github.com/stardist/stardist/blob/f73cdc44f718d36844b38c1f1662dbb66d157182/stardist/models/__init__.py#L17-L29).)

**Pre-trained Model**: Select a registered pre-trained model from a list. The first time a model is selected, it is downloaded and cached locally.

**Custom Model**: Provide a path to a StarDist model folder, containing at least `config.json` and a compatible neural network weights file (with suffix `.h5` or `.hdf5`). If present, `thresholds.json` is also loaded and its values can be used via the button *Set optimized postprocessing thresholds (for selected model)*. If you want to use [a model from bioimage.io](https://bioimage.io/#/?tags=stardist&type=model), you first need to convert it to the regular StarDist model folder format (see how to do this [here](https://nbviewer.org/github/stardist/stardist/blob/main/examples/other2D/bioimageio.ipynb#Import-bioimage.io-model-as-StarDist-model)).

**Model Axes**: A read-only text field that shows the semantic axes that the currently selected model expects as input. Additionally, we show the number of expected input channels, e.g. `YXC[2]` to indicate that the model expects a 2D input image with 2 channels. Seeing the model axes is helpful to understand whether the axes of the input image are compatible or not.

**Normalize Image**: A checkbox to indicate whether to perform [percentile-based input image normalization](https://forum.image.sc/t/normalization-in-stardist/41696/2) or not. This should be checked if the input image wasn't [manually normalized](https://forum.image.sc/t/stardist-extension/37696/7) such that most pixel values are in the range 0 to 1. If unchecked, inputs *Percentile low* and *Percentile high* are hidden.

**Percentile low**: Percentile value of input pixel distribution that is mapped to 0 (~min value). If there aren't any outlier pixels in your image, you may use percentile `0` to do a standard [min-max image normalization](https://www.codecademy.com/article/normalization).

**Percentile high**: Percentile value of input pixel distribution that is mapped to 1 (~max value). If there aren't any outlier pixels in your image, you may use percentile `100` to do a standard [min-max image normalization](https://www.codecademy.com/article/normalization).

**Input image scaling**: Number or list of numbers (one per input axis) to scale the input image before prediction and rescale the output accordingly. For example, a value of `0.5` indicates that all spatial axes are downscaled to half their size before prediction, and that the outputs are scaled to double their size. This is useful to adapt to different object sizes in the input image.  
*Tooltip:* Shows the mapping of scale values to the semantic axes of the selected input image.

#### *NMS Postprocessing*

**Probability/Score Threshold**: Determine the number of object candidates to enter non-maximum suppression. Higher values lead to fewer segmented objects, but will likely avoid false positives. The selected model may have an associated threshold value, which can be loaded via the *Set optimized postprocessing thresholds (for selected model)* button.

**Overlap Threshold**: Determine when two objects are considered the same during non-maximum suppression. Higher values allow segmented objects to overlap substantially. The selected model may have an associated threshold value, which can be loaded via the *Set optimized postprocessing thresholds (for selected model)* button.

**Output Type**: Choose format of [outputs](#outputs) (see below for details). Selecting `Label Image` will create the outputs *StarDist labels* and *StarDist class labels* (for multi-class models only) as napari `Labels` layers. Selecting `Polygons / Polyhedra` will instead return the output *StarDist polygons* as a napari `Shapes` layer for a 2D model, or *StarDist polyhedra* as a napari `Surface` layer for a 3D model. Selecting `Both` will return both types of outputs.

#### *Advanced Options*

**Number of Tiles**: String `None` (to disable tiling) or list of integer numbers (one per axis of input image) to determine how the input image is tiled before the CNN prediction is computed on each tile individually. This is needed to avoid (GPU) memory issues that can occur for large input images. Note that the NMS postprocessing is still run only once with candidates from the predictions of all image tiles.  
*Tooltip:* Shows the mapping of tile values to the semantic axes of the selected input image.

**Normalization Axes**: String of semantic axes which are jointly normalized (if they are present in the input image). For example, the default value `ZYX` indicates that all spatial axes are always normalized together; if an image has multiple channels, the pixels will be normalized separately per channel (e.g. this is what typically makes sense for fluorescence microscopy where channels are independent). On the other hand, the channels in RGB color images typically need to be normalized jointly, hence using `ZYXC` makes sense in this case. Note: if an image is explicitly opened with `rgb=True` in napari, the channels are automatically normalized together.  
*Tooltip:* Shows a brief explanation.

**Time-lapse Labels**: If the input is a time-lapse/movie, each frame is first independently processed by StarDist. If `Separate per frame (no processing)` is chosen, the object ids in the label images of each frame are not modified, i.e. they are consecutive integers that always start at 1. Selecting `Unique through time` will cause object ids to be unique over time, i.e. the smallest object id in a given frame is larger than the largest object id of the previous frame. Finally, choosing `Match to previous frame (via overlap)` will perform a simple form of [greedy](https://en.wikipedia.org/wiki/Greedy_algorithm) matching/tracking, where object ids are propagated from one frame to the next based on object overlap.

**Show CNN Output**: Create additional [outputs](#outputs) (see below for details) *StarDist probability* and *StarDist distances* that show the direct results of the CNN prediction which are the inputs to the NMS postprocessing. Additionally, *StarDist class probabilities* is created for multi-class models.

**Set optimized postprocessing thresholds (for selected model)**: Button to set *Probability/Score Threshold* and *Overlap Threshold* to the values provided by the selected model. Nothing is changed if the model does not provide threshold values.

### Outputs

**StarDist polygons**: The detected/segmented 2D objects as polygons (napari `Shapes` layer).

**StarDist polyhedra**: The detected/segmented 3D objects as surfaces (napari `Surface` layer).

**StarDist labels**: The detected/segmented 2D/3D objects as a *label image* (napari `Labels` layer). In an integer-valued label image, the value of a given pixel denotes the id of the object that it belongs to. For example, all pixels with value 5 belong to the object with id 5. All background pixels (that don't belong to any object) have value 0.

**StarDist class labels** ([multi-class models](https://nbviewer.org/github/stardist/stardist/blob/master/examples/other2D/multiclass.ipynb) only): The classes of detected/segmented 2D/3D objects as a *semantic segmentation labeling* (napari `Labels` layer). The integer value of a given pixel denotes the class id of the object that it belongs to. For example, all pixels with value 3 belong to the object class 3. Note that all pixels that belong to a specific object instance (as returned by *StarDist labels*) do have the same object class here. All background pixels (that don't belong to an object class) have value 0.

**StarDist probability**: The object probabilities predicted by the neural network as a single-channel image (napari `Image` layer).

**StarDist distances**: The radial distances predicted by the neural network as a multi-channel image (napari `Image` layer).

**StarDist class probabilities** ([multi-class models](https://nbviewer.org/github/stardist/stardist/blob/master/examples/other2D/multiclass.ipynb) only): The object class probabilities predicted by the neural network as a multi-channel image (napari `Image` layer).


## Troubleshooting & Support

- The [image.sc forum](https://forum.image.sc/tag/stardist) is the best place to start getting help and support. Make sure to use the tag `stardist`, since we are monitoring all questions with this tag.
- For general questions about StarDist, it's worth taking a look at the [frequently asked questions (FAQ)]( https://stardist.net/docs/faq.html).
- If you have technical questions or found a bug, feel free to [open an issue](https://github.com/stardist/stardist-napari/issues).


## Other resources

A demonstration of an earlier version of the plugin is shown in [this video](https://www.youtube.com/watch?v=Km1_TnUQ4FM&list=PLilvrWT8aLuZCaOkjucLjvDu2YRtCS-JT&index=5).

Many of the parameters are identical to those of our [StarDist ImageJ/Fiji plugin](https://github.com/stardist/stardist-imagej), which are documented [here](https://imagej.net/plugins/stardist#usage).
","['Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'Topic :: Scientific/Engineering', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Framework :: napari']","['Source Code, https://github.com/stardist/stardist-napari', 'Documentation, https://github.com/stardist/stardist-napari', 'Bug Tracker, https://github.com/stardist/stardist-napari/issues', 'User Support, https://forum.image.sc/tag/stardist', 'Twitter, https://twitter.com/martweig']",,,stardist-napari.widget,stardist-napari.data.nuclei_2d,,,
520,test-detect-spots,test-detect-spots,napari Detect Spots,0.0.1,2023-04-20,2023-04-20,Kevin Lai,klai@chanzuckerberg.com,BSD-3-Clause,,https://pypi.org/project/test-detect-spots/,None,,A dummy plugin to learn how to create plugins,>=3.8,"['numpy', 'magicgui', 'qtpy', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# test-detect-spots

[![License BSD-3](https://img.shields.io/pypi/l/test-detect-spots.svg?color=green)](https://github.com/klai95/test-detect-spots/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/test-detect-spots.svg?color=green)](https://pypi.org/project/test-detect-spots)
[![Python Version](https://img.shields.io/pypi/pyversions/test-detect-spots.svg?color=green)](https://python.org)
[![tests](https://github.com/klai95/test-detect-spots/workflows/tests/badge.svg)](https://github.com/klai95/test-detect-spots/actions)
[![codecov](https://codecov.io/gh/klai95/test-detect-spots/branch/main/graph/badge.svg)](https://codecov.io/gh/klai95/test-detect-spots)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/test-detect-spots)](https://napari-hub.org/plugins/test-detect-spots)

A dummy plugin to learn how to create plugins

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `test-detect-spots` via [pip]:

    pip install test-detect-spots




## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""test-detect-spots"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']",,,,test-detect-spots.make_func_widget,,,,
521,tracking-challenge-demo,tracking-challenge-demo,Tracking Challenge Solver,0.0.8,2022-05-03,2023-11-29,Draga Doncila,ddoncila@gmail.com,BSD-3-Clause,https://github.com/DragaDoncila/tracking-challenge-demo/issues,https://pypi.org/project/tracking-challenge-demo/,,https://github.com/DragaDoncila/tracking-challenge-demo,"A demo plugin to load, segment and save tracking challenge data.",>=3.8,"['dask[array]', 'imagecodecs', 'napari', 'napari-plugin-engine >=0.1.4', 'numpy', 'scikit-image', 'tifffile', ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""tox ; extra == 'testing'""]","# tracking-challenge-demo

[![License](https://img.shields.io/pypi/l/tracking-challenge-demo.svg?color=green)](https://github.com/DragaDoncila/tracking-challenge-demo/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/tracking-challenge-demo.svg?color=green)](https://pypi.org/project/tracking-challenge-demo)
[![Python Version](https://img.shields.io/pypi/pyversions/tracking-challenge-demo.svg?color=green)](https://python.org)
[![tests](https://github.com/DragaDoncila/tracking-challenge-demo/workflows/tests/badge.svg)](https://github.com/DragaDoncila/tracking-challenge-demo/actions)
[![codecov](https://codecov.io/gh/DragaDoncila/tracking-challenge-demo/branch/main/graph/badge.svg)](https://codecov.io/gh/DragaDoncila/tracking-challenge-demo)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/tracking-challenge-demo)](https://napari-hub.org/plugins/tracking-challenge-demo)

A demo plugin to load, segment and save tracking challenge data.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/index.html
-->

## Installation

You can install `tracking-challenge-demo` via [pip]:

    pip install tracking-challenge-demo



To install latest development version :

    pip install git+https://github.com/DragaDoncila/tracking-challenge-demo.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""tracking-challenge-demo"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/DragaDoncila/tracking-challenge-demo/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/DragaDoncila/tracking-challenge-demo/issues', 'Documentation, https://github.com/DragaDoncila/tracking-challenge-demo#README.md', 'Source Code, https://github.com/DragaDoncila/tracking-challenge-demo', 'User Support, https://github.com/DragaDoncila/tracking-challenge-demo/issues']",tracking-challenge-demo.get_reader,tracking-challenge-demo.write_single_image,tracking-challenge-demo.make_qwidget,,,['.zip'],
522,the-segmentation-game,the-segmentation-game,the-segmentation-game,0.2.0,2022-05-27,2022-10-02,"Robert Haase, Martin SchÃ¤tz",robert.haase@tu-dresden.de,BSD-3-Clause,https://github.com/haesleinhuepf/the-segmentation-game/issues,https://pypi.org/project/the-segmentation-game/,,https://github.com/haesleinhuepf/the-segmentation-game,Gamified image segmentation quality estimation,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'napari-tools-menu', 'napari-skimage-regionprops', 'scikit-learn']","# The segmentation game - for napari

[![License](https://img.shields.io/pypi/l/the-segmentation-game.svg?color=green)](https://github.com/haesleinhuepf/the-segmentation-game/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/the-segmentation-game.svg?color=green)](https://pypi.org/project/the-segmentation-game)
[![Python Version](https://img.shields.io/pypi/pyversions/the-segmentation-game.svg?color=green)](https://python.org)
[![tests](https://github.com/haesleinhuepf/the-segmentation-game/workflows/tests/badge.svg)](https://github.com/haesleinhuepf/the-segmentation-game/actions)
[![codecov](https://codecov.io/gh/haesleinhuepf/the-segmentation-game/branch/main/graph/badge.svg)](https://codecov.io/gh/haesleinhuepf/the-segmentation-game)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/the-segmentation-game)](https://napari-hub.org/plugins/the-segmentation-game)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.6588373.svg)](https://doi.org/10.5281/zenodo.6588373)

Gamified image segmentation quality estimation

![img.png](https://github.com/haesleinhuepf/the-segmentation-game/raw/main/images/screencast.gif)

----------------------------------

## Usage

The Segmentation Game allows to quantitatively compare segmentation results to a given ground truth annotation.
This allows fine-tuning parameters of image processing workflows to get optimal segmentation quality. 
It also allows comparing different segmentation algorithms and identify which algorithm performs best objectively.

The game can be found in napari's `Tools > Games > The Segmentation Game` menu.

### Ground Truth Annotation

Before you can start playing the game, some annotated cells/nuclei are necessary to later compute segmentation quality from.
Depending on the used metric, it might be sufficient to annotate a hand full of objects. 
Use napari's annotation tools as shown below. 
Use the `+` and `-` keys on your keyboard to increase and decrease the label number that is currently drawn.
Note: Avoid label gaps. The labels must be continuously subsequent. If there are pixels annotated with value 2, there must be pixels annotated with value 1.

![](https://github.com/haesleinhuepf/the-segmentation-game/raw/main/images/annotation.gif)

### Parameter tuning

If you work with one of [napari's segmentation plugins](https://www.napari-hub.org/?search=segmentation&sort=relevance&page=1) that produce labels layers,
you can tune their parameters and see how this influences segmentation quality.

![](https://github.com/haesleinhuepf/the-segmentation-game/raw/main/images/parameter_tuning.gif)

### Segmentation algorithm comparison

If you aim at comparing different segmentation algorithms, you can collect their results in label layers in the napari viewer.
You can then select the segmentation result from the corresponding pulldown and save quantitative comparison results in the Highscore table.

![](https://github.com/haesleinhuepf/the-segmentation-game/raw/main/images/algorithm_comparison.gif)

## Metrics

Currently, these metrics are implemented:
* Jaccard Index (sparse): The [Jaccard Index](https://en.wikipedia.org/wiki/Jaccard_index) is a measure of overlap. 
  It lies between 0 (no overlap) and 1 (perfect overlap). 
  For each annotated ground truth label, the maximum overlap of any segmented label is determined. 
  The mean overlap of all annotated labels serves as metric result.
* Jaccard Index (binary): The annotated ground truth labels and the segmentation result are first binarized considering all annotated pixels as positive and all other labels as negative.
  Afterwards, the overlap between the two binary images is computed. This allows comparing binary segmentation algorithms, such as thresholding techniques.
* Jaccard Index (binary, sparse): The annotated ground truth image can contain values 1 (negative, false) and 2 (positive, true) and
  the segmentation result image will be binarized (0: False, otherwise: True). This allows comparing object/no-object annotations with label images.
 
 
Receiver operating characteristic ([ROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic))
  
Consider a two-class thresholding problem (binary pixel-wise classification object/background), in which the outcomes are labeled either as positive (p) or negative (n). There are four possible outcomes from a binary classifier. If the outcome from a prediction is p and the actual value is also p, then it is called a true positive (TP); however if the actual value is n then it is said to be a false positive (FP). Conversely, a true negative (TN) has occurred when both the prediction outcome and the actual value are n, and false negative (FN) is when the prediction outcome is n while the actual value is p. We can organize result in table called confusion matrix, based on positive/neagtive results in row and true and false result in columns. From the confucsion matrix we can get many metrics with various usefulness. The curently implemented used for classification evaluation are:

* Sensitivity, recall, hit rate, or true positive rate (TPR): (TP)/ (TP + FP), Sensitivity and specificity mathematically describe the accuracy of a test which reports the presence or absence of a condition. Individuals for which the condition is satisfied are considered ""positive"" and those for which it is not are considered ""negative"".
* Specificity, selectivity or true negative rate (TNR): (TN)/ (TN + FN), Sensitivity and specificity mathematically describe the accuracy of a test which reports the presence or absence of a condition. Individuals for which the condition is satisfied are considered ""positive"" and those for which it is not are considered ""negative"".
* Precision or positive predictive value (PPV): (TP)/ (TP + FP), in computing and information science is the process of obtaining information system resources that are relevant to an information need from a collection of those resources. It is quantification for the TP events.
* Accuracy: (TP + TN)/ (TP + FP + TN + FN), Accuracy measures observational error. Accuracy is how close or far off a given set of measurements are to their true value. However, it usually fails in imbalanced sets.
* Balanced Accuracy: (TP/(TP+FN) + TN/(TN+FP))/2, Balanced Accuracy is trying to even out problems of accuracy in imbalanced sets.
* F1 Score: 2*TP/(2*TP + FP + TN + FN), In statistical analysis of binary classification, the F-score or F-measure is a measure of a test's accuracy. It is calculated from the precision and recall of the test, where the precision is the number of true positive results divided by the number of all positive results, including those not identified.
* Threat score (TS) or critical success index (CSI): TP/(TP + FP + FN), TC is another name for Jaccard Index (binary).

The ROC measures or confusion matrix is invaluable in cases when when our binary classifier is not ideal (which is often) and we are aiming to not get a general good result but specified low error. In that case we usually need to decide for some trade off, for example we need all (as many as possible) classified true positive objects, but we do not mind getting (usually as few as possible) false positive objects.

**What we want to achieve**

![Precision-versus-accuracy, source: 10.13140/RG.2.1.1668.7603](https://github.com/martinschatz-cz/the-segmentation-game/blob/main/images/Precision-versus-accuracy.png)

When we are doing semantic segmentation, we are aiming to classify each pixel (ideally correctly) to each of our classes. But that can be hugr ammount of information, and our object might have significantly much less pixels then number of pixels belonging to background and/or other classes. Before choosing right metrics, we need to set up goal for our classification results. Idealy, we would like to have high accuracy and precission for ach class (as is on pictur above), but we might be happy getting high accuracy with good precision. Realisticaly we might need to be more specific, as to choose how big error we are prepared to accept, or decide if it is acceptable to have FN findings but no FP.

Picking up a metric for highly unbalanced classification as in semantic segmentation is challenging. Most of the classic metrics wil fail (but they are stil usable object-wise). And we usually stick up with Jaccard Index/Threat score, F1 Score or anything that will tell us result for TP rate (as we expect we will have less pixels for objects then background and/or other classes).

## Literature recommendation

How to choose the right metric for comparing segmentation results is explained in this paper:
* [Metrics reloaded: Pitfalls and recommendations for image analysis validation. Maier-Hein L. and Reinke A. et al.](https://arxiv.org/abs/2206.01653)

## Related plugins

If you aim at automatically optimizing segmentation quality, there are also napari plugins available with this capability:

* [napari-accelerated-pixel-and-object-classification](https://www.napari-hub.org/plugins/napari-accelerated-pixel-and-object-classification)
* [napari-workflow-optimizer](https://www.napari-hub.org/plugins/napari-workflow-optimizer)

## Installation

You can install `the-segmentation-game` via [pip]:

    pip install the-segmentation-game

## Contributing

Contributions - especially new image segmentation quality metrics - are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""the-segmentation-game"" is free and open source software

## Issues

If you encounter any problems, please open a thread on [image.sc](https://image.sc) along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/haesleinhuepf/the-segmentation-game/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Topic :: Scientific/Engineering :: Information Analysis', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/haesleinhuepf/the-segmentation-game/issues', 'Documentation, https://github.com/haesleinhuepf/the-segmentation-game#README.md', 'Source Code, https://github.com/haesleinhuepf/the-segmentation-game', 'User Support, https://github.com/haesleinhuepf/the-segmentation-game/issues']",,,the-segmentation-game.TheSegmentationGameWidget,,,,
523,unet-lungs-segmentation,unet-lungs-segmentation,Mouse lungs segmentation,1.0.9,2025-03-25,2025-03-28,"Quentin Chappuis, Center for Imaging, Ecole Polytechnique Federale de Lausanne (EPFL)",quentin.chappuis@epfl.ch,BSD-3-Clause,https://github.com/qchapp/lungs-segmentation.git,https://pypi.org/project/unet-lungs-segmentation/,,https://github.com/qchapp/lungs-segmentation.git,3D U-Net model for the segmentation of the lungs in mice CT scans.,>=3.8,"['magicgui', 'qtpy', 'napari[all]>=0.4.16', 'napari-label-focus', 'tifffile', 'scikit-image', 'matplotlib', 'csbdeep', 'python-dotenv', 'huggingface-hub', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# ð­ Lungs segmentation in mice CT scans

We provide a neural network model for segmenting the lungs of the mice. The model is based on the [U-Net](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/) architecture.

<p align=""center"">
    <img src=""https://raw.githubusercontent.com/qchapp/lungs-segmentation/refs/heads/master/images/main_fig.png"" height=""500"">
</p>

The goal of our tool is to provid a reliable way to segment the lungs in mouse CT scans. The U-net model produces a binary mask representing the segmentation of the lungs.

## Try the model 

- [Install the package](#installation)
- [Follow the usage instructions](#usage-in-napari)

## Installation

We recommend performing the installation in a clean Python environment.

The code requires `python>=3.9`, as well as `pytorch>=2.0`. Please install Pytorch first and separately following the instructions for your platform on [pytorch.org](https://pytorch.org/get-started/locally/).

Install `unet_lungs_segmentation` using *pip* after you've installed Pytorch:

```sh
pip install unet_lungs_segmentation
```

or clone the repository and install with:

```sh
git clone https://github.com/qchapp/lungs-segmentation.git
pip install -e .
```

## Models

The model weights (~1 GB) will be automatically downloaded from [Hugging Face](https://huggingface.co/qchapp/unet-lungs-segmentation-weights).


## Usage in Napari

[Napari](https://napari.org/stable/) is a multi-dimensional image viewer for python. To use our model in Napari, start the viewer with

```sh
napari
```

To open an image, use `File > Open files` or drag-and-drop an image into the viewer window. If you want to open medical image formats such as NIFTI directly, consider installing the [napari-medical-image-formats](https://pypi.org/project/napari-medical-image-formats/) plugin.

**Sample data**: To test the model, you can run it on our provided sample image. In Napari, open the image from `File > Open Sample > Mouse lung CT scan`.

Next, in the menu bar select `Plugins > Lungs segmentation (unet_lungs_segmentation)`. Select an image and run it by pressing the ""Segment lungs"" button.

<p align=""center"">
    <img src=""https://raw.githubusercontent.com/qchapp/lungs-segmentation/refs/heads/master/images/napari-screenshot.png"" height=""500"">
</p>

## Usage as a library

You can run a model in just a few lines of code to produce a segmentation mask from an image (represented as a numpy array).

```py
from unet_lungs_segmentation import LungsPredict

lungs_predict = LungsPredict()
mask = lungs_predict.segment_lungs(your_image)
```
or if you want to apply a specific `threshold` (`float` between 0 and 1):
```py
mask = lungs_predict.segment_lungs(your_image, threshold)
```

## Usage as a CLI

Run inference on an image from the command-line. For example:

```sh
uls_predict_image -i /path/to/folder/image_001.tif [-t <threshold>]
```

The `<threshold>` will be applied to the predicted image in order to have a binary mask. A default threshold of 0.5 will be applied if none is given. Should be a `float` between 0 and 1.

The command will save the segmentation next to the image:
```
folder/
    âââ image_001.tif
    âââ image_001_mask.tif
```

Run inference in batch on all images in a folder:

```sh
uls_predict_folder -i /path/to/folder/ [-t <threshold>]
```
Will produce:
```
folder/
    âââ image_001.tif
    âââ image_001_mask.tif
    âââ image_002.tif
    âââ image_002_mask.tif
```

## Dataset

Our model was trained using a dataset of `355` images coming from 17 different experiments, 2 different scanners and validated on `62` images.

## Issues

If you encounter any problems, please fill an issue along with a detailed description.

## License

This model is licensed under the [BSD-3](LICENSE.txt) license.

## Carbon footprint of this project

As per the online tool [*Green algorithms*](http://calculator.green-algorithms.org/), the footprint of training this model was estimated to be around 584 g CO2e.
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Source Code, https://github.com/qchapp/lungs-segmentation.git']",,,unet-lungs-segmentation.predict,,,,
524,vessqc,VessQC,Vessel Quality Check,0.7.0,2025-02-18,2025-06-13,Peter Lampen,Peter Lampen <lampen@isas.de>,"Copyright (c) 2024, Peter Lamp...",https://github.com/MMV-Lab/VessQC/issues,https://pypi.org/project/VessQC/,,,Napari plugin for checking and correcting the segmentation,>=3.9,"['napari', 'numpy', 'qtpy', 'scipy', 'SimpleITK', 'tifffile', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# VessQC

[![License BSD-3](https://img.shields.io/pypi/l/VessQC.svg?color=green)](https://github.com/MMV-Lab/VessQC/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/VessQC.svg?color=green)](https://pypi.org/project/VessQC)
[![Python Version](https://img.shields.io/pypi/pyversions/VessQC.svg?color=green)](https://python.org)
[![tests](https://github.com/MMV-Lab/VessQC/workflows/tests/badge.svg)](https://github.com/MMV-Lab/VessQC/actions)
[![codecov](https://codecov.io/gh/MMV-Lab/VessQC/branch/main/graph/badge.svg)](https://codecov.io/gh/MMV-Lab/VessQC)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/VessQC)](https://napari-hub.org/plugins/VessQC)

A plugin for a vessel quality check

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `VessQC` via [pip]:

    pip install VessQC



To install latest development version :

    pip install git+https://github.com/MMV-Lab/VessQC.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""VessQC"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/MMV-Lab/VessQC/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Science/Research', 'Framework :: napari', 'Topic :: Scientific/Engineering :: Image Processing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Homepage, https://github.com/MMV-Lab/VessQC', 'Bug Tracker, https://github.com/MMV-Lab/VessQC/issues', 'Documentation, https://github.com/MMV-Lab/VessQC#README.md', 'Source Code, https://github.com/MMV-Lab/VessQC', 'User Support, https://github.com/MMV-Lab/VessQC/issues']",,,VessQC.make_vessqc,,,,
525,tootapari,tootapari,Tootapari,0.0.1,2023-07-03,2023-07-03,Kyle Harrington,czi@kyleharrington.com,BSD-3-Clause,https://github.com/kephale/tootapari/issues,https://pypi.org/project/tootapari/,,https://github.com/kephale/tootapari,A plugin to send Mastodon toots from napari,>=3.8,"['numpy', 'python-dotenv', 'Mastodon.py', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'""]","# tootapari

[![License BSD-3](https://img.shields.io/pypi/l/tootapari.svg?color=green)](https://github.com/kephale/tootapari/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/tootapari.svg?color=green)](https://pypi.org/project/tootapari)
[![Python Version](https://img.shields.io/pypi/pyversions/tootapari.svg?color=green)](https://python.org)
[![tests](https://github.com/kephale/tootapari/workflows/tests/badge.svg)](https://github.com/kephale/tootapari/actions)
[![codecov](https://codecov.io/gh/kephale/tootapari/branch/main/graph/badge.svg)](https://codecov.io/gh/kephale/tootapari)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/tootapari)](https://napari-hub.org/plugins/tootapari)

A plugin to send Mastodon toots from napari

----------------------------------

## Installation

You can install `tootapari` via [pip]:

    pip install tootapari



To install latest development version :

    pip install git+https://github.com/kephale/tootapari.git


## Setup

1. Setup your `.env` file in your XDG config directory. On MacOS this is `/Users/<username>/Library/Application\ Support/tootapari/`

It should include:

```
MASTODON_INSTANCE_URL=""https://mastodon.social""
MASTODON_ACCESS_TOKEN=""<your access token>""
```

2. You can generate your access token by following these instructions: https://learn.adafruit.com/intro-to-mastodon-api-circuitpython/generate-your-mastodon-token

TODO: someone should port these instructions to this readme.

3. Start tooting!

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""tootapari"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/kephale/tootapari/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/kephale/tootapari/issues', 'Documentation, https://github.com/kephale/tootapari#README.md', 'Source Code, https://github.com/kephale/tootapari', 'User Support, https://github.com/kephale/tootapari/issues']",,,tootapari.make_qwidget,,,,
526,vessel-express-napari,vessel-express-napari,vessel-express-napari,0.0.9,2022-05-17,2023-04-28,Lennart Kowitz,lennart.kowitz@isas.de,BSD-3-Clause,https://github.com/MMV-Lab/vessel-express-napari/issues,https://pypi.org/project/vessel-express-napari/,,https://github.com/MMV-Lab/vessel-express-napari,A simple plugin for 3D vessel segmentation,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'itk', 'scikit-image', 'aicssegmentation']","# vessel-express-napari

[![License](https://img.shields.io/pypi/l/vessel-express-napari.svg?color=green)](https://github.com/MMV-Lab/vessel-express-napari/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/vessel-express-napari.svg?color=green)](https://pypi.org/project/vessel-express-napari/)
[![Python Version](https://img.shields.io/pypi/pyversions/vessel-express-napari.svg?color=green)](https://python.org)
[![tests](https://github.com/MMV-Lab/vessel-express-napari/workflows/tests/badge.svg)](https://github.com/MMV-Lab/vessel-express-napari/actions)
[![codecov](https://codecov.io/gh/MMV-Lab/vessel-express-napari/branch/main/graph/badge.svg?token=mJPpDiioxu)](https://codecov.io/gh/MMV-Lab/vessel-express-napari)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/vessel-express-napari)](https://www.napari-hub.org/plugins/vessel-express-napari)

A simple plugin for 3D vessel segmentation of LSFM images

This [napari] plugin can be used to optimize the segmentation parameters for the [main VesselExpress software platform](https://github.com/RUB-Bioinf/VesselExpress).

----------------------------------


## Installation

The easiest way to install the plugin is to open napari, go to Plugins, then Install/Uninstall plugins. You will be able to find the plugin by name ""vessel-express-napari"". 

Or, you can install `vessel-express-napari` via [pip]:

    pip install vessel-express-napari


To install latest development version :

    pip install git+https://github.com/MMV-Lab/vessel-express-napari.git


## Documentation

We provide a [quick start guide] to explain the important pieces of this plugin. Suggestions and feature quests are very welcomed. 


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""vessel-express-napari"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/MMV-Lab/vessel-express-napari/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[quick start guide]: https://github.com/MMV-Lab/vessel-express-napari/blob/main/quick_start.md

","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']","['Bug Tracker, https://github.com/MMV-Lab/vessel-express-napari/issues', 'Documentation, https://github.com/MMV-Lab/vessel-express-napari#README.md', 'Source Code, https://github.com/MMV-Lab/vessel-express-napari', 'User Support, https://github.com/MMV-Lab/vessel-express-napari/issues']",vessel-express-napari.napari_get_reader,,vessel-express-napari.ParameterTuning,,['*'],,
527,vollseg-napari,vollseg-napari,vollseg-napari,2.4.9,2021-12-10,2025-07-16,Varun Kapoor,varun.kapoor@kapoorlabs.org,BSD 3-Clause,https://github.com/kapoorlab/vollseg-napari/issues,https://pypi.org/project/vollseg-napari/,,https://github.com/kapoorlab/vollseg-napari,Irregular cell shape segmentation using VollSeg,>=3.7,"['vollseg', 'tensorflow; platform_system != ""Darwin"" or platform_machine != ""arm64""', 'tensorflow-macos; platform_system == ""Darwin"" and platform_machine == ""arm64""', 'napari>=0.4.13', 'magicgui>=0.4.0', 'pyqt6', 'pynvml', 'pytest; extra == ""test""', 'pytest-qt; extra == ""test""', 'napari[pyqt]>=0.4.13; extra == ""test""']","# VollSeg Napari Plugin

# Developed by KapoorLabs


<img src=""images/mtrack.png"" alt=""Logo1"" width=""150""/>
<img src=""images/kapoorlablogo.png"" alt=""Logo2"" width=""150""/>

This product is a testament to our expertise at KapoorLabs, where we specialize in creating cutting-edge solutions. We offer bespoke pipeline development services, transforming your developmental biology questions into publishable figures with our advanced computer vision and AI tools. Leverage our expertise and resources to achieve end-to-end solutions that make your research stand out.

**Note:** The tools and pipelines showcased here represent only a fraction of what we can achieve. For tailored and comprehensive solutions beyond what was done in the referenced publication, engage with us directly. Our team is ready to provide the expertise and custom development you need to take your research to the next level. Visit us at [KapoorLabs](https://www.kapoorlabs.org/).


[![PyPI version](https://img.shields.io/pypi/v/vollseg-napari.svg)](https://pypi.org/project/vollseg-napari)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/vollseg-napari)](https://napari-hub.org/plugins/vollseg-napari)
[![License](https://img.shields.io/pypi/l/napari-metroid.svg?color=green)](https://github.com/kapoorlab/napari-vollseg/raw/main/LICENSE)
[![codecov](https://codecov.io/gh/kapoorlab/napari-vollseg/branch/main/graph/badge.svg)](https://codecov.io/gh/kapoorlab/napari-vollseg)
[![Twitter Badge](https://badgen.net/badge/icon/twitter?icon=twitter&label)](https://twitter.com/entracod)

## Segmentation Algorithm

VollSeg is more than just a single segmentation algorithm; it is a meticulously designed modular segmentation tool tailored to diverse model organisms and imaging methods. While a U-Net might suffice for certain image samples, others might benefit from utilizing StarDist, and some could require a blend of both, potentially coupled with denoising or region of interest models. The pivotal decision left to make is how to select the most appropriate VollSeg configuration for your dataset, a question we comprehensively address in our [documentation website](https://kapoorlabs-caped.github.io/vollseg-napari/).

This project provides the [napari](https://napari.org/) plugin for [VollSeg](https://github.com/kapoorlab/vollseg), a deep learning based 2D and 3D segmentation tool for irregular shaped cells. VollSeg has originally been developed (see [papers](http://conference.scipy.org/proceedings/scipy2021/varun_kapoor.html)) for the segmentation of densely packed membrane labelled cells in challenging images with low signal-to-noise ratios. The plugin allows to apply pretrained and custom trained models from within napari.
For detailed demo of the plugin see these [videos](https://www.youtube.com/watch?v=W_gKrLWKNpQ) and a short video about the [parameter selection](https://www.youtube.com/watch?v=7tQMn_u8_7s&t=1s) 


## Installation & Usage

Install the plugin with `pip install vollseg-napari` or from within napari via `Plugins > Install/Uninstall Package(s)â¦`. 

You can activate the plugin in napari via `Plugins > VollSeg: VollSeg`. Example images for testing are provided via `File > Open Sample > VollSeg`.

If you use this plugin for your research, please [cite us](http://conference.scipy.org/proceedings/scipy2021/varun_kapoor.html).


## Examples

VollSeg comes with different options to combine CARE based denoising with UNET, StarDist and segmentation in a region of interest (ROI). We present some examples which are represent optimal combination of these different modes for segmenting different cell types. We summarize this in the table below:
| Example Image | Description | Training Data | Trained Model |
| --- | --- |--- | --- |
| ![Raw Ascadian Embryo](images/Ascadian_raw.png)| Light sheet fused from four angles 3D single channel| [Training Data ~320 GB](https://figshare.com/articles/dataset/Astec-half-Pm1_Cut_at_2-cell_stage_half_Phallusia_mammillata_embryo_live_SPIM_imaging_stages_6-16_/11309570?backTo=/s/765d4361d1b073beedd5)| [UNET model](https://zenodo.org/record/6337699) |
| ![Raw Carcinoma](images/Carcinoma_raw.png)| Confocal microscopy 3D single channel 8 bit| [Training Data](https://zenodo.org/record/5904082#.Yi8-BnrMJD8)| [Denoising Model](https://zenodo.org/record/5910645/) and [StarDist Model](https://zenodo.org/record/6354077/) |
| ![Raw Xenopus Tissue](images/Xenopus_tissue_raw.png)| LaserScanningConfocalMicroscopy 2D single channel| [Dataset](https://zenodo.org/record/6076614#.YjBaNnrMJD8)| [UNET Model](https://zenodo.org/record/6060378/)  |



## Troubleshooting & Support

- The [image.sc forum](https://forum.image.sc/tag/vollseg) is the best place to start getting help and support. Make sure to use the tag `vollseg`, since we are monitoring all questions with this tag.
- If you have technical questions or found a bug, feel free to [open an issue](https://github.com/kapoorlab/vollseg-napari/issues).

## Authors

- Varun Kapoor <randomaccessiblekapoor@gmail.com>
- Mari Tolonen
- Jakub Sedzinski
","['Development Status :: 4 - Beta', 'Intended Audience :: Science/Research', 'Topic :: Scientific/Engineering', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Framework :: napari']","['Source Code, https://github.com/kapoorlab/vollseg-napari', 'Documentation, https://github.com/kapoorlab/vollseg-napari', 'Bug Tracker, https://github.com/kapoorlab/vollseg-napari/issues', 'User Support, https://forum.image.sc/tag/vollseg-napari', 'Twitter, https://twitter.com/entracod']",,,vollseg-napari.widget,vollseg-napari.test_image_ascadian_3d,,,
528,vollseg-napari-trackmate,vollseg-napari-trackmate,vollseg-napari-trackmate,2.6.6,2022-12-31,2025-05-05,"Varun Kapoor, Mari Tolonen, Jakub Sedzinski",randomaccessiblekapoor@gmail.com,BSD-3-Clause,https://github.com/Kapoorlabs-CAPED/vollseg-napari-trackmate/issues,https://pypi.org/project/vollseg-napari-trackmate/,,https://github.com/Kapoorlabs-CAPED/vollseg-napari-trackmate,Track analysis using TrackMate xml and csv generated tracks using NapaTrackMater as the base library,>=3.8,"['napari-plugin-engine>=0.1.4', 'caped-ai', 'tox; extra == ""testing""', 'pytest; extra == ""testing""', 'pytest-cov; extra == ""testing""', 'pytest-qt; extra == ""testing""', 'napari; extra == ""testing""', 'pyqt5; extra == ""testing""']","# vollseg-napari-trackmate

[![License BSD-3](https://img.shields.io/pypi/l/vollseg-napari-trackmate.svg?color=green)](https://github.com/Kapoorlabs-CAPED/vollseg-napari-trackmate/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/vollseg-napari-trackmate.svg?color=green)](https://pypi.org/project/vollseg-napari-trackmate)
[![Python Version](https://img.shields.io/pypi/pyversions/vollseg-napari-trackmate.svg?color=green)](https://python.org)
[![codecov](https://codecov.io/gh/Kapoorlabs-CAPED/vollseg-napari-trackmate/branch/main/graph/badge.svg)](https://codecov.io/gh/Kapoorlabs-CAPED/vollseg-napari-trackmate)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/vollseg-napari-trackmate)](https://napari-hub.org/plugins/vollseg-napari-trackmate)

Track analysis using TrackMate xml and csv generated tracks using NapaTrackMater as the base library

----------------------------------

Elaborate documentation for users of this repository at this [documentation]

## Tutorial

- A detailed tutorial can be found at [Demo](https://youtu.be/7Yjd-Z3zJtk?si=_AksSBUJuEXbvIFM)

This [napari] plugin was generated with [Cookiecutter] using [@caped]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `vollseg-napari-trackmate` via [pip]:

    pip install vollseg-napari-trackmate



To install latest development version :

    pip install git+https://github.com/Kapoorlabs-CAPED/vollseg-napari-trackmate.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""vollseg-napari-trackmate"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[@caped]: https://github.com/Kapoorlabs-CAPED/
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/Kapoorlabs-CAPED/cookiecutter-kapoorlabs-napari-plugin
[documentation]: https://kapoorlabs-caped.github.io/vollseg-napari-trackmate
[file an issue]: https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/Kapoorlabs-CAPED/vollseg-napari-trackmate/issues', 'Documentation, https://github.com/Kapoorlabs-CAPED/vollseg-napari-trackmate#README.md', 'Source Code, https://github.com/Kapoorlabs-CAPED/vollseg-napari-trackmate', 'User Support, https://github.com/Kapoorlabs-CAPED/vollseg-napari-trackmate/issues']",,,vollseg-napari-trackmate.widget,vollseg-napari-trackmate.get_test_tracks_xenopus,,,
529,vollseg-napari-mtrack,vollseg-napari-mtrack,VollSeg Napari MTrack Plugin,1.4.7,2022-12-20,2023-10-28,Varun Kapoor,randomaccessiblekapoor@gmail.com,BSD-3-Clause,https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack/issues,https://pypi.org/project/vollseg-napari-mtrack/,,https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack,"Segment kymographs of microtubules, actin filaments and perform Ransac based fits to compute dynamic instability parameters for individual kymographs and also in batch",>=3.8,"['numpy', 'magicgui', 'qtpy', 'caped-ai', ""tox ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari ; extra == 'testing'"", ""pyqt5 ; extra == 'testing'""]","# vollseg-napari-mtrack

[![License BSD-3](https://img.shields.io/pypi/l/vollseg-napari-mtrack.svg?color=green)](https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/vollseg-napari-mtrack.svg?color=green)](https://pypi.org/project/vollseg-napari-mtrack)
[![Python Version](https://img.shields.io/pypi/pyversions/vollseg-napari-mtrack.svg?color=green)](https://python.org)
[![tests](https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack/workflows/tests/badge.svg)](https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack/actions)
[![codecov](https://codecov.io/gh/Kapoorlabs-CAPED/vollseg-napari-mtrack/branch/main/graph/badge.svg)](https://codecov.io/gh/Kapoorlabs-CAPED/vollseg-napari-mtrack)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/vollseg-napari-mtrack)](https://napari-hub.org/plugins/vollseg-napari-mtrack)

Segment kymographs of microtubules, actin filaments and perform Ransac based fits to compute dynamic instability parameters for individual kymographs and also in batch

----------------------------------

Elaborate documentation for users of this repository at this [documentation]

This [napari] plugin was generated with [Cookiecutter] using [@caped]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/stable/plugins/index.html
-->

## Installation

You can install `vollseg-napari-mtrack` via [pip]:

    pip install vollseg-napari-mtrack



To install latest development version :

    pip install git+https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack.git


## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""vollseg-napari-mtrack"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[@caped]: https://github.com/Kapoorlabs-CAPED/
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/Kapoorlabs-CAPED/cookiecutter-kapoorlabs-napari-plugin
[documentation]: https://kapoorlabs-caped.github.io/vollseg-napari-mtrack
[file an issue]: https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Scientific/Engineering :: Image Processing']","['Bug Tracker, https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack/issues', 'Documentation, https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack#README.md', 'Source Code, https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack', 'User Support, https://github.com/Kapoorlabs-CAPED/vollseg-napari-mtrack/issues']",vollseg-napari-mtrack.get_reader,,vollseg-napari-mtrack.widget,vollseg-napari-mtrack.get_microtubule_test_data,,,
530,waver,waver,waver,0.0.4,2021-05-15,2021-08-15,Nicholas Sofroniew,sofroniewn@gmail.com,BSD-3,https://github.com/sofroniewn/waver,https://pypi.org/project/waver/,,https://github.com/sofroniewn/waver,Wave simulations,>=3.7,"['magicgui (>=0.2.10)', 'napari (>=0.4.10)', 'napari-plugin-engine (>=0.1.4)', 'numpy', 'zarr']","# waver

[![License](https://img.shields.io/pypi/l/waver.svg?color=green)](https://github.com/sofroniewn/waver/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/waver.svg?color=green)](https://pypi.org/project/waver)
[![Python Version](https://img.shields.io/pypi/pyversions/waver.svg?color=green)](https://python.org)
[![tests](https://github.com/sofroniewn/waver/workflows/tests/badge.svg)](https://github.com/sofroniewn/waver/actions)
[![codecov](https://codecov.io/gh/sofroniewn/waver/branch/main/graph/badge.svg?token=QBP7K6YUT7)](https://codecov.io/gh/sofroniewn/waver)

Run simulations of the [wave equation](https://en.wikipedia.org/wiki/Wave_equation) in nD on grids of variable speed in Python. This library owes a lot of its design and approach to the [fdtd](https://github.com/flaport/fdtd) library, a Python 3D electromagnetic FDTD simulator.

This package allows for a fair amount of customization over your wave simulation. You can
 - specify the size and spacing of the grid
 - specify the time step for the simulation, which will be checked to ensure stability of the simulation
 - specify the duration of the simulation
 - setting a variable speed array (one value per grid point) to allow for ""objects"" in your environment
 - set the source of the wave, which can be a point, line, or any (n-1)D subarray
 - record the wave with a detector, which can be the full grid, the full boundary, or a particular boundary
 - use convenience methods to run many simulations with different sources on the same grid and detector combination

You can use [napari](https://napari.org/), a multi-dimensional image viewer for Python, to allow for easy visualization of the detected wave. Some functionality is also available as a napari plugin to allow for running simulations from a graphical user interface.

Results can look like

https://user-images.githubusercontent.com/6531703/128283012-a784ec06-4df9-4ddf-bf4f-e21b927fe4a3.mov

----------------------------------

## Installation

You can install `waver` via [pip]:

    pip install waver

## Usage

### Convenience Methods

The most convenient way to use waver is to use one of two convenience methods that will create and run a simulation
for you and return the results.

The first method `run_single_source` allows you to run a single simulation with a single source on one grid and 
record the results using a detector. For example

```python
from waver.simulation import run_single_source

single_sim_params = {
    'size': (12.8e-3, 12.8e-3),
    'spacing': 100e-6,
    'duration': 80e-6,
    'min_speed': 343,
    'max_speed': 686,
    'speed': 686,
    'time_step': 50e-9,
    'temporal_downsample': 2,
    'location': (6.4e-3, 6.4e-3),
    'period': 5e-6,
    'ncycles':1,
}

detected_wave, speed_grid = run_single_source(**single_sim_params)
```

The second method `run_multiple_sources` allows you to run multiple simulations with multiple sources on the same
grid and with the same detector and return the results. For example

```python
from waver.simulation import run_multiple_sources

multi_sim_params = {
    'size': (12.8e-3, 12.8e-3),
    'spacing': 100e-6,
    'duration': 80e-6,
    'min_speed': 343,
    'max_speed': 686,
    'speed': 686,
    'time_step': 50e-9,
    'temporal_downsample': 2,
    'sources': [{
        'location': (6.4e-3, 6.4e-3),
        'period': 5e-6,
        'ncycles':1,
    }]
}

detected_wave, speed_grid = run_multiple_sources(**multi_sim_params)
```

The main difference between these two methods is that `run_multiple_sources` takes a `sources` parameter which takes a list 
of dictionaries with keys corresponding to source related keyword arguments found in `run_single_source`.

### Visualization

If you want to quickly visualize the results of `run_multiple_sources`, you can use the `run_and_visualize` command which will 
run the simulation and then launch napari with the results, as seen in [examples/2D/point_source.py](./examples/2D/point_source.py)

```python
from waver.datasets import run_and_visualize

run_and_visualize(**multi_sim_params)
```

### Datasets

If you want to run simulations with on many different speed grids you can use the `generate_simulation_dataset` method as a convenience. The results will be saved to a [zarr](https://zarr.readthedocs.io/en/stable/) file of your chosing. You can then use the `load_simulation_dataset` to load the dataset.

```python
from waver.datasets import generate_simulation_dataset

# Define root path for simulation
path = './simulation_dataset.zarr'
runs = 5

# Define a simulation, 12.8mm, 100um spacing
dataset_sim_params = {
    'size': (12.8e-3, 12.8e-3),
    'spacing': 100e-6,
    'duration': 80e-6,
    'min_speed': 343,
    'max_speed': 686,
    'speed': 'mixed_random_ifft',
    'time_step': 50e-9,
    'sources': [{
        'location': (None, 0),
        'period': 5e-6,
        'ncycles':1,
    }],
    'temporal_downsample': 2,
    'boundary': 1,
    'edge': 1,
}

# Run and save simulation
generate_simulation_dataset(path, runs, **dataset_sim_params)
```

The `generate_simulation_dataset` allows the `speed` to be a string that will specify a particular method of randomly generating speed values for the simulation grid.

### The Simulation Object

If you'd like to understand in a little bit more detail how a simulation is defined then you might want to use the unerlying simulation object `Simulation` and manually set key objects like the `Source` and `Detector`. A full example of this is as follows

```python
# Create a simulation
sim = Simulation(size=size, spacing=spacing, max_speed=max_speed, time_step=time_step)

# Set speed array
sim.set_speed(speed=speed, min_speed=min_speed, max_speed=max_speed)

# Add source
sim.add_source(location=location, period=period, ncycles=ncycles, phase=phase)

# Add detector grid
sim.add_detector(spatial_downsample=spatial_downsample,
                    boundary=boundary, edge=edge)

# Run simulation
sim.run(duration=duration, temporal_downsample=temporal_downsample, progress=progress, leave=leave)

# Print simulation wave and speed data
print('wave: ', sim.detected_wave)
print('speed: ', sim.grid_speed)
```

Note these steps are done inside the `run_single_source` method for you as a convenience.

## Known Limitations

A [perfectly matched layer](https://en.wikipedia.org/wiki/Perfectly_matched_layer) boundary has recently been added, but might not perform well under all conditions. Additional contributions would be welcome here.

Right now the simulations are quite slow. I'd like to add a [JAX](https://github.com/google/jax) backend, but 
havn't done so yet. Contributions would be welcome.

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""waver"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/sofroniewn/waver/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,waver.napari_get_reader,,waver.simulation,,['*'],,
531,world2data,World2Data,World2Data,0.0.3,2022-01-14,2022-01-14,"Marc Boucsein, Robin Koch",,BSD-3,https://github.com/MBPhys/World2Data,https://pypi.org/project/World2Data/,,https://github.com/MBPhys/World2Data,A napari plugin in order to convert the world information to the data of a 2D/3D layer,>=3.7,"['napari-plugin-engine (>=0.1.4)', 'numpy', 'gryds', 'dask', 'scikit-image']","# World2Data

[![License](https://img.shields.io/pypi/l/napari-medical-image-formats.svg?color=green)](https://github.com/MBPhys/World2Data/raw/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/World2Data.svg?color=green)](https://pypi.org/project/World2Data)
[![Python Version](https://img.shields.io/pypi/pyversions/World2Data.svg?color=green)](https://python.org)


A napari plugin in order to convert the world information to the data of a 2D/3D layer.

----------------------------------

## Installation

You can install `World2Data` via [pip]:

    pip install World2Data

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""World2Data"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/MBPhys/World2Data/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,,,World2Data.World2Data,,,,
532,yt-napari,yt-napari,yt-napari,0.5.0,2022-05-02,2024-05-23,Chris Havlin,chris.havlin@gmail.com,BSD-3-Clause,https://github.com/data-exp-lab/yt-napari/issues,https://pypi.org/project/yt-napari/,,https://github.com/data-exp-lab/yt-napari,A napari plugin for loading data from yt,>=3.8,"['magicgui >=0.6.1', 'napari >=0.4.19', 'numpy', 'packaging', 'pydantic >2.0', 'qtpy', 'unyt', 'yt >=4.0.1', ""pytest ; extra == 'dev'"", ""pytest-qt ; extra == 'dev'"", ""taskipy ; extra == 'dev'"", ""sphinx ; extra == 'docs'"", ""nbsphinx <0.8.8 ; extra == 'docs'"", ""sphinx-jsonschema <1.19.0 ; extra == 'docs'"", ""Jinja2 <3.1.0 ; extra == 'docs'"", ""dask[array,distributed] ; extra == 'full'""]","# yt-napari

[![License](https://img.shields.io/pypi/l/yt-napari.svg?color=green)](https://github.com/data-exp-lab/yt-napari/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/yt-napari.svg?color=green)](https://pypi.org/project/yt-napari)
[![Python Version](https://img.shields.io/pypi/pyversions/yt-napari.svg?color=green)](https://python.org)
[![tests](https://github.com/data-exp-lab/yt-napari/workflows/tests/badge.svg)](https://github.com/data-exp-lab/yt-napari/actions)
[![codecov](https://codecov.io/gh/data-exp-lab/yt-napari/branch/main/graph/badge.svg)](https://codecov.io/gh/data-exp-lab/yt-napari)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/yt-napari)](https://napari-hub.org/plugins/yt-napari)
[![Documentation Status](https://readthedocs.org/projects/yt-napari/badge/?version=latest)](https://yt-napari.readthedocs.io/en/latest/?badge=latest)

A [napari] plugin for loading data from [yt].

This readme provides a brief overview including:

1. [Installation](#Installation)
2. [Quick Start](#Quick-Start)
3. [Contributing](#Contributing)

Full documentation is available at [yt-napari.readthedocs.io].

## Installation

### 1. (optional) install `yt` and `napari`

If you skip this step, the installation in the following section will only install the minimal package requirements for `yt` or `napari`, in which case you will likely need to manually install some packages. So if you are new to either package, or if you are installing in a clean environment, it may be simpler to  install these packages first.

For `napari`,

    pip install napari[all]

will install `napari` with the default `Qt` backend (see [here](https://napari.org/tutorials/fundamentals/installation#choosing-a-different-qt-backend) for how to choose between `PyQt5` or `PySide2`).

For `yt`, you will need `yt>=4.0.1` and any of the optional dependencies for your particular workflow. If you know that you'll need more than the base `yt` install, you can install the full suite of dependent packages with

    pip install yt[full]

See the [`yt` documentation](https://yt-project.org/doc/installing.html#leveraging-optional-yt-runtime-dependencies) for more information. If you're not sure which packages you'll need but don't want the full yt installation, you can proceed to the next step and then install any packages as needed (you will receive error messages when a required package is missing).

### 2. install `yt-napari`

You can install the `yt-napari` plugin with:

    pip install yt-napari

If you are missing either `yt` or `napari` (or they need to be updated), the above installation will fetch and run a minimal installation for both.

To install the latest development version of the plugin instead, use:

    pip install git+https://github.com/data-exp-lab/yt-napari.git

Note that if you are working off the development version, be sure to use the latest documentation
for reference: https://yt-napari.readthedocs.io/en/latest/

## Quick Start

After [installation](#Installation), there are three modes of using `yt-napari`:

1. jupyter notebook interaction ([jump down](#jupyter-notebook-interaction))
2. loading a json file from the napari gui ([jump down](#loading-a-json-file-from-the-napari-gui))
3. napari widget plugins ([jump down](#napari-widget-plugins))

### jupyter notebook interaction

`yt-napari` provides a helper class, `yt_napari.viewer.Scene` that assists in properly aligning new yt selections in the napari viewer when working in a Jupyter notebook.

```python
import napari
import yt
from yt_napari.viewer import Scene
from napari.utils import nbscreenshot

viewer = napari.Viewer()
ds = yt.load(""IsolatedGalaxy/galaxy0030/galaxy0030"")
yt_scene = Scene()

left_edge = ds.domain_center - ds.arr([40, 40, 40], 'kpc')
right_edge = ds.domain_center + ds.arr([40, 40, 40], 'kpc')
res = (600, 600, 600)

yt_scene.add_region(viewer,
                    ds,
                    (""enzo"", ""Temperature""),
                    left_edge=left_edge,
                    right_edge=right_edge,
                    resolution=res)

yt_scene.add_region(viewer,
                    ds,
                    (""enzo"", ""Density""),
                    left_edge=left_edge,
                    right_edge=right_edge,
                    resolution=res)

nbscreenshot(viewer)
```

 ![Loading a subset of a yt dataset in napari from a Jupyter notebook](./assets/images/readme_ex_001.png)

`yt_scene.add_to_viewer` accepts any of the keyword arguments allowed by `viewer.add_image`. See the full documentation ([yt-napari.readthedocs.io]) for more examples, including additional helper methods for linking layer appearance.

Additionally, with `yt_napari`>= v0.2.0, you can use the `yt_napari.timeseries` module to help sample and load in selections from across datasets.

### loading a selection from a yt dataset interactively

`yt-napari` provides two ways to sample a yt dataset and load in an image layer into a Napari viewer: the yt Reader plugin and json file specification.

#### using the yt Reader plugin

To use the yt Reader plugin, click on `Plugins -> yt-napari: yt Reader`. From there, add a region or slice selector then specify a field type and field and bounds to sample  between and then simply click ""Load"":

![Loading a subset of a yt dataset from the napari viewer](./assets/images/readme_ex_003_gui_reader.gif)

You can add multiple selections and load them all at once or adjust values and click ""Load"" again.

#### using the yt Time Series Reader plugin

To use the yt Time Series Reader plugin, click on  `Plugins -> yt-napari: yt Time Series Reader`. Specify your file matching: use `file_pattern` to enter glob expressions or use `file_list` to enter a list of specific files.
Then add a slice or region to sample for each matched dataset file (note: be careful of memory here!):

![Loading timeseries selections from the napari viewer](./assets/images/readme_ex_004_gui_timeseries.gif)

#### using a json file and schema

`yt-napari` also provides the ability to load json that contain specifications for loading a file. Properly formatted files can be loaded from the napari GUI as you would load any image file (`File->Open`). The json file describes the selection process for a dataset as described by a json-schema. The following json file results in similar layers as the above examples:


```json
{""$schema"": ""https://raw.githubusercontent.com/data-exp-lab/yt-napari/main/src/yt_napari/schemas/yt-napari_0.0.1.json"",
 ""datasets"": [{""filename"": ""IsolatedGalaxy/galaxy0030/galaxy0030"",
               ""selections"": {""regions"": [{
                                ""fields"": [{""field_name"": ""Temperature"", ""field_type"": ""enzo"", ""take_log"": true},
                                           {""field_name"": ""Density"", ""field_type"": ""enzo"", ""take_log"": true}],
                                ""left_edge"": [460.0, 460.0, 460.0],
                                ""right_edge"": [560.0, 560.0, 560.0],
                                ""resolution"": [600, 600, 600]
                              }]},
               ""edge_units"": ""kpc""
             }]
}
```

To help in filling out a json file, it is recommended that you use an editor capable of parsing a json schema and displaying hints. For example, in vscode, you will see field suggestions after specifying the `yt-napari` schema:

![interactive json completion for yt-napari](./assets/images/readme_ex_002_json.png)

See the full documentation at [yt-napari.readthedocs.io] for a complete specification.


## Contributing

Contributions are very welcome! Development follows a fork and pull request workflow. To get started, you'll need a development installation and a testing environment.

### development environment

To start developing, fork the repository and clone your fork to get a local copy. You can then install in development mode with

    pip install -e .

### tests and style checks

Both bug fixes and new features will need to pass the existing test suite and style checks. While both will be run automatically when you submit a pull request, it is helpful to run the test suites locally and run style checks throughout development. For testing, you can use [tox] to test different python versions on your platform.

    pip install tox

And then from the top level of the `yt-napari` directory, run

    tox

Tox will then run a series of tests in isolated environments. In addition to checking the terminal output for test results, the tox run will generate a test coverage report: a `coverage.xml` file and a `htmlcov` folder -- to view the results, open `htmlcov/index.html` in a browser.

If you prefer a lighter weight test, you can also use `pytest` directly and rely on the Github CI to test different python versions and systems. To do so, first install `pytest` and some related plugins:

    pip install pytest pytest-qt pytest-cov

Now, to run the tests:

    pytest -v --cov=yt_napari --cov-report=html

In addition to telling you whether or not the tests pass, the above command will write out a code coverage report to the `htmlcov` directory. You can open up `htmlcov/index.html` in a browser and check out the lines of code that were missed by existing tests.

For style checks, you can use [pre-commit](https://pre-commit.com/) to run checks as you develop. To set up `pre-commit`:

    pip install pre-commit
    pre-commit install

after which, every time you run `git commit`, some automatic style adjustments and checks will run. The same style checks will run when you submit a pull request, but it's often easier to catch them early.

After submitting a pull request, the `pre-commit.ci` bot will run the style checks. If style checks fail, you can have the bot attempt to auto-fix the failures by adding the following in a comment on it's own:

    pre-commit.ci autofix

The bot will then commit changes to your pull request after which you will want to run `git pull` locally to update your local version of the branch before making further changes to the branch.

### building documentation locally

Documentation can be built using `sphinx` in two steps. First, update the api mapping with

    sphinx-apidoc -f -o docs/source src/yt_napari/

This will update the `rst` files in `docs/source/` with the latest docstrings in `yt_napari`. Next, build the html documentation with

    make html


### updating the pydantic models and schema

The schema versioning follows a `major.minor.micro` versioning pattern that matches the yt-napari versioning. Each yt-napari release should have an accompanying updated schema file, even if the  contents of the schema file have not changed. On-disk schema are stored in  `src/yt_napari/schemas/`, with copies in the documentation at `docs/_static`.

There are a number of utilities to help automate the management of schema in `repo_utilities/`. The easiest way to use these utitities is with `taskipy` from the command line. To list available scripts:

```commandline
task --list
```

Before a release, run

```commandline
task validate_release vX.X.X
```

where `vX.X.X` is the version of the upcoming release. This script will run through some checks that ensure:
* the on-disk schema matches the schema generated by the pydantic model
* the schema files in the documentation match the schema files in the package

If any of the checks fail, you will be advised to update the schema using `update_schema_docs`. If you
run without providing a version:

```commandline
task update_schema_docs
```

It will simply copy over the existing on-disk schema files to the documentation. If you run with a version:

```commandline
task update_schema_docs -v vX.X.X
```
It will write a schema file for the current pydantic model, overwriting any on-disk schema files for
the provided version.

## License

Distributed under the terms of the [BSD-3] license,
""yt-napari"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

## Funding

The yt-napari plugin project was funded with support from the Chan Zuckerberg Initiative through the napari Plugin Accelerator Grants project, [Enabling Access To Multi-resolution Data](https://chanzuckerberg.com/science/programs-resources/imaging/napari/enabling-access-to-multi-resolution-data/).

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/plugins/stable/index.html
-->

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[yt-napari.readthedocs.io]: https://yt-napari.readthedocs.io/en/stable/

[file an issue]: https://github.com/data-exp-lab/yt-napari/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
[yt]: https://yt-project.org/
","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: OS Independent', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/data-exp-lab/yt-napari/issues', 'Documentation, https://github.com/data-exp-lab/yt-napari#README.md', 'Source Code, https://github.com/data-exp-lab/yt-napari', 'User Support, https://github.com/data-exp-lab/yt-napari/issues']",yt-napari.get_reader,,yt-napari.reader_widget,,['*.json'],,
533,workshop-demo,workshop-demo,workshop demo,0.0.2,2021-12-15,2022-03-10,Draga Doncila Pop,ddoncilapop@contractor.chanzuckerberg.com,BSD-3-Clause,https://github.com/DragaDoncila/workshop-demo/issues,https://pypi.org/project/workshop-demo/,,https://github.com/DragaDoncila/workshop-demo,"A demo napari plugin incorporating reader, writer and dock widget contributions using the new npe2 plugin architecture.",>=3.7,"['dask[array]', 'imagecodecs', 'napari', 'napari-plugin-engine (>=0.1.4)', 'npe2', 'numpy', 'scikit-image', 'tifffile']","# workshop-demo

[![License](https://img.shields.io/pypi/l/workshop-demo.svg?color=green)](https://github.com/DragaDoncila/workshop-demo/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/workshop-demo.svg?color=green)](https://pypi.org/project/workshop-demo)
[![Python Version](https://img.shields.io/pypi/pyversions/workshop-demo.svg?color=green)](https://python.org)
[![tests](https://github.com/DragaDoncila/workshop-demo/workflows/tests/badge.svg)](https://github.com/DragaDoncila/workshop-demo/actions)
[![codecov](https://codecov.io/gh/DragaDoncila/workshop-demo/branch/main/graph/badge.svg)](https://codecov.io/gh/DragaDoncila/workshop-demo)
[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/workshop-demo)](https://napari-hub.org/plugins/workshop-demo)

A demo napari plugin incorporating reader, writer and dock widget contributions using the new npe2 plugin architecture.

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `workshop-demo` via [pip]:

    pip install workshop-demo


To install latest development version :

    pip install git+https://github.com/DragaDoncila/workshop-demo.git

## What is this?

This plugin was created to serve as a semi-meaningful example of a plugin using
the new napari [npe2](https://pypi.org/project/npe2/) architecture.

It provides a reader, a writer and two dock widgets to support opening, processing
and writing out [cell tracking challenge](https://celltrackingchallenge.net/) data.

We've provided comments and example tests that can be used as a reference
when building your own plugin.

## Using this plugin

### Sample Data
You can download sample data for this plugin from the tracking challenge website. Any 2D+T
sequence should work, but this plugin has been tested only with the 
[Human hepatocarcinoma-derived cells expressing the fusion protein YFP-TIA-1](http://data.celltrackingchallenge.net/training-datasets/Fluo-C2DL-Huh7.zip) 
dataset.
### Reading Data
This plugin's reader is designed for tracking challenge segmentation gold standard ground truth
data conforming to the file format described in the [data specification](https://public.celltrackingchallenge.net/documents/Naming%20and%20file%20content%20conventions.pdf).

Ground truth data is only provided for a subset of the frames of the entire sequence. This
reader will attempt to find the number of frames of the associated sequence in a sister
directory of the ground truth data directory and open a labels layer with the same number
of frames, thus ensuring the labelled data is correctly overlaid onto the original sequence.



https://user-images.githubusercontent.com/17995243/146114062-36124c05-f44a-488e-8991-f39a702c917f.mov



### Segmenting Data
One of the dock widgets provided by this plugin is ""Segment by Threshold"". The widget
allows you to select a 2D+T image layer in the viewer (e.g. any of the sequences in the Human 
hepatocarcinoma dataset above) and segment it using a selection of scikit-image thresholding functions.

The segmentation is then returned as a `Labels` layer into the viewer.


https://user-images.githubusercontent.com/17995243/146114088-f6fb645e-8d78-4880-827b-2f0334dad859.mov



### Highlighting Segmentation Differences
The second dock widget provided by this plugin allows you to visually compare your segmentation
against the ground truth data by computing the difference between the two and adding this as a
layer in the napari viewer.

To use this widget, open it from the Plugins menu and select the two layers you wish to compare.



https://user-images.githubusercontent.com/17995243/146114112-c891723f-8640-4708-8014-c78731fb3396.mov



### Writing to Zip
Finally, you can save your segmentation to a zip file whose internal directory structure
will closely mimic that of the tracking challenge datasets, so that it may be opened 
again in the viewer.

To save your layer, choose File -> Save selected layer(s) with *one* labels layer selected,
then select label zipper from the dropdown choices.



https://user-images.githubusercontent.com/17995243/146114163-ee886990-979c-4756-97c5-aaf2c39dccde.mov



## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""workshop-demo"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin

[file an issue]: https://github.com/DragaDoncila/workshop-demo/issues

[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/


","['Development Status :: 2 - Pre-Alpha', 'Framework :: napari', 'Intended Audience :: Developers', 'License :: OSI Approved :: BSD License', 'Operating System :: MacOS :: MacOS X', 'Operating System :: POSIX :: Linux', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3 :: Only', 'Programming Language :: Python :: 3.7', 'Programming Language :: Python :: 3.8', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Topic :: Software Development :: Testing']","['Bug Tracker, https://github.com/DragaDoncila/workshop-demo/issues', 'Documentation, https://github.com/DragaDoncila/workshop-demo#README.md', 'Source Code, https://github.com/DragaDoncila/workshop-demo', 'User Support, https://github.com/DragaDoncila/workshop-demo/issues']",workshop-demo.get_reader,workshop-demo.write_labels,workshop-demo.get_segment_widget,,,['.zip'],
534,zarpaint,zarpaint,zarpaint,0.4.0,2021-06-17,2024-06-26,Abigail S McGovern and Juan Nunez-Iglesias,juan.nunez-iglesias@monash.edu,BSD-3,https://github.com/jni/zarpaint,https://pypi.org/project/zarpaint/,,https://github.com/jni/zarpaint,Paint segmentations directly to on-disk/remote zarr arrays,>=3.7,"['magicgui', 'napari >=0.4.19', 'numpy', 'pyyaml', 'qtpy', 'scipy', 'scikit-image >=0.21', 'toolz', 'zarr <3,>=2.11', ""tensorstore ; extra == 'all'"", ""coverage ; extra == 'testing'"", ""pytest ; extra == 'testing'"", ""pytest-cov ; extra == 'testing'"", ""pytest-qt ; extra == 'testing'"", ""napari[pyqt5] ; extra == 'testing'""]","# zarpaint

[![License](https://img.shields.io/pypi/l/zarpaint.svg?color=green)](https://github.com/jni/zarpaint/raw/main/LICENSE)
[![PyPI](https://img.shields.io/pypi/v/zarpaint.svg?color=green)](https://pypi.org/project/zarpaint)
[![Python Version](https://img.shields.io/pypi/pyversions/zarpaint.svg?color=green)](https://python.org)
[![tests](https://github.com/jni/zarpaint/workflows/tests/badge.svg)](https://github.com/jni/zarpaint/actions)
[![codecov](https://codecov.io/gh/jni/zarpaint/branch/main/graph/badge.svg)](https://codecov.io/gh/jni/zarpaint)

Paint segmentations directly to on-disk/remote zarr arrays

----------------------------------

This [napari] plugin was generated with [Cookiecutter] using with [@napari]'s [cookiecutter-napari-plugin] template.

<!--
Don't miss the full getting started guide to set up your new package:
https://github.com/napari/cookiecutter-napari-plugin#getting-started

and review the napari docs for plugin developers:
https://napari.org/docs/plugins/index.html
-->

## Installation

You can install `zarpaint` via [pip]:

    pip install zarpaint

## Contributing

Contributions are very welcome. Tests can be run with [tox], please ensure
the coverage at least stays the same before you submit a pull request.

## License

Distributed under the terms of the [BSD-3] license,
""zarpaint"" is free and open source software

## Issues

If you encounter any problems, please [file an issue] along with a detailed description.

[napari]: https://github.com/napari/napari
[Cookiecutter]: https://github.com/audreyr/cookiecutter
[@napari]: https://github.com/napari
[MIT]: http://opensource.org/licenses/MIT
[BSD-3]: http://opensource.org/licenses/BSD-3-Clause
[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt
[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt
[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0
[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt
[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin
[file an issue]: https://github.com/jni/zarpaint/issues
[napari]: https://github.com/napari/napari
[tox]: https://tox.readthedocs.io/en/latest/
[pip]: https://pypi.org/project/pip/
[PyPI]: https://pypi.org/
","['Development Status :: 4 - Beta', 'Intended Audience :: Developers', 'Framework :: napari', 'Topic :: Software Development :: Testing', 'Programming Language :: Python', 'Programming Language :: Python :: 3', 'Programming Language :: Python :: 3.9', 'Programming Language :: Python :: 3.10', 'Programming Language :: Python :: 3.11', 'Programming Language :: Python :: 3.12', 'Operating System :: OS Independent', 'License :: OSI Approved :: BSD License']",,zarpaint.get_reader,,zarpaint.add_points_3d_with_alt_click,,['*.zarr'],,
