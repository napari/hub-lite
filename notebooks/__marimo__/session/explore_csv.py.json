{
  "version": "1",
  "metadata": {
    "marimo_version": "0.14.9"
  },
  "cells": [
    {
      "id": "Hbol",
      "code_hash": "c1b7b1d18b5ff786fb8c4d2ef4e0138a",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "PyqB",
      "code_hash": "f6df5793ae444b07483d33d66384af47",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "DnZY",
      "code_hash": "80faf5e3b8865770ff486ec4370b44d9",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "nNbV",
      "code_hash": "eff7d5dba32b4da32d9a67a519434d3f",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/html": "<marimo-ui-element object-id='nNbV-0' random-id='105787fa-c0eb-cc75-3175-9da635fd4245'><marimo-table data-initial-value='[]' data-label='null' data-data='&quot;[{&#92;&quot;Unnamed: 0&#92;&quot;:0,&#92;&quot;normalized_name&#92;&quot;:&#92;&quot;arcospx-napari&#92;&quot;,&#92;&quot;name&#92;&quot;:&#92;&quot;arcosPx-napari&#92;&quot;,&#92;&quot;display_name&#92;&quot;:&#92;&quot;arcosPx&#92;&quot;,&#92;&quot;version&#92;&quot;:&#92;&quot;0.1.3&#92;&quot;,&#92;&quot;created_at&#92;&quot;:&#92;&quot;2025-03-27&#92;&quot;,&#92;&quot;modified_at&#92;&quot;:&#92;&quot;2025-06-14&#92;&quot;,&#92;&quot;author&#92;&quot;:&#92;&quot;Benjamin Gr&#92;&#92;u00e4del&#92;&quot;,&#92;&quot;package_metadata_author_email&#92;&quot;:&#92;&quot;benjamin.graedel@unibe.ch&#92;&quot;,&#92;&quot;license&#92;&quot;:&#92;&quot;BSD-3-Clause&#92;&quot;,&#92;&quot;home&#92;&quot;:null,&#92;&quot;package_metadata_home_page&#92;&quot;:&#92;&quot;https://github.com/pertzlab/arcosPx-napari&#92;&quot;,&#92;&quot;summary&#92;&quot;:&#92;&quot;A plugin to track spatio-temporal correlations in images&#92;&quot;,&#92;&quot;package_metadata_requires_python&#92;&quot;:&#92;&quot;&gt;=3.10&#92;&quot;,&#92;&quot;package_metadata_requires_dist&#92;&quot;:&#92;&quot;[&#x27;numpy&#x27;, &#x27;magicgui&#x27;, &#x27;qtpy&#x27;, &#x27;arcos4py&gt;=0.3.0&#x27;, &#x27;tox; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;, &#x27;pytest; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;, &#x27;pytest-cov; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;, &#x27;pytest-qt; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;, &#x27;napari; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;, &#x27;pyqt5; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;]&#92;&quot;,&#92;&quot;package_metadata_description&#92;&quot;:&#92;&quot;# arcosPx-napari&#92;&#92;n&#92;&#92;n[![License BSD-3](https://img.shields.io/pypi/l/arcosPx-napari.svg?color=green)](https://github.com/pertzlab/arcosPx-napari/raw/main/LICENSE)&#92;&#92;n[![PyPI](https://img.shields.io/pypi/v/arcosPx-napari.svg?color=green)](https://pypi.org/project/arcosPx-napari)&#92;&#92;n[![Python Version](https://img.shields.io/pypi/pyversions/arcosPx-napari.svg?color=green)](https://python.org)&#92;&#92;n[![tests](https://github.com/pertzlab/arcosPx-napari/workflows/tests/badge.svg)](https://github.com/pertzlab/arcosPx-napari/actions)&#92;&#92;n[![codecov](https://codecov.io/gh/pertzlab/arcosPx-napari/branch/main/graph/badge.svg)](https://codecov.io/gh/pertzlab/arcosPx-napari)&#92;&#92;n[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/arcosPx-napari)](https://napari-hub.org/plugins/arcosPx-napari)&#92;&#92;n&#92;&#92;n&#92;&#92;n## Introduction&#92;&#92;n&#92;&#92;nThis repository contains a dedicated ARCOS.px plugin for the [napari](https://napari.org/stable/) image viewer. It tracks spatio-temporal correlations in images as described in a publication of Gr&#92;&#92;u00e4del et al. _Tracking Coordinated Cellular Dynamics in Time-Lapse Microscopy with ARCOS.px_ ([link](https://doi.org/10.1101/2025.03.14.643386)).&#92;&#92;n&#92;&#92;n&lt;p align=&#92;&#92;&#92;&quot;center&#92;&#92;&#92;&quot;&gt;&#92;&#92;n  &lt;img alt=&#92;&#92;&#92;&quot;ARCOS.px logo&#92;&#92;&#92;&quot; src=&#92;&#92;&#92;&quot;misc/ARCOS-px-logo.png&#92;&#92;&#92;&quot; width=&#92;&#92;&#92;&quot;45%&#92;&#92;&#92;&quot;&gt;&#92;&#92;n&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;&#92;&#92;n  &lt;img alt=&#92;&#92;&#92;&quot;CDL logo&#92;&#92;&#92;&quot; src=&#92;&#92;&#92;&quot;misc/cellular-dynamics-lab-logo2.png&#92;&#92;&#92;&quot; width=&#92;&#92;&#92;&quot;45%&#92;&#92;&#92;&quot;&gt; &#92;&#92;n&lt;/p&gt;&#92;&#92;n&#92;&#92;nARCOS.px is a computational method to identify and track clusters of correlated cell signaling in time-lapse microscopy images. &#92;&#92;nIt is the latest addition to the [ARCOS ecosystem](https://arcos.gitbook.io/home) developed in the [Cellular Dynamics Lab](https://www.pertzlab.net) at the University of Bern.&#92;&#92;n&#92;&#92;n![ARCOS.px napari plugin screenshot](misc/napari-plugin.png)&#92;&#92;n&#92;&#92;n&#92;&#92;n&lt;!--&#92;&#92;nDon&#x27;t miss the full getting started guide to set up your new package:&#92;&#92;nhttps://github.com/napari/cookiecutter-napari-plugin#getting-started&#92;&#92;n&#92;&#92;nand review the napari docs for plugin developers:&#92;&#92;nhttps://napari.org/stable/plugins/index.html&#92;&#92;n--&gt;&#92;&#92;n&#92;&#92;n## Example tracking&#92;&#92;n&#92;&#92;nActin polymerization waves in REF52 fibroblasts treated with 50 ng/mL PDGF, 24h before imaging.&#92;&#92;n&#92;&#92;n![Polymerisation wave in REF52 cells](misc/tracked_waves_rgb_wLabels_F1-181.gif)&#92;&#92;n&#92;&#92;n&#92;&#92;n## Installation&#92;&#92;n&#92;&#92;nYou can install `arcosPx-napari` via [pip]:&#92;&#92;n&#92;&#92;n    pip install arcosPx-napari&#92;&#92;n&#92;&#92;n&#92;&#92;n&#92;&#92;nTo install latest development version :&#92;&#92;n&#92;&#92;n    pip install git+https://github.com/pertzlab/arcosPx-napari.git&#92;&#92;n&#92;&#92;n&#92;&#92;n## Contributing&#92;&#92;n&#92;&#92;nContributions are very welcome. Tests can be run with [tox], please ensure&#92;&#92;nthe coverage at least stays the same before you submit a pull request.&#92;&#92;n&#92;&#92;n## License&#92;&#92;n&#92;&#92;nDistributed under the terms of the [BSD-3] license,&#92;&#92;n&#92;&#92;&#92;&quot;arcosPx-napari&#92;&#92;&#92;&quot; is free and open source software&#92;&#92;n&#92;&#92;n## Issues&#92;&#92;n&#92;&#92;nIf you encounter any problems, please [file an issue] along with a detailed description.&#92;&#92;n&#92;&#92;n[napari]: https://github.com/napari/napari&#92;&#92;n[Cookiecutter]: https://github.com/audreyr/cookiecutter&#92;&#92;n[@napari]: https://github.com/napari&#92;&#92;n[MIT]: http://opensource.org/licenses/MIT&#92;&#92;n[BSD-3]: http://opensource.org/licenses/BSD-3-Clause&#92;&#92;n[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt&#92;&#92;n[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt&#92;&#92;n[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0&#92;&#92;n[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt&#92;&#92;n[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin&#92;&#92;n&#92;&#92;n[file an issue]: https://github.com/pertzlab/arcosPx-napari/issues&#92;&#92;n&#92;&#92;n[napari]: https://github.com/napari/napari&#92;&#92;n[tox]: https://tox.readthedocs.io/en/latest/&#92;&#92;n[pip]: https://pypi.org/project/pip/&#92;&#92;n[PyPI]: https://pypi.org/&#92;&#92;n&#92;&quot;,&#92;&quot;package_metadata_classifier&#92;&quot;:&#92;&quot;[&#x27;Development Status :: 2 - Pre-Alpha&#x27;, &#x27;Framework :: napari&#x27;, &#x27;Intended Audience :: Developers&#x27;, &#x27;Operating System :: OS Independent&#x27;, &#x27;Programming Language :: Python&#x27;, &#x27;Programming Language :: Python :: 3&#x27;, &#x27;Programming Language :: Python :: 3 :: Only&#x27;, &#x27;Programming Language :: Python :: 3.10&#x27;, &#x27;Programming Language :: Python :: 3.11&#x27;, &#x27;Programming Language :: Python :: 3.12&#x27;, &#x27;Programming Language :: Python :: 3.13&#x27;, &#x27;Topic :: Scientific/Engineering :: Image Processing&#x27;]&#92;&quot;,&#92;&quot;package_metadata_project_url&#92;&quot;:&#92;&quot;[&#x27;Bug Tracker, https://github.com/pertzlab/arcosPx-napari/issues&#x27;, &#x27;Documentation, https://github.com/pertzlab/arcosPx-napari#README.md&#x27;, &#x27;Source Code, https://github.com/pertzlab/arcosPx-napari&#x27;, &#x27;User Support, https://github.com/pertzlab/arcosPx-napari/issues&#x27;]&#92;&quot;,&#92;&quot;contributions_readers_0_command&#92;&quot;:null,&#92;&quot;contributions_writers_0_command&#92;&quot;:null,&#92;&quot;contributions_widgets_0_command&#92;&quot;:&#92;&quot;arcosPx-napari.remove_background&#92;&quot;,&#92;&quot;contributions_sample_data_0_command&#92;&quot;:null,&#92;&quot;contributions_readers_0_filename_patterns&#92;&quot;:null,&#92;&quot;contributions_writers_0_filename_extensions&#92;&quot;:null,&#92;&quot;contributions_writers_1_filename_extensions&#92;&quot;:null,&#92;&quot;home_pypi&#92;&quot;:&#92;&quot;https://pypi.org/project/arcosPx-napari&#92;&quot;,&#92;&quot;home_github&#92;&quot;:null,&#92;&quot;home_other&#92;&quot;:null},{&#92;&quot;Unnamed: 0&#92;&quot;:1,&#92;&quot;normalized_name&#92;&quot;:&#92;&quot;acquifer-napari&#92;&quot;,&#92;&quot;name&#92;&quot;:&#92;&quot;acquifer-napari&#92;&quot;,&#92;&quot;display_name&#92;&quot;:&#92;&quot;acquifer-napari&#92;&quot;,&#92;&quot;version&#92;&quot;:&#92;&quot;0.0.2&#92;&quot;,&#92;&quot;created_at&#92;&quot;:&#92;&quot;2023-07-07&#92;&quot;,&#92;&quot;modified_at&#92;&quot;:&#92;&quot;2024-02-27&#92;&quot;,&#92;&quot;author&#92;&quot;:&#92;&quot;Laurent Thomas&#92;&quot;,&#92;&quot;package_metadata_author_email&#92;&quot;:null,&#92;&quot;license&#92;&quot;:&#92;&quot;GPL-3.0-only&#92;&quot;,&#92;&quot;home&#92;&quot;:&#92;&quot;https://github.com/acquifer/acquifer-napari&#92;&quot;,&#92;&quot;package_metadata_home_page&#92;&quot;:null,&#92;&quot;summary&#92;&quot;:&#92;&quot;Loader plugin for napari, to load Acquifer Imaging Machine datasets in napari, using dask for efficient lazy data-loading.&#92;&quot;,&#92;&quot;package_metadata_requires_python&#92;&quot;:&#92;&quot;&gt;=3.7&#92;&quot;,&#92;&quot;package_metadata_requires_dist&#92;&quot;:&#92;&quot;[&#x27;acquifer&#x27;, &#x27;napari&#x27;, &#x27;numpy&#x27;, &#x27;sortedcontainers&#x27;, &#x27;dask-image&#x27;, &#x27;xarray&#x27;]&#92;&quot;,&#92;&quot;package_metadata_description&#92;&quot;:&#92;&quot;# acquifer-napari&#92;&#92;n&#92;&#92;nThe acquifer-napari plugin allows loading IM04 dataset directory, as multi-dimensional images in napari.  &#92;&#92;nSliders for well, channel, time and Z are automatically rendered when there are more than 1 coordinates along the dimension.  &#92;&#92;nThe plugin uses Dask-Image for efficient data-loading &#92;&#92;&#92;&quot;on request&#92;&#92;&#92;&quot; similar to the VirtualStack in ImageJ.  &#92;&#92;n&#92;&#92;n## Installation&#92;&#92;nVia the napari plugin manager : acquifer-napari.&#92;&#92;nOr with pip : `pip install acquifer-napari`.&#92;&#92;n&#92;&#92;nUse `pip install -e .` to install in developement mode, so any change in the source code is directly reflected.  &#92;&#92;nUse `npe2 list` to check that the plugin is correctly installed and visible by napari.  &#92;&#92;nFor instance here, the package defines 1 command, which is a reader.  &#92;&#92;nOne could have more commands, which would be implement other types.   &#92;&#92;nThis should output something like following &#92;&#92;n&#92;&#92;u250c&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u252c&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u252c&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u252c&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2510&#92;&#92;n&#92;&#92;u2502 Name                         &#92;&#92;u2502 Version &#92;&#92;u2502 Npe2 &#92;&#92;u2502 Contributions                                             &#92;&#92;u2502&#92;&#92;n&#92;&#92;u251c&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u253c&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u253c&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u253c&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2500&#92;&#92;u2524&#92;&#92;n&#92;&#92;u2502 acquifer-napari              &#92;&#92;u2502 0.0.1   &#92;&#92;u2502 &#92;&#92;u2705   &#92;&#92;u2502 commands (1), readers (1)&#92;&#92;n&#92;&#92;nThe plugin should be installed in an environment with napari installed.  &#92;&#92;nNapari can be started with the `napari`command in a command prompt with a system wide python installation.  &#92;&#92;nOnce installed, napari can be opened in a IPython interactive session with&#92;&#92;n&#92;&#92;n```python&#92;&#92;n&gt;&gt; import napari&#92;&#92;n&gt;&gt; napari.Viewer()&#92;&#92;n```&#92;&#92;n&#92;&#92;n## Configurations&#92;&#92;nThe file `napari.yaml` in `acquifer_napari_plugin` defines what functions of the python package are visible to napari.  &#92;&#92;nThe top level `name` field must be the same than the python package name defined in `setup.cfg`.&#92;&#92;nIt first define a set of commands, which have a custom `id`, and a `python_name`, which is the actual location of the function in the python package (or module).  &#92;&#92;nThen the napari.yaml has optional subsections `readers`, `writers`, `widget`, to reference some of the commands previously defined, to notify napari that they implemente those standard functions.  &#92;&#92;nFor instance I first define a command myReader pointing to myPackage.myReader, and I reference that command using the id it in the section readers  &#92;&#92;nSee https://napari.org/stable/plugins/first_plugin.html#add-a-napari-yaml-manifest  &#92;&#92;n&#92;&#92;n&#92;&#92;n## Issues&#92;&#92;nIf you encounter any problems, please [file an issue](https://github.com/Luxendo/acquifer-napari/issues) along with a detailed description.&#92;&#92;n&#92;&quot;,&#92;&quot;package_metadata_classifier&#92;&quot;:&#92;&quot;[&#x27;Framework :: napari&#x27;, &#x27;Topic :: Software Development :: Testing&#x27;, &#x27;Programming Language :: Python&#x27;, &#x27;Programming Language :: Python :: 3&#x27;, &#x27;Programming Language :: Python :: 3.7&#x27;, &#x27;Programming Language :: Python :: 3.8&#x27;, &#x27;Programming Language :: Python :: 3.9&#x27;, &#x27;Operating System :: OS Independent&#x27;, &#x27;License :: OSI Approved :: GNU General Public License v3 (GPLv3)&#x27;]&#92;&quot;,&#92;&quot;package_metadata_project_url&#92;&quot;:&#92;&quot;[&#x27;HomePage, https://acquifer.de&#x27;, &#x27;Twitter, https://twitter.com/myacquifer&#x27;, &#x27;Bug Tracker, https://github.com/Luxendo/acquifer-napari/issues&#x27;, &#x27;Documentation, https://github.com/Luxendo/acquifer-napari#README.md&#x27;, &#x27;Source Code, https://github.com/Luxendo/acquifer-napari&#x27;]&#92;&quot;,&#92;&quot;contributions_readers_0_command&#92;&quot;:&#92;&quot;acquifer-napari.get_reader&#92;&quot;,&#92;&quot;contributions_writers_0_command&#92;&quot;:null,&#92;&quot;contributions_widgets_0_command&#92;&quot;:null,&#92;&quot;contributions_sample_data_0_command&#92;&quot;:null,&#92;&quot;contributions_readers_0_filename_patterns&#92;&quot;:&#92;&quot;[&#x27;*&#x27;]&#92;&quot;,&#92;&quot;contributions_writers_0_filename_extensions&#92;&quot;:null,&#92;&quot;contributions_writers_1_filename_extensions&#92;&quot;:null,&#92;&quot;home_pypi&#92;&quot;:&#92;&quot;https://pypi.org/project/acquifer-napari&#92;&quot;,&#92;&quot;home_github&#92;&quot;:&#92;&quot;https://github.com/acquifer/acquifer-napari&#92;&quot;,&#92;&quot;home_other&#92;&quot;:null},{&#92;&quot;Unnamed: 0&#92;&quot;:2,&#92;&quot;normalized_name&#92;&quot;:&#92;&quot;biaplotter&#92;&quot;,&#92;&quot;name&#92;&quot;:&#92;&quot;biaplotter&#92;&quot;,&#92;&quot;display_name&#92;&quot;:&#92;&quot;Canvas Widget from BiAPoL&#92;&quot;,&#92;&quot;version&#92;&quot;:&#92;&quot;0.3.1&#92;&quot;,&#92;&quot;created_at&#92;&quot;:&#92;&quot;2024-05-06&#92;&quot;,&#92;&quot;modified_at&#92;&quot;:&#92;&quot;2025-05-06&#92;&quot;,&#92;&quot;author&#92;&quot;:&#92;&quot;Marcelo Leomil Zoccoler&#92;&quot;,&#92;&quot;package_metadata_author_email&#92;&quot;:&#92;&quot;marzoccoler@gmail.com&#92;&quot;,&#92;&quot;license&#92;&quot;:&#92;&quot;BSD-3-Clause&#92;&quot;,&#92;&quot;home&#92;&quot;:null,&#92;&quot;package_metadata_home_page&#92;&quot;:&#92;&quot;https://github.com/BiAPoL/biaplotter&#92;&quot;,&#92;&quot;summary&#92;&quot;:&#92;&quot;A base napari plotter widget for interactive plotting&#92;&quot;,&#92;&quot;package_metadata_requires_python&#92;&quot;:&#92;&quot;&gt;=3.9&#92;&quot;,&#92;&quot;package_metadata_requires_dist&#92;&quot;:&#92;&quot;[&#x27;numpy&#x27;, &#x27;magicgui&#x27;, &#x27;qtpy&#x27;, &#x27;napari-matplotlib&#x27;, &#x27;nap-plot-tools&gt;=0.1.0&#x27;, &#x27;numpy&gt;=1.22.0&#x27;, &#x27;tox; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;, &#x27;pytest; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;, &#x27;pytest-cov; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;, &#x27;pytest-qt; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;, &#x27;napari; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;, &#x27;pyqt5; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;]&#92;&quot;,&#92;&quot;package_metadata_description&#92;&quot;:&#92;&quot;# biaplotter&#92;&#92;n&#92;&#92;n[![License BSD-3](https://img.shields.io/pypi/l/biaplotter.svg?color=green)](https://github.com/BiAPoL/biaplotter/raw/main/LICENSE)&#92;&#92;n[![PyPI](https://img.shields.io/pypi/v/biaplotter.svg?color=green)](https://pypi.org/project/biaplotter)&#92;&#92;n[![Python Version](https://img.shields.io/pypi/pyversions/biaplotter.svg?color=green)](https://python.org)&#92;&#92;n[![tests](https://github.com/BiAPoL/biaplotter/workflows/tests/badge.svg)](https://github.com/BiAPoL/biaplotter/actions)&#92;&#92;n[![codecov](https://codecov.io/gh/BiAPoL/biaplotter/branch/main/graph/badge.svg)](https://codecov.io/gh/BiAPoL/biaplotter)&#92;&#92;n[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/biaplotter)](https://napari-hub.org/plugins/biaplotter)&#92;&#92;n&#92;&#92;nA base napari plotter widget for interactive plotting&#92;&#92;n&#92;&#92;n----------------------------------&#92;&#92;n&#92;&#92;nThis [napari] plugin was generated with [Cookiecutter] using [@napari]&#x27;s [cookiecutter-napari-plugin] template.&#92;&#92;n&#92;&#92;n&lt;!--&#92;&#92;nDon&#x27;t miss the full getting started guide to set up your new package:&#92;&#92;nhttps://github.com/napari/cookiecutter-napari-plugin#getting-started&#92;&#92;n&#92;&#92;nand review the napari docs for plugin developers:&#92;&#92;nhttps://napari.org/stable/plugins/index.html&#92;&#92;n--&gt;&#92;&#92;n&#92;&#92;n## Documentation&#92;&#92;n&#92;&#92;nThe full documentation with API and examples can be found [here](https://biapol.github.io/biaplotter/).&#92;&#92;n&#92;&#92;n## Installation&#92;&#92;n&#92;&#92;n* Make sure you have Python in your computer, e.g. download [miniforge](https://github.com/conda-forge/miniforge?tab=readme-ov-file#download).&#92;&#92;n&#92;&#92;n* Create a new environment, for example, like this:&#92;&#92;n&#92;&#92;n```&#92;&#92;nmamba create --name biaplotter-env python=3.9&#92;&#92;n```&#92;&#92;n&#92;&#92;nIf you never used mamba/conda environments before, take a look at [this blog post](https://biapol.github.io/blog/mara_lampert/getting_started_with_mambaforge_and_python/readme.html).&#92;&#92;n&#92;&#92;n* **Activate** the new environment with `mamba`:&#92;&#92;n&#92;&#92;n```&#92;&#92;nmamba activate biaplotter-env&#92;&#92;n```&#92;&#92;n&#92;&#92;n* Install [napari](https://napari.org/stable/), e.g. via `mamba`:&#92;&#92;n&#92;&#92;n```&#92;&#92;nmamba install -c conda-forge napari pyqt&#92;&#92;n```&#92;&#92;n&#92;&#92;nAfterwards, install `biaplotter` via `pip`:&#92;&#92;n&#92;&#92;n```&#92;&#92;npip install biaplotter&#92;&#92;n```&#92;&#92;n&#92;&#92;nTo install latest development version :&#92;&#92;n&#92;&#92;n```&#92;&#92;npip install git+https://github.com/BiAPoL/biaplotter.git&#92;&#92;n```&#92;&#92;n&#92;&#92;n&#92;&#92;n## Contributing&#92;&#92;n&#92;&#92;nContributions are very welcome. Tests can be run with [tox], please ensure&#92;&#92;nthe coverage at least stays the same before you submit a pull request.&#92;&#92;n&#92;&#92;n## License&#92;&#92;n&#92;&#92;nDistributed under the terms of the [BSD-3] license,&#92;&#92;n&#92;&#92;&#92;&quot;biaplotter&#92;&#92;&#92;&quot; is free and open source software&#92;&#92;n&#92;&#92;n## Issues&#92;&#92;n&#92;&#92;nIf you encounter any problems, please [file an issue] along with a detailed description.&#92;&#92;n&#92;&#92;n[napari]: https://github.com/napari/napari&#92;&#92;n[Cookiecutter]: https://github.com/audreyr/cookiecutter&#92;&#92;n[@napari]: https://github.com/napari&#92;&#92;n[MIT]: http://opensource.org/licenses/MIT&#92;&#92;n[BSD-3]: http://opensource.org/licenses/BSD-3-Clause&#92;&#92;n[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt&#92;&#92;n[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt&#92;&#92;n[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0&#92;&#92;n[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt&#92;&#92;n[cookiecutter-napari-plugin]: https://github.com/napari/cookiecutter-napari-plugin&#92;&#92;n&#92;&#92;n[file an issue]: https://github.com/BiAPoL/biaplotter/issues&#92;&#92;n&#92;&#92;n[napari]: https://github.com/napari/napari&#92;&#92;n[tox]: https://tox.readthedocs.io/en/latest/&#92;&#92;n[pip]: https://pypi.org/project/pip/&#92;&#92;n[PyPI]: https://pypi.org/&#92;&#92;n&#92;&quot;,&#92;&quot;package_metadata_classifier&#92;&quot;:&#92;&quot;[&#x27;Development Status :: 2 - Pre-Alpha&#x27;, &#x27;Framework :: napari&#x27;, &#x27;Intended Audience :: Developers&#x27;, &#x27;License :: OSI Approved :: BSD License&#x27;, &#x27;Operating System :: OS Independent&#x27;, &#x27;Programming Language :: Python&#x27;, &#x27;Programming Language :: Python :: 3&#x27;, &#x27;Programming Language :: Python :: 3 :: Only&#x27;, &#x27;Programming Language :: Python :: 3.9&#x27;, &#x27;Programming Language :: Python :: 3.10&#x27;, &#x27;Programming Language :: Python :: 3.11&#x27;, &#x27;Programming Language :: Python :: 3.12&#x27;, &#x27;Programming Language :: Python :: 3.13&#x27;, &#x27;Topic :: Scientific/Engineering :: Image Processing&#x27;]&#92;&quot;,&#92;&quot;package_metadata_project_url&#92;&quot;:&#92;&quot;[&#x27;Bug Tracker, https://github.com/BiAPoL/biaplotter/issues&#x27;, &#x27;Documentation, https://github.com/BiAPoL/biaplotter#README.md&#x27;, &#x27;Source Code, https://github.com/BiAPoL/biaplotter&#x27;, &#x27;User Support, https://github.com/BiAPoL/biaplotter/issues&#x27;]&#92;&quot;,&#92;&quot;contributions_readers_0_command&#92;&quot;:null,&#92;&quot;contributions_writers_0_command&#92;&quot;:null,&#92;&quot;contributions_widgets_0_command&#92;&quot;:&#92;&quot;biaplotter.make_qwidget&#92;&quot;,&#92;&quot;contributions_sample_data_0_command&#92;&quot;:null,&#92;&quot;contributions_readers_0_filename_patterns&#92;&quot;:null,&#92;&quot;contributions_writers_0_filename_extensions&#92;&quot;:null,&#92;&quot;contributions_writers_1_filename_extensions&#92;&quot;:null,&#92;&quot;home_pypi&#92;&quot;:&#92;&quot;https://pypi.org/project/biaplotter&#92;&quot;,&#92;&quot;home_github&#92;&quot;:null,&#92;&quot;home_other&#92;&quot;:null},{&#92;&quot;Unnamed: 0&#92;&quot;:3,&#92;&quot;normalized_name&#92;&quot;:&#92;&quot;annotrack&#92;&quot;,&#92;&quot;name&#92;&quot;:&#92;&quot;annotrack&#92;&quot;,&#92;&quot;display_name&#92;&quot;:&#92;&quot;annotrack&#92;&quot;,&#92;&quot;version&#92;&quot;:&#92;&quot;0.0.3&#92;&quot;,&#92;&quot;created_at&#92;&quot;:&#92;&quot;2023-12-01&#92;&quot;,&#92;&quot;modified_at&#92;&quot;:&#92;&quot;2024-03-19&#92;&quot;,&#92;&quot;author&#92;&quot;:&#92;&quot;Abigail S McGovern&#92;&quot;,&#92;&quot;package_metadata_author_email&#92;&quot;:&#92;&quot;abigail_mcgovern@hotmail.com&#92;&quot;,&#92;&quot;license&#92;&quot;:&#92;&quot;BSD-3-Clause&#92;&quot;,&#92;&quot;home&#92;&quot;:null,&#92;&quot;package_metadata_home_page&#92;&quot;:&#92;&quot;https://github.com/abigailmcgovern/annotrack&#92;&quot;,&#92;&quot;summary&#92;&quot;:&#92;&quot;napari plugin for annotating tracks to estimate error rates&#92;&quot;,&#92;&quot;package_metadata_requires_python&#92;&quot;:&#92;&quot;&gt;=3.7&#92;&quot;,&#92;&quot;package_metadata_requires_dist&#92;&quot;:&#92;&quot;[&#x27;dask&#x27;, &#x27;napari&#x27;, &#x27;numpy&#x27;, &#x27;zarr&#x27;, &#x27;pandas&#x27;, &#92;&#92;&#92;&quot;sphinx ; extra == &#x27;docs&#x27;&#92;&#92;&#92;&quot;, &#92;&#92;&#92;&quot;nd2 ; extra == &#x27;io&#x27;&#92;&#92;&#92;&quot;, &#92;&#92;&#92;&quot;pytest ; extra == &#x27;testing&#x27;&#92;&#92;&#92;&quot;]&#92;&quot;,&#92;&quot;package_metadata_description&#92;&quot;:&#92;&quot;# annotrack&#92;&#92;nAnnotrack is a napari plugin for annotating errors in object trajectories. The plugin will help you take a sample of track segments along with a small section of corresponding image and segmentation. Annotrack allows you to annotate three types of errors: (1) ID swap errors (track jumps between objects), (2) false starts (track starts on a pre-existing object) and false terminations (track ends but object still exists). By looking at the combined rates of false starts and false terminations you can assess track discontinutation errors. &#92;&#92;n&#92;&#92;n**Please note:** Images and segmentations must be in zarr format. Tracks should be in parquet format.  &#92;&#92;n&#92;&#92;n## Installation &#92;&#92;n&#92;&#92;nThere are three main ways to install annotrack:&#92;&#92;n&#92;&#92;n### Install Using pip&#92;&#92;n*Please note that this is planned/under development*&#92;&#92;n&#92;&#92;nType the following into your terminal (MacOS or Ubuntu) or annaconda prompt (windows):&#92;&#92;n&#92;&#92;n```bash&#92;&#92;npip install annotrack&#92;&#92;n```&#92;&#92;n&#92;&#92;n### Install&#92;&#92;n*Please note that this is planned/under development*&#92;&#92;n&#92;&#92;nType the following into your terminal (MacOS or Ubuntu) or annaconda prompt (windows):&#92;&#92;n&#92;&#92;n```bash&#92;&#92;ninstall napari&#92;&#92;nnapari&#92;&#92;n```&#92;&#92;n&#92;&#92;nOnce napari has opened (this may take a second the first time you open it), go to the pannel at the top of the screen and select the &#x27;plugins&#x27; dropdown. Then select install/uninstall plugins. A new window will open showing available plugins. Either scroll down to or search &#x27;annotrack&#x27; and click &#x27;install&#x27;. &#92;&#92;n&#92;&#92;n### Install from Source Code&#92;&#92;n*please use this for now*&#92;&#92;n&#92;&#92;nType the following into your terminal (MacOS or Ubuntu) or annaconda prompt (windows):&#92;&#92;n&#92;&#92;n```bash&#92;&#92;ngit clone https://github.com/AbigailMcGovern/annotrack.git&#92;&#92;ncd annotrack&#92;&#92;npip install .&#92;&#92;n```&#92;&#92;n&#92;&#92;n## Opening Annotrack&#92;&#92;nOnce annotrack is properly installed you will be able to open annotrack by opening napari. You can open napari through the command line (terminal (MacOS or Ubuntu) or annaconda prompt (windows)) as follows:&#92;&#92;n&#92;&#92;n```bash&#92;&#92;nnapari&#92;&#92;n```&#92;&#92;n&#92;&#92;nYou can find the annotrack widgets by selecting the dropdown &#x27;plugins&#x27; at the pannel at the top of the screen and hovering over &#x27;annotrack&#x27;.  &#92;&#92;n&#92;&#92;n## Sample from CSV&#92;&#92;n&#92;&#92;nTo sample your tracks you will need to supply the file paths for the images, segmentations, and tracks. You supply this in a csv that is structured as shown below:&#92;&#92;n&#92;&#92;n ![csv_structure widget](https://github.com/AbigailMcGovern/annotrack/blob/main/media/csv_structure.png)&#92;&#92;n&#92;&#92;nIn this csv, you may also specify how many samples are to be taken from each file. If this is not provided, annotrack will use the value you supply to the `sample_from_csv` widget. The csv must contain a column that specifies a category to which each sample belongs (e.g., species, experimental condition, drug, etc.).  If this isnt important for your samples, just add a dummy category (e.g., sample_type : [A, A, A, A]). &#92;&#92;n&#92;&#92;nTo access the widget and sample track segments, go to the top of the screen, go to **plugins &gt; annotrack &gt; sample_from_csv**. When the widget is displayed, select the csv file, select a directory into which to save results, and proivide a name for the summary data file (i.e., where your annotations will be written). &#92;&#92;n&#92;&#92;n ![sample_from_csv widget](https://github.com/AbigailMcGovern/annotrack/blob/main/media/sample_from_csv.png)&#92;&#92;n&#92;&#92;n### Widget parameters&#92;&#92;n- **path to csv**: &#92;&#92;n        The path storing the info from which to generate the samples. &#92;&#92;n        The CSV should have the columns: image_path, labels_path, tracks_path, &lt;category_col&gt;, &#92;&#92;n        You can also add an optional n_samples column if you would like to &#92;&#92;n        specify how many samples to take from each individual file. Otherwise, &#92;&#92;n        the default &#92;&#92;&#92;&quot;n_samples&#92;&#92;&#92;&quot; you&#x27;ve supplied will be used.&#92;&#92;n- **output dir**: &#92;&#92;n        Where will the output be saved?&#92;&#92;n- **output name**: &#92;&#92;n        What will output summary files/directories be called?&#92;&#92;n- **n samples**: &#92;&#92;n        How many samples to be obtained from each file. Will be overwritten&#92;&#92;n        if there is a valid integer number in the n_samples colum of the csv.&#92;&#92;n- **tzyx cols**: &#92;&#92;n        What are the names of the columns denoting time (in frames) and coordinate&#92;&#92;n        positions (in pixels) in the file containing tracks? The order should be:&#92;&#92;n        t, z, y, x. &#92;&#92;n- **id col**: &#92;&#92;n        What is the name of the column denoting the specific ID for each tracked&#92;&#92;n        object?&#92;&#92;n- **scale**: &#92;&#92;n        size of pixels (e.g., in um) for the z, y, and x coordinates (in that&#92;&#92;n        order)&#92;&#92;n- **frames**: &#92;&#92;n        Approximate maximum number of frames of track segment. &#92;&#92;n        Max frames = frames (if even) or frames - 1 (if odd)&#92;&#92;n- **box size**: &#92;&#92;n        Approximate size of bounding box (in pixels). &#92;&#92;n- **min track len**: &#92;&#92;n        You can set a minimum track len to include in the search. &#92;&#92;n        This can help to eliminate less useful data. This should be at least 1 to only include tracked objects. Set higher only if you are specifically interested in longer lived tracks. &#92;&#92;n- **image channel**: &#92;&#92;n        This denotes the index of the channel from which to get &#92;&#92;n        image data (0: channel 1, 1: channel 2, 2: channel 3, 3: channel 4)&#92;&#92;n&#92;&#92;n### Annotate Now?&#92;&#92;n&#92;&#92;nIn the case that we are annotating multiple conditions to compare, we want to show them in the one session in randomised order with the annotator blinded to where the sample has originated from. We want to be able to annotated unannotated data from the sample without having the burden of having to do this all at once. The annotations are therefore saved into the saved sample. A selected number of samples saved from the various tracking experiments can be annotated using the following code. If you re-execute this code, you will only be shown not yet annotated data, unless you request otherwise.&#92;&#92;n&#92;&#92;nKeys to navagate and annotate samples&#92;&#92;n- &#x27;2&#x27; - move to next sample&#92;&#92;n- &#x27;1&#x27; - move to previous sample&#92;&#92;n- &#x27;y&#x27; - annotate as correct (will move to the next sample automatically)&#92;&#92;n- &#x27;n&#x27; - annotate as containing an error (will move to the next sample automatically)&#92;&#92;n- &#x27;i&#x27; - annotate the frame following a ID swap error&#92;&#92;n- &#x27;t&#x27; - annotate the fame following an incorrect termination&#92;&#92;n- &#x27;Shift-t&#x27; - annotate the frame containing a false start error&#92;&#92;n- &#x27;s&#x27; - annotate an error (&#x27;i&#x27;, &#x27;t&#x27;, or &#x27;Shift-t&#x27;) as being associated with a segmentation error (merge or split of objects)&#92;&#92;n&#92;&#92;nWhen an error is associated the specific frame (&#x27;i&#x27;, &#x27;t&#x27;, &#x27;Shift-t&#x27;, or &#x27;s&#x27;), the frame number (within the original image) will be added to a list of errors for the sample within the sample&#x27;s (.smpl) info data frame. E.g., you may have a list of ID swaps for your sampled track segment (`[108, 111, 112]`) and a corresponding list of segmentation error associations (`[108, 112]`). &#92;&#92;n&#92;&#92;n## Annotate Existing Sample&#92;&#92;nIf you have already saved a sample and want to annotate it, you can load the sample data using the `annotate_existing_sample` widget. This might be useful if you want to have several annotators annotate the same sample. To access this widget, open napari&#92;&#92;n&#92;&#92;n ![annotate_existing_sample widget](https://github.com/AbigailMcGovern/annotrack/blob/main/media/annotate_existing_sample.png)&#92;&#92;n&#92;&#92;n## Contributing and User Support&#92;&#92;n&#92;&#92;n**User support:** If you have an issue with annotrack please add an issue (go to the Issues tab at the top of the GitHub page). If your issue is a bug, please include as much information as possible to help debug the problem. Examples of information include: details about the image and segmentation data (dimensions), number of images, number of samples you are trying to take. If you are requesting an improvement, try to be as clear as possible about what you need. &#92;&#92;n&#92;&#92;n**Contributing:** If you want to contribute to annotrack, please fork the repo and if you want to make changes make a pull request with as much detail about the change as possible. Please ensure any changes you want to make don&#x27;t break the existing functions.&#92;&#92;n&#92;&quot;,&#92;&quot;package_metadata_classifier&#92;&quot;:&#92;&quot;[&#x27;Programming Language :: Python :: 3&#x27;, &#x27;License :: OSI Approved :: BSD License&#x27;, &#x27;Operating System :: OS Independent&#x27;, &#x27;Intended Audience :: Science/Research&#x27;, &#x27;Topic :: Scientific/Engineering&#x27;, &#x27;Topic :: Scientific/Engineering :: Image Processing&#x27;, &#x27;Framework :: napari&#x27;]&#92;&quot;,&#92;&quot;package_metadata_project_url&#92;&quot;:&#92;&quot;[&#x27;Bug Tracker, https://github.com/abigailmcgovern/annotrack/issues&#x27;, &#x27;Documentation, https://github.com/abigailmcgovern/annotrack#README.md&#x27;, &#x27;Source Code, https://github.com/abigailmcgovern/annotrack&#x27;, &#x27;User Support, https://github.com/abigailmcgovern/annotrack/issues&#x27;]&#92;&quot;,&#92;&quot;contributions_readers_0_command&#92;&quot;:null,&#92;&quot;contributions_writers_0_command&#92;&quot;:null,&#92;&quot;contributions_widgets_0_command&#92;&quot;:&#92;&quot;annotrack.sample_from_csv&#92;&quot;,&#92;&quot;contributions_sample_data_0_command&#92;&quot;:null,&#92;&quot;contributions_readers_0_filename_patterns&#92;&quot;:null,&#92;&quot;contributions_writers_0_filename_extensions&#92;&quot;:null,&#92;&quot;contributions_writers_1_filename_extensions&#92;&quot;:null,&#92;&quot;home_pypi&#92;&quot;:&#92;&quot;https://pypi.org/project/annotrack&#92;&quot;,&#92;&quot;home_github&#92;&quot;:null,&#92;&quot;home_other&#92;&quot;:null},{&#92;&quot;Unnamed: 0&#92;&quot;:4,&#92;&quot;normalized_name&#92;&quot;:&#92;&quot;beetlesafari&#92;&quot;,&#92;&quot;name&#92;&quot;:&#92;&quot;beetlesafari&#92;&quot;,&#92;&quot;display_name&#92;&quot;:&#92;&quot;beetlesafari&#92;&quot;,&#92;&quot;version&#92;&quot;:&#92;&quot;0.4.0&#92;&quot;,&#92;&quot;created_at&#92;&quot;:&#92;&quot;2022-04-21&#92;&quot;,&#92;&quot;modified_at&#92;&quot;:&#92;&quot;2022-06-21&#92;&quot;,&#92;&quot;author&#92;&quot;:&#92;&quot;Robert Haase&#92;&quot;,&#92;&quot;package_metadata_author_email&#92;&quot;:&#92;&quot;robert.haase@tu-dresden.de&#92;&quot;,&#92;&quot;license&#92;&quot;:null,&#92;&quot;home&#92;&quot;:&#92;&quot;https://github.com/haesleinhuepf/beetlesafari&#92;&quot;,&#92;&quot;package_metadata_home_page&#92;&quot;:&#92;&quot;https://github.com/haesleinhuepf/beetlesafari&#92;&quot;,&#92;&quot;summary&#92;&quot;:&#92;&quot;A napari plugin for loading and working with light sheet imaging data of developing embryos acquired using ClearControl, e.g. _Tribolium castaneum_.&#92;&quot;,&#92;&quot;package_metadata_requires_python&#92;&quot;:&#92;&quot;&gt;=3.7&#92;&quot;,&#92;&quot;package_metadata_requires_dist&#92;&quot;:&#92;&quot;[&#x27;numpy&#x27;, &#x27;pyopencl&#x27;, &#x27;toolz&#x27;, &#x27;scikit-image&#x27;, &#x27;requests&#x27;, &#x27;pyclesperanto-prototype&#x27;, &#x27;napari&#x27;, &#x27;magicgui&#x27;, &#x27;dask&#x27;, &#x27;cachetools&#x27;, &#x27;napari-tools-menu&#x27;]&#92;&quot;,&#92;&quot;package_metadata_description&#92;&quot;:&#92;&quot;A library for working with light sheet imaging data of developing embryos acquired using [ClearControl](https://github.com/ClearControl) at the [Center for Systems Biology Dresden](https://www.csbdresden.de/), e.g. _Tribolium castaneum_.&#92;&#92;n&#92;&#92;n# Installation&#92;&#92;n```&#92;&#92;nconda install -c conda-forge pyopencl&#92;&#92;npip install beetlesafari&#92;&#92;n```&#92;&#92;n&#92;&quot;,&#92;&quot;package_metadata_classifier&#92;&quot;:&#92;&quot;[&#x27;Programming Language :: Python :: 3&#x27;, &#x27;License :: OSI Approved :: BSD License&#x27;, &#x27;Operating System :: OS Independent&#x27;, &#x27;Framework :: napari&#x27;, &#x27;Intended Audience :: Science/Research&#x27;, &#x27;Development Status :: 3 - Alpha&#x27;]&#92;&quot;,&#92;&quot;package_metadata_project_url&#92;&quot;:null,&#92;&quot;contributions_readers_0_command&#92;&quot;:null,&#92;&quot;contributions_writers_0_command&#92;&quot;:null,&#92;&quot;contributions_widgets_0_command&#92;&quot;:null,&#92;&quot;contributions_sample_data_0_command&#92;&quot;:null,&#92;&quot;contributions_readers_0_filename_patterns&#92;&quot;:null,&#92;&quot;contributions_writers_0_filename_extensions&#92;&quot;:null,&#92;&quot;contributions_writers_1_filename_extensions&#92;&quot;:null,&#92;&quot;home_pypi&#92;&quot;:&#92;&quot;https://pypi.org/project/beetlesafari&#92;&quot;,&#92;&quot;home_github&#92;&quot;:&#92;&quot;https://github.com/haesleinhuepf/beetlesafari&#92;&quot;,&#92;&quot;home_other&#92;&quot;:null},{&#92;&quot;Unnamed: 0&#92;&quot;:5,&#92;&quot;normalized_name&#92;&quot;:&#92;&quot;allencell-segmenter-ml&#92;&quot;,&#92;&quot;name&#92;&quot;:&#92;&quot;allencell-segmenter-ml&#92;&quot;,&#92;&quot;display_name&#92;&quot;:&#92;&quot;allencell-segmenter-ml&#92;&quot;,&#92;&quot;version&#92;&quot;:&#92;&quot;1.0.0&#92;&quot;,&#92;&quot;created_at&#92;&quot;:&#92;&quot;2024-09-20&#92;&quot;,&#92;&quot;modified_at&#92;&quot;:&#92;&quot;2025-05-29&#92;&quot;,&#92;&quot;author&#92;&quot;:null,&#92;&quot;package_metadata_author_email&#92;&quot;:null,&#92;&quot;license&#92;&quot;:&#92;&quot;Allen Institute Software License &#92;&#92;u2013 This software license is the 2-clause BSD license plus clause a third clause that&#92;&#92;nprohibits redistribution for commercial purposes without further permission.&#92;&#92;n&#92;&#92;nCopyright &#92;&#92;u00a9 2024. Allen Institute.  All rights reserved.&#92;&#92;n&#92;&#92;n&#92;&#92;n&#92;&#92;nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the&#92;&#92;nfollowing conditions are met:&#92;&#92;n&#92;&#92;n1. Redistributions of source code must retain the above copyright notice, this list of conditions&#92;&#92;nand the following disclaimer.&#92;&#92;n&#92;&#92;n2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions&#92;&#92;nand the following disclaimer in the documentation and/or other materials provided with the distribution.&#92;&#92;n&#92;&#92;n3. Redistributions for commercial purposes are not permitted without the Allen Institute&#92;&#92;u2019s written permission.&#92;&#92;nFor purposes of this license, commercial purposes is the incorporation of the Allen Institute&#x27;s software into&#92;&#92;nanything for which you will charge fees or other compensation.&#92;&#92;nContact terms@alleninstitute.org for commercial licensing opportunities.&#92;&#92;n&#92;&#92;nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &#92;&#92;&#92;&quot;AS IS&#92;&#92;&#92;&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES,&#92;&#92;nINCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE&#92;&#92;nARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,&#92;&#92;nINCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE&#92;&#92;nGOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY&#92;&#92;nOF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY&#92;&#92;nOUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.&#92;&#92;n&#92;&quot;,&#92;&quot;home&#92;&quot;:null,&#92;&quot;package_metadata_home_page&#92;&quot;:null,&#92;&quot;summary&#92;&quot;:&#92;&quot;A plugin to leverage ML segmentation in napari&#92;&quot;,&#92;&quot;package_metadata_requires_python&#92;&quot;:&#92;&quot;&lt;3.11,&gt;=3.9&#92;&quot;,&#92;&quot;package_metadata_requires_dist&#92;&quot;:&#92;&quot;[&#x27;npe2&gt;=0.6.2&#x27;, &#x27;numpy&#x27;, &#x27;hydra-core==1.3.2&#x27;, &#x27;bioio==1.1.0&#x27;, &#x27;bioio-base==1.0.4&#x27;, &#x27;tifffile&lt;2025.2.18,&gt;=2023.4.12&#x27;, &#x27;watchdog&#x27;, &#x27;cyto-dl&gt;=0.4.5&#x27;, &#x27;scikit-image!=0.23.0&#x27;, &#x27;napari&gt;=0.4.18; extra == &#92;&#92;&#92;&quot;napari&#92;&#92;&#92;&quot;&#x27;, &#x27;pyqt5; extra == &#92;&#92;&#92;&quot;napari&#92;&#92;&#92;&quot;&#x27;, &#x27;pytest&lt;8.0.0; extra == &#92;&#92;&#92;&quot;test-lint&#92;&#92;&#92;&quot;&#x27;, &#x27;pytest-cov; extra == &#92;&#92;&#92;&quot;test-lint&#92;&#92;&#92;&quot;&#x27;, &#x27;pytest-qt; extra == &#92;&#92;&#92;&quot;test-lint&#92;&#92;&#92;&quot;&#x27;, &#x27;qtpy; extra == &#92;&#92;&#92;&quot;test-lint&#92;&#92;&#92;&quot;&#x27;, &#x27;pyqt5; extra == &#92;&#92;&#92;&quot;test-lint&#92;&#92;&#92;&quot;&#x27;, &#x27;black&gt;=24.2.0; extra == &#92;&#92;&#92;&quot;test-lint&#92;&#92;&#92;&quot;&#x27;, &#x27;pytest-xvfb; sys_platform == &#92;&#92;&#92;&quot;linux&#92;&#92;&#92;&quot; and extra == &#92;&#92;&#92;&quot;test-lint&#92;&#92;&#92;&quot;&#x27;, &#x27;responses; extra == &#92;&#92;&#92;&quot;test-lint&#92;&#92;&#92;&quot;&#x27;, &#x27;mypy; extra == &#92;&#92;&#92;&quot;test-lint&#92;&#92;&#92;&quot;&#x27;, &#x27;toml; extra == &#92;&#92;&#92;&quot;test-lint&#92;&#92;&#92;&quot;&#x27;, &#x27;bumpver; extra == &#92;&#92;&#92;&quot;test-lint&#92;&#92;&#92;&quot;&#x27;, &#x27;napari&gt;=0.4.18; extra == &#92;&#92;&#92;&quot;test-lint&#92;&#92;&#92;&quot;&#x27;, &#x27;magicgui; extra == &#92;&#92;&#92;&quot;test-lint&#92;&#92;&#92;&quot;&#x27;, &#x27;black&gt;=24.2.0; extra == &#92;&#92;&#92;&quot;dev&#92;&#92;&#92;&quot;&#x27;, &#x27;coverage&gt;=7.2.2; extra == &#92;&#92;&#92;&quot;dev&#92;&#92;&#92;&quot;&#x27;, &#x27;flake8&gt;=6.0.0; extra == &#92;&#92;&#92;&quot;dev&#92;&#92;&#92;&quot;&#x27;, &#x27;pytest&lt;8.0.0,&gt;=7.2.2; extra == &#92;&#92;&#92;&quot;dev&#92;&#92;&#92;&quot;&#x27;, &#x27;pytest-qt&gt;=3.3.0; extra == &#92;&#92;&#92;&quot;dev&#92;&#92;&#92;&quot;&#x27;, &#x27;pytest-cov&gt;=2.6.1; extra == &#92;&#92;&#92;&quot;dev&#92;&#92;&#92;&quot;&#x27;, &#x27;pyqt5&gt;=5.15.9; extra == &#92;&#92;&#92;&quot;dev&#92;&#92;&#92;&quot;&#x27;, &#x27;bumpver&gt;=2023.1129; extra == &#92;&#92;&#92;&quot;dev&#92;&#92;&#92;&quot;&#x27;, &#x27;build&gt;=1.0.3; extra == &#92;&#92;&#92;&quot;dev&#92;&#92;&#92;&quot;&#x27;, &#x27;twine&gt;=5.0.0; extra == &#92;&#92;&#92;&quot;dev&#92;&#92;&#92;&quot;&#x27;, &#x27;responses; extra == &#92;&#92;&#92;&quot;dev&#92;&#92;&#92;&quot;&#x27;, &#x27;mypy; extra == &#92;&#92;&#92;&quot;dev&#92;&#92;&#92;&quot;&#x27;, &#x27;linkify-it-py; extra == &#92;&#92;&#92;&quot;sphinx-docs&#92;&#92;&#92;&quot;&#x27;, &#x27;sphinx; extra == &#92;&#92;&#92;&quot;sphinx-docs&#92;&#92;&#92;&quot;&#x27;, &#x27;furo; extra == &#92;&#92;&#92;&quot;sphinx-docs&#92;&#92;&#92;&quot;&#x27;, &#x27;sphinxext-opengraph; extra == &#92;&#92;&#92;&quot;sphinx-docs&#92;&#92;&#92;&quot;&#x27;, &#x27;sphinx_inline_tabs; extra == &#92;&#92;&#92;&quot;sphinx-docs&#92;&#92;&#92;&quot;&#x27;, &#x27;sphinx_copybutton; extra == &#92;&#92;&#92;&quot;sphinx-docs&#92;&#92;&#92;&quot;&#x27;, &#x27;myst_parser; extra == &#92;&#92;&#92;&quot;sphinx-docs&#92;&#92;&#92;&quot;&#x27;, &#x27;sphinx_togglebutton; extra == &#92;&#92;&#92;&quot;sphinx-docs&#92;&#92;&#92;&quot;&#x27;, &#x27;sphinx_design; extra == &#92;&#92;&#92;&quot;sphinx-docs&#92;&#92;&#92;&quot;&#x27;]&#92;&quot;,&#92;&quot;package_metadata_description&#92;&quot;:&#92;&quot;# Allencell-segmenter-ml&#92;&#92;n&#92;&#92;n[![Test and lint](https://github.com/AllenCell/allencell-segmenter-ml/actions/workflows/test_lint.yaml/badge.svg?branch=main&amp;event=push)](https://github.com/AllenCell/allencell-segmenter-ml/actions/workflows/test_lint_pr.yaml)&#92;&#92;n&#92;&#92;n&#92;&#92;n## What is Allen Cell Segmenter ML&#92;&#92;nA napari plugin for deep-learning based segmentation of cellular structures.&#92;&#92;n&#92;&#92;n![SegmenterML-plugin_fig1_output.png](docs%2Fuser_docs%2Fimages%2FSegmenterML-plugin_fig1_output.png)&#92;&#92;n&#92;&#92;n- **Available at no cost** &#92;&#92;u2014 available on PyPI&#92;&#92;n- **User-friendly** &#92;&#92;u2014 leverage napari as a fast 3D viewer with interactive plugin interface&#92;&#92;n- **Beginner-friendly** &#92;&#92;u2014 new to machine learning? This plugin simplifies the application of machine learning in the segmentation process through the 3 main modules:&#92;&#92;n  - **Curation**: curate training datasets&#92;&#92;n  - **Training**: iteratively train custom segmentation model(s) (UNET) to target cellular structure with wide morphological variability&#92;&#92;n  - **Prediction &amp; Thresholding**: generate segmentation prediction on 2D and 3D cell image data&#92;&#92;n&#92;&#92;n&#92;&#92;n##  &#92;&#92;ud83d&#92;&#92;udcf0 News&#92;&#92;n&#92;&#92;n - **[2024.09.24]** :tada: Initial release of the plugin and Megaseg models!&#92;&#92;n - **[2024.05.29]** :tada: v1.0.0 Released on PyPi&#92;&#92;n&#92;&#92;n&#92;&#92;n## User Documentation&#92;&#92;n[See our full user documentation on our github pages site.](https://allencell.github.io/allencell-segmenter-ml/index.html)&#92;&#92;n&#92;&#92;n&#92;&#92;n## &#92;&#92;ud83d&#92;&#92;udee0&#92;&#92;ufe0f Installation&#92;&#92;n&#92;&#92;n### System and Data Requirements&#92;&#92;n&#92;&#92;n[Please click here to check out our latest System and Data requirements.](https://allencell.github.io/allencell-segmenter-ml/1_Get-started/1_prerequisites.html)&#92;&#92;n&#92;&#92;n&#92;&#92;n### Installation Steps&#92;&#92;n[Please click here for our latest installation steps.](https://allencell.github.io/allencell-segmenter-ml/1_Get-started/2_installation.html)&#92;&#92;n&#92;&#92;n&#92;&#92;n## Models&#92;&#92;n[More information about the pre-trained models we provide with our plugin, and citation information, can be found here.](https://allencell.github.io/allencell-segmenter-ml/1_Get-started/4_pretrained-models.html)&#92;&#92;n&#92;&#92;n## License&#92;&#92;n&#92;&#92;nDistributed under the terms of the [Allen Institute Software License].&#92;&#92;n&#92;&#92;n## Issues&#92;&#92;n&#92;&#92;nIf you encounter any problems, please [file an issue] along with a detailed description.&#92;&#92;n&#92;&#92;n[napari]: https://github.com/napari/napari&#92;&#92;n[@napari]: https://github.com/napari&#92;&#92;n[Allen Institute Software License]: https://github.com/AllenCell/allencell-segmenter-ml/blob/main/LICENSE&#92;&#92;n[file an issue]: https://github.com/AllenCell/allencell-ml-segmenter/issues&#92;&#92;n[napari]: https://github.com/napari/napari&#92;&#92;n[tox]: https://tox.readthedocs.io/en/latest/&#92;&#92;n[pip]: https://pypi.org/project/pip/&#92;&#92;n[PyPI]: https://pypi.org/&#92;&#92;n[PyTorch]: https://pytorch.org/get-started/locally/&#92;&#92;n&#92;&quot;,&#92;&quot;package_metadata_classifier&#92;&quot;:&#92;&quot;[&#x27;Development Status :: 2 - Pre-Alpha&#x27;, &#x27;Framework :: napari&#x27;, &#x27;Intended Audience :: Science/Research&#x27;, &#x27;License :: Other/Proprietary License&#x27;, &#x27;License :: Free for non-commercial use&#x27;, &#x27;Operating System :: OS Independent&#x27;, &#x27;Programming Language :: Python&#x27;, &#x27;Programming Language :: Python :: 3&#x27;, &#x27;Programming Language :: Python :: 3 :: Only&#x27;, &#x27;Programming Language :: Python :: 3.9&#x27;, &#x27;Programming Language :: Python :: 3.10&#x27;, &#x27;Topic :: Scientific/Engineering :: Image Processing&#x27;]&#92;&quot;,&#92;&quot;package_metadata_project_url&#92;&quot;:&#92;&quot;[&#x27;Homepage, https://github.com/AllenCell/allencell-ml-segmenter&#x27;, &#x27;Bug Tracker, https://github.com/AllenCell/allencell-ml-segmenter/issues&#x27;, &#x27;Documentation, https://github.com/AllenCell/allencell-ml-segmenter#README.md&#x27;, &#x27;User Support, https://github.com/AllenCell/allencell-ml-segmenter/issues&#x27;]&#92;&quot;,&#92;&quot;contributions_readers_0_command&#92;&quot;:null,&#92;&quot;contributions_writers_0_command&#92;&quot;:null,&#92;&quot;contributions_widgets_0_command&#92;&quot;:&#92;&quot;allencell-segmenter-ml.make_qwidget&#92;&quot;,&#92;&quot;contributions_sample_data_0_command&#92;&quot;:null,&#92;&quot;contributions_readers_0_filename_patterns&#92;&quot;:null,&#92;&quot;contributions_writers_0_filename_extensions&#92;&quot;:null,&#92;&quot;contributions_writers_1_filename_extensions&#92;&quot;:null,&#92;&quot;home_pypi&#92;&quot;:&#92;&quot;https://pypi.org/project/allencell-segmenter-ml&#92;&quot;,&#92;&quot;home_github&#92;&quot;:null,&#92;&quot;home_other&#92;&quot;:null},{&#92;&quot;Unnamed: 0&#92;&quot;:6,&#92;&quot;normalized_name&#92;&quot;:&#92;&quot;applet3&#92;&quot;,&#92;&quot;name&#92;&quot;:&#92;&quot;AppleT3&#92;&quot;,&#92;&quot;display_name&#92;&quot;:&#92;&quot;Appletree&#92;&quot;,&#92;&quot;version&#92;&quot;:&#92;&quot;0.1.dev1&#92;&quot;,&#92;&quot;created_at&#92;&quot;:&#92;&quot;2025-04-19&#92;&quot;,&#92;&quot;modified_at&#92;&quot;:&#92;&quot;2025-04-19&#92;&quot;,&#92;&quot;author&#92;&quot;:&#92;&quot;Herearii Metuarea&#92;&quot;,&#92;&quot;package_metadata_author_email&#92;&quot;:&#92;&quot;herearii.metuarea@univ-angers.fr&#92;&quot;,&#92;&quot;license&#92;&quot;:&#92;&quot;Copyright (c) 2025, Herearii Metuarea&#92;&#92;nAll rights reserved.&#92;&#92;n&#92;&#92;nRedistribution and use in source and binary forms, with or without&#92;&#92;nmodification, are permitted provided that the following conditions are met:&#92;&#92;n&#92;&#92;n* Redistributions of source code must retain the above copyright notice, this&#92;&#92;n  list of conditions and the following disclaimer.&#92;&#92;n&#92;&#92;n* Redistributions in binary form must reproduce the above copyright notice,&#92;&#92;n  this list of conditions and the following disclaimer in the documentation&#92;&#92;n  and/or other materials provided with the distribution.&#92;&#92;n&#92;&#92;n* Neither the name of copyright holder nor the names of its&#92;&#92;n  contributors may be used to endorse or promote products derived from&#92;&#92;n  this software without specific prior written permission.&#92;&#92;n&#92;&#92;nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &#92;&#92;&#92;&quot;AS IS&#92;&#92;&#92;&quot;&#92;&#92;nAND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE&#92;&#92;nIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE&#92;&#92;nDISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE&#92;&#92;nFOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL&#92;&#92;nDAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR&#92;&#92;nSERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER&#92;&#92;nCAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,&#92;&#92;nOR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE&#92;&#92;nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.&#92;&#92;n&#92;&quot;,&#92;&quot;home&#92;&quot;:null,&#92;&quot;package_metadata_home_page&#92;&quot;:null,&#92;&quot;summary&#92;&quot;:&#92;&quot;Apple tree segmentation for young apple tree&#92;&quot;,&#92;&quot;package_metadata_requires_python&#92;&quot;:&#92;&quot;==3.10.16&#92;&quot;,&#92;&quot;package_metadata_requires_dist&#92;&quot;:&#92;&quot;[&#x27;numpy&#x27;, &#x27;magicgui&#x27;, &#x27;qtpy&#x27;, &#x27;scikit-image&#x27;, &#x27;torch&gt;=2.5.1&#x27;, &#x27;torchvision&gt;=0.20.1&#x27;, &#x27;numpy&gt;=1.24.4&#x27;, &#x27;tqdm&gt;=4.66.1&#x27;, &#x27;hydra-core&gt;=1.3.2&#x27;, &#x27;iopath&gt;=0.1.10&#x27;, &#x27;pillow&gt;=9.4.0&#x27;, &#x27;supervision==0.25.1&#x27;, &#x27;transformers==4.51.3&#x27;, &#x27;einops==0.8.1&#x27;, &#x27;tensorflow==2.19.0&#x27;, &#x27;accelerate==1.6.0&#x27;, &#x27;tox; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;, &#x27;pytest; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;, &#x27;pytest-cov; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;, &#x27;pytest-qt; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;, &#x27;napari; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;, &#x27;pyqt5; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;]&#92;&quot;,&#92;&quot;package_metadata_description&#92;&quot;:&#92;&quot;# appletree&#92;&#92;n&#92;&#92;n[![License BSD-3](https://img.shields.io/pypi/l/appletree.svg?color=green)](https://github.com/hereariim/appletree/raw/main/LICENSE)&#92;&#92;n[![PyPI](https://img.shields.io/pypi/v/appletree.svg?color=green)](https://pypi.org/project/appletree)&#92;&#92;n[![Python Version](https://img.shields.io/pypi/pyversions/appletree.svg?color=green)](https://python.org)&#92;&#92;n[![tests](https://github.com/hereariim/appletree/workflows/tests/badge.svg)](https://github.com/hereariim/appletree/actions)&#92;&#92;n[![codecov](https://codecov.io/gh/hereariim/appletree/branch/main/graph/badge.svg)](https://codecov.io/gh/hereariim/appletree)&#92;&#92;n[![napari hub](https://img.shields.io/endpoint?url=https://api.napari-hub.org/shields/appletree)](https://napari-hub.org/plugins/appletree)&#92;&#92;n[![npe2](https://img.shields.io/badge/plugin-npe2-blue?link=https://napari.org/stable/plugins/index.html)](https://napari.org/stable/plugins/index.html)&#92;&#92;n[![Copier](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/copier-org/copier/master/img/badge/badge-grayscale-inverted-border-purple.json)](https://github.com/copier-org/copier)&#92;&#92;n&#92;&#92;nApple tree segmentation for young apple tree&#92;&#92;n&#92;&#92;n----------------------------------&#92;&#92;n&#92;&#92;nThis [napari] plugin was generated with [copier] using the [napari-plugin-template].&#92;&#92;n&#92;&#92;n&lt;!--&#92;&#92;nDon&#x27;t miss the full getting started guide to set up your new package:&#92;&#92;nhttps://github.com/napari/napari-plugin-template#getting-started&#92;&#92;n&#92;&#92;nand review the napari docs for plugin developers:&#92;&#92;nhttps://napari.org/stable/plugins/index.html&#92;&#92;n--&gt;&#92;&#92;n&#92;&#92;n## Installation&#92;&#92;n&#92;&#92;nYou can install `appletree` via [pip]:&#92;&#92;n&#92;&#92;n    pip install appletree&#92;&#92;n&#92;&#92;nTo install latest development version :&#92;&#92;n&#92;&#92;n    pip install git+https://github.com/hereariim/appletree.git&#92;&#92;n&#92;&#92;n## Contributing&#92;&#92;n&#92;&#92;nContributions are very welcome. Tests can be run with [tox], please ensure&#92;&#92;nthe coverage at least stays the same before you submit a pull request.&#92;&#92;n&#92;&#92;n## License&#92;&#92;n&#92;&#92;nDistributed under the terms of the [BSD-3] license,&#92;&#92;n&#92;&#92;&#92;&quot;appletree&#92;&#92;&#92;&quot; is free and open source software&#92;&#92;n&#92;&#92;n## Issues&#92;&#92;n&#92;&#92;nIf you encounter any problems, please [file an issue] along with a detailed description.&#92;&#92;n&#92;&#92;n[napari]: https://github.com/napari/napari&#92;&#92;n[copier]: https://copier.readthedocs.io/en/stable/&#92;&#92;n[@napari]: https://github.com/napari&#92;&#92;n[MIT]: http://opensource.org/licenses/MIT&#92;&#92;n[BSD-3]: http://opensource.org/licenses/BSD-3-Clause&#92;&#92;n[GNU GPL v3.0]: http://www.gnu.org/licenses/gpl-3.0.txt&#92;&#92;n[GNU LGPL v3.0]: http://www.gnu.org/licenses/lgpl-3.0.txt&#92;&#92;n[Apache Software License 2.0]: http://www.apache.org/licenses/LICENSE-2.0&#92;&#92;n[Mozilla Public License 2.0]: https://www.mozilla.org/media/MPL/2.0/index.txt&#92;&#92;n[napari-plugin-template]: https://github.com/napari/napari-plugin-template&#92;&#92;n&#92;&#92;n[file an issue]: https://github.com/hereariim/appletree/issues&#92;&#92;n&#92;&#92;n[napari]: https://github.com/napari/napari&#92;&#92;n[tox]: https://tox.readthedocs.io/en/latest/&#92;&#92;n[pip]: https://pypi.org/project/pip/&#92;&#92;n[PyPI]: https://pypi.org/&#92;&#92;n&#92;&quot;,&#92;&quot;package_metadata_classifier&#92;&quot;:&#92;&quot;[&#x27;Development Status :: 2 - Pre-Alpha&#x27;, &#x27;Framework :: napari&#x27;, &#x27;Intended Audience :: Developers&#x27;, &#x27;License :: OSI Approved :: BSD License&#x27;, &#x27;Operating System :: OS Independent&#x27;, &#x27;Programming Language :: Python&#x27;, &#x27;Programming Language :: Python :: 3&#x27;, &#x27;Programming Language :: Python :: 3 :: Only&#x27;, &#x27;Programming Language :: Python :: 3.10&#x27;, &#x27;Programming Language :: Python :: 3.11&#x27;, &#x27;Programming Language :: Python :: 3.12&#x27;, &#x27;Programming Language :: Python :: 3.13&#x27;, &#x27;Topic :: Scientific/Engineering :: Image Processing&#x27;]&#92;&quot;,&#92;&quot;package_metadata_project_url&#92;&quot;:&#92;&quot;[&#x27;Bug Tracker, https://github.com/hereariim/appletree/issues&#x27;, &#x27;Documentation, https://github.com/hereariim/appletree#README.md&#x27;, &#x27;Source Code, https://github.com/hereariim/appletree&#x27;, &#x27;User Support, https://github.com/hereariim/appletree/issues&#x27;]&#92;&quot;,&#92;&quot;contributions_readers_0_command&#92;&quot;:null,&#92;&quot;contributions_writers_0_command&#92;&quot;:null,&#92;&quot;contributions_widgets_0_command&#92;&quot;:&#92;&quot;appletree.make_container_widget&#92;&quot;,&#92;&quot;contributions_sample_data_0_command&#92;&quot;:null,&#92;&quot;contributions_readers_0_filename_patterns&#92;&quot;:null,&#92;&quot;contributions_writers_0_filename_extensions&#92;&quot;:null,&#92;&quot;contributions_writers_1_filename_extensions&#92;&quot;:null,&#92;&quot;home_pypi&#92;&quot;:&#92;&quot;https://pypi.org/project/AppleT3&#92;&quot;,&#92;&quot;home_github&#92;&quot;:null,&#92;&quot;home_other&#92;&quot;:null},{&#92;&quot;Unnamed: 0&#92;&quot;:7,&#92;&quot;normalized_name&#92;&quot;:&#92;&quot;alveoleye&#92;&quot;,&#92;&quot;name&#92;&quot;:&#92;&quot;AlveolEye&#92;&quot;,&#92;&quot;display_name&#92;&quot;:&#92;&quot;AlveolEye&#92;&quot;,&#92;&quot;version&#92;&quot;:&#92;&quot;0.1.6&#92;&quot;,&#92;&quot;created_at&#92;&quot;:&#92;&quot;2024-05-22&#92;&quot;,&#92;&quot;modified_at&#92;&quot;:&#92;&quot;2025-06-27&#92;&quot;,&#92;&quot;author&#92;&quot;:&#92;&quot;Joseph Hirsh&#92;&quot;,&#92;&quot;package_metadata_author_email&#92;&quot;:&#92;&quot;josephhirsh9@gmail.com&#92;&quot;,&#92;&quot;license&#92;&quot;:&#92;&quot;BSD&#92;&quot;,&#92;&quot;home&#92;&quot;:null,&#92;&quot;package_metadata_home_page&#92;&quot;:null,&#92;&quot;summary&#92;&quot;:&#92;&quot;Reads lung slides with AI-driven and classical methods&#92;&quot;,&#92;&quot;package_metadata_requires_python&#92;&quot;:&#92;&quot;&gt;=3.8&#92;&quot;,&#92;&quot;package_metadata_requires_dist&#92;&quot;:&#92;&quot;[&#x27;numpy&#x27;, &#x27;magicgui&#x27;, &#x27;qtpy&#x27;, &#x27;typeguard&#x27;, &#x27;pytest; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;, &#x27;pytest-cov; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;, &#x27;pytest-qt; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;, &#x27;napari; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;, &#x27;qtpy; extra == &#92;&#92;&#92;&quot;testing&#92;&#92;&#92;&quot;&#x27;]&#92;&quot;,&#92;&quot;package_metadata_description&#92;&quot;:&#92;&quot;# AlveolEye: Automated Lung Morphometry Made Easy&#92;&#92;n&#92;&#92;n[![Napari Plugin](https://img.shields.io/badge/Napari-Plugin-1157c4?logo=napari)](https://www.napari-hub.org/plugins/AlveolEye)&#92;&#92;n![Python Version](https://img.shields.io/badge/Python-3.9%20|%203.10%20|%203.11-blue)&#92;&#92;n![OS Support](https://img.shields.io/badge/Platform-Windows%20%7C%20macOS%20%7C%20Linux-blue)&#92;&#92;n![GitHub Release](https://img.shields.io/github/v/release/SucreLab/AlveolEye?display_name=tag)&#92;&#92;n![License](https://img.shields.io/github/license/SucreLab/AlveolEye)&#92;&#92;n[![PyPI Downloads](https://img.shields.io/pypi/dm/AlveolEye)](https://pypi.org/project/AlveolEye/)&#92;&#92;n![Maintenance](https://img.shields.io/maintenance/yes/2025)&#92;&#92;n![Last Commit](https://img.shields.io/github/last-commit/SucreLab/AlveolEye)&#92;&#92;n![Issues](https://img.shields.io/github/issues/SucreLab/AlveolEye)&#92;&#92;n&#92;&#92;nThis repository contains the beta version of AlveolEye, created by the [Sucre lab](https://www.sucrelab.org/).  &#92;&#92;nThe code is authored by Samuel Hirsh, Joseph Hirsh, Nick Negretti, and Shawyon Shirazi.&#92;&#92;n&#92;&#92;nAlveolEye is a Napari plugin that uses computer vision and classical image processing  &#92;&#92;nto calculate mean linear intercept (MLI) and airspace volume density (ASVD) of histologic images.&#92;&#92;n&#92;&#92;nThe goal of this tool is to aid researchers, not provide a complete automated annotation solution.&#92;&#92;n&#92;&#92;nWe welcome GitHub issues and feedback!&#92;&#92;n&#92;&#92;n## Installation&#92;&#92;n&#92;&#92;nThe goal of this process is to create a conda environment containing Napari and all AlveolEye requirements.&#92;&#92;n&#92;&#92;n*If you already have conda set up, you can skip step 1.*&#92;&#92;n&#92;&#92;n1. **Install Miniconda** by downloading the appropriate version from [here](https://www.anaconda.com/docs/getting-started/miniconda/install):  &#92;&#92;n   - Choose the version that matches your processor.  &#92;&#92;n   - Download the `.pkg` version for easy installation.&#92;&#92;n&#92;&#92;n2. **Clone the repository** (by opening a terminal or Miniconda prompt and running the following)&#92;&#92;n   ```&#92;&#92;n   git clone https://github.com/SucreLab/AlveolEye&#92;&#92;n   ```&#92;&#92;n&#92;&#92;n3. **Navigate to the directory**:&#92;&#92;n   ```&#92;&#92;n   cd AlveolEye&#92;&#92;n   ```&#92;&#92;n&#92;&#92;n4. **Create the conda environment**:&#92;&#92;n   ```&#92;&#92;n   conda env create -f ./environment.yml&#92;&#92;n   ```&#92;&#92;n&#92;&#92;n5. **Activate the environment**:&#92;&#92;n   ```&#92;&#92;n   conda activate AlveolEye&#92;&#92;n   ```&#92;&#92;n&#92;&#92;n6. **Install the plugin**:&#92;&#92;n   ```&#92;&#92;n   pip install .&#92;&#92;n   ```&#92;&#92;n&#92;&#92;n7. **Launch Napari** and locate the plugin in the plugin menu:&#92;&#92;n   ```&#92;&#92;n   napari&#92;&#92;n   ```&#92;&#92;n&#92;&#92;n## Running Post-Installation&#92;&#92;n&#92;&#92;n1. **Activate the environment** in the terminal or Miniconda prompt:&#92;&#92;n   ```&#92;&#92;n   conda activate AlveolEye&#92;&#92;n   ```&#92;&#92;n&#92;&#92;n2. **Run Napari** in the terminal:&#92;&#92;n   ```&#92;&#92;n   napari&#92;&#92;n   ```&#92;&#92;n&#92;&#92;n&lt;div align=&#92;&#92;&#92;&quot;right&#92;&#92;&#92;&quot;&gt;&#92;&#92;n  &lt;a href=&#92;&#92;&#92;&quot;#alveoleye-automated-lung-morphometry-made-easy&#92;&#92;&#92;&quot;&gt;Back to Top&lt;/a&gt;&#92;&#92;n&lt;/div&gt;&#92;&#92;n&#92;&#92;n## Usage&#92;&#92;n&#92;&#92;n### Processing: Identify and Segment Vessel Endothelium and Airway Epithelium with Computer Vision&#92;&#92;n&#92;&#92;n![processing diagram](https://raw.githubusercontent.com/SucreLab/AlveolEye/main/docs/PROCESSING_FINAL.svg)&#92;&#92;n&#92;&#92;n1. **Import image**  &#92;&#92;n   - Click the &#92;&#92;&#92;&quot;Import Image&#92;&#92;&#92;&quot; button.  &#92;&#92;n   - Use the file dialog to select an image (`.jpg`, `.png`, or `.tiff`).  &#92;&#92;n   - Verify that the image correctly loaded. The file name should appear to the right of the button.&#92;&#92;n&#92;&#92;n2. **Toggle processing with computer vision**  &#92;&#92;n   - Keep the checkbox selected to process the image with computer vision (continue to step 3).  &#92;&#92;n   - Deselect to skip computer vision processing (skip to step 5).&#92;&#92;n&#92;&#92;n3. **Import weights**  &#92;&#92;n   - To use the default model, proceed to step 4.  &#92;&#92;n   - To use a custom model:  &#92;&#92;n     - Click the &#92;&#92;&#92;&quot;Import Weights&#92;&#92;&#92;&quot; button.  &#92;&#92;n     - Select a model file (`.pth`).  &#92;&#92;n     - Verify that the weights correctly loaded. The file name should appear to the right of the button.&#92;&#92;n&#92;&#92;n4. **Set minimum confidence**  &#92;&#92;n   - Adjust the minimum confidence using the input box or the &#92;&#92;&#92;&quot;-/+&#92;&#92;&#92;&quot; buttons.  &#92;&#92;n   - Predictions from the computer vision model with lower confidence than this threshold will not appear.&#92;&#92;n&#92;&#92;n5. **Run processing**  &#92;&#92;n   - Click the &#92;&#92;&#92;&quot;Run Processing&#92;&#92;&#92;&quot; button.  &#92;&#92;n   - Once completed, manually edit the prediction as needed using Napari&#x27;s built-in tools.&#92;&#92;n&#92;&#92;n&lt;div align=&#92;&#92;&#92;&quot;right&#92;&#92;&#92;&quot;&gt;&#92;&#92;n  &lt;a href=&#92;&#92;&#92;&quot;#alveoleye-automated-lung-morphometry-made-easy&#92;&#92;&#92;&quot;&gt;Back to Top&lt;/a&gt;&#92;&#92;n&lt;/div&gt;&#92;&#92;n&#92;&#92;n### Postprocessing: Segment Alveolar Tissue and Find Vessel and Aireway Lumens&#92;&#92;n&#92;&#92;n![postprocessing diagram](https://raw.githubusercontent.com/SucreLab/AlveolEye/main/docs/POSTPROCESSING_FINAL.svg)&#92;&#92;n&#92;&#92;n1. **Configure thresholding**  &#92;&#92;n   - For manual thresholding: Select the &#92;&#92;&#92;&quot;Manual threshold&#92;&#92;&#92;&quot; checkbox and use the spinbox to set the threshold level.  &#92;&#92;n   - For automatic thresholding ([Otsu&#x27;s method](https://learnopencv.com/otsu-thresholding-with-opencv/)): Leave the box unchecked.&#92;&#92;n&#92;&#92;n2. **Remove small particles**  &#92;&#92;n   - Set the minimum size cutoff.&#92;&#92;n   - Particles with fewer pixels than this value will be removed.&#92;&#92;n&#92;&#92;n3. **Remove small holes**  &#92;&#92;n   - Set the minimum size cutoff.  &#92;&#92;n   - Holes with fewer pixels than this value will be removed.&#92;&#92;n&#92;&#92;n4. **Run postprocessing**  &#92;&#92;n   - Click the &#92;&#92;&#92;&quot;Run Postprocessing&#92;&#92;&#92;&quot; button.  &#92;&#92;n   - Once completed, manually edit the results as needed using Napari&#x27;s built-in tools.&#92;&#92;n&#92;&#92;n&lt;div align=&#92;&#92;&#92;&quot;right&#92;&#92;&#92;&quot;&gt;&#92;&#92;n  &lt;a href=&#92;&#92;&#92;&quot;#alveoleye-automated-lung-morphometry-made-easy&#92;&#92;&#92;&quot;&gt;Back to Top&lt;/a&gt;&#92;&#92;n&lt;/div&gt;&#92;&#92;n&#92;&#92;n### Assessments: Calculate Morphometry Measurements&#92;&#92;n&#92;&#92;n![assessments diagram](https://raw.githubusercontent.com/SucreLab/AlveolEye/main/docs/ASSESSMENTS_FINAL.svg)&#92;&#92;n&#92;&#92;n1. **Airspace Volume Density (ASVD)**&#92;&#92;n   - Select the checkbox to run ASVD calculation.&#92;&#92;n   - Deselect the checkbox to exclude data from export and increase processing speed.&#92;&#92;n&#92;&#92;n2. **Mean Linear Intercept (MLI)**&#92;&#92;n   - Select the checkbox to run MLI calculation.&#92;&#92;n   - Deselect the checkbox to exclude data from export and increase processing speed.&#92;&#92;n&#92;&#92;n3. **Number of lines**&#92;&#92;n   - Set the number of lines used for MLI calculation.&#92;&#92;n&#92;&#92;n5. **Minimum length**&#92;&#92;n   - Set the minimum chord length for inclusion in MLI calculations.&#92;&#92;n   - Note: Chords are the line segments that span across an airspace between two alveolar tissue boundaries during MLI calculation.&#92;&#92;n&#92;&#92;n7. **Scale**&#92;&#92;n   - Set the pixel-to-physical space multiplier.&#92;&#92;n&#92;&#92;n9. **Run assessments**&#92;&#92;n   - Click the &#92;&#92;&#92;&quot;Run Assessments&#92;&#92;&#92;&quot; button.&#92;&#92;n   - View results displayed beside assessment checkboxes and in the export box.&#92;&#92;n&#92;&#92;n&lt;div align=&#92;&#92;&#92;&quot;right&#92;&#92;&#92;&quot;&gt;&#92;&#92;n  &lt;a href=&#92;&#92;&#92;&quot;#alveoleye-automated-lung-morphometry-made-easy&#92;&#92;&#92;&quot;&gt;Back to Top&lt;/a&gt;&#92;&#92;n&lt;/div&gt;&#92;&#92;n&#92;&#92;n### Export Results: Save Assessment Results as a CSV or JSON File&#92;&#92;n&#92;&#92;n![export diagram](https://raw.githubusercontent.com/SucreLab/AlveolEye/main/docs/EXPORT_FINAL.svg)&#92;&#92;n&#92;&#92;n1. **Add results**&#92;&#92;n   - Click &#92;&#92;&#92;&quot;Add&#92;&#92;&#92;&quot; to include current assessment data in the export file.&#92;&#92;n&#92;&#92;n3. **Remove last result**&#92;&#92;n   - Click &#92;&#92;&#92;&quot;Remove&#92;&#92;&#92;&quot; to delete the last added results from the export file.&#92;&#92;n&#92;&#92;n5. **Clear export data**&#92;&#92;n   - Click &#92;&#92;&#92;&quot;Clear&#92;&#92;&#92;&quot; to empty the export file.&#92;&#92;n&#92;&#92;n7. **Export results**&#92;&#92;n   - Click &#92;&#92;&#92;&quot;Export Results&#92;&#92;&#92;&quot; to save the data (`.csv` or `.json` format).&#92;&#92;n&#92;&#92;n**Results Key**&#92;&#92;n&#92;&#92;n- **MLI**: Mean Linear Intercept for the tissue image&#92;&#92;n &#92;&#92;n- **Standard deviation**: Standard deviation of chord lengths used in MLI calculation&#92;&#92;n  &#92;&#92;n- **Number of chords**: Number of chords used in MLI calculation&#92;&#92;n&#92;&#92;n- **ASVD**: Airspace Volume Density for the image&#92;&#92;n &#92;&#92;n- **Airspace pixels**: Total number of airspace pixels&#92;&#92;n   &#92;&#92;n- **Non-airspace pixels**: Total number of non-airspace pixels&#92;&#92;n&#92;&#92;n&lt;div align=&#92;&#92;&#92;&quot;right&#92;&#92;&#92;&quot;&gt;&#92;&#92;n  &lt;a href=&#92;&#92;&#92;&quot;#alveoleye-automated-lung-morphometry-made-easy&#92;&#92;&#92;&quot;&gt;Back to Top&lt;/a&gt;&#92;&#92;n&lt;/div&gt;&#92;&#92;n&#92;&#92;n## Manual Annotation Guide&#92;&#92;n&#92;&#92;n### Label Reference&#92;&#92;n&#92;&#92;n| Structure          | Label Number |&#92;&#92;n|--------------------|--------------|&#92;&#92;n| Blocker            | 1            |&#92;&#92;n| Airway Epithelium  | 2            |&#92;&#92;n| Vessel Endothelium | 3            |&#92;&#92;n| Airway Lumen       | 4            |&#92;&#92;n| Vessel Lumen       | 5            |&#92;&#92;n| Parenchyma         | 6            |&#92;&#92;n| Alveoli            | 7            |&#92;&#92;n&#92;&#92;n### Annotation Tips&#92;&#92;n&#92;&#92;n- **Eyedropper tool**: Click the eyedropper tool, then click a pixel in the image to set your active label (for drawing and editing) to that pixel&#x27;s label.  &#92;&#92;n- **Layer selection**: Ensure you&#x27;re working on the correct layer before annotating.  &#92;&#92;n- **Visibility control**: Hide unnecessary layers using the eye icon on the layer boxes (to the left of the image viewer) for clearer viewing.&#92;&#92;n- **Blocking**: Encircle airways and vessels in the blocking label, and everything within that closed shape will be discounted from assessments calculation. &#92;&#92;n&#92;&#92;n&lt;div align=&#92;&#92;&#92;&quot;right&#92;&#92;&#92;&quot;&gt;&#92;&#92;n  &lt;a href=&#92;&#92;&#92;&quot;#alveoleye-automated-lung-morphometry-made-easy&#92;&#92;&#92;&quot;&gt;Back to Top&lt;/a&gt;&#92;&#92;n&lt;/div&gt;&#92;&#92;n&#92;&#92;n## Additional Information&#92;&#92;n&#92;&#92;n### Theme Settings&#92;&#92;n&#92;&#92;nToggle between dark and light mode using:&#92;&#92;n&#92;&#92;n- **Windows/Linux**: `Ctrl + Shift + T`  &#92;&#92;n- **macOS**: `Cmd + Shift + T`&#92;&#92;n&#92;&#92;nOr through Napari preferences:&#92;&#92;n&#92;&#92;n1. Select &#92;&#92;&#92;&quot;napari&#92;&#92;&#92;&quot; in the menu bar.&#92;&#92;n   &#92;&#92;n2. Choose &#92;&#92;&#92;&quot;Preferences.&#92;&#92;&#92;&quot;&#92;&#92;n   &#92;&#92;n3. Click &#92;&#92;&#92;&quot;Appearance&#92;&#92;&#92;&quot; in the left menu.&#92;&#92;n     &#92;&#92;n4. Select &#92;&#92;&#92;&quot;dark,&#92;&#92;&#92;&quot; &#92;&#92;&#92;&quot;light,&#92;&#92;&#92;&quot; or &#92;&#92;&#92;&quot;system&#92;&#92;&#92;&quot; in the theme dropdown.&#92;&#92;n&#92;&#92;n&lt;div align=&#92;&#92;&#92;&quot;right&#92;&#92;&#92;&quot;&gt;&#92;&#92;n  &lt;a href=&#92;&#92;&#92;&quot;#alveoleye-automated-lung-morphometry-made-easy&#92;&#92;&#92;&quot;&gt;Back to Top&lt;/a&gt;&#92;&#92;n&lt;/div&gt;&#92;&#92;n&#92;&quot;,&#92;&quot;package_metadata_classifier&#92;&quot;:&#92;&quot;[&#x27;Development Status :: 2 - Pre-Alpha&#x27;, &#x27;Framework :: napari&#x27;, &#x27;Intended Audience :: Developers&#x27;, &#x27;License :: OSI Approved :: BSD License&#x27;, &#x27;Operating System :: OS Independent&#x27;, &#x27;Programming Language :: Python&#x27;, &#x27;Programming Language :: Python :: 3&#x27;, &#x27;Programming Language :: Python :: 3 :: Only&#x27;, &#x27;Programming Language :: Python :: 3.8&#x27;, &#x27;Programming Language :: Python :: 3.9&#x27;, &#x27;Programming Language :: Python :: 3.10&#x27;, &#x27;Topic :: Scientific/Engineering :: Image Processing&#x27;]&#92;&quot;,&#92;&quot;package_metadata_project_url&#92;&quot;:null,&#92;&quot;contributions_readers_0_command&#92;&quot;:&#92;&quot;AlveolEye.get_reader&#92;&quot;,&#92;&quot;contributions_writers_0_command&#92;&quot;:&#92;&quot;AlveolEye.write_multiple&#92;&quot;,&#92;&quot;contributions_widgets_0_command&#92;&quot;:&#92;&quot;AlveolEye.make_qwidget&#92;&quot;,&#92;&quot;contributions_sample_data_0_command&#92;&quot;:&#92;&quot;AlveolEye.make_sample_data&#92;&quot;,&#92;&quot;contributions_readers_0_filename_patterns&#92;&quot;:&#92;&quot;[&#x27;.jpeg&#x27;, &#x27;.jpg&#x27;, &#x27;.png&#x27;, &#x27;.tif&#x27;, &#x27;.tiff&#x27;]&#92;&quot;,&#92;&quot;contributions_writers_0_filename_extensions&#92;&quot;:null,&#92;&quot;contributions_writers_1_filename_extensions&#92;&quot;:&#92;&quot;[&#x27;.npy&#x27;]&#92;&quot;,&#92;&quot;home_pypi&#92;&quot;:&#92;&quot;https://pypi.org/project/AlveolEye&#92;&quot;,&#92;&quot;home_github&#92;&quot;:null,&#92;&quot;home_other&#92;&quot;:null},{&#92;&quot;Unnamed: 0&#92;&quot;:8,&#92;&quot;normalized_name&#92;&quot;:&#92;&quot;affinder&#92;&quot;,&#92;&quot;name&#92;&quot;:&#92;&quot;affinder&#92;&quot;,&#92;&quot;display_name&#92;&quot;:&#92;&quot;affinder&#92;&quot;,&#92;&quot;version&#92;&quot;:&#92;&quot;0.4.0&#92;&quot;,&#92;&quot;created_at&#92;&quot;:&#92;&quot;2021-02-04&#92;&quot;,&#92;&quot;modified_at&#92;&quot;:&#92;&quot;2024-06-26&#92;&quot;,&#92;&quot;author&#92;&quot;:&#92;&quot;Juan Nunez-Iglesias&#92;&quot;,&#92;&quot;package_metadata_author_email&#92;&quot;:&#92;&quot;juan.nunez-iglesias@monash.edu&#92;&quot;,&#92;&quot;license&#92;&quot;:&#92;&quot;BSD-3&#92;&quot;,&#92;&quot;home&#92;&quot;:&#92;&quot;https://github.com/jni/affinder&#92;&quot;,&#92;&quot;package_metadata_home_page&#92;&quot;:&#92;&quot;https://github.com/jni/affinder&#92;&quot;,&#92;&quot;summary&#92;&quot;:&#92;&quot;Quickly find the affine matrix mapping one image to another using manual correspondence points annotation&#92;&quot;,&#92;&quot;package_metadata_requires_python&#92;&quot;:&#92;&quot;&gt;=3.9&#92;&quot;,&#92;&quot;package_metadata_requires_dist&#92;&quot;:&#92;&quot;[&#x27;napari &gt;=0.4.17&#x27;, &#x27;npe2 &gt;=0.1.2&#x27;, &#x27;numpy&#x27;, &#x27;scikit-image &gt;=0.19.2&#x27;, &#x27;magicgui &gt;=0.3.7&#x27;, &#x27;toolz&#x27;, &#92;&#92;&#92;&quot;furo ; extra == &#x27;docs&#x27;&#92;&#92;&#92;&quot;, &#92;&#92;&#92;&quot;myst-parser ; extra == &#x27;docs&#x27;&#92;&#92;&#92;&quot;, &#92;&#92;&#92;&quot;coverage ; extra == &#x27;testing&#x27;&#92;&#92;&#92;&quot;, &#92;&#92;&#92;&quot;pydantic &lt;2 ; extra == &#x27;testing&#x27;&#92;&#92;&#92;&quot;, &#92;&#92;&#92;&quot;pytest ; extra == &#x27;testing&#x27;&#92;&#92;&#92;&quot;, &#92;&#92;&#92;&quot;pytest-cov ; extra == &#x27;testing&#x27;&#92;&#92;&#92;&quot;, &#92;&#92;&#92;&quot;pytest-qt ; extra == &#x27;testing&#x27;&#92;&#92;&#92;&quot;, &#92;&#92;&#92;&quot;scikit-image[data] ; extra == &#x27;testing&#x27;&#92;&#92;&#92;&quot;, &#92;&#92;&#92;&quot;napari[pyqt5] !=0.4.18 ; extra == &#x27;testing&#x27;&#92;&#92;&#92;&quot;, &#92;&#92;&#92;&quot;pygments !=2.16 ; extra == &#x27;testing&#x27;&#92;&#92;&#92;&quot;, &#92;&#92;&#92;&quot;zarr ; extra == &#x27;testing&#x27;&#92;&#92;&#92;&quot;]&#92;&quot;,&#92;&quot;package_metadata_description&#92;&quot;:&#92;&quot;# Description&#92;&#92;n&#92;&#92;nThis GUI plugin allows you to quickly find the affine matrix mapping&#92;&#92;none image to another using manual correspondence points annotation.&#92;&#92;n&#92;&#92;nMore simply, this plugin allows you to select corresponding points&#92;&#92;non an image, and a second image you wish to transform. It computes &#92;&#92;nthe requisite transformation matrix using Affine Transform, Euclidean Transform, &#92;&#92;nor Similarity Transform, and performs this transformation on the&#92;&#92;nmoving image, aligning it to the reference image.&#92;&#92;n&#92;&#92;nhttps://user-images.githubusercontent.com/17995243/120086403-f1d0b300-c121-11eb-8000-a44a2ac54339.mp4&#92;&#92;n&#92;&#92;n&#92;&#92;n# Who is This For?&#92;&#92;n&#92;&#92;nThis is a simple plugin which can be used on any 2D images, provided&#92;&#92;nthey can be loaded as layers into napari. The images need not be the same&#92;&#92;nfile format and this plugin also works with labels layers.&#92;&#92;n&#92;&#92;nNo prior understanding of the transformation methods is required, as&#92;&#92;nthey perform in the background based on the reference points selected.&#92;&#92;n&#92;&#92;n# How to Guide&#92;&#92;n&#92;&#92;nYou will need a combination of two or more 2D image and/or labels layers &#92;&#92;nloaded into napari. Once you have installed affinder, you can find it in&#92;&#92;nthe dock widgets menu.&#92;&#92;n&#92;&#92;n![Affinder widget in the Plugins-&gt;Add Dock Widget menu](https://i.imgur.com/w7MCXQy.png)&#92;&#92;n&#92;&#92;nThe first two dropdown boxes will be populated with the layers currently&#92;&#92;nloaded into napari. Select a layer to use as reference, and another to&#92;&#92;ntransform.&#92;&#92;n&#92;&#92;n![Dropdowns allow you to select the reference and moving layers](https://i.imgur.com/Tdbm1sX.png)&#92;&#92;n&#92;&#92;nNext, you can select the transformation model to use (affine is selected by default&#92;&#92;nand is the least rigid transformation of those available). See [below](#transformation-models) for a&#92;&#92;ndescription of the different models.&#92;&#92;n&#92;&#92;nFinally, you can optionally select a path to a text file for saving out the&#92;&#92;nresulting transformation matrix.&#92;&#92;n&#92;&#92;nWhen you click Start, affinder will add two points layers to napari. &#92;&#92;nThe plugin will also bring your reference image in focus, and its associated points&#92;&#92;nlayer. You can then start adding reference points by clicking on your image.&#92;&#92;n&#92;&#92;n![Adding reference points to layer](https://i.imgur.com/WPzNtyy.png)&#92;&#92;n&#92;&#92;nOnce three points are added, affinder will switch focus to the moving image,&#92;&#92;nand you should then proceed to select the corresponding three points.&#92;&#92;n&#92;&#92;n![Adding corresponding points to newly focused layer](https://i.imgur.com/JVZCvmp.png)&#92;&#92;n&#92;&#92;naffinder will immediately transform the moving image to align the points you&#x27;ve&#92;&#92;nselected when you add your third corresponding point to your moving image.&#92;&#92;n&#92;&#92;n![The moving image is transformed once three points are added](https://i.imgur.com/NTne9fj.png)&#92;&#92;n&#92;&#92;nFrom there, you can continue iteratively adding points until you &#92;&#92;nare happy with the alignment. Affinder will switch focus between&#92;&#92;nreference and moving image with each point.&#92;&#92;n&#92;&#92;nClick Finish to exit affinder.&#92;&#92;n&#92;&#92;n## Transformation Models&#92;&#92;n&#92;&#92;nThere are three transformation models available for use with affinder.&#92;&#92;nThey are listed here in order of increasing rigidity in the types of&#92;&#92;ntransforms they will allow. The eponymous Affine Transform is the &#92;&#92;nleast rigid and is the default choice.&#92;&#92;n&#92;&#92;n- [**Affine Transform**](https://en.wikipedia.org/wiki/Affine_transformation): &#92;&#92;nthe least rigid transformation, it preserves&#92;&#92;nlines and parallelism, but not necessarily distance and angles. Translation,&#92;&#92;nscaling, similarity, reflection, rotation and shearing are all valid&#92;&#92;naffine transformations.&#92;&#92;n&#92;&#92;n- [**Similarity Transform**](https://en.wikipedia.org/wiki/Similarity_(geometry)): &#92;&#92;nthis is a &#92;&#92;&#92;&quot;shape preserving&#92;&#92;&#92;&quot; transformation, producing objects which are &#92;&#92;ngeometrically similar. Translation, rotation, reflection and uniform scaling are &#92;&#92;nvalid similarity transforms. Shearing is not.&#92;&#92;n&#92;&#92;n- [**Euclidean Transform**](https://en.wikipedia.org/wiki/Rigid_transformation):&#92;&#92;nAlso known as a rigid transformation, this transform preserves the Euclidean&#92;&#92;ndistance between each pair of points on the image. This includes rotation,&#92;&#92;ntranslation and reflection but not scaling or shearing.&#92;&#92;n&#92;&#92;n# Getting Help&#92;&#92;n&#92;&#92;nIf you find a bug with affinder, or would like support with using it, please raise an&#92;&#92;nissue on the [GitHub repository](https://github.com/jni/affinder).&#92;&#92;n&#92;&#92;n# How to Cite&#92;&#92;n&#92;&#92;nMany plugins may be used in the course of published (or publishable) research, as well as&#92;&#92;nduring conference talks and other public facing events. If you&#x27;d like to be cited in&#92;&#92;na particular format, or have a DOI you&#x27;d like used, you should provide that information here.&#92;&#92;n&#92;&quot;,&#92;&quot;package_metadata_classifier&#92;&quot;:&#92;&quot;[&#x27;Development Status :: 3 - Alpha&#x27;, &#x27;Intended Audience :: Developers&#x27;, &#x27;Framework :: napari&#x27;, &#x27;Topic :: Software Development :: Testing&#x27;, &#x27;Programming Language :: Python&#x27;, &#x27;Programming Language :: Python :: 3&#x27;, &#x27;Programming Language :: Python :: 3.9&#x27;, &#x27;Programming Language :: Python :: 3.10&#x27;, &#x27;Programming Language :: Python :: 3.11&#x27;, &#x27;Operating System :: OS Independent&#x27;, &#x27;License :: OSI Approved :: BSD License&#x27;]&#92;&quot;,&#92;&quot;package_metadata_project_url&#92;&quot;:null,&#92;&quot;contributions_readers_0_command&#92;&quot;:null,&#92;&quot;contributions_writers_0_command&#92;&quot;:null,&#92;&quot;contributions_widgets_0_command&#92;&quot;:&#92;&quot;affinder.start_affinder&#92;&quot;,&#92;&quot;contributions_sample_data_0_command&#92;&quot;:null,&#92;&quot;contributions_readers_0_filename_patterns&#92;&quot;:null,&#92;&quot;contributions_writers_0_filename_extensions&#92;&quot;:null,&#92;&quot;contributions_writers_1_filename_extensions&#92;&quot;:null,&#92;&quot;home_pypi&#92;&quot;:&#92;&quot;https://pypi.org/project/affinder&#92;&quot;,&#92;&quot;home_github&#92;&quot;:&#92;&quot;https://github.com/jni/affinder&#92;&quot;,&#92;&quot;home_other&#92;&quot;:null},{&#92;&quot;Unnamed: 0&#92;&quot;:9,&#92;&quot;normalized_name&#92;&quot;:&#92;&quot;axondeepseg&#92;&quot;,&#92;&quot;name&#92;&quot;:&#92;&quot;AxonDeepSeg&#92;&quot;,&#92;&quot;display_name&#92;&quot;:&#92;&quot;AxonDeepSeg&#92;&quot;,&#92;&quot;version&#92;&quot;:&#92;&quot;5.1.0&#92;&quot;,&#92;&quot;created_at&#92;&quot;:&#92;&quot;2025-02-28&#92;&quot;,&#92;&quot;modified_at&#92;&quot;:&#92;&quot;2025-06-27&#92;&quot;,&#92;&quot;author&#92;&quot;:&#92;&quot;NeuroPoly Lab, Polytechnique Montreal&#92;&quot;,&#92;&quot;package_metadata_author_email&#92;&quot;:&#92;&quot;&#92;&#92;&#92;&quot;NeuroPoly Lab, Polytechnique Montreal&#92;&#92;&#92;&quot; &lt;axondeepseg@googlegroups.com&gt;&#92;&quot;,&#92;&quot;license&#92;&quot;:&#92;&quot;MIT&#92;&quot;,&#92;&quot;home&#92;&quot;:null,&#92;&quot;package_metadata_home_page&#92;&quot;:null,&#92;&quot;summary&#92;&quot;:&#92;&quot;Axon/Myelin segmentation using AI&#92;&quot;,&#92;&quot;package_metadata_requires_python&#92;&quot;:&#92;&quot;&lt;3.13,&gt;=3.11&#92;&quot;,&#92;&quot;package_metadata_requires_dist&#92;&quot;:&#92;&quot;[&#x27;numpy&lt;2&#x27;, &#x27;scipy&#x27;, &#x27;scikit-image!=0.25.0,!=0.25.1&#x27;, &#x27;tabulate&#x27;, &#x27;pandas&#x27;, &#x27;matplotlib&#x27;, &#x27;mpld3&#x27;, &#x27;tqdm&#x27;, &#x27;requests&#x27;, &#x27;pillow!=9.0.0&#x27;, &#x27;imageio&gt;=2.28.0&#x27;, &#x27;pytest&#x27;, &#x27;pytest-cov&#x27;, &#x27;prettytable&#x27;, &#x27;jupyter&#x27;, &#x27;openpyxl&#x27;, &#x27;qtconsole&lt;5.4.2&#x27;, &#x27;napari[all]&#x27;, &#x27;acvl_utils!=0.2.1&#x27;, &#x27;nnunetv2==2.2.1&#x27;, &#x27;loguru&#x27;, &#x27;torch&lt;2.4.0&#x27;, &#x27;pydicom&lt;3&#x27;, &#x27;pytest-qt&#x27;, &#x27;magicgui&#x27;, &#x27;qtpy&#x27;]&#92;&quot;,&#92;&quot;package_metadata_description&#92;&quot;:&#92;&quot;&#92;&#92;n&lt;picture&gt;&#92;&#92;n  &lt;source media=&#92;&#92;&#92;&quot;(prefers-color-scheme: dark)&#92;&#92;&#92;&quot; srcset=&#92;&#92;&#92;&quot;https://github.com/axondeepseg/doc-figures/blob/main/logo/logo_ads-dark-alpha.png?raw=true&#92;&#92;&#92;&quot; width=&#92;&#92;&#92;&quot;385&#92;&#92;&#92;&quot;&gt;&#92;&#92;n  &lt;img alt=&#92;&#92;&#92;&quot;ADS logo (simplified image of segmented axons/myelin in blue and red beside the text &#x27;AxonDeepSeg&#x27;)&#92;&#92;&#92;&quot; src=https://github.com/axondeepseg/doc-figures/blob/main/logo/logo_ads-alpha.png?raw=true&#92;&#92;&#92;&quot; width=&#92;&#92;&#92;&quot;385&#92;&#92;&#92;&quot;&gt;&#92;&#92;n&lt;/picture&gt;&#92;&#92;n&#92;&#92;n&#92;&#92;n[![Binder](https://mybinder.org/badge.svg)](https://mybinder.org/v2/gh/neuropoly/axondeepseg/master?filepath=notebooks%2Fgetting_started.ipynb)&#92;&#92;n[![Build Status](https://github.com/axondeepseg/axondeepseg/actions/workflows/run_tests.yaml/badge.svg)](https://github.com/axondeepseg/axondeepseg/actions/workflows/run_tests.yaml)&#92;&#92;n[![Documentation Status](https://readthedocs.org/projects/axondeepseg/badge/?version=stable)](http://axondeepseg.readthedocs.io/en/latest/?badge=latest)&#92;&#92;n[![Coverage Status](https://coveralls.io/repos/github/axondeepseg/axondeepseg/badge.svg?branch=master)](https://coveralls.io/github/axondeepseg/axondeepseg?branch=master)&#92;&#92;n[![Twitter Follow](https://img.shields.io/twitter/follow/axondeepseg.svg?style=social&amp;label=Follow)](https://twitter.com/axondeepseg)&#92;&#92;n&#92;&#92;nSegment axon and myelin from microscopy data using deep learning. Written in Python. Using the TensorFlow framework.&#92;&#92;nBased on a convolutional neural network architecture. Pixels are classified as either axon, myelin or background.&#92;&#92;n&#92;&#92;nFor more information, see the [documentation website](http://axondeepseg.readthedocs.io/).&#92;&#92;n&#92;&#92;n![alt tag](https://github.com/axondeepseg/doc-figures/blob/main/animations/napari.gif?raw=true)&#92;&#92;n&#92;&#92;n&#92;&#92;n&#92;&#92;n## Help&#92;&#92;n&#92;&#92;nWhether you are a newcomer or an experienced user, we will do our best to help and reply to you as soon as possible. Of course, please be considerate and respectful of all people participating in our community interactions.&#92;&#92;n&#92;&#92;n* If you encounter difficulties during installation and/or while using AxonDeepSeg, or have general questions about the project, you can start a new discussion on the [AxonDeepSeg GitHub Discussions forum](https://github.com/neuropoly/axondeepseg/discussions). We also encourage you, once you&#x27;ve familiarized yourself with the software, to continue participating in the forum by helping answer future questions from fellow users!&#92;&#92;n* If you encounter bugs during installation and/or use of AxonDeepSeg, you can open a new issue ticket on the [AxonDeepSeg GitHub issues webpage](https://github.com/neuropoly/axondeepseg/issues).&#92;&#92;n&#92;&#92;n&#92;&#92;n&#92;&#92;n&#92;&#92;n### Napari plugin&#92;&#92;n&#92;&#92;nA tutorial demonstrating the basic features of our plugin for Napari is hosted on YouTube, and can be viewed by clicking [this link](https://www.youtube.com/watch?v=zibDbpko6ko).&#92;&#92;n&#92;&#92;n## References&#92;&#92;n&#92;&#92;n**AxonDeepSeg**&#92;&#92;n&#92;&#92;n* [Lubrano et al. *Deep Active Leaning for Myelin Segmentation on Histology Data.* Montreal Artificial Intelligence and Neuroscience 2019](https://arxiv.org/abs/1907.05143) - &#92;&#92;&#92;&#92;[[**source code**](https://github.com/neuropoly/deep-active-learning)&#92;&#92;&#92;&#92;]&#92;&#92;n* [Zaimi et al. *AxonDeepSeg: automatic axon and myelin segmentation from microscopy data using convolutional neural networks.* Scientific Reports 2018](https://www.nature.com/articles/s41598-018-22181-4)&#92;&#92;n* [Collin et al. *Multi-Domain Data Aggregation for Axon and Myelin Segmentation in Histology Images*. preprint](https://arxiv.org/abs/2409.11552v1) - &#92;&#92;&#92;&#92;[[**source code**](https://github.com/axondeepseg/model_seg_generalist)]&#92;&#92;n&#92;&#92;n**Applications**&#92;&#92;n&#92;&#92;n* [Tabarin et al. *Deep learning segmentation (AxonDeepSeg) to generate axonal-property map from ex vivo human optic chiasm using light microscopy.* ISMRM 2019](https://www.ismrm.org/19/program_files/DP23.htm) - &#92;&#92;&#92;&#92;[[**source code**](https://github.com/thibaulttabarin/UnAxSeg)&#92;&#92;&#92;&#92;]&#92;&#92;n* [Lousada et al. *Characterization of cortico-striatal myelination in the context of pathological Repetitive Behaviors.*  International Basal Ganglia Society (IBAGS) 2019](http://www.ibags2019.com/key4register/images/client/863/files/Abstractbook1405.pdf)&#92;&#92;n* [Duval et al. *Axons morphometry in the human spinal cord.* NeuroImage 2019](https://www.sciencedirect.com/science/article/pii/S1053811918320044)&#92;&#92;n* [Yu et al. *Model-informed machine learning for multi-component T2 relaxometry.* Medical Image Analysis 2021](https://www.sciencedirect.com/science/article/pii/S1361841520303042) - &#92;&#92;&#92;&#92;[[**source code**](https://github.com/thomas-yu-epfl/Model_Informed_Machine_Learning)&#92;&#92;&#92;&#92;]&#92;&#92;n&#92;&#92;n**Reviews**&#92;&#92;n&#92;&#92;n* [Riordon et al. *Deep learning with microfluidics for biotechnology.* Trends in Biotechnology 2019](https://www.sciencedirect.com/science/article/pii/S0167779918302452)&#92;&#92;n&#92;&#92;n## Citation&#92;&#92;n&#92;&#92;nIf you use this work in your research, please cite it as follows:&#92;&#92;n&#92;&#92;nZaimi, A., Wabartha, M., Herman, V., Antonsanti, P.-L., Perone, C. S., &amp; Cohen-Adad, J. (2018). AxonDeepSeg: automatic axon and myelin segmentation from microscopy data using convolutional neural networks. Scientific Reports, 8(1), 3816. Link to paper: https://doi.org/10.1038/s41598-018-22181-4.&#92;&#92;n&#92;&#92;nCopyright (c) 2018 NeuroPoly (Polytechnique Montreal)&#92;&#92;n&#92;&#92;n## Licence&#92;&#92;n&#92;&#92;nThe MIT License (MIT)&#92;&#92;n&#92;&#92;nCopyright (c) 2018 NeuroPoly, &#92;&#92;u00c9cole Polytechnique, Universit&#92;&#92;u00e9 de Montr&#92;&#92;u00e9al&#92;&#92;n&#92;&#92;nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the &#92;&#92;u201cSoftware&#92;&#92;u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:&#92;&#92;n&#92;&#92;nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.&#92;&#92;n&#92;&#92;nTHE SOFTWARE IS PROVIDED &#92;&#92;u201cAS IS&#92;&#92;u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.&#92;&#92;n&#92;&#92;n## Contributors&#92;&#92;n&#92;&#92;nPierre-Louis Antonsanti, Stoyan Asenov, Mathieu Boudreau, Oumayma Bounou, Marie-H&#92;&#92;u00e9l&#92;&#92;u00e8ne Bourget, Julien Cohen-Adad, Victor Herman, Melanie Lubrano, Antoine Moevus, Christian Perone, Vasudev Sharma, Thibault Tabarin, Maxime Wabartha, Aldo Zaimi.&#92;&#92;n&#92;&quot;,&#92;&quot;package_metadata_classifier&#92;&quot;:&#92;&quot;[&#x27;Development Status :: 5 - Production/Stable&#x27;, &#x27;Intended Audience :: Science/Research&#x27;, &#x27;License :: OSI Approved :: MIT License&#x27;, &#x27;Framework :: napari&#x27;, &#x27;Operating System :: OS Independent&#x27;, &#x27;Programming Language :: Python&#x27;, &#x27;Programming Language :: Python :: 3&#x27;, &#x27;Programming Language :: Python :: 3 :: Only&#x27;, &#x27;Programming Language :: Python :: 3.11&#x27;, &#x27;Programming Language :: Python :: 3.12&#x27;, &#x27;Topic :: Scientific/Engineering :: Image Processing&#x27;]&#92;&quot;,&#92;&quot;package_metadata_project_url&#92;&quot;:&#92;&quot;[&#x27;Homepage, https://github.com/neuropoly/axondeepseg&#x27;, &#x27;Bug Tracker, https://github.com/axondeepseg/axondeepseg/issues&#x27;, &#x27;Documentation, https://github.com/axondeepseg/axondeepseg#README.md&#x27;, &#x27;Source Code, https://github.com/axondeepseg/axondeepseg&#x27;, &#x27;User Support, https://github.com/axondeepseg/axondeepseg/issues&#x27;]&#92;&quot;,&#92;&quot;contributions_readers_0_command&#92;&quot;:null,&#92;&quot;contributions_writers_0_command&#92;&quot;:null,&#92;&quot;contributions_widgets_0_command&#92;&quot;:&#92;&quot;AxonDeepSeg.ads_napari.make_qwidget&#92;&quot;,&#92;&quot;contributions_sample_data_0_command&#92;&quot;:null,&#92;&quot;contributions_readers_0_filename_patterns&#92;&quot;:null,&#92;&quot;contributions_writers_0_filename_extensions&#92;&quot;:null,&#92;&quot;contributions_writers_1_filename_extensions&#92;&quot;:null,&#92;&quot;home_pypi&#92;&quot;:&#92;&quot;https://pypi.org/project/AxonDeepSeg&#92;&quot;,&#92;&quot;home_github&#92;&quot;:null,&#92;&quot;home_other&#92;&quot;:null}]&quot;' data-total-rows='521' data-total-columns='28' data-max-columns='50' data-banner-text='&quot;&quot;' data-pagination='true' data-page-size='10' data-field-types='[[&quot;Unnamed: 0&quot;, [&quot;integer&quot;, &quot;int64&quot;]], [&quot;normalized_name&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;name&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;display_name&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;version&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;created_at&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;modified_at&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;author&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;package_metadata_author_email&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;license&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;home&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;package_metadata_home_page&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;summary&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;package_metadata_requires_python&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;package_metadata_requires_dist&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;package_metadata_description&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;package_metadata_classifier&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;package_metadata_project_url&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;contributions_readers_0_command&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;contributions_writers_0_command&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;contributions_widgets_0_command&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;contributions_sample_data_0_command&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;contributions_readers_0_filename_patterns&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;contributions_writers_0_filename_extensions&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;contributions_writers_1_filename_extensions&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;home_pypi&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;home_github&quot;, [&quot;string&quot;, &quot;object&quot;]], [&quot;home_other&quot;, [&quot;string&quot;, &quot;object&quot;]]]' data-show-filters='true' data-show-download='true' data-show-column-summaries='true' data-row-headers='[]' data-has-stable-row-id='false' data-lazy='false' data-preload='false'></marimo-table></marimo-ui-element>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "itqf",
      "code_hash": null,
      "outputs": [],
      "console": []
    }
  ]
}